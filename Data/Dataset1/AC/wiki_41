<doc id="29485" url="https://en.wikipedia.org/wiki?curid=29485" title="Skyscraper">
Skyscraper

A skyscraper is a continuously habitable high-rise building that has over 40 floors and is taller than approximately . Historically, the term first referred to buildings with 10 to 20 floors in the 1880s. The definition shifted with advancing construction technology during the 20th Century. Skyscrapers may host commercial offices or residential space, or both. For buildings above a height of , the term "supertall" can be used, while skyscrapers reaching beyond are classified as "megatall".

One common feature of skyscrapers is having a steel framework that supports curtain walls. These curtain walls either bear on the framework below or are suspended from the framework above, rather than resting on load-bearing walls of conventional construction. Some early skyscrapers have a steel frame that enables the construction of load-bearing walls taller than of those made of reinforced concrete.

Modern skyscrapers' walls are not load-bearing, and most skyscrapers are characterized by large surface areas of windows made possible by steel frames and curtain walls. However, skyscrapers can have curtain walls that mimic conventional walls with a small surface area of windows. Modern skyscrapers often have a tubular structure, and are designed to act like a hollow cylinder to resist wind, seismic, and other lateral loads. To appear more slender, allow less wind exposure, and transmit more daylight to the ground, many skyscrapers have a design with setbacks, which are sometimes also structurally required.

The term "skyscraper" was first applied to buildings of steel framed construction of at least 10 stories in the late 19th century, a result of public amazement at the tall buildings being built in major American cities like Chicago, New York City, Philadelphia, Detroit, and St. Louis. The first steel-frame skyscraper was the Home Insurance Building (originally 10 stories with a height of ) in Chicago, Illinois in 1885. Some point to Philadelphia's 10-story Jayne Building (1849–50) as a proto-skyscraper, or to New York's seven-floor Equitable Life Building (New York City), built in 1870, for its innovative use of a kind of skeletal frame, but such designation depends largely on what factors are chosen. Even the scholars making the argument find it to be purely academic.

The structural definition of the word "skyscraper" was refined later by architectural historians, based on engineering developments of the 1880s that had enabled construction of tall multi-story buildings. This definition was based on the steel skeleton—as opposed to constructions of load-bearing masonry, which passed their practical limit in 1891 with Chicago's Monadnock Building.

The Council on Tall Buildings and Urban Habitat defines skyscrapers as those buildings which reach or exceed in height. Others in the United States and Europe also draw the lower limit of a skyscraper at . 

The Emporis Standards Committee defines a high-rise building as "a multi-story structure between 35–100 meters tall, or a building of unknown height from 12–39 floors" and a skyscraper as "a multi-story building whose architectural height is at least ." Some structural engineers define a highrise as any vertical construction for which wind is a more significant load factor than earthquake or weight. Note that this criterion fits not only high-rises but some other tall structures, such as towers. 

The word "skyscraper" often carries a connotation of pride and achievement. The skyscraper, in name and social function, is a modern expression of the age-old symbol of the world center or "axis mundi": a pillar that connects earth to heaven and the four compass directions to one another.

The tallest building in ancient times was the Great Pyramid of Giza in ancient Egypt, built in the 26th century BC. It was not surpassed in height for thousands of years, the Lincoln Cathedral having exceeded it in 1311–1549, before its central spire collapsed. The latter in turn was not surpassed until the Washington Monument in 1884. However, being uninhabited, none of these structures actually comply with the modern definition of a skyscraper.

High-rise apartments flourished in classical antiquity. Ancient Roman insulae in imperial cities reached 10 and more stories. Beginning with Augustus (r. 30 BC-14 AD), several emperors attempted to establish limits of 20–25 m for multi-story buildings, but met with only limited success. Lower floors were typically occupied by shops or wealthy families, the upper rented to the lower classes. Surviving Oxyrhynchus Papyri indicate that seven-story buildings existed in provincial towns such as in 3rd century AD Hermopolis in Roman Egypt.

The skylines of many important medieval cities had large numbers of high-rise urban towers, built by the wealthy for defense and status. The residential Towers of 12th century Bologna numbered between 80 and 100 at a time, the tallest of which is the high Asinelli Tower. A Florentine law of 1251 decreed that all urban buildings be immediately reduced to less than 26 m. Even medium-sized towns of the era are known to have proliferations of towers, such as the 72 up to 51 m height in San Gimignano.

The medieval Egyptian city of Fustat housed many high-rise residential buildings, which Al-Muqaddasi in the 10th century described as resembling minarets. Nasir Khusraw in the early 11th century described some of them rising up to 14 stories, with roof gardens on the top floor complete with ox-drawn water wheels for irrigating them. Cairo in the 16th century had high-rise apartment buildings where the two lower floors were for commercial and storage purposes and the multiple stories above them were rented out to tenants. An early example of a city consisting entirely of high-rise housing is the 16th-century city of Shibam in Yemen. Shibam was made up of over 500 tower houses, each one rising 5 to 11 stories high, with each floor being an apartment occupied by a single family. The city was built in this way in order to protect it from Bedouin attacks. Shibam still has the tallest mudbrick buildings in the world, with many of them over high.

An early modern example of high-rise housing was in 17th-century Edinburgh, Scotland, where a defensive city wall defined the boundaries of the city. Due to the restricted land area available for development, the houses increased in height instead. Buildings of 11 stories were common, and there are records of buildings as high as 14 stories. Many of the stone-built structures can still be seen today in the old town of Edinburgh. The oldest iron framed building in the world, although only partially iron framed, is The Flaxmill (also locally known as the "Maltings"), in Shrewsbury, England. Built in 1797, it is seen as the "grandfather of skyscrapers", since its fireproof combination of cast iron columns and cast iron beams developed into the modern steel frame that made modern skyscrapers possible. In 2013 funding was confirmed to convert the derelict building into offices.

In 1857 Elisha Otis introduced the safety elevator, allowing convenient and safe passenger movement to upper floors. Another crucial development was the use of a steel frame instead of stone or brick, otherwise the walls on the lower floors on a tall building would be too thick to be practical. An early development in this area was Oriel Chambers in Liverpool, England. It was only five floors high. Further developments led to the world's first skyscraper, the ten-story Home Insurance Building in Chicago, built in 1884–1885. While its height is not considered very impressive today, it was at that time. The building of tall buildings in the 1880s gave the skyscraper its first architectural movement the Chicago School, which developed what has been called the Commercial Style.

The architect, Major William Le Baron Jenney, created a load-bearing structural frame. In this building, a steel frame supported the entire weight of the walls, instead of load-bearing walls carrying the weight of the building. This development led to the "Chicago skeleton" form of construction. In addition to the steel frame, the Home Insurance Building also utilized fireproofing, elevators, and electrical wiring, key elements in most skyscrapers today.

Burnham and Root's Rand McNally Building in Chicago, 1889, was the first all-steel framed skyscraper, while Louis Sullivan's Wainwright Building in St. Louis, Missouri, 1891, was the first steel-framed building with soaring vertical bands to emphasize the height of the building and is therefore considered to be the first early skyscraper.

Most early skyscrapers emerged in the land-strapped areas of Chicago and New York City toward the end of the 19th century. A land boom in Melbourne, Australia between 1888 and 1891 spurred the creation of a significant number of early skyscrapers, though none of these were steel reinforced and few remain today. Height limits and fire restrictions were later introduced. London builders soon found building heights limited due to a complaint from Queen Victoria, rules that continued to exist with few exceptions.

Concerns about aesthetics and fire safety had likewise hampered the development of skyscrapers across continental Europe for the first half of the twentieth century. Some notable exceptions are the tall 1898 Witte Huis "(White House)" in Rotterdam; the Royal Liver Building in Liverpool, completed in 1911 and high; the tall 1924 Marx House in Düsseldorf, Germany; the Kungstornen "(Kings' Towers)" in Stockholm, Sweden, which were built 1924–25, the Edificio Telefónica in Madrid, Spain, built in 1929; the Boerentoren in Antwerp, Belgium, built in 1932; the Prudential Building in Warsaw, Poland, built in 1934; and the Torre Piacentini in Genoa, Italy, built in 1940.

After an early competition between Chicago and New York City for the world's tallest building, New York took the lead by 1895 with the completion of the tall American Surety Building, leaving New York with the title of the world's tallest building for many years.

Modern skyscrapers are built with steel or reinforced concrete frameworks and curtain walls of glass or polished stone. They use mechanical equipment such as water pumps and elevators.

From the 1930s onwards, skyscrapers began to appear around the world—such as in Latin America (such as São Paulo, Rio de Janeiro, Buenos Aires, Santiago, Lima, Caracas, Bogotá, Panama City, Mexico City, Monterrey) and in Asia (Tokyo, Shanghai, Hong Kong, Manila, Jakarta, Singapore, Mumbai, Seoul, Kuala Lumpur, Taipei, Bangkok).

Immediately after World War II, the Soviet Union planned eight massive skyscrapers, seven of which were built by 1953, dubbed the "Seven Sisters of Moscow". The Building of Moscow State University was the tallest building in Europe in 1953–1990. Other skyscrapers in the style of Socialist Classicism were erected in East Germany (Frankfurter Tor), Poland (PKiN), Ukraine (Hotel Ukrayina), Latvia (Academy of Sciences) and other countries. The western countries of Europe also began to permit taller skyscrapers than before WW2, such as Madrid during the 1950s (Gran Vía). Finally, skyscrapers also began to be constructed in cities of Africa, the Middle East and Oceania (mainly Australia) from the late 1950s on.

Skyscraper projects after World War II typically rejected the classical designs of the early skyscrapers, instead embracing the uniform international style; many older skyscrapers were redesigned to suit contemporary tastes or even demolished—such as New York's Singer Building, once the world's tallest skyscraper.

German architect Ludwig Mies van der Rohe became one of the world's most renowned architects in the second half of the 20th century. He conceived of the glass façade skyscraper and, along with Norwegian Fred Severud, he designed the Seagram Building in 1958, a skyscraper that is often regarded as the pinnacle of the modernist high-rise architecture.

After the Great Depression skyscrapers construction suffered a hiatus for over thirty years due to economic problems. A revival occurred with structural innovations that transformed the industry, making it possible for people to live and work in "cities in the sky".

In the early 1960s structural engineer Fazlur Rahman Khan, considered the "father of tubular designs" for high-rises, discovered that the dominating rigid steel frame structure was not the only system apt for tall buildings, marking a new era of skyscraper construction in terms of multiple structural systems. His central innovation in skyscraper design and construction was the concept of the "tube" structural system, including the "framed tube", "trussed tube", and "bundled tube". His "tube concept", using all the exterior wall perimeter structure of a building to simulate a thin-walled tube, revolutionized tall building design. These systems allow greater economic efficiency, and also allow skyscrapers to take on various shapes, no longer needing to be rectangular and box-shaped. The first building to employ the tube structure was the Chestnut De-Witt apartment building, this building is considered to be a major development in modern architecture. These new designs opened an economic door for contractors, engineers, architects, and investors, providing vast amounts of real estate space on minimal plots of land. Over the next fifteen years, many towers were built by Fazlur Rahman Khan and the "Second Chicago School", including the hundred story John Hancock Center and the massive Willis Tower. Other pioneers of this field include Hal Iyengar and William LeMessurier.

Many buildings designed in the 70s lacked a particular style and recalled ornamentation from earlier buildings designed before the 50s. These design plans ignored the environment and loaded structures with decorative elements and extravagant finishes. This approach to design was opposed by Fazlur Khan and he considered the designs to be whimsical rather than rational. Moreover he considered the work to be a waste of precious natural resources. Khan's work promoted structures integrated with architecture and the least use of material resulting in the least carbon emission impact on the environment. The next era of skyscrapers will focus on the environment including performance of structures, types of material, construction practices, absolute minimal use of materials/natural resources, emboided energy within the structures, and more importantly, a holistically integrated building systems apporaoch.

Modern building practices regarding supertall structures have led to the study of "vanity height". Vanity height, according to the CTBUH, is the distance between the highest floor and its architectural top (excluding antennae, flagpole or other functional extensions). Vanity height first appeared in New York City skyscrapers as early as the 1920s and 1930s but supertall buildings have relied on such uninhabitable extensions for on average 30% of their height, raising potential definitional and sustainability issues. The current era of skyscrapers focuses on sustainability, its built and natural environments, including the performance of structures, types of materials, construction practices, absolute minimal use of materials and natural resources, energy within the structure, and a holistically integrated building systems approach. LEED is a current green building standard.

Architecturally, with the movements of Postmodernism, New Urbanism and New Classical Architecture, that established since the 1980s, a more classical approach came back to global skyscraper design, that remains popular today. Examples are the Wells Fargo Center, NBC Tower, Parkview Square, 30 Park Place, the Messeturm, the iconic Petronas Towers and Jin Mao Tower.

Other contemporary styles and movements in skyscraper design include organic, sustainable, neo-futurist, structuralist, high-tech, deconstructivist, blob, digital, streamline, novelty, critical regionalist, vernacular, Neo Art Deco and neo-historist, also known as revivalist.

3 September is the global commemorative day for skyscrapers, called "Skyscraper Day".

New York City developers competed among themselves, with successively taller buildings claiming the title of "world's tallest" in the 1920s and early 1930s, culminating with the completion of the Chrysler Building in 1930 and the Empire State Building in 1931, the world's tallest building for forty years. The first completed tall World Trade Center tower became the world's tallest building in 1972. However, it was overtaken by the Sears Tower (now Willis Tower) in Chicago within two years. The tall Sears Tower stood as the world's tallest building for 24 years, from 1974 until 1998, until it was edged out by Petronas Twin Towers in Kuala Lumpur, which held the title for six years.

The design and construction of skyscrapers involves creating safe, habitable spaces in very tall buildings. The buildings must support their weight, resist wind and earthquakes, and protect occupants from fire. Yet they must also be conveniently accessible, even on the upper floors, and provide utilities and a comfortable climate for the occupants. The problems posed in skyscraper design are considered among the most complex encountered given the balances required between economics, engineering, and construction management.

One common feature of skyscrapers is a steel framework from which curtain walls are suspended, rather than load-bearing walls of conventional construction. Most skyscrapers have a steel frame that enables them to be built taller than typical load-bearing walls of reinforced concrete. Skyscrapers usually have a particularly small surface area of what are conventionally thought of as walls. Because the walls are not load-bearing most skyscrapers are characterized by surface areas of windows made possible by the concept of steel frame and curtain wall. However, skyscrapers can also have curtain walls that mimick conventional walls and have a small surface area of windows.

The concept of a skyscraper is a product of the industrialized age, made possible by cheap fossil fuel derived energy and industrially refined raw materials such as steel and concrete. The construction of skyscrapers was enabled by steel frame construction that surpassed brick and mortar construction starting at the end of the 19th century and finally surpassing it in the 20th century together with reinforced concrete construction as the price of steel decreased and labour costs increased.

The steel frames become inefficient and uneconomic for supertall buildings as usable floor space is reduced for progressively larger supporting columns. Since about 1960, tubular designs have been used for high rises. This reduces the usage of material (more efficient in economic terms – Willis Tower uses a third less steel than the Empire State Building) yet allows greater height. It allows fewer interior columns, and so creates more usable floor space. It further enables buildings to take on various shapes.

Elevators are characteristic to skyscrapers. In 1852 Elisha Otis introduced the safety elevator, allowing convenient and safe passenger movement to upper floors. Another crucial development was the use of a steel frame instead of stone or brick, otherwise the walls on the lower floors on a tall building would be too thick to be practical. Today major manufacturers of elevators include Otis, ThyssenKrupp, Schindler, and KONE.

Advances in construction techniques have allowed skyscrapers to narrow in width, while increasing in height. Some of these new techniques include mass dampers to reduce vibrations and swaying, and gaps to allow air to pass through, reducing wind shear.

Good structural design is important in most building design, but particularly for skyscrapers since even a small chance of catastrophic failure is unacceptable given the high price. This presents a paradox to civil engineers: the only way to assure a lack of failure is to test for all modes of failure, in both the laboratory and the real world. But the only way to know of all modes of failure is to learn from previous failures. Thus, no engineer can be absolutely sure that a given structure will resist all loadings that could cause failure, but can only have large enough margins of safety such that a failure is acceptably unlikely. When buildings do fail, engineers question whether the failure was due to some lack of foresight or due to some unknowable factor.

The load a skyscraper experiences is largely from the force of the building material itself. In most building designs, the weight of the structure is much larger than the weight of the material that it will support beyond its own weight. In technical terms, the dead load, the load of the structure, is larger than the live load, the weight of things in the structure (people, furniture, vehicles, etc.). As such, the amount of structural material required within the lower levels of a skyscraper will be much larger than the material required within higher levels. This is not always visually apparent. The Empire State Building's setbacks are actually a result of the building code at the time (1916 Zoning Resolution), and were not structurally required. On the other hand, John Hancock Center's shape is uniquely the result of how it supports loads. Vertical supports can come in several types, among which the most common for skyscrapers can be categorized as steel frames, concrete cores, tube within tube design, and shear walls.

The wind loading on a skyscraper is also considerable. In fact, the lateral wind load imposed on super-tall structures is generally the governing factor in the structural design. Wind pressure increases with height, so for very tall buildings, the loads associated with wind are larger than dead or live loads.

Other vertical and horizontal loading factors come from varied, unpredictable sources, such as earthquakes.

By 1895, steel had replaced cast iron as skyscrapers' structural material. Its malleability allowed it to be formed into a variety of shapes, and it could be riveted, ensuring strong connections. The simplicity of a steel frame eliminated the inefficient part of a shear wall, the central portion, and consolidated support members in a much stronger fashion by allowing both horizontal and vertical supports throughout. Among steel's drawbacks is that as more material must be supported as height increases, the distance between supporting members must decrease, which in turn increases the amount of material that must be supported. This becomes inefficient and uneconomic for buildings above 40 stories tall as usable floor spaces are reduced for supporting column and due to more usage of steel.

A new structural system of framed tubes was developed in 1963. Fazlur Khan and J. Rankine defined the framed tube structure as "a three dimensional space structure composed of three, four, or possibly more frames, braced frames, or shear walls, joined at or near their edges to form a vertical tube-like structural system capable of resisting lateral forces in any direction by cantilevering from the foundation." Closely spaced interconnected exterior columns form the tube. Horizontal loads (primarily wind) are supported by the structure as a whole. Framed tubes allow fewer interior columns, and so create more usable floor space, and about half the exterior surface is available for windows. Where larger openings like garage doors are required, the tube frame must be interrupted, with transfer girders used to maintain structural integrity. Tube structures cut down costs, at the same time allowing buildings to reach greater heights. Concrete tube-frame construction was first used in the DeWitt-Chestnut Apartment Building, completed in Chicago in 1963, and soon after in the John Hancock Center and World Trade Center.

The tubular systems are fundamental to tall building design. Most buildings over 40-stories constructed since the 1960s now use a tube design derived from Khan's structural engineering principles, examples including the construction of the World Trade Center, Aon Center, Petronas Towers, Jin Mao Building, and most other supertall skyscrapers since the 1960s. The strong influence of tube structure design is also evident in the construction of the current tallest skyscraper, the Burj Khalifa.

Khan pioneered several other variations of the tube structure design. One of these was the concept of X-bracing, or the "trussed tube", first employed for the John Hancock Center. This concept reduced the lateral load on the building by transferring the load into the exterior columns. This allows for a reduced need for interior columns thus creating more floor space. This concept can be seen in the John Hancock Center, designed in 1965 and completed in 1969. One of the most famous buildings of the structural expressionist style, the skyscraper's distinctive X-bracing exterior is actually a hint that the structure's skin is indeed part of its 'tubular system'. This idea is one of the architectural techniques the building used to climb to record heights (the tubular system is essentially the spine that helps the building stand upright during wind and earthquake loads). This X-bracing allows for both higher performance from tall structures and the ability to open up the inside floorplan (and usable floor space) if the architect desires.

The John Hancock Center was far more efficient than earlier steel-frame structures. Where the Empire State Building (1931), required about 206 kilograms of steel per square metre and Chase Manhattan Bank Building (1961) required 275, the John Hancock Center required only 145. The trussed tube concept was applied to many later skyscrapers, including the Onterie Center, Citigroup Center and Bank of China Tower.

An important variation on the tube frame is the "bundled tube", which uses several interconnected tube frames. The Willis Tower in Chicago used this design, employing nine tubes of varying height to achieve its distinct appearance. The bundled tube structure meant that "buildings no longer need be boxlike in appearance: they could become sculpture."

The invention of the elevator was a precondition for the invention of skyscrapers, given that most people would not (or could not) climb more than a few flights of stairs at a time. The elevators in a skyscraper are not simply a necessary utility, like running water and electricity, but are in fact closely related to the design of the whole structure: a taller building requires more elevators to service the additional floors, but the elevator shafts consume valuable floor space. If the service core, which contains the elevator shafts, becomes too big, it can reduce the profitability of the building. Architects must therefore balance the value gained by adding height against the value lost to the expanding service core.

Many tall buildings use elevators in a non-standard configuration to reduce their footprint. Buildings such as the former World Trade Center Towers and Chicago's John Hancock Center use sky lobbies, where express elevators take passengers to upper floors which serve as the base for local elevators. This allows architects and engineers to place elevator shafts on top of each other, saving space. Sky lobbies and express elevators take up a significant amount of space, however, and add to the amount of time spent commuting between floors.

Other buildings, such as the Petronas Towers, use double-deck elevators, allowing more people to fit in a single elevator, and reaching two floors at every stop. It is possible to use even more than two levels on an elevator, although this has never been done. The main problem with double-deck elevators is that they cause everyone in the elevator to stop when only people on one level need to get off at a given floor.

Buildings with sky lobbies include the World Trade Center, Petronas Twin Towers and Taipei 101. The 44th-floor sky lobby of the John Hancock Center also featured the first high-rise indoor swimming pool, which remains the highest in America.

Skyscrapers are usually situated in city centers where the price of land is high. Constructing a skyscraper becomes justified if the price of land is so high that it makes economic sense to build upwards as to minimize the cost of the land per the total floor area of a building. Thus the construction of skyscrapers is dictated by economics and results in skyscrapers in a certain part of a large city unless a building code restricts the height of buildings.

Skyscrapers are rarely seen in small cities and they are characteristic of large cities, because of the critical importance of high land prices for the construction of skyscrapers. Usually only office, commercial and hotel users can afford the rents in the city center and thus most tenants of skyscrapers are of these classes. Some skyscrapers have been built in areas where the bedrock is near surface, because this makes constructing the foundation cheaper, for example this is the case in Midtown Manhattan and Lower Manhattan, in New York City, but not in-between these two parts of the city.

Today, skyscrapers are an increasingly common sight where land is expensive, as in the centers of big cities, because they provide such a high ratio of rentable floor space per unit area of land.

formula_1

One problem with skyscrapers is car parking. In the largest cities most people commute via public transport, but for smaller cities a lot of parking spaces are needed. Multi-storey car parks are impractical to build very tall, so a lot of land area is needed.

There may be a correlation between skyscraper construction and great income inequality but this has not been conclusively proven.

The amount of steel, concrete, and glass needed to construct a single skyscraper is large, and these materials represent a great deal of embodied energy. Skyscrapers are thus energy intensive buildings, but skyscrapers have a long lifespan, for example the Empire State Building in New York City, United States completed in 1931 and is still in active use.

Skyscrapers have considerable mass, which means that they must be built on a sturdier foundation than would be required for shorter, lighter buildings. Building materials must also be lifted to the top of a skyscraper during construction, requiring more energy than would be necessary at lower heights. Furthermore, a skyscraper consumes a lot of electricity because potable and non-potable water has to be pumped to the highest occupied floors, skyscrapers are usually designed to be mechanically ventilated, elevators are generally used instead of stairs, and natural lighting cannot be utilized in rooms far from the windows and the windowless spaces such as elevators, bathrooms and stairwells.

Skyscrapers can be artificially lit and the energy requirements can be covered by renewable energy or other electricity generation with low greenhouse gas emissions. Heating and cooling of skyscrapers can be efficient, because of centralized HVAC systems, heat radiation blocking windows and small surface area of the building. There is Leadership in Energy and Environmental Design (LEED) certification for skyscrapers. For example, the Empire State Building received a gold Leadership in Energy and Environmental Design rating in September 2011 and the Empire State Building is the tallest LEED certified building in the United States, proving that skyscrapers can be environmentally friendly. Also the 30 St Mary Axe in London, the United Kingdom is an environmentally friendly skyscraper.

In the lower levels of a skyscraper a larger percentage of the building cross section must be devoted to the building structure and services than is required for lower buildings:

In low-rise structures, the support rooms (chillers, transformers, boilers, pumps and air handling units) can be put in basements or roof space—areas which have low rental value. There is, however, a limit to how far this plant can be located from the area it serves. The farther away it is the larger the risers for ducts and pipes from this plant to the floors they serve and the more floor area these risers take. In practice this means that in highrise buildings this plant is located on 'plant levels' at intervals up the building.

At the beginning of the 20th century, New York City was a center for the Beaux-Arts architectural movement, attracting the talents of such great architects as Stanford White and Carrere and Hastings. As better construction and engineering technology became available as the century progressed, New York City and Chicago became the focal point of the competition for the tallest building in the world. Each city's striking skyline has been composed of numerous and varied skyscrapers, many of which are icons of 20th-century architecture:

Momentum in setting records passed from the United States to other nations with the opening of the Petronas Twin Towers in Kuala Lumpur, Malaysia, in 1998. The record for the world's tallest building has remained in Asia since the opening of Taipei 101 in Taipei, Taiwan, in 2004. A number of architectural records, including those of the world's tallest building and tallest free-standing structure, moved to the Middle East with the opening of the Burj Khalifa in Dubai, United Arab Emirates.

This geographical transition is accompanied by a change in approach to skyscraper design. For much of the twentieth century large buildings took the form of simple geometrical shapes. This reflected the "international style" or modernist philosophy shaped by Bauhaus architects early in the century. The last of these, the Willis Tower and World Trade Center towers in New York, erected in the 1970s, reflect the philosophy. Tastes shifted in the decade which followed, and new skyscrapers began to exhibit postmodernist influences. This approach to design avails itself of historical elements, often adapted and re-interpreted, in creating technologically modern structures. The Petronas Twin Towers recall Asian pagoda architecture and Islamic geometric principles. Taipei 101 likewise reflects the pagoda tradition as it incorporates ancient motifs such as the ruyi symbol. The Burj Khalifa draws inspiration from traditional Islamic art. Architects in recent years have sought to create structures that would not appear equally at home if set in any part of the world, but that reflect the culture thriving in the spot where they stand.

The following list measures height of the roof. The more common gauge is the "highest architectural detail"; such ranking would have included Petronas Towers, built in 1996.

Many skyscrapers were never built due to financial problems, politics and culture. The Chicago Spire was to be the tallest building in the Western Hemisphere, but it was on hold due to the global financial crisis of 2008. One year later, the project was cancelled.

Proposals for such structures have been put forward, including the Burj Mubarak Al Kabir in Kuwait and Azerbaijan Tower in Baku. Kilometer-plus structures present architectural challenges that may eventually place them in a new architectural category. The first building under construction and planned to be over one kilometre tall is the Jeddah Tower.

Several wooden skyscraper designs have been designed and built. A 14-story housing project in Bergen, Norway known as 'Treet' or 'The Tree' became the world's tallest wooden apartment block when it was completed in late 2015. The Tree's record was eclipsed by Brock Commons, an 18-story wooden dormitory at the University of British Columbia in Canada, when it was completed in September 2016. 

A 40-story residential building 'Trätoppen' has been proposed by architect Anders Berensson to be built in Stockholm, Sweden. Trätoppen would be the tallest building in Stockholm, though there are no immediate plans to begin construction. The tallest currently-planned wooden skyscraper is the 70-story W350 Project in Tokyo, to be built by the Japanese wood products company Sumitomo Forestry Co. to celebrate its 350th anniversary in 2041. An 80-story wooden skyscraper, the River Beech Tower, has been proposed by a team including architects Perkins + Will and the University of Cambridge. The River Beech Tower, on the banks of the Chicago River in Chicago, Illinois, would be 348 feet shorter than the W350 Project despite having 10 more stories. 

Wooden skyscrapers are estimated to be around a quarter of the weight of an equivalent reinforced-concrete structure as well as reducing the building carbon footprint by 60–75%. Buildings have been designed using cross-laminated timber (CLT) which gives a higher rigidity and strength to wooden structures. CLT panels are prefabricated and can therefore speed up building time.





</doc>
<doc id="29486" url="https://en.wikipedia.org/wiki?curid=29486" title="Sagas of Icelanders">
Sagas of Icelanders

The Sagas of Icelanders (), also known as family sagas, are prose narratives mostly based on historical events that mostly took place in Iceland in the 9th, 10th, and early 11th centuries, during the so-called Saga Age. They are the best-known specimens of Icelandic literature.

They are focused on history, especially genealogical and family history. They reflect the struggle and conflict that arose within the societies of the early generations of Icelandic settlers.

Eventually many of Icelandic sagas were recorded, mostly in the thirteenth and fourteenth centuries. The 'authors', or rather recorders of these sagas are unknown. One saga, "Egils saga", is believed by some scholars to have been written by Snorri Sturluson, a descendant of the saga's hero, but this remains uncertain. The standard modern edition of Icelandic sagas is known as Íslenzk fornrit.


The Saga of "Gaukur á Stöng" is believed to have existed but is now considered lost. The saga set in the anthology of sagas known as Möðruvallabók between "Njáls saga" and "Egils saga Skalla-Grímssonar" tells of a man named Gaukur Trandilsson who lived in the 10th century. Gaukur is mentioned in chapter 26 of Njáls saga. Icelandic professor and poet Jón Helgason managed to decipher a line that read "Let Trandilsson's story be written here. I am told that [Mr.] Grim knows it." However, the story was never put to paper. The Grim mentioned in the manuscript is believed to have been Grímur Þorsteinsson, knight and governor ().

Gaukur is reported to have been an exceptionally brave and gentle man. He was the foster brother of Ásgrimur. However, it is said that he had a falling out with his foster brother, who ultimately killed him.

Gaukur must have been a well-known figure in Icelandic folklore as he is mentioned in not only Njáls Saga but also the Íslendigadrápa, a poem about the Icelandic heroes. He is also mentioned on a tomb in the Orkney Islands, where a runic inscription translates to "These runes were carved by the man who was the most knowledgeable of runes in the west of the sea, using the axe that belonged to Gaukur Trandilsson in the south of the land". The south of the land refers to Iceland.

Icelanders produced a high volume of literature relative to the size of the population. Historians have proposed various theories for the high volume of saga writing:





</doc>
<doc id="29489" url="https://en.wikipedia.org/wiki?curid=29489" title="Staind">
Staind

Staind ( ) is an American rock band formed in 1995. The original lineup consisted of lead vocalist and rhythm guitarist Aaron Lewis, lead guitarist Mike Mushok, bassist and backing vocalist Johnny April, and drummer Jon Wysocki. The lineup has been stable outside of Wysocki's departure in 2011, who was replaced by Sal Giancarelli. The band has recorded seven studio albums: "Tormented" (1996), "Dysfunction" (1999), "Break the Cycle" (2001), "14 Shades of Grey" (2003), "Chapter V" (2005), "The Illusion of Progress" (2008), and "Staind" (2011). The band's activity became more sporadic after their self-titled release; with Lewis pursuing a solo country music career and Mushok subsequently joining the band Saint Asonia, but the band continued to tour off and on in the coming years. As of 2016, Lewis had reiterated that the band has not broken up, and will possibly create another album, but that his current focus is his solo career. The band's most recently performed live in 2017, and as of 2018, is in a hiatus. The band has sold over 15 million records worldwide. Many of the band's singles have reached high positions on US rock and all-format charts as well, including "It's Been Awhile", "Fade", "Price to Play", "So Far Away", and "Right Here".

In 1993, vocalist Aaron Lewis and guitarist Mike Mushok met at a Christmas party in Springfield, Massachusetts. Mushok introduced drummer Jon Wysocki while Lewis brought in bassist Johnny April to form the band in 1995. Their first public performance was in February 1995, playing in a heavy, dark and introspective style of metal. Extensive touring in the Northeast helped Staind acquire a regional following over the next few years.

The band started covering Korn, Rage Against the Machine, Pearl Jam, Tool, and Alice in Chains, among others, and played at local clubs (most commonly playing at Club Infinity) for a year and a half. Staind self-released their debut album, "Tormented", in November 1996, citing Tool, Faith No More, and Pantera as their influences. In October 1997, Staind acquired a concert slot through Aaron's cousin Justin Cantor with Limp Bizkit. Just prior to the performance, Limp Bizkit frontman Fred Durst was appalled by Staind's grotesque album cover and unsuccessfully attempted to remove them from the bill. Durst thought that Staind were Theistic Satanists. After being persuaded to let Staind perform, Durst was impressed with their performance. After hearing Staind perform, Durst was so impressed that he signed them to Flip Records by February 1998.

On April 13, 1999, Staind released its major label debut "Dysfunction" on Flip Records. The album, which was co-produced by Fred Durst and Terry Date (who also produced acts like Soundgarden, Deftones, and Pantera), received comparisons to alternative metal giants Tool and Korn. In particular, Aaron Lewis was lauded for his vocals, which were likened to those of Pearl Jam's Eddie Vedder.

The album achieved slow success, reaching the No. 1 spot on Billboard's Heatseeker Charts almost six months after its debut. In the same week, the album jumped to No. 74 on Billboard's Top 200 Album Charts. The nine-track LP (with one hidden track, "Excess Baggage") produced three singles, "Just Go", "Mudshovel", and "Home". "Mudshovel" and "Home" both received radio play, cracking the Top 20 of Billboard's Modern Rock and Mainstream Rock charts. In promotion of "Dysfunction", Staind went on several tours, including the Family Values Tour with acts like Limp Bizkit and The Crystal Method, as well as opening for Sevendust's headlining tour.

Staind toured with Limp Bizkit for the Family Values Tour during the fall of 1999, where Aaron Lewis performed an early version of "Outside" with Fred Durst at the Mississippi Coast Coliseum. Staind released their third studio album "Break the Cycle" on May 22, 2001. Propelled by the success of their first single "It's Been Awhile", the album debuted at No. 1 on Billboard's Top 200 Album charts, selling 716,000 albums in its first week. The album's first week sales were the second highest of any album that year.

The album saw the band retaining their previous nu metal sound from their previous album. Despite the album having a lot of nu metal sounds, the album saw the band going further into their post-grunge sound which is evident in the smash hit song "It's Been Awhile" and the song led critics to compare the band to several of other post-grunge bands at the time. "It's Been Awhile" (which hit the Billboard Top 10), "Fade", "Outside", "For You", and the acoustic ballad "Epiphany". "It's Been Awhile" spent a total of 16 and 14 weeks on top of the modern and mainstream rock charts, respectively, making it one of the highest joint numbers of all time. In 2001, "Break the Cycle" sold four million copies worldwide, making it one of the best selling albums that year. "Break the Cycle" would go on to sell seven million copies worldwide, making this Staind's best selling album.

In early 2003, Staind embarked on a worldwide tour to promote the release of the follow-up to "Break the Cycle", "14 Shades of Grey", which sold two million albums and debuted at number 1 on the Billboard 200. The album saw a departure from their previous nu metal sound and the album mostly contain a lighter and more melodic post-grunge sound. The album provided two mainstream hits: the lead single "Price to Play" and "So Far Away", which spent 14 weeks on top of the rock chart. In addition, two other singles were released; "How About You" and "Zoe Jane". The band's appearance at Reading Festival during the 2003 tour had another impromptu acoustic set, this time due to equipment failure. The singles "So Far Away" and "Price to Play" came with two unreleased tracks, "Novocaine" and "Let It Out", which were released for the special edition of the group's "Chapter V", which came out in late 2005. In 2003, Staind unsuccessfully sued their logo designer Jon Stainbrook in New York Federal Court for attempting to re-use the logo he had sold to the band. They re-opened the case in mid-2005.

Staind's fifth album, titled "Chapter V", was released on August 9, 2005, and became their third consecutive number one. The album opened to sales of 185,000 and has since been certified platinum in the U.S. The first single "Right Here" was the biggest success from the album, garnering much mainstream radio play and peaking at number 1 on the mainstream rock chart. "Falling" (the video of which does not feature the band members at all) was released as the second single, followed by "Everything Changes" and "King of All Excuses". Staind went on the road when the album came out, doing live shows and promoting it for a full year, including participating in the Fall Brawl tour with P.O.D., Taproot and Flyleaf, a solo tour across Europe and a mini-promotional tour in Australia for the first time. Other live shows included a cover of Pantera's "This Love", a tribute to Dimebag Darrell. Staind appeared on "The Howard Stern Show" on August 10, 2005, to promote "Chapter V". They performed acoustic renditions of the single "Right Here" and Beetlejuice's song "This is Beetle". In early November 2005, Staind released the limited edition 2-CD/DVD set of "Chapter V". On September 6, 2006, Staind performed an acoustic show in the Hiro Ballroom, New York City that was recorded for their singles collection. They played sixteen songs including three covers: Tool's "Sober", Pink Floyd's "Comfortably Numb" and Alice in Chains's "Nutshell".

The collection "" was released on November 14, 2006. It included all the band's singles, the three covers performed at the New York show and a remastered version of "Come Again", from Staind's first independent release "Tormented".

On August 19, 2008, Staind released their sixth album, "The Illusion of Progress". Prior to the album's release, the track "This Is It" was available for download on the iTunes Store, as well as for "Rock Band". The album debuted at No. 3 on US Billboard 200, No. 1 on the Top Modern Rock/Alternative Albums Chart, No. 1 on the Top Digital Albums Chart, and also No. 1 on the Top Internet Albums Chart, with first week sales of 91,800 units. The first single on the album, "Believe", topped Billboard's Top 10 Modern Rock Tracks on September 5, 2008. The band also supported Nickelback on their 2008 European tour. The second single was "All I Want", and came out on November 24. The single also became Staind's 13th top 20 hit on the rock charts. In Europe the second single was "The Way I Am", released on January 26, 2009. The final single released from the album, "This Is It", was sent to radio stations across the country on May 4, 2009. The single was also included on the successful "" released in late June 2009. Staind embarked on a fall tour with the newly reunited Creed.

In March 2010, Aaron Lewis stated the band would start working on their seventh studio album by the end of the year. Lewis had finished recording his country-tinged solo EP and had started a nonprofit organization to reopen his daughter's elementary school in Worthington, Massachusetts. Guitarist Mike Mushok stated in a question and answer session with fans that the band was looking to make a heavy record, but still "explore some of the things we did on the last record and take them somewhere new for us". In a webisode posted on the band's website, Lewis stated that eight songs were written and that "every one of them is as heavy or heavier than the heaviest song on the last record".

In December 2010, Staind posted three webisodes from the studio, which featured the band members discussing the writing and recording process of their new album. They announced that as of April 20, the band had completed the recording of their untitled seventh album and would release it later that year.

On May 20, 2011, Staind announced that original drummer Jon Wysocki had left the band. Drummer Will Hunt filled in for a few dates, while Wysocki's drum tech Sal Giancarelli filled in for the rest of the tour. Three days later, it was reported that Staind's new album was originally called "Seven", but was renamed "Staind". It was released on September 13, 2011. The first single "Not Again" was released to active radio stations on July 18. The song "The Bottom" appeared on the "" soundtrack. On June 30, Staind released a song called "Eyes Wide Open" from their new record. "Eyes Wide Open" would later be released on November 29 as the album's second single. On July 12, Staind released the first single "Not Again" through YouTube and was officially released/available on July 26.

In November 2011, the band announced through their YouTube page that Sal Giancarelli was now an official member. The band continued to tour heavily into 2012; embarking on an April and May touring with Godsmack and Halestorm, and the Uproar Festival in August and September with Shinedown and a number of other artists.

It was announced in July 2012 that the band was to be taking a hiatus. In an interview with Billboard Aaron Lewis stated that "We're not breaking up. We're not gonna stop making music. We're just going to take a little hiatus that really hasn't ever been taken in our career. We put out seven records in 14 years. We've been pretty busy." Lewis also had plans to release his first solo album "The Road". During this time, Mike Mushok auditioned, and was selected, to play guitar for former Metallica bassist Jason Newsted's new band Newsted. He featured on their debut album "Heavy Metal Music".

Staind played their first show in two years at the Welcome To Rockville Festival on April 27, 2014. They also played the Carolina Rebellion and Rock on the Range festivals in May 2014.

In late 2014, the band went on another hiatus. Aaron Lewis continued to play solo shows and work on his next solo album. He also confirmed that the hiatus would last "for a while". Mike Mushok teamed up with former Three Days Grace singer Adam Gontier, former Finger Eleven drummer Rich Beddoe and Eye Empire bassist Corey Lowery to form Saint Asonia.

When asked in an August 2016 interview about Staind's future, Mushok stated that the hiatus could possibly be the end of the band. He explained, "I remember '09, we stopped touring, and we did a record after that. We did the self-titled "Staind" record, which we did a little touring on. It was one of my favorite Staind records we had done. Aaron, I know, has another country record coming out in September. So...you know, we say we're gonna do something else, but there's no real plan for it right now. I know he's pursuing. And I know we're writing another record.". In addition, Aaron Lewis indicated that he is focused on country music while noting "Do I think there's room somewhere down the road for Staind to play shows in the summertime, radio festivals and stuff like that? Sure. Do I think I have another one of those Staind records in me? Of course I do. All I have to do is live."

On August 4, 2017, the band performed for the first time since November 2014 for an acoustic performance at Aaron Lewis' 6th annual charity golf tournament and concert when bassist Johnny April & drummer Sal Giancarelli joined Aaron Lewis & Mike Mushok to perform "Outside", "Something to Remind You", and "It's Been Awhile". Three days later, Lewis announced that Staind would never tour extensively again, stating:

Topics of their lyrics cover issues of depression, relationships, death, addictions, finding one's self, betrayal and even Lewis' thoughts about becoming a father in the song "Zoe Jane" from "14 Shades of Grey", as well as reflecting on his upbringing in the song "The Corner" from "The Illusion of Progress". Also from "14 Shades of Grey", the track titled "Layne" was written about Alice in Chains frontman Layne Staley in response to his death in 2002. The song is also about Staley's legacy and the effect his music had on the members of Staind, especially Aaron Lewis. Staind has been categorized as nu metal, alternative metal, heavy metal, hard rock and post-grunge.

In 2001, "Rolling Stone" outlined the band's relationship to the nu metal label:
Members of Staind have cited Pantera, Kiss, Van Halen, Led Zeppelin, Whitesnake, the Beatles, Alice in Chains, Black Sabbath, Pearl Jam, Nirvana, Stone Temple Pilots, Helmet, James Taylor, Korn, Crosby, Stills & Nash as influences.


Touring musicians

Timeline

Studio albums



</doc>
<doc id="29490" url="https://en.wikipedia.org/wiki?curid=29490" title="Saddam Hussein">
Saddam Hussein

Saddam Hussein Abd al-Majid al-Tikriti (; Arabic: ""; 28 April 1937 – 30 December 2006) was President of Iraq from 16 July 1979 until 9 April 2003. A leading member of the revolutionary Arab Socialist Ba'ath Party, and later, the Baghdad-based Ba'ath Party and its regional organization the Iraqi Ba'ath Party—which espoused Ba'athism, a mix of Arab nationalism and socialism—Saddam played a key role in the 1968 coup (later referred to as the 17 July Revolution) that brought the party to power in Iraq.

As vice president under the ailing General Ahmed Hassan al-Bakr, and at a time when many groups were considered capable of overthrowing the government, Saddam created security forces through which he tightly controlled conflicts between the government and the armed forces. In the early 1970s, Saddam nationalized oil and foreign banks leaving the system eventually insolvent mostly due to the Iran–Iraq War, the Gulf War, and UN sanctions. Through the 1970s, Saddam cemented his authority over the apparatus of government as oil money helped Iraq's economy to grow at a rapid pace. Positions of power in the country were mostly filled with Sunni Arabs, a minority that made up only a fifth of the population.

Saddam formally rose to power in 1979, although he had already been the "de facto" head of Iraq for several years. He suppressed several movements, particularly Shi'a and Kurdish movements, which sought to overthrow the government or gain independence, and maintained power during the Iran–Iraq War and the Gulf War. Whereas some in the Arab world lauded Saddam for opposing the United States and attacking Israel, he was widely condemned for the brutality of his dictatorship. The total number of Iraqis killed by the security services of Saddam's government in various purges and genocides is conservatively estimated to be 250,000. Saddam's invasions of Iran and Kuwait also resulted in hundreds of thousands of deaths. He acquired the title "Butcher of Baghdad".

In 2003, a coalition led by the United States invaded Iraq to depose Saddam, in which United States President George W. Bush and British Prime Minister Tony Blair falsely accused him of possessing weapons of mass destruction and having ties to al-Qaeda. Saddam's Ba'ath party was disbanded and elections were held. Following his capture on 13 December 2003, the trial of Saddam took place under the Iraqi Interim Government. On 5 November 2006, Saddam was convicted by an Iraqi court of crimes against humanity related to the 1982 killing of 148 Iraqi Shi'a, and sentenced to death by hanging. He was executed on 30 December 2006.

Saddam Hussein Abd al-Majid al-Tikriti was born in the town of Al-Awja, 13 km (8 mi) from the Iraqi town of Tikrit, to a family of shepherds from the al-Begat clan group, a sub-group of the Al-Bu Nasir (البو ناصر) tribe. His mother, Subha Tulfah al-Mussallat, named her newborn son "Saddam", which in Arabic means "One who confronts". He is always referred to by this personal name, which may be followed by the patronymic and other elements. He never knew his father, Hussein 'Abd al-Majid, who disappeared six months before Saddam was born. Shortly afterward, Saddam's 13-year-old brother died of cancer. The infant Saddam was sent to the family of his maternal uncle Khairallah Talfah until he was three.

His mother remarried, and Saddam gained three half-brothers through this marriage. His stepfather, Ibrahim al-Hassan, treated Saddam harshly after his return. At about age 10, Saddam fled the family and returned to live in Baghdad with his uncle Kharaillah Talfah. Talfah, the father of Saddam's future wife, was a devout Sunni Muslim and a veteran of the 1941 Anglo-Iraqi War between Iraqi nationalists and the United Kingdom, which remained a major colonial power in the region.

Later in his life relatives from his native Tikrit became some of his closest advisors and supporters. Under the guidance of his uncle he attended a nationalistic high school in Baghdad. After secondary school Saddam studied at an Iraqi law school for three years, dropping out in 1957 at the age of 20 to join the revolutionary pan-Arab Ba'ath Party, of which his uncle was a supporter. During this time, Saddam apparently supported himself as a secondary school teacher.
Revolutionary sentiment was characteristic of the era in Iraq and throughout the Middle East. In Iraq progressives and socialists assailed traditional political elites (colonial era bureaucrats and landowners, wealthy merchants and tribal chiefs, and monarchists). Moreover, the pan-Arab nationalism of Gamal Abdel Nasser in Egypt profoundly influenced young Ba'athists like Saddam. The rise of Nasser foreshadowed a wave of revolutions throughout the Middle East in the 1950s and 1960s, with the collapse of the monarchies of Iraq, Egypt, and Libya. Nasser inspired nationalists throughout the Middle East by fighting the British and the French during the Suez Crisis of 1956, modernizing Egypt, and uniting the Arab world politically.

In 1958, a year after Saddam had joined the Ba'ath party, army officers led by General Abd al-Karim Qasim overthrew Faisal II of Iraq in the 14 July Revolution.

Of the 16 members of Qasim's cabinet, 12 were Ba'ath Party members; however, the party turned against Qasim due to his refusal to join Gamal Abdel Nasser's United Arab Republic. To strengthen his own position within the government, Qasim created an alliance with the Iraqi Communist Party, which was opposed to any notion of pan-Arabism. Later that year, the Ba'ath Party leadership was planning to assassinate Qasim. Saddam was a leading member of the operation. At the time, the Ba'ath Party was more of an ideological experiment than a strong anti-government fighting machine. The majority of its members were either educated professionals or students, and Saddam fit the bill. The choice of Saddam was, according to historian Con Coughlin, "hardly surprising". The idea of assassinating Qasim may have been Nasser's, and there is speculation that some of those who participated in the operation received training in Damascus, which was then part of the UAR. However, "no evidence has ever been produced to implicate Nasser directly in the plot." The assassination attempt was partially conceived as revenge for communist massacres that killed hundreds of Iraqi nationalists in 1959 and which Qasim's government allowed to take place in the aftermath of the 1959 Mosul uprising.

The assassins planned to ambush Qasim at Al-Rashid Street on 7 October 1959: one man was to kill those sitting at the back of the car, the rest killing those in front. During the ambush it is claimed that Saddam began shooting prematurely, which disorganised the whole operation. Qasim's chauffeur was killed, and Qasim was hit in the arm and shoulder. The assassins believed they had killed him and quickly retreated to their headquarters, but Qasim survived. At the time of the attack the Ba'ath Party had fewer than 1,000 members. Saddam's role in the failed assassination became a crucial part of his public image for decades. Kanan Makiya recounts:
The man and the myth merge in this episode. His biography—and Iraqi television, which stages the story ad nasueam—tells of his familiarity with guns from the age of ten; his fearlessness and loyalty to the party during the 1959 operation; his bravery in saving his comrades by commandeering a car at gunpoint; the bullet that was gouged out of his flesh under his direction in hiding; the iron discipline that led him to draw a gun on weaker comrades who would have dropped off a seriously wounded member of the hit team at a hospital; the calculating shrewdness that helped him save himself minutes before the police broke in leaving his wounded comrades behind; and finally the long trek of a wounded man from house to house, city to town, across the desert to refuge in Syria.

Some of the plotters (including Saddam) quickly managed to leave the country for Syria, the spiritual home of Ba'athist ideology. There Saddam was given full-membership in the party by Michel Aflaq. Some members of the operation were arrested and taken into custody by the Iraqi government. At the show trial, six of the defendants were given death sentences; for unknown reasons the sentences were not carried out. Aflaq, the leader of the Ba'athist movement, organised the expulsion of leading Iraqi Ba'athist members, such as Fuad al-Rikabi, on the grounds that the party should not have initiated the attempt on Qasim's life. At the same time, Aflaq secured seats in the Iraqi Ba'ath leadership for his supporters, one of them being Saddam. Saddam moved from Syria to Egypt itself in February 1960, and he continued to live there until 1963, graduating from high school in 1961 and unsuccessfully pursuing a law degree.

Army officers with ties to the Ba'ath Party overthrew Qasim in the Ramadan Revolution coup of February 1963. Ba'athist leaders were appointed to the cabinet and Abdul Salam Arif became president. Arif dismissed and arrested the Ba'athist leaders later that year in the November 1963 Iraqi coup d'état. Being exiled in Egypt at the time, Saddam played no role in the 1963 coup or the brutal anti-communist purge that followed; although he returned to Iraq after the coup, Saddam remained "on the fringes of the newly installed Ba'thi administration and [had] to content himself with the minor position of a member of the Party's central bureau for peasants," in the words of Efraim Karsh and Inari Rautsi Unlike during the Qasim years, Saddam remained in Iraq following Arif's anti-Ba'athist purge in November 1963, and became involved in planning to assassinate Arif. In marked contrast to Qasim, Saddam knew that he faced no death penalty from Arif's government and knowingly accepted the risk of being arrested rather than fleeing to Syria again. Saddam was arrested in October 1964 and served approximately two years in prison before escaping in 1966. In 1966, Ahmed Hassan al-Bakr appointed him Deputy Secretary of the Regional Command. Saddam, who would prove to be a skilled organiser, revitalised the party. He was elected to the Regional Command, as the story goes, with help from Michel Aflaq—the founder of Ba'athist thought. In September 1966, Saddam initiated an extraordinary challenge to Syrian domination of the Ba'ath Party in response to the Marxist takeover of the Syrian Ba'ath earlier that year, resulting in the Party's formalized split into two separate factions. Saddam then created a Ba'athist security service, which he alone controlled.

In July 1968, Saddam participated in a bloodless coup led by Ahmed Hassan al-Bakr that overthrew Abdul Rahman Arif, Salam Arif's brother and successor. While Saddam's role in the coup was not hugely significant (except in the official account), Saddam planned and carried out the subsequent purge of the non-Ba'athist faction led by Prime Minister Abd ar-Razzaq an-Naif, whose support had been essential to the coup's success. According to a semi-official biography, Saddam personally led Naif at gunpoint to the plane that escorted him out of Iraq. Arif was given refuge in London and then Istanbul. Al-Bakr was named president and Saddam was named his deputy, and deputy chairman of the Ba'athist Revolutionary Command Council. According to biographers, Saddam never forgot the tensions within the first Ba'athist government, which formed the basis for his measures to promote Ba'ath party unity as well as his resolve to maintain power and programs to ensure social stability. Although Saddam was al-Bakr's deputy, he was a strong behind-the-scenes party politician. Al-Bakr was the older and more prestigious of the two, but by 1969 Saddam clearly had become the moving force behind the party.

In the late 1960s and early 1970s, as vice chairman of the Revolutionary Command Council, formally al-Bakr's second-in-command, Saddam built a reputation as a progressive, effective politician. At this time, Saddam moved up the ranks in the new government by aiding attempts to strengthen and unify the Ba'ath party and taking a leading role in addressing the country's major domestic problems and expanding the party's following.

After the Ba'athists took power in 1968, Saddam focused on attaining stability in a nation riddled with profound tensions. Long before Saddam, Iraq had been split along social, ethnic, religious, and economic fault lines: Sunni versus Shi'ite, Arab versus Kurd, tribal chief versus urban merchant, nomad versus peasant. The desire for stable rule in a country rife with factionalism led Saddam to pursue both massive repression and the improvement of living standards.

Saddam actively fostered the modernization of the Iraqi economy along with the creation of a strong security apparatus to prevent coups within the power structure and insurrections apart from it. Ever concerned with broadening his base of support among the diverse elements of Iraqi society and mobilizing mass support, he closely followed the administration of state welfare and development programs.

At the center of this strategy was Iraq's oil. On 1 June 1972, Saddam oversaw the seizure of international oil interests, which, at the time, dominated the country's oil sector. A year later, world oil prices rose dramatically as a result of the 1973 energy crisis, and skyrocketing revenues enabled Saddam to expand his agenda.
Within just a few years, Iraq was providing social services that were unprecedented among Middle Eastern countries. Saddam established and controlled the "National Campaign for the Eradication of Illiteracy" and the campaign for "Compulsory Free Education in Iraq," and largely under his auspices, the government established universal free schooling up to the highest education levels; hundreds of thousands learned to read in the years following the initiation of the program. The government also supported families of soldiers, granted free hospitalization to everyone, and gave subsidies to farmers. Iraq created one of the most modernized public-health systems in the Middle East, earning Saddam an award from the United Nations Educational, Scientific and Cultural Organization (UNESCO).

With the help of increasing oil revenues, Saddam diversified the largely oil-based Iraqi economy. Saddam implemented a national infrastructure campaign that made great progress in building roads, promoting mining, and developing other industries. The campaign helped Iraq's energy industries. Electricity was brought to nearly every city in Iraq, and many outlying areas. Before the 1970s, most of Iraq's people lived in the countryside and roughly two-thirds were peasants. This number would decrease quickly during the 1970s as global oil prices helped revenues to rise from less than a half billion dollars to tens of billions of dollars and the country invested into industrial expansion.

The oil revenue benefited Saddam politically. According to "The Economist", "Much as Adolf Hitler won early praise for galvanising German industry, ending mass unemployment and building autobahns, Saddam earned admiration abroad for his deeds. He had a good instinct for what the "Arab street" demanded, following the decline in Egyptian leadership brought about by the trauma of Israel's six-day victory in the 1967 war, the death of the pan-Arabist hero, Gamal Abdul Nasser, in 1970, and the "traitorous" drive by his successor, Anwar Sadat, to sue for peace with the Jewish state. Saddam's self-aggrandising propaganda, with himself posing as the defender of Arabism against Jewish or Persian intruders, was heavy-handed, but consistent as a drumbeat. It helped, of course, that his mukhabarat (secret police) put dozens of Arab news editors, writers and artists on the payroll."

In 1972, Saddam signed a 15-year Treaty of Friendship and Cooperation with the Soviet Union. According to historian Charles R. H. Tripp, the treaty upset "the U.S.-sponsored security system established as part of the Cold War in the Middle East. It appeared that any enemy of the Baghdad regime was a potential ally of the United States." In response, the U.S. covertly financed Kurdish rebels led by Mustafa Barzani during the Second Iraqi–Kurdish War; the Kurds were defeated in 1975, leading to the forcible relocation of hundreds of thousands of Kurdish civilians.

Saddam focused on fostering loyalty to the Ba'athists in the rural areas. After nationalizing foreign oil interests, Saddam supervised the modernization of the countryside, mechanizing agriculture on a large scale, and distributing land to peasant farmers. The Ba'athists established farm cooperatives and the government also doubled expenditures for agricultural development in 1974–1975. Saddam's welfare programs were part of a combination of "carrot and stick" tactics to enhance support for Saddam. The state-owned banks were put under his thumb. Lending was based on cronyism. Development went forward at such a fevered pitch that two million people from other Arab countries and even Yugoslavia worked in Iraq to meet the growing demand for labor.

In 1976, Saddam rose to the position of general in the Iraqi armed forces, and rapidly became the strongman of the government. As the ailing, elderly al-Bakr became unable to execute his duties, Saddam took on an increasingly prominent role as the face of the government both internally and externally. He soon became the architect of Iraq's foreign policy and represented the nation in all diplomatic situations. He was the "de facto" leader of Iraq some years before he formally came to power in 1979. He slowly began to consolidate his power over Iraq's government and the Ba'ath party. Relationships with fellow party members were carefully cultivated, and Saddam soon accumulated a powerful circle of support within the party.

In 1979 al-Bakr started to make treaties with Syria, also under Ba'athist leadership, that would lead to unification between the two countries. Syrian President Hafez al-Assad would become deputy leader in a union, and this would drive Saddam to obscurity. Saddam acted to secure his grip on power. He forced the ailing al-Bakr to resign on 16 July 1979, and formally assumed the presidency.

Saddam convened an assembly of Ba'ath party leaders on 22 July 1979. During the assembly, which he ordered videotaped, Saddam claimed to have found a fifth column within the Ba'ath Party and directed Muhyi Abdel-Hussein to read out a confession and the names of 68 alleged co-conspirators. These members were labelled "disloyal" and were removed from the room one by one and taken into custody. After the list was read, Saddam congratulated those still seated in the room for their past and future loyalty. The 68 people arrested at the meeting were subsequently tried together and found guilty of treason. 22 were sentenced to execution. Other high-ranking members of the party formed the firing squad. By 1 August 1979, hundreds of high-ranking Ba'ath party members had been executed.

Iraqi society fissures along lines of language, religion and ethnicity. The Ba'ath Party, secular by nature, adopted Pan-Arab ideologies which in turn were problematic for significant parts of the population. Following the Iranian Revolution of 1979, Iraq faced the prospect of régime change from two Shi'ite factions (Dawa and SCIRI) which aspired to model Iraq on its neighbour Iran as a Shia theocracy. A separate threat to Iraq came from parts of the ethnic Kurdish population of northern Iraq which opposed being part of an Iraqi state and favoured independence (an ongoing ideology which had preceded Ba'ath Party rule). To alleviate the threat of revolution, Saddam afforded certain benefits to the potentially hostile population. Membership in the Ba'ath Party remained open to all Iraqi citizens regardless of background. However, repressive measures were taken against its opponents.

The major instruments for accomplishing this control were the paramilitary and police organizations. Beginning in 1974, Taha Yassin Ramadan (himself a Kurdish Ba'athist), a close associate of Saddam, commanded the People's Army, which had responsibility for internal security. As the Ba'ath Party's paramilitary, the People's Army acted as a counterweight against any coup attempts by the regular armed forces. In addition to the People's Army, the Department of General Intelligence was the most notorious arm of the state-security system, feared for its use of torture and assassination. Barzan Ibrahim al-Tikriti, Saddam's younger half-brother, commanded Mukhabarat. Foreign observers believed that from 1982 this department operated both at home and abroad in its mission to seek out and eliminate Saddam's perceived opponents.

Saddam was notable for using terror against his own people. "The Economist" described Saddam as "one of the last of the 20th century's great dictators, but not the least in terms of egotism, or cruelty, or morbid will to power". Saddam's regime brought about the deaths of at least 250,000 Iraqis and committed war crimes in Iran, Kuwait, and Saudi Arabia. Human Rights Watch and Amnesty International issued regular reports of widespread imprisonment and torture.

As a sign of his consolidation of power, Saddam's personality cult pervaded Iraqi society. He had thousands of portraits, posters, statues and murals erected in his honor all over Iraq. His face could be seen on the sides of office buildings, schools, airports, and shops, as well as on Iraqi currency. Saddam's personality cult reflected his efforts to appeal to the various elements in Iraqi society. This was seen in his variety of apparel: he appeared in the costumes of the Bedouin, the traditional clothes of the Iraqi peasant (which he essentially wore during his childhood), and even Kurdish clothing, but also appeared in Western suits fitted by his favorite tailor, projecting the image of an urbane and modern leader. Sometimes he would also be portrayed as a devout Muslim, wearing full headdress and robe, praying toward Mecca.

He also conducted two show elections, in 1995 and 2002. In the 1995 referendum, conducted on 15 October, he reportedly received 99.96% of the votes in a 99.47% turnout, getting only 3,052 negative votes among an electorate of 8.4 million. In the October 15, 2002 referendum he officially achieved 100% of approval votes and 100% turnout, as the electoral commission reported the next day that every one of the 11,445,638 eligible voters cast a "Yes" vote for the president.

He erected statues around the country, which Iraqis toppled after his fall.

Iraq's relations with the Arab world have been extremely varied. Relations between Iraq and Egypt violently ruptured in 1977, when the two nations broke relations with each other following Iraq's criticism of Egyptian President Anwar Sadat's peace initiatives with Israel. In 1978, Baghdad hosted an Arab League summit that condemned and ostracized Egypt for accepting the Camp David Accords. However, Egypt's strong material and diplomatic support for Iraq in the war with Iran led to warmer relations and numerous contacts between senior officials, despite the continued absence of ambassadorial-level representation. Since 1983, Iraq has repeatedly called for restoration of Egypt's "natural role" among Arab countries.
Saddam developed a reputation for liking expensive goods, such as his diamond-coated Rolex wristwatch, and sent copies of them to his friends around the world. To his ally Kenneth Kaunda Saddam once sent a Boeing 747 full of presents – rugs, televisions, ornaments. Kaunda sent back his own personal magician.

Saddam enjoyed a close relationship with Russian intelligence agent Yevgeny Primakov that dated back to the 1960s; Primakov may have helped Saddam to stay in power in 1991.

Saddam visited only two Western countries. The first visit took place in December 1974, when the dictator of Spain, Francisco Franco, invited him to Madrid and he visited Granada, Córdoba and Toledo. In September 1975 he met with Prime Minister Jacques Chirac in Paris, France.

Several Iraqi leaders, Lebanese arms merchant Sarkis Soghanalian and others have claimed that Saddam financed Chirac's party. In 1991 Saddam threatened to expose those who had taken largesse from him: "From Mr. Chirac to Mr. Chevènement, politicians and economic leaders were in open competition to spend time with us and flatter us. We have now grasped the reality of the situation. If the trickery continues, we will be forced to unmask them, all of them, before the French public." France armed Saddam and it was Iraq's largest trade partner throughout Saddam's rule. Seized documents show how French officials and businessmen close to Chirac, including Charles Pasqua, his former interior minister, personally benefitted from the deals with Saddam.

Because Saddam Hussein rarely left Iraq, Tariq Aziz, one of Saddam's aides, traveled abroad extensively and represented Iraq at many diplomatic meetings. In foreign affairs, Saddam sought to have Iraq play a leading role in the Middle East. Iraq signed an aid pact with the Soviet Union in 1972, and arms were sent along with several thousand advisers. However, the 1978 crackdown on Iraqi Communists and a shift of trade toward the West strained Iraqi relations with the Soviet Union; Iraq then took on a more Western orientation until the Gulf War in 1991.

After the oil crisis of 1973, France had changed to a more pro-Arab policy and was accordingly rewarded by Saddam with closer ties. He made a state visit to France in 1975, cementing close ties with some French business and ruling political circles. In 1975 Saddam negotiated an accord with Iran that contained Iraqi concessions on border disputes. In return, Iran agreed to stop supporting opposition Kurds in Iraq. Saddam led Arab opposition to the Camp David Accords between Egypt and Israel (1979).

Saddam initiated Iraq's nuclear enrichment project in the 1980s, with French assistance. The first Iraqi nuclear reactor was named by the French "Osirak". Osirak was destroyed on 7 June 1981 by an Israeli air strike (Operation Opera).

Nearly from its founding as a modern state in 1920, Iraq has had to deal with Kurdish separatists in the northern part of the country. Saddam did negotiate an agreement in 1970 with separatist Kurdish leaders, giving them autonomy, but the agreement broke down. The result was brutal fighting between the government and Kurdish groups and even Iraqi bombing of Kurdish villages in Iran, which caused Iraqi relations with Iran to deteriorate. However, after Saddam had negotiated the 1975 treaty with Iran, the Shah withdrew support for the Kurds, who suffered a total defeat.

In early 1979, Iran's Shah Mohammad Reza Pahlavi was overthrown by the Islamic Revolution, thus giving way to an Islamic republic led by the Ayatollah Ruhollah Khomeini. The influence of revolutionary Shi'ite Islam grew apace in the region, particularly in countries with large Shi'ite populations, especially Iraq. Saddam feared that radical Islamic ideas—hostile to his secular rule—were rapidly spreading inside his country among the majority Shi'ite population.

There had also been bitter enmity between Saddam and Khomeini since the 1970s. Khomeini, having been exiled from Iran in 1964, took up residence in Iraq, at the Shi'ite holy city of An Najaf. There he involved himself with Iraqi Shi'ites and developed a strong, worldwide religious and political following against the Iranian Government, which Saddam tolerated. However, when Khomeini began to urge the Shi'ites there to overthrow Saddam and under pressure from the Shah, who had agreed to a rapprochement between Iraq and Iran in 1975, Saddam agreed to expel Khomeini in 1978 to France. However this turned out to be an imminent failure and a political catalyst, for Khomeini had access to more media connections and also collaborated with a much larger Iranian community under his support which he used to his advantage.

After Khomeini gained power, skirmishes between Iraq and revolutionary Iran occurred for ten months over the sovereignty of the disputed Shatt al-Arab waterway, which divides the two countries. During this period, Saddam Hussein publicly maintained that it was in Iraq's interest not to engage with Iran, and that it was in the interests of both nations to maintain peaceful relations. However, in a private meeting with Salah Omar al-Ali, Iraq's permanent ambassador to the United Nations, he revealed that he intended to invade and occupy a large part of Iran within months. Later (probably to appeal for support from the United States and most Western nations), he would make toppling the Islamic government one of his intentions as well.
Iraq invaded Iran, first attacking Mehrabad Airport of Tehran and then entering the oil-rich Iranian land of Khuzestan, which also has a sizable Arab minority, on 22 September 1980 and declared it a new province of Iraq. With the support of the Arab states, the United States, and Europe, and heavily financed by the Arab states of the Persian Gulf, Saddam Hussein had become "the defender of the Arab world" against a revolutionary Iran. The only exception was the Soviet Union, who initially refused to supply Iraq on the basis of neutrality in the conflict, although in his memoirs, Mikhail Gorbachev claimed that Leonid Brezhnev refused to aid Saddam over infuriation of Saddam's treatment of Iraqi communists. Consequently, many viewed Iraq as "an agent of the civilized world". The blatant disregard of international law and violations of international borders were ignored. Instead Iraq received economic and military support from its allies, who conveniently overlooked Saddam's use of chemical warfare against the Kurds and the Iranians and Iraq's efforts to develop nuclear weapons.

In the first days of the war, there was heavy ground fighting around strategic ports as Iraq launched an attack on Khuzestan. After making some initial gains, Iraq's troops began to suffer losses from human wave attacks by Iran. By 1982, Iraq was on the defensive and looking for ways to end the war.

At this point, Saddam asked his ministers for candid advice. Health Minister Dr. Riyadh Ibrahim suggested that Saddam temporarily step down to promote peace negotiations. Initially, Saddam Hussein appeared to take in this opinion as part of his cabinet democracy. A few weeks later, Dr. Ibrahim was sacked when held responsible for a fatal incident in an Iraqi hospital where a patient died from intravenous administration of the wrong concentration of potassium supplement.

Dr. Ibrahim was arrested a few days after he started his new life as a sacked minister. He was known to have publicly declared before that arrest that he was "glad that he got away alive." Pieces of Ibrahim's dismembered body were delivered to his wife the next day.

Iraq quickly found itself bogged down in one of the longest and most destructive wars of attrition of the 20th century. During the war, Iraq used chemical weapons against Iranian forces fighting on the southern front and Kurdish separatists who were attempting to open up a northern front in Iraq with the help of Iran. These chemical weapons were developed by Iraq from materials and technology supplied primarily by West German companies as well as using dual-use technology imported following the Reagan administration's lifting of export restrictions. The United States also supplied Iraq with "satellite photos showing Iranian deployments". In a US bid to open full diplomatic relations with Iraq, the country was removed from the US list of State Sponsors of Terrorism. Ostensibly, this was because of improvement in the regime's record, although former United States Assistant Secretary of Defense Noel Koch later stated, "No one had any doubts about [the Iraqis'] continued involvement in terrorism ... The real reason was to help them succeed in the war against Iran." The Soviet Union, France, and China together accounted for over 90% of the value of Iraq's arms imports between 1980 and 1988.

Saddam reached out to other Arab governments for cash and political support during the war, particularly after Iraq's oil industry severely suffered at the hands of the Iranian navy in the Persian Gulf. Iraq successfully gained some military and financial aid, as well as diplomatic and moral support, from the Soviet Union, China, France, and the United States, which together feared the prospects of the expansion of revolutionary Iran's influence in the region. The Iranians, demanding that the international community should force Iraq to pay war reparations to Iran, refused any suggestions for a cease-fire. Despite several calls for a ceasefire by the United Nations Security Council, hostilities continued until 20 August 1988.

On 16 March 1988, the Kurdish town of Halabja was attacked with a mix of mustard gas and nerve agents, killing 5,000 civilians, and maiming, disfiguring, or seriously debilitating 10,000 more. ("see Halabja poison gas attack") The attack occurred in conjunction with the 1988 al-Anfal Campaign designed to reassert central control of the mostly Kurdish population of areas of northern Iraq and defeat the Kurdish peshmerga rebel forces. The United States now maintains that Saddam ordered the attack to terrorize the Kurdish population in northern Iraq, but Saddam's regime claimed at the time that Iran was responsible for the attack which some including the U.S. supported until several years later.

The bloody eight-year war ended in a stalemate. There were hundreds of thousands of casualties with estimates of up to one million dead. Neither side had achieved what they had originally desired and at the borders were left nearly unchanged. The southern, oil rich and prosperous Khuzestan and Basra area (the main focus of the war, and the primary source of their economies) were almost completely destroyed and were left at the pre-1979 border, while Iran managed to make some small gains on its borders in the Northern Kurdish area. Both economies, previously healthy and expanding, were left in ruins.

Saddam borrowed tens of billions of dollars from other Arab states and a few billions from elsewhere during the 1980s to fight Iran, mainly to prevent the expansion of Shi'a radicalism. However, this had proven to completely backfire both on Iraq and on the part of the Arab states, for Khomeini was widely perceived as a hero for managing to defend Iran and maintain the war with little foreign support against the heavily backed Iraq and only managed to boost Islamic radicalism not only within the Arab states, but within Iraq itself, creating new tensions between the Sunni Ba'ath Party and the majority Shi'a population. Faced with rebuilding Iraq's infrastructure and internal resistance, Saddam desperately re-sought cash, this time for postwar reconstruction.

The Al-Anfal Campaign was a genocidal campaign against the Kurdish people (and many others) in Kurdish regions of Iraq led by the government of Saddam Hussein and headed by Ali Hassan al-Majid. The campaign takes its name from Surat al-Anfal in the Qur'an, which was used as a code name by the former Iraqi Ba'athist administration for a series of attacks against the "peshmerga" rebels and the mostly Kurdish civilian population of rural Northern Iraq, conducted between 1986 and 1989 culminating in 1988. This campaign also targeted Shabaks and Yazidis, Assyrians, Turkoman people and Mandeans and many villages belonging to these ethnic groups were also destroyed. Human Rights Watch estimates that between 50,000 and 100,000 people were killed. Some Kurdish sources put the number higher, estimating that 182,000 Kurds were killed.

The end of the war with Iran served to deepen latent tensions between Iraq and its wealthy neighbor Kuwait. Saddam urged the Kuwaitis to waive the Iraqi debt accumulated in the war, some $30 billion, but they refused.

Saddam pushed oil-exporting countries to raise oil prices by cutting back production; Kuwait refused, however. In addition to refusing the request, Kuwait spearheaded the opposition in OPEC to the cuts that Saddam had requested. Kuwait was pumping large amounts of oil, and thus keeping prices low, when Iraq needed to sell high-priced oil from its wells to pay off a huge debt.

Saddam had always argued that Kuwait was historically an integral part of Iraq, and that Kuwait had only come into being through the maneuverings of British imperialism; this echoed a belief that Iraqi nationalists had voiced for the past 50 years. This belief was one of the few articles of faith uniting the political scene in a nation rife with sharp social, ethnic, religious, and ideological divides.

The extent of Kuwaiti oil reserves also intensified tensions in the region. The oil reserves of Kuwait (with a population of 2 million next to Iraq's 25) were roughly equal to those of Iraq. Taken together, Iraq and Kuwait sat on top of some 20 percent of the world's known oil reserves; as an article of comparison, Saudi Arabia holds 25 percent.

Saddam complained to the U.S. State Department that Kuwait had slant drilled oil out of wells that Iraq considered to be within its disputed border with Kuwait. Saddam still had an experienced and well-equipped army, which he used to influence regional affairs. He later ordered troops to the Iraq–Kuwait border.

As Iraq-Kuwait relations rapidly deteriorated, Saddam was receiving conflicting information about how the U.S. would respond to the prospects of an invasion. For one, Washington had been taking measures to cultivate a constructive relationship with Iraq for roughly a decade. The Reagan administration gave Iraq roughly $4 billion in agricultural credits to bolster it against Iran. Saddam's Iraq became "the third-largest recipient of U.S. assistance".

Reacting to Western criticism in April 1990 Saddam threatened to destroy half of Israel with chemical weapons if it moved against Iraq. In May 1990 he criticized U.S. support for Israel warning that "the United States cannot maintain such a policy while professing friendship towards the Arabs." In July 1990 he threatened force against Kuwait and the UAE saying "The policies of some Arab rulers are American ... They are inspired by America to undermine Arab interests and security." The U.S. sent aerial planes and combat ships to the Persian Gulf in response to these threats.

U.S. ambassador to Iraq April Glaspie met with Saddam in an emergency meeting on 25 July 1990, where the Iraqi leader attacked American policy with regards to Kuwait and the United Arab Emirates:

Glaspie replied:

Saddam stated that he would attempt last-ditch negotiations with the Kuwaitis but Iraq "would not accept death".

U.S. officials attempted to maintain a conciliatory line with Iraq, indicating that while George H. W. Bush and James Baker did not want force used, they would not take any position on the Iraq–Kuwait boundary dispute and did not want to become involved.

Later, Iraq and Kuwait met for a final negotiation session, which failed. Saddam then sent his troops into Kuwait. As tensions between Washington and Saddam began to escalate, the Soviet Union, under Mikhail Gorbachev, strengthened its military relationship with the Iraqi leader, providing him military advisers, arms and aid.

On 2 August 1990, Saddam invaded Kuwait, initially claiming assistance to "Kuwaiti revolutionaries," thus sparking an international crisis. On 4 August an Iraqi-backed "Provisional Government of Free Kuwait" was proclaimed, but a total lack of legitimacy and support for it led to an 8 August announcement of a "merger" of the two countries. On 28 August Kuwait formally became the 19th Governorate of Iraq. Just two years after the 1988 Iraq and Iran truce, "Saddam Hussein did what his Gulf patrons had earlier paid him to prevent." Having removed the threat of Iranian fundamentalism he "overran Kuwait and confronted his Gulf neighbors in the name of Arab nationalism and Islam."

When later asked why he invaded Kuwait, Saddam first claimed that it was because Kuwait was rightfully Iraq's 19th province and then said "When I get something into my head I act. That's just the way I am." After Saddam's seizure of Kuwait in August 1990, a UN coalition led by the United States drove Iraq's troops from Kuwait in February 1991. The ability for Saddam Hussein to pursue such military aggression was from a "military machine paid for in large part by the tens of billions of dollars Kuwait and the Gulf states had poured into Iraq and the weapons and technology provided by the Soviet Union, Germany, and France."

Shortly before he invaded Kuwait, he shipped 100 new Mercedes 200 Series cars to top editors in Egypt and Jordan. Two days before the first attacks, Saddam reportedly offered Egypt's Hosni Mubarak 50 million dollars in cash, "ostensibly for grain".
U.S. President George H. W. Bush responded cautiously for the first several days. On one hand, Kuwait, prior to this point, had been a virulent enemy of Israel and was the Persian Gulf monarchy that had the most friendly relations with the Soviets. On the other hand, Washington foreign policymakers, along with Middle East experts, military critics, and firms heavily invested in the region, were extremely concerned with stability in this region. The invasion immediately triggered fears that the world's price of oil, and therefore control of the world economy, was at stake. Britain profited heavily from billions of dollars of Kuwaiti investments and bank deposits. Bush was perhaps swayed while meeting with British prime minister Margaret Thatcher, who happened to be in the U.S. at the time.

Cooperation between the United States and the Soviet Union made possible the passage of resolutions in the United Nations Security Council giving Iraq a deadline to leave Kuwait and approving the use of force if Saddam did not comply with the timetable. U.S. officials feared Iraqi retaliation against oil-rich Saudi Arabia, since the 1940s a close ally of Washington, for the Saudis' opposition to the invasion of Kuwait. Accordingly, the U.S. and a group of allies, including countries as diverse as Egypt, Syria and Czechoslovakia, deployed a massive amount of troops along the Saudi border with Kuwait and Iraq in order to encircle the Iraqi army, the largest in the Middle East.

Saddam's officers looted Kuwait, stripping even the marble from its palaces to move it to Saddam's own palace.

During the period of negotiations and threats following the invasion, Saddam focused renewed attention on the Palestinian problem by promising to withdraw his forces from Kuwait if Israel would relinquish the occupied territories in the West Bank, the Golan Heights, and the Gaza Strip. Saddam's proposal further split the Arab world, pitting U.S.- and Western-supported Arab states against the Palestinians. The allies ultimately rejected any linkage between the Kuwait crisis and Palestinian issues.

Saddam ignored the Security Council deadline. Backed by the Security Council, a U.S.-led coalition launched round-the-clock missile and aerial attacks on Iraq, beginning 16 January 1991. Israel, though subjected to attack by Iraqi missiles, refrained from retaliating in order not to provoke Arab states into leaving the coalition. A ground force consisting largely of U.S. and British armoured and infantry divisions ejected Saddam's army from Kuwait in February 1991 and occupied the southern portion of Iraq as far as the Euphrates.

On 6 March 1991, Bush announced "What is at stake is more than one small country, it is a big idea—a new world order, where diverse nations are drawn together in common cause to achieve the universal aspirations of mankind: peace and security, freedom, and the rule of law."

In the end, the out-numbered and under-equipped Iraqi army proved unable to compete on the battlefield with the highly mobile coalition land forces and their overpowering air support. Some 175,000 Iraqis were taken prisoner and casualties were estimated at over 85,000. As part of the cease-fire agreement, Iraq agreed to scrap all poison gas and germ weapons and allow UN observers to inspect the sites. UN trade sanctions would remain in effect until Iraq complied with all terms. Saddam publicly claimed victory at the end of the war.

Iraq's ethnic and religious divisions, together with the brutality of the conflict that this had engendered, laid the groundwork for postwar rebellions. In the aftermath of the fighting, social and ethnic unrest among Shi'ite Muslims, Kurds, and dissident military units threatened the stability of Saddam's government. Uprisings erupted in the Kurdish north and Shi'a southern and central parts of Iraq, but were ruthlessly repressed.

The United States, which had urged Iraqis to rise up against Saddam, did nothing to assist the rebellions. The Iranians, despite the widespread Shi'ite rebellions, had no interest in provoking another war, while Turkey opposed any prospect of Kurdish independence, and the Saudis and other conservative Arab states feared an Iran-style Shi'ite revolution. Saddam, having survived the immediate crisis in the wake of defeat, was left firmly in control of Iraq, although the country never recovered either economically or militarily from the Gulf War.

Saddam routinely cited his survival as "proof" that Iraq had in fact won the war against the U.S. This message earned Saddam a great deal of popularity in many sectors of the Arab world. John Esposito, however, claims that "Arabs and Muslims were pulled in two directions. That they rallied not so much to Saddam Hussein as to the bipolar nature of the confrontation (the West versus the Arab Muslim world) and the issues that Saddam proclaimed: Arab unity, self-sufficiency, and social justice." As a result, Saddam Hussein appealed to many people for the same reasons that attracted more and more followers to Islamic revivalism and also for the same reasons that fueled anti-Western feelings.

As one U.S. Muslim observer noted: "People forgot about Saddam's record and concentrated on America ... Saddam Hussein might be wrong, but it is not America who should correct him." A shift was, therefore, clearly visible among many Islamic movements in the post war period "from an initial Islamic ideological rejection of Saddam Hussein, the secular persecutor of Islamic movements, and his invasion of Kuwait to a more populist Arab nationalist, anti-imperialist support for Saddam (or more precisely those issues he represented or championed) and the condemnation of foreign intervention and occupation."

Saddam, therefore, increasingly portrayed himself as a devout Muslim, in an effort to co-opt the conservative religious segments of society. Some elements of Sharia law were re-introduced, and the ritual phrase "Allahu Akbar" ("God is great"), in Saddam's handwriting, was added to the national flag. Saddam also commissioned the production of a "Blood Qur'an", written using 27 litres of his own blood, to thank God for saving him from various dangers and conspiracies.

The United Nations sanctions placed upon Iraq when it invaded Kuwait were not lifted, blocking Iraqi oil exports. During the late 1990s, the UN considered relaxing the sanctions imposed because of the hardships suffered by ordinary Iraqis. Studies dispute the number of people who died in south and central Iraq during the years of the sanctions. On 9 December 1996, Saddam's government accepted the Oil-for-Food Programme that the UN had first offered in 1992.

Relations between the United States and Iraq remained tense following the Gulf War. The U.S. launched a missile attack aimed at Iraq's intelligence headquarters in Baghdad 26 June 1993, citing evidence of repeated Iraqi violations of the "no fly zones" imposed after the Gulf War and for incursions into Kuwait. U.S. officials continued to accuse Saddam of violating the terms of the Gulf War's cease fire, by developing weapons of mass destruction and other banned weaponry, and violating the UN-imposed sanctions. Also during the 1990s, President Bill Clinton maintained sanctions and ordered air strikes in the "Iraqi no-fly zones" (Operation Desert Fox), in the hope that Saddam would be overthrown by political enemies inside Iraq. Western charges of Iraqi resistance to UN access to suspected weapons were the pretext for crises between 1997 and 1998, culminating in intensive U.S. and British missile strikes on Iraq, 16–19 December 1998. After two years of intermittent activity, U.S. and British warplanes struck harder at sites near Baghdad in February 2001. Former CIA case officer Robert Baer reports that he "tried to assassinate" Saddam in 1995, amid "a decade-long effort to encourage a military coup in Iraq."

Saddam continued involvement in politics abroad. Video tapes retrieved after show his intelligence chiefs meeting with Arab journalists, including a meeting with the former managing director of Al-Jazeera, Mohammed Jassem al-Ali, in 2000. In the video Saddam's son Uday advised al-Ali about hires in Al-Jazeera: "During your last visit here along with your colleagues we talked about a number of issues, and it does appear that you indeed were listening to what I was saying since changes took place and new faces came on board such as that lad, Mansour." He was later sacked by Al-Jazeera.

In 2002, Austrian prosecutors investigated Saddam government's transactions with Fritz Edlinger that possibly violated Austrian money laundering and embargo regulations. Fritz Edlinger, president of the "General Secretary of the Society for Austro-Arab relations" (GÖAB) and a former member of Socialist International's Middle East Committee, was an outspoken supporter of Saddam Hussein. In 2005, an Austrian journalist revealed that Fritz Edlinger's GÖAB had received $100,000 from an Iraqi front company as well as donations from Austrian companies soliciting business in Iraq.

In 2002, a resolution sponsored by the European Union was adopted by the Commission for Human Rights, which stated that there had been no improvement in the human rights crisis in Iraq. The statement condemned President Saddam Hussein's government for its "systematic, widespread and extremely grave violations of human rights and international humanitarian law". The resolution demanded that Iraq immediately put an end to its "summary and arbitrary executions ... the use of rape as a political tool and all enforced and involuntary disappearances".

Many members of the international community, especially the U.S., continued to view Saddam as a bellicose tyrant who was a threat to the stability of the region. After the September 11 attacks, Vladimir Putin began to tell the United States that Iraq was preparing terrorist attacks against the United States. In his January 2002 state of the union address to Congress, President George W. Bush spoke of an "axis of evil" consisting of Iran, North Korea, and Iraq. Moreover, Bush announced that he would possibly take action to topple the Iraqi government, because of the threat of its weapons of mass destruction. Bush stated that "The Iraqi regime has plotted to develop anthrax, and nerve gas, and nuclear weapons for over a decade ... Iraq continues to flaunt its hostility toward America and to support terror."

After the passing of United Nations Security Council Resolution 1441, which demanded that Iraq give "immediate, unconditional and active cooperation" with UN and IAEA inspections, Saddam allowed U.N. weapons inspectors led by Hans Blix to return to Iraq. During the renewed inspections beginning in November 2002, Blix found no stockpiles of WMD and noted the "proactive" but not always "immediate" Iraqi cooperation as called for by UN Security Council Resolution 1441.

With war still looming on 24 February 2003, Saddam Hussein took part in an interview with CBS News reporter Dan Rather. Talking for more than three hours, he denied possessing any weapons of mass destruction, or any other weapons prohibited by UN guidelines. He also expressed a wish to have a live televised debate with George W. Bush, which was declined. It was his first interview with a U.S. reporter in over a decade. CBS aired the taped interview later that week. Saddam Hussein later told an FBI interviewer that he once left open the possibility that Iraq possessed weapons of mass destruction in order to appear strong against Iran.

The Iraqi government and military collapsed within three weeks of the beginning of the U.S.-led 2003 invasion of Iraq on 20 March. By the beginning of April, U.S.-led forces occupied much of Iraq. The resistance of the much-weakened Iraqi Army either crumbled or shifted to guerrilla tactics, and it appeared that Saddam had lost control of Iraq. He was last seen in a video which purported to show him in the Baghdad suburbs surrounded by supporters. When Baghdad fell to U.S.-led forces on 9 April, marked symbolically by the toppling of his statue by iconoclasts, Saddam was nowhere to be found.

In April 2003, Saddam's whereabouts remained in question during the weeks following the fall of Baghdad and the conclusion of the major fighting of the war. Various sightings of Saddam were reported in the weeks following the war, but none was authenticated. At various times Saddam released audio tapes promoting popular resistance to his ousting.

Saddam was placed at the top of the "U.S. list of most-wanted Iraqis". In July 2003, his sons Uday and Qusay and 14-year-old grandson Mustapha were killed in a three-hour gunfight with U.S. forces.

On 13 December 2003, in Operation Red Dawn, Saddam Hussein was captured by American forces after being found hiding in a hole in the ground near a farmhouse in ad-Dawr, near Tikrit. Following his capture, Saddam was transported to a U.S. base near Tikrit, and later taken to the American base near Baghdad. On 14 December, U.S. administrator in Iraq L. Paul Bremer confirmed that Saddam Hussein had indeed been captured at a farmhouse in ad-Dawr near Tikrit. Bremer presented video footage of Saddam in custody.

Saddam was shown with a full beard and hair longer than his familiar appearance. He was described by U.S. officials as being in good health. Bremer reported plans to put Saddam on trial, but claimed that the details of such a trial had not yet been determined. Iraqis and Americans who spoke with Saddam after his capture generally reported that he remained self-assured, describing himself as a "firm, but just leader."

British tabloid newspaper "The Sun" posted a picture of Saddam wearing white briefs on the front cover of a newspaper. Other photographs inside the paper show Saddam washing his trousers, shuffling, and sleeping. The United States government stated that it considered the release of the pictures a violation of the Geneva Convention, and that it would investigate the photographs. During this period Saddam was interrogated by FBI agent George Piro.

The guards at the Baghdad detention facility called their prisoner "Vic," which stands for 'Very Important Criminal', and let him plant a small garden near his cell. The nickname and the garden are among the details about the former Iraqi leader that emerged during a March 2008 tour of the Baghdad prison and cell where Saddam slept, bathed, and kept a journal and wrote poetry in the final days before his execution; he was concerned to ensure his legacy and how the history would be told. The tour was conducted by U.S. Marine Maj. Gen. Doug Stone, overseer of detention operations for the U.S. military in Iraq at the time.

On 30 June 2004, Saddam Hussein, held in custody by U.S. forces at the U.S. base "Camp Cropper", along with 11 other senior Ba'athist leaders, were handed over legally (though not physically) to the interim Iraqi government to stand trial for crimes against humanity and other offences.

A few weeks later, he was charged by the Iraqi Special Tribunal with crimes committed against residents of Dujail in 1982, following a failed assassination attempt against him. Specific charges included the murder of 148 people, torture of women and children and the illegal arrest of 399 others.
Among the many challenges of the trial were:

On 5 November 2006, Saddam Hussein was found guilty of crimes against humanity and sentenced to death by hanging. Saddam's half brother, Barzan Ibrahim, and Awad Hamed al-Bandar, head of Iraq's Revolutionary Court in 1982, were convicted of similar charges. The verdict and sentencing were both appealed, but subsequently affirmed by Iraq's Supreme Court of Appeals.

Saddam was hanged on the first day of Eid ul-Adha, 30 December 2006, despite his wish to be shot (which he felt would be more dignified). The execution was carried out at Camp Justice, an Iraqi army base in Kadhimiya, a neighborhood of northeast Baghdad.

Saudi Arabia condemned Iraqi authorities for carrying on with the execution on a holy day. A presenter from the Al—Ikhbariya television station officially stated "There is a feeling of surprise and disapproval that the verdict has been applied during the holy months and the first days of Eid al-Adha. Leaders of Islamic countries should show respect for this blessed occasion ... not demean it." 

Video of the execution was recorded on a mobile phone and his captors could be heard insulting Saddam. The video was leaked to electronic media and posted on the Internet within hours, becoming the subject of global controversy. It was later claimed by the head guard at the tomb where his remains lay that Saddam's body had been stabbed six times after the execution. Saddam's demeanor while being led to the gallows have been discussed by two witnesses, Iraqi Judge Munir Haddad and Iraqi national security adviser Mowaffak al-Rubaie. The accounts of the two witnesses are contradictory as Haddad describes Saddam as being strong in his final moments whereas al-Rubaie says Saddam was clearly afraid.

Not long before the execution, Saddam's lawyers released his last letter.

A second unofficial video, apparently showing Saddam's body on a trolley, emerged several days later. It sparked speculation that the execution was carried out incorrectly as Saddam Hussein had a gaping hole in his neck.

Saddam was buried at his birthplace of Al-Awja in Tikrit, Iraq, on 31 December 2006. He was buried 3 km (2 mi) from his sons Uday and Qusay Hussein. His tomb was reported to have been destroyed in March 2015. Before it was destroyed, a Sunni tribal group reportedly removed his body to a secret location, fearful of what might happen.



In August 1995, Raghad and her husband Hussein Kamel al-Majid and Rana and her husband, Saddam Kamel al-Majid, defected to Jordan, taking their children with them. They returned to Iraq when they received assurances that Saddam would pardon them. Within three days of their return in February 1996, both of the Kamel brothers were attacked and killed in a gunfight with other clan members who considered them traitors.

In August 2003, Saddam's daughters Raghad and Rana received sanctuary in Amman, Jordan, where they are currently staying with their nine children. That month, they spoke with CNN and the Arab satellite station Al-Arabiya in Amman. When asked about her father, Raghad told CNN, "He was a very good father, loving, has a big heart." Asked if she wanted to give a message to her father, she said: "I love you and I miss you." Her sister Rana also remarked, "He had so many feelings and he was very tender with all of us."

With the intention of discrediting Saddam Hussein with his supporters, CIA was considering making a video in which he would be seen having sex with a teenager.

In 1979, Rev. Jacob Yasso of Chaldean Sacred Heart Church congratulated Saddam Hussein on his presidency. In return, Rev. Yasso said that Saddam Hussein donated US$250,000 to his church, which is made up of at least 1,200 families of Middle Eastern descent. In 1980, Detroit Mayor Coleman Young allowed Rev. Yasso to present the key to the city of Detroit to Saddam Hussein. At the time, Saddam then asked Rev. Yasso, "I heard there was a debt on your church. How much is it?" After the inquiry, Saddam then donated another $200,000 to Chaldean Sacred Heart Church. Rev. Yasso said that Saddam made donations to Chaldean churches all over the world, and even went on record as saying "He's very kind to Christians."






</doc>
<doc id="29491" url="https://en.wikipedia.org/wiki?curid=29491" title="Sonja Henie">
Sonja Henie

Sonja Henie (8 April 1912 – 12 October 1969) was a Norwegian figure skater and film star. She was a three-time Olympic Champion (1928, 1932, 1936) in Ladies' Singles, a ten-time World Champion (1927–1936) and a six-time European Champion (1931–1936). Henie won more Olympic and World titles than any other ladies' figure skater. At the height of her acting career, she was one of the highest-paid stars in Hollywood and starred in a series of box-office hits, including "Thin Ice" (1937), "My Lucky Star" (1938), "Second Fiddle" (1939) and "Sun Valley Serenade" (1941).

Henie was born in 1912 in Kristiania (now Oslo) Norway; she was the only daughter of Wilhelm Henie (1872–1937), a prosperous Norwegian furrier, and his wife, Selma Lochmann-Nielsen (1888–1961). In addition to the income from the fur business, both of Henie's parents had inherited wealth. Wilhelm Henie had been a one-time World Cycling Champion and the Henie children were encouraged to take up a variety of sports at a young age. Henie initially showed talent at skiing, then followed her older brother, Leif, to take up figure skating. As a girl Henie also was a nationally ranked tennis player, and a skilled swimmer and equestrienne. Once Henie began serious training as a figure skater, her formal schooling ended. She was educated by tutors, and her father hired the best experts in the world, including the famous Russian ballerina, Tamara Karsavina, to transform his daughter into a sporting celebrity.

Henie won her first major competition, the senior Norwegian championships, at the age of 10. She then placed eighth in a field of eight at the 1924 Winter Olympics, at the age of eleven. During the 1924 program, she skated over to the side of the rink several times to ask her coach for directions, but by the next Olympiad, she needed no such assistance.

Henie won the first of an unprecedented ten consecutive World Figure Skating Championships in 1927 at the age of fourteen. The results of 1927 World Championships, where Henie won in 3–2 decision (or 7 vs. 8 ordinal points) over the defending Olympic and World Champion Herma Szabo of Austria, was controversial, as three of the five judges that gave Henie first-place ordinals were Norwegian (1 + 1 + 1 + 2 + 2 = 7 points) while Szabo received first-place ordinals from an Austrian and a German Judge (1 + 1 + 2 + 2 + 2 = 8 points). Henie went on to win first of her three Olympic gold medals the following year, became one of the youngest figure skating Olympic champions. She defended her Olympic titles in 1932 and in 1936, and her world titles annually until 1936. She also won six consecutive European championships from 1931 to 1936. Henie's unprecedented three Olympic gold medals haven't been matched by any ladies' single skater since; neither are her achievements as ten-time consecutive World Champion. While Irina Slutskaya of Russia won her seventh European Championship in 2006 to become the most successful ladies' skater in European Championships, Henie retains record of most consecutive titles, sharing it with Katarina Witt of Eastern Germany/Germany (1983–1988).

Towards the end of her career, she began to be strongly challenged by younger skaters including Cecilia Colledge, Megan Taylor, and Hedy Stenuf. However, she held off these competitors and went on to win her third Olympic title at the 1936 Winter Olympics, albeit in very controversial circumstances with Cecilia Colledge finishing a very close second. Indeed, after the school figures section at the 1936 Olympic competition, Colledge and Henie were virtually neck and neck with Colledge trailing by just a few points. As Sandra Stevenson recounted in her article in "The Independent" of 21 April 2008, "the closeness [of the competition] infuriated Henie, who, when the result for that section was posted on a wall in the competitors' lounge, swiped the piece of paper and tore it into little pieces. The draw for the free skating [then] came under suspicion after Henie landed the plum position of skating last, while Colledge had to perform second of the 26 competitors. The early start was seen as a disadvantage, with the audience not yet whipped into a clapping frenzy and the judges known to become freer with their higher marks as the event proceeded. Years later, a fairer, staggered draw was adopted to counteract this situation".

During her competitive career, Henie traveled widely and worked with a variety of foreign coaches. At home in Oslo, she trained at Frogner Stadium, where her coaches included Hjørdis Olsen and Oscar Holte. During the latter part of her competitive career she was coached primarily by the American Howard Nicholson in London. In addition to traveling to train and compete, she was much in demand as a performer at figure skating exhibitions in both Europe and North America. Henie became so popular with the public that police had to be called out for crowd control on her appearances in various disparate cities such as Prague and New York City. It was an open secret that, in spite of the strict amateurism requirements of the time, Wilhelm Henie demanded "expense money" for his daughter's skating appearances. Both of Henie's parents had given up their own pursuits in Norway—leaving Leif to run the fur business—in order to accompany Sonja on her travels and act as her managers.

Henie is credited with being the first figure skater to adopt the short skirt costume in figure skating, wear white boots, and make use of dance choreography. Her innovative skating techniques and glamorous demeanor transformed the sport permanently and confirmed its acceptance as a legitimate sport in the Winter Olympics.

After the 1936 World Figure Skating Championships, Henie gave up her amateur status and took up a career as a professional performer in acting and live shows. While still a girl, Henie had decided that she wanted to move to California and become a movie star when her competitive days were over, without considering that her thick accent might hinder her acting ambitions.

In 1936, following a successful ice show in Los Angeles orchestrated by her father to launch her film career, Hollywood studio chief Darryl Zanuck signed her to a long term contract at Twentieth Century Fox, which made her one of the highest-paid actresses of the time. After the success of her first film, "One in a Million" (1936), Henie's position was assured and she became increasingly demanding in her business dealings with Zanuck. Henie also insisted on having total control of the skating numbers in her films such as "Second Fiddle" (1939).

Henie tried to break the musical comedy mould with the anti-Nazi film "Everything Happens at Night" (1939) and "It's a Pleasure" (1945), a skating variation of the often-told "A Star Is Born" tale about alcoholic-star-in-decline-helps-newcomer-up. It was her only film shot in Technicolor, but it was not as huge at the box office as her other films and also proved her limitations as a dramatic actress in her one only dramatic film.

When Zanuck realized her limits in the pseudo-dramatic vein, he cast her in more musical comedies; "Sun Valley Serenade" (1941) with Glenn Miller, John Payne, The Nicholas Brothers, and hit songs such as "In the Mood", "Chattanooga Choo Choo", "It Happened in Sun Valley", and "I Know Why (And So Do You)", followed by "Iceland" (1942) with Jack Oakie, Payne, and the hit song "There Will Never Be Another You", and finally "Wintertime" (1943) with Cesar Romero, Carole Landis, Cornel Wilde, and Oakie. Sonja had by now developed a comedy flair and these films were all among the top box-office hits for 20th Century-Fox the respective years.

In addition to her film career at Fox from 1936-1943, Henie formed a business arrangement with Arthur Wirtz, who produced her touring ice shows under the name of "Hollywood Ice Revue". Wirtz also acted as Henie's financial advisor. At the time, figure skating and ice shows were not yet an established form of entertainment in the United States. Henie's popularity as a film actress attracted many new fans and instituted skating shows as a popular new entertainment. Throughout the 1940s, Henie and Wirtz produced lavish musical ice skating extravaganzas at Rockefeller Center's Center Theatre attracting millions of ticket buyers.

At the height of her fame, Henie brought as much as $2 million per year from her shows and touring activities. She also had numerous lucrative endorsement contracts, and deals to market skates, clothing, jewelry, dolls, and other merchandise branded with her name. These activities made her one of the wealthiest women in the world in her time.

Henie broke off her arrangement with Wirtz in 1950 and for the next three seasons produced her own tours under the name "Sonja Henie Ice Revue". It was an ill-advised decision to set herself up in competition with Wirtz, whose shows now featured the new Olympic champion Barbara Ann Scott. Since Wirtz controlled the best arenas and dates, Henie was left playing smaller venues and markets already saturated by other touring ice shows such as Ice Capades. The collapse of a section of bleachers during a show in Baltimore, Maryland, in 1952 compounded the tour's legal and financial woes.

In 1953, Henie formed a new partnership with Morris Chalfen to appear in his European "Holiday On Ice" tour, which proved to be a great success. She produced her own show at New York's Roxy Theatre in January 1956. However, a subsequent South American tour in 1956 was a disaster. Henie was drinking heavily at that time and could no longer keep up with the demands of touring, and this marked her retirement from skating. She did try to make a film series at her own expense; a series that would serve as a travelogue to several cities. Paris and London were mentioned, but only "Hello London" (1958) was made with her own backing, co-starring Michael Wilding and special guest star Stanley Holloway. While her ice show numbers were still worth watching, the film received few distributors and poor reviews, ending her film career. 

Her autobiography "Mitt livs eventyr", was published in 1938 which was translated and released as "Wings on My Feet" in 1940, and which was republished in a revised edition in 1954. At the time of her death, Henie was planning a comeback for a television special that would have aired in January 1970. She was to have danced to "Lara's Theme" from "Doctor Zhivago".

Henie's connections with Adolf Hitler and other high-ranking Nazi officials made her the subject of controversy before, during, and after World War II. During her amateur skating career, she performed often in Germany and was a favorite of German audiences and of Hitler personally. As a wealthy celebrity, she moved in the same social circles as royalty and heads of state and made Hitler's acquaintance as a matter of course. During the shooting of "Second Fiddle" (1939), she greeted the then Crown-prince couple of Norway, Olav V of Norway and his wife Princess Märtha of Sweden during their US tour. Through the years, her shows and later art exhibitions drew the attention and meetings with such people as Princess Margaret, Countess of Snowdon and Gustaf VI Adolf of Sweden to name but a few.

Controversy appeared first when Henie greeted Hitler with a Nazi salute at the Olympics in Garmisch-Partenkirchen and after the Games she accepted an invitation to lunch with Hitler at his resort home in nearby Berchtesgaden, where Hitler presented Henie with an autographed photo with a lengthy inscription. She was strongly denounced in the Norwegian press for this. In her revised 1954 biography she states that no Norwegian judge was in the panel for the 1936 Olympics - as she was entitled to as a Norwegian. She therefore made the most of it and she won her third Olympic medal. When she as a gold medal winner passed Hitler's tribune with silver medalist Cecilia Colledge and bronze medalist Vivi-Anne Hultén, neither she or the others honored Hitler with the Nazi salute. The 1936 European Figure Skating Championships also took place in Berlin and neither Sonja, Colledge, nor Megan Taylor paid obeisance to Hitler. 

In her film "Everything Happens at Night" (1939), Ray Milland and Robert Cummings star as rival reporters hot on the trail of Dr. Hugo Norden (Maurice Moscovich). Norden, a Nobel Prize winner, was supposedly murdered by the Gestapo, but is rumored to be in hiding and writing anonymous dispatches advocating world peace. When Geoffrey and Ken track Dr. Norden to a small village in the Swiss Alps, they soon find themselves competing over the affections of beautiful Louise (Henie), who has a deeper connection to the missing Nobel laureate than the reporters realize. When Geoffrey and Ken get so distracted by romance that they begin to neglect their assignments, it almost leads to disaster as the Gestapo sets out to silence Dr. Norden once and for all. Released on December 22, 1939, it was banned in Nazi Germany.

Through her 1940 marriage to Dan Topping she had become an American citizen. As such she was not eligible to speak Norway`s cause and with producer Alexander Korda, who was set to produce the propaganda flick That Hamilton Woman, could have faced deportation. The Senate Subcommittee (Senate Foreign Relations) dealt with such matters. After the bombing of Pearl Harbor, when America was no longer neutral, Henie pulled in uniform and visited and gave money to Little Norway. All Norwegians got free tickets to her shows during the war and she paid and held parties for them.

During the occupation of Norway by Nazi Germany, German troops saw Hitler's autographed photo prominently displayed at the piano in the Henie family home in Landøya, Asker. As a result, none of Henie's properties in Norway were confiscated or damaged by the Germans. Henie became a naturalized citizen of the United States in 1940. Like many Hollywood stars, she supported the U.S. war effort through USO and similar activities. After the Japanese attack, she invited the boys from Little Norway to her iceshows, gave the mechanics a plane as well a substantial sum of money to their educational fund. But her first rejection before the US entered the war was never to be forgotten. For this, she was condemned by many Norwegians and Norwegian-Americans. After the war, Henie was mindful that many of her countrymen considered her to be a quisling. However, she made a triumphant return to Norway with the Holiday on Ice tour in 1953 and 1955. The Norwegian Royal Family attended both events and indeed attended her funeral in 1969. The Royal Family were very mindful of whom they supported after the war and Norwegians looked to them as role models in that respect. Her complex reputation and legacy continues to stimulate debate amongst Norwegians, writers and historians

Henie was married three times, to Dan Topping (1940–1946), Winthrop Gardiner Jr. (1949–1956), and the Norwegian shipping magnate and art patron Niels Onstad (1956–1969) (her death). After her retirement in 1956, Henie and Onstad settled in Oslo and accumulated a large collection of modern art that formed the basis for the Henie Onstad Kunstsenter at Høvikodden in Bærum near Oslo.

Henie was diagnosed with leukemia in the mid-1960s. She died of the disease at age 57 in 1969 during a flight from Paris to Oslo. Generally regarded as one of the greatest figure skaters in history, she is buried with Onstad in Oslo on the hilltop overlooking the Henie Onstad Art Centre.







</doc>
<doc id="29493" url="https://en.wikipedia.org/wiki?curid=29493" title="Science &amp; Environmental Policy Project">
Science &amp; Environmental Policy Project

The Science & Environmental Policy Project (SEPP) is an advocacy group financed by private contributions based in Arlington, Virginia in the United States. It was founded in 1990 by atmospheric physicist S. Fred Singer. SEPP disputes the prevailing scientific views of climate change and ozone depletion. SEPP also questioned the science used to establish the dangers of secondhand smoke, arguing the risks are overstated.

SEPP's former Chairman of the Board of Directors is listed as Rockefeller University president emeritus Frederick Seitz, a former president of the National Academy of Sciences, now deceased.

SEPP listed the following key issues in 2010: 

On September 2, 1997, Singer said that "The possibility that global temperatures could rise because of an increase in carbon dioxide in the atmosphere is a concern that needs to be monitored...But there has been no indication in the last century that we've seen anything other than natural climate fluctuations. Both greenhouse theory and computer models predict that global warming should be more rapid in the polar regions than anywhere else," he says, "but in July the Antarctic experienced the coldest weather on record."

SEPP was the author of the Leipzig Declaration, which was based on the conclusions drawn from a November 1995 conference in Leipzig, Germany, which SEPP organized with the European Academy for Environmental Affairs.

SEPP's critics offer the following rebuttals to its claims:


In 2008, The Science and Environmental Policy Project completed the organization of the Nongovernmental International Panel on Climate Change (NIPCC) as the culmination of a process that began in 2003. The NIPCC calls itself "an international coalition of scientists convened to provide an independent examination of the evidence available on the causes and consequences of climate change in the published, peer-reviewed literature – examined without bias and selectivity."

The 2008 NIPCC document titled "Nature, Not Human Activity Rules the Climate: Summary for Policymakers of the Report of the Nongovernmental International Panel of Climate Change", published by The Heartland Institute, was released in February–March 2008. Singer served as General Editor and also holds the copyright.

Unnamed climate scientists from NASA, Stanford University and Princeton who were contacted by ABC News dismissed the same report as "fabricated nonsense.". In response, Singer objected to the ABC News piece, calling it "an appalling display of bias, unfairness, journalistic misbehavior, and a breakdown of ethical standards" which used "prejudicial language, distorted facts, libelous insinuations, and anonymous smears."


In 2004 Singer was coauthor of two papers published in Geophysical Research Letters:

Scientific criticism of SEPP's views:



</doc>
<doc id="29494" url="https://en.wikipedia.org/wiki?curid=29494" title="Abbey of Saint Gall">
Abbey of Saint Gall

The Abbey of Saint Gall () is a dissolved abbey (747–1805) in a Roman Catholic religious complex in the city of St. Gallen in Switzerland. The Carolingian-era monastery has existed since 719 and became an independent principality between 9th and 13th centuries, and was for many centuries one of the chief Benedictine abbeys in Europe. It was founded by Saint Othmar on the spot where Saint Gall had erected his hermitage. The library at the Abbey is one of the richest medieval libraries in the world. The city of St. Gallen originated as an adjoining settlement of the abbey. Following the secularization of the abbey around 1800 the former Abbey church became a Cathedral in 1848. Since 1983 the whole remaining abbey precinct has been a UNESCO World Heritage Site.

Around 613 Gallus, according to tradition an Irish monk and disciple and companion of Saint Columbanus, established a hermitage on the site that would become the monastery. He lived in his cell until his death in 646. in Arbon. The people kept looking for protection at Gallus' cell in time of danger.

Following Gallus' death, Charles Martel appointed Otmar as custodian of St Gall's relics. Several different dates are given for the foundation of the monastery, including 719, 720, 747 and the middle of the 8th century. During the reign of Pepin the Short, in the 8th century, Othmar founded the Carolingian style Abbey of St Gall, where arts, letters and sciences flourished. The abbey grew fast and many Alemannic noblemen became monks. At the end of abbot Otmar's reign, the "Professbuch" mentions 53 names. Two monks of the Abbey of St Gall, Magnus von Füssen and Theodor, founded the monasteries in Kempten and Füssen in the Allgäu. With the increase in the number of monks the abbey grew stronger also economically. Much land in Thurgau, Zürichgau and in the rest of Alemannia as far as the Neckar was transferred to the abbey due to "Stiftungen". Under abbot Waldo of Reichenau (740–814) copying of manuscripts was undertaken and a famous library was gathered. Numerous Anglo-Saxon and Irish monks came to copy manuscripts. At Charlemagne's request Pope Adrian I sent distinguished chanters from Rome, who propagated the use of the Gregorian chant. In 744, the Alemannic nobleman Beata sells several properties to the abbey in order to finance his journey to Rome.

In the subsequent century, St Gall came into conflict with the nearby Bishopric of Constance which had recently acquired jurisdiction over the Abbey of Reichenau on Lake Constance. It was not until Emperor Louis the Pious (ruled 814–840) confirmed in 813 the imperial immediacy ("Reichsunmittelbarkeit") of the abbey, that this conflict ceased. The abbey became an Imperial Abbey ("Reichsabtei"). King Louis the German confirmed in 833 the immunity of the abbey and allowed the monks the free choice of their abbot. In 854 finally, the Abbey of St Gall reached its full autonomy by King Louis the German releasing the abbey from the obligation to pay tithes to the Bishop of Constance.

From this time until the 10th century, the abbey flourished. It was home to several famous scholars, including Notker of Liège, Notker the Stammerer, Notker Labeo and Hartker (who developed the antiphonal liturgical books for the abbey). During the 9th century a new, larger church was built and the library was expanded. Manuscripts on a wide variety of topics were purchased by the abbey and copies were made. Over 400 manuscripts from this time have survived and are still in the library today.

Between 924 and 933 the Magyars threatened the abbey and the books had to be removed to Reichenau for safety. Not all the books were returned.

On 26 April 937 a fire broke out and destroyed much of the abbey and the adjoining settlement, though the library was undamaged. About 954 they started to protect the monastery and buildings by a surrounding wall. Around 971/974 abbot Notker finalized the walling and the adjoining settlements started to become the town of St Gall. In 1006, the abbey was the northernmost place where a sighting of the 1006 supernova was recorded.

The death of abbot Ulrich on 9 December 1076 terminates the cultural silver age of the monastery.

In 1207 abbot Ulrich von Sax becomes an Prince ("Reichsfürst", or simply "Fürst") of the Holy Roman Empire by King Philip of Swabia. The abbey became a Princely Abbey ("Reichsabtei"). As the abbey became more involved in local politics, it entered a period of decline. 
The city of St. Gallen proper progressively freed itself from the rule of the abbot, acquiring Imperial immediacy, and by the late 15th century was recognized as a Free imperial city.
By about 1353 the guilds, headed by the cloth-weavers guild, gained control of the civic government. In 1415 the city bought its liberty from the German king King Sigismund.
During the 14th century Humanists were allowed to carry off some of the rare texts from the abbey library.

In the late 14th and early 15th centuries, the farmers of the abbot's personal estates (known as "Appenzell", from meaning "cell (i.e. estate) of the abbot") began seeking independence. In 1401, the first of the Appenzell Wars broke out, and following the Appenzell victory at Stoss in 1405 they became allies of the Swiss Confederation in 1411. During the Appenzell Wars, the town of St. Gallen often sided with Appenzell against the abbey. So when Appenzell allied with the Swiss, the town of St. Gallen followed just a few months later. The abbot became an ally of several members of the Swiss Confederation (Zürich, Lucerne, Schwyz and Glarus) in 1451. While Appenzell and St. Gallen became full members of the Swiss Confederation in 1454. Then, in 1457 the town of St. Gallen became officially free from the abbot.

In 1468 the abbot, Ulrich Rösch, bought the County of Toggenburg from the representatives of its counts, after the family died out in 1436. In 1487 he built a monastery at Rorschach on Lake Constance, to which he planned to move. However, he encountered stiff resistance from the St. Gallen citizenry, other clerics, and the Appenzell nobility in the Rhine Valley who were concerned about their holdings. The town of St. Gallen wanted to restrict the increase of power in the abbey and simultaneously increase the power of the town. The mayor of St. Gallen, Ulrich Varnbüler, established contact with farmers and Appenzell residents (led by the fanatical Hermann Schwendiner) who were seeking an opportunity to weaken the abbot. Initially, he protested to the abbot and the representatives of the four sponsoring Confederate cantons (Zürich, Lucerne, Schwyz, and Glarus) against the construction of the new abbey in Rorschach. Then on July 28, 1489 he had armed troops from St. Gallen and Appenzell destroy the buildings already under construction. When the abbot complained to the Confederates about the damages and demanded full compensation, Varnbüler responded with a counter suit and in cooperation with Schwendiner rejected the arbitration efforts of the non-partisan Confederates. He motivated the clerics from Wil to Rorschach to discard their loyalty to the abbey and spoke against the abbey at the town meeting at Waldkirch, where the popular league was formed. He was confident that the four sponsoring cantons would not intervene with force, due to the prevailing tensions between the Confederation and the Swabian League. He was strengthened in his resolve by the fact that the people of St. Gallen elected him again to the highest magistrate in 1490.

However, in early 1490 the four cantons decided to carry out their duty to the abbey and to invade the St. Gallen canton with an armed force. The people of Appenzell and the local clerics submitted to this force without noteworthy resistance, while the city of St. Gallen braced for a fight to the finish. However, when they learned that their compatriots had given up the fight, they lost confidence; the end result was that they concluded a peace pact that greatly restricted the city's powers and burdened the city with serious penalties and reparations payments. Varnbüler and Schwendiner fled to the court of King Maximilian and lost all their property in St. Gallen and Appenzell. However, the abbot's reliance on the Swiss to support him reduced his position almost to that of a "subject district".

The town adopted the Reformation in 1524, while the abbey remained Catholic, which damaged relations between the town and abbey. Both the abbot and a representative of the town were admitted to the Swiss Tagsatzung or Diet as the closest associates of the Confederation.

In the 16th century the abbey was raided by Calvinist groups, which scattered many of the old books. In 1530, abbot Diethelm began a restoration that stopped the decline and led to an expansion of the schools and library.

Under abbot Pius (1630–74) a printing press was started. In 1712 during the Toggenburg war, also called the second war of Villmergen, the Abbey of St. Gall was pillaged by the Swiss. They took most of the books and manuscripts to Zürich and Bern. For security, the abbey was forced to request the protection of the townspeople of St. Gallen. Until 1457 the townspeople had been serfs of the abbey, but they had grown in power until they were protecting the abbey.

Following the disturbances, the abbey was still the largest religious city-state in Switzerland, with over 77,000 inhabitants. A final attempt to expand the abbey resulted in the demolition of most of the medieval monastery. The new structures, including the cathedral by architect Peter Thumb (1681-1766), were designed in the late Baroque style and constructed between 1755 and 1768. The large and ornate new abbey did not remain a monastery for very long. In 1798 the Prince-Abbot's secular power was suppressed, and the abbey was secularized. The monks were driven out and moved into other abbeys. The abbey became a separate See in 1846, with the abbey church as its cathedral and a portion of the monastic buildings for the bishop.

The Abbey library of Saint Gall is recognized as one of the richest medieval libraries in the world. It is home to one of the most comprehensive collections of early medieval books in the German-speaking part of Europe. , the library consists of over 160,000 books, of which 2100 are handwritten. Nearly half of the handwritten books are from the Middle Ages and 400 are over 1000 years old. Lately the "Stiftsbibliothek" has launched a project for the digitisation of the priceless manuscript collection, which currently (December 2009) contains 355 documents that are available on the "Codices Electronici Sangallenses" webpage.

The library interior is exquisitely realised in the Rococo style with carved polished wood, stucco and paint used to achieve its overall effect. It was designed by the architect Peter Thumb and is open to the public. In addition it holds exhibitions as well as concerts and other events.

One of the more interesting documents in the Stiftsbibliothek is a copy of Priscian's "Institutiones grammaticae" which contains the poem "Is acher in gaíth in-nocht..." written in Old Irish.

The library also preserves a unique 9th-century document, known as the Plan of St. Gall, the only surviving major architectural drawing from the roughly 700-year period between the fall of the Western Roman Empire and the 13th century. The Plan drawn was never actually built, and was so named because it was kept at the famous medieval monastery library, where it remains to this day. The plan was an ideal of what a well-designed and well-supplied monastery should have, as envisioned by one of the synods held at Aachen for the reform of monasticism in the Frankish empire during the early years of emperor Louis the Pious (between 814 and 817).

A late 9th-century drawing of St. Paul lecturing an agitated crowd of Jews and gentiles, part of a copy of a Pauline epistles produced at and still held by the monastery, was included in a medieval-drawing show at the Metropolitan Museum of Art in New York the summer of 2009. A reviewer noted that the artist had "a special talent for depicting hair, ... with the saint's beard ending in curling droplets of ink."

St. Gall is noted its early use of the neume, the basic element of Western and Eastern systems of musical notation prior to the invention of five-line staff notation. The earliest extant manuscripts are from the 9th or 10th century.

In 1983, the Convent of St. Gall was inscribed on the UNESCO World Heritage List as "a perfect example of a great Carolingian monastery".

There were a total of 73 ruling abbots (including six anti-abbots) during 719 and 1805.
A complete collection of abbots' biographies was published 
by Henggeler (1929). A table of abbots' names complete with their coats of arms was printed by Beat Jakob Anton Hiltensperger in 1778.




</doc>
<doc id="29498" url="https://en.wikipedia.org/wiki?curid=29498" title="Secondary education">
Secondary education

Secondary education covers two phases on the International Standard Classification of Education scale. Level 2 or lower secondary education (less common junior secondary education) is considered the second and final phase of basic education, and level 3 (upper) secondary education is the stage before tertiary education. Every country aims to provide basic education, but the systems and terminology remain unique to them. Secondary education typically takes place after six years of primary education and is followed by higher education, vocational education or employment. Like primary education, in most countries secondary education is compulsory, at least until the age of 16. Children typically enter the lower secondary phase around age 11. Compulsory education sometimes extends to age 19.

Since 1989 education has been seen as a basic human right for a child; Article 28, of the Convention on the Rights of the Child states that primary education should be free and compulsory while different forms of secondary education, including general and vocational education, should be available and accessible to every child. The terminology has proved difficult, and there was no universal definition before ISCED divided the period between primary education and university into junior secondary education and upper secondary education.

In classical and mediaeval times secondary education was provided by the church for the sons of nobility and to boys preparing for universities and the priesthood. As trade required navigational and scientific skills the church reluctantly expanded the curriculum and widened the intake. With the Reformation the state wrestled the control of learning from the church, and with Comenius and John Locke education changed from being repetition of Latin text to building up knowledge in the child. Education was for the few. Up to the middle of the 19th century, secondary schools were organised to satisfy the needs of different social classes with the labouring classes getting 4 years, the merchant class 5 years and the elite getting 7 years. The rights to a secondary education were codified after 1945, and countries are still working to achieve the goal of mandatory and free secondary education for all youth under 19.

Secondary education is in most countries the phase in the education continuum responsible for the development of the young during their adolescence, the most rapid phase of their physical, mental and emotional growth. It is at this very education level, particularly in its first cycle, where values and attitudes formed at primary school are more firmly ingrained alongside the acquisition of knowledge and skills. From UNESCO Towards a Convergence of Knowledge Acquisition and Skills Development 

The International Standard Classification of Education (ISCED) (1997) describes seven levels that can be used to compare education internationally. Within a country these can be implemented in different ways, with different age levels and local denominations.

Within this system, national governments can call levels 2, 3 and 4, levels 2 and 3 or just level 2, secondary education. Level 1 and Level 2, that is primary education and lower secondary together form basic education. These definition were put together for statistical purposes, and to allow the gathering of comparative data nationally and internationally and approved by the UNESCO General Conference at its 29th session in November 1997. Though they may be dated they do provide a universal set of definitions, and remain unchanged in the 2011 update.

The start of lower secondary education is characterised by the transition from the single class-teacher delivering all the content to a cohort of pupils, to one where content is delivered by a series of subject specialist. The educational aim is to complete provision of basic education, completing the delivery of basic skills and to lay the foundations for lifelong learning.

Lower secondary education is likely to show these criteria-

The end of lower secondary education often coincides with the end of compulsory education in countries where that exists.

(Upper) secondary education starts on the completion of basic education, which also is defined as completion of lower secondary education and its completion will provide the entry requirements to level 5 tertiary education, the entry requirements to technical or vocational education (Level 5- non tertiary course, or direct entry into the workplace. More subjects may be dropped, and increased specialism occurs. The educational focus is varied according to future direction of the student, and their interests. Education at this level is usually voluntary
(Upper) secondary education is likely to show these criteria-

In 2012 the International Standard Classification of Education (ISCED) published a further work on education levels where it codified particular paths and redefined the tertiary levels. Lower secondary education and (Upper) secondary education could last between 2 and 5 years, and the transition between two often would be when students were allowed some subject choice.

Secondary schools may be called "high schools", "academies", "gymnasiums", "lyceums", "middle schools", "upper schools", "colleges", "sixth-form colleges", "vocational schools", or "preparatory schools", and the exact meaning of any of these varies among the countries. 

A form of education for adolescents became necessary in all societies that had an alphabet and engaged in commerce. In Western Europe, formal secondary education can be traced back to the Athenian educational reforms of 320BC. Though their civilisation was eclipsed and they were enslaved, Hellenistic Athenian teachers were valued in the Roman system. The Roman and Hellenistic schools of rhetoric taught the seven liberal arts and sciences – "grammar, rhetoric, logic, arithmetic, geometry, music" and "astronomy" – which were regarded as a preparation for the study at a tertiary level of theology, law and medicine. Boys would have been prepared to enter these schools by private tutors at home. Girls would have only received tuition at home.
When the Romans retreated, all traces of civilisation were erased.

England provides a good case study. When Augustine of Canterbury brought Christianity there in 597, no schools existed. He needed trained priests to conduct church services and boys to sing in the choir. He had to create both the grammar schools that taught Latin, to enable the English to study for the priesthood, and song schools (choir schools) that trained the 'sons of gentlefolk' to sing in cathedral choirs. In the case of Canterbury (597) and Rochester (604), both still exist. Bede in his Ecclesiastical history (732) tells that the Canterbury school taught more than the 'intended reading and understanding of Latin', but 'the rules of metric, astronomy and the computus as well as the works of the saints' Even at this stage,there was tension, as the church was worried that knowledge of Latin would give the student access to non-Christian texts that it would not wish them to read.

Over the centuries leading to the renaissance and reformation the church was the main provider of secondary education. Various invasions and schisms within the controlling church challenged the focus of the schools, and the curriculum and language of instruction waxed and waned. From 1100, With the growth of the towns, grammar schools 'free' of the church were founded, and some church grammar schools were handed over to the laïty. Universities were founded that didn't just train students for the priesthood.

Whereas in mainland Europe the renaissance preceded the reformation, local conditions in England caused the reformation to come first. The reformation was about allowing the laïty to interpret the Bible in their own way without the intervention of priests, and prefereably in the vernacular. This stimulated the foundation of free Grammar schools- who searched for a less constrained curriculum. Colonialisation required navigation, mensuration, languages and administrative skills. The laïty wanted these taught to their sons. After Gutenberg1455 had mastered moveable metal type printing and Tyndale had translated the Bible into English (1525), Latin became a skill reserved for the catholic church and sons conservative nobility. Schools started to be set up for the sons of merchants in Europe and the colonies too- for example Boston Latin Grammar School (1635).

Comenius (1592–1670), a Moravian protestant proposed a new model of education- where ideas were developed from the familiar to the theoretical rather than through repetition, where languages were taught in the vernacular and supported universal education. In his "Didactica Magna" (Great Didactic), he outlined a system of schools that is the exact counterpart of many western school systems: kindergarten, elementary school, secondary school, six-form college, university.
Locke's Some Thoughts Concerning Education (1693) stressed the importance of a broader intellectual training, moral development and physical hardening. .

The grammar schools of the period can be categorised in three groups: the nine leading schools, seven of them boarding institutions which maintained the traditional curriculum of the classics, and mostly served 'the aristocracy and the squirearchy' ; most of the old endowed grammar schools serving a broad social base in their immediate localities which also stuck to the old curriculum; the grammar schools situated in the larger cities, serving the families of merchants and tradesmen who embraced change.

During the 18th century their social base widened and their curriculum developed, particularly in mathematics and the natural sciences. But this was not universal education and was self-selecting by wealth The industrial revolution changed that. Industry required an educated workforce where all workers needed to have completed a basic education. In France, Louis XIV, wrestled the control of education from the Jesuits, Condorcet set up Collèges for universal lower secondary education throughout the country, then Napoleon set up a regulated system of Lycee. In England, Robert Peel's Factory Act of 1802 required an employer to provide instruction in reading, writing and arithmetic during at least the first four years of the seven years of apprenticeship. The state had accepted responsibility for the basic education of the poor.
The provision of school places remained inadequate, so an Order in Council dated 10 April 1839 created the Committee of the Privy Council on Education.

There was considerable opposition to the idea that children of all classes should receive basic education, all the initiatives such as industrial schools and Sunday schools were initially a private or church initiative. With the Great Exhibition of 1851, it became clear just how far behind the English education system had fallen. 

Three reports were commissioned to examine the education of upper, middle and labouring class children. The Clarendon Commission sought to improve the nine Great Public Schools. The Taunton Commission looked at the 782 endowed grammar schools (private and public). They found varying quality and a patchy geographical coverage, with two thirds of all towns not having any secondary school. There was no clear conception of the purpose of secondary education. There were only thirteen girls' schools and their tuition was superficial, unorganised and unscientific. They recommended a system of first-grade schools targeted at a leaving age of 18 as preparation for upper and upper-middle class boys entering university, second-grade targeted at a leaving age of 16 for boys preparing for the army or the newer professions, and third-grade targeted at a leaving age of 14 for boys of small tenant farmers, small tradesmen, and superior artisans. This resulted in the 1869 Endowed Schools Act which advocated that girls should enjoy the same education as boys.

The Newcastle Commission inquired "into the state of public education in England and to consider and report what measures, if any, are required for the extension of sound and cheap elementary instruction to all classes of the people". It produced 1861 Newcastle Report and this led to the 1870 Elementary Education Act (Forster Act).

The school boards set up by the 1870 Elementary Education Act (Forster Act) and were stopped from providing secondary education by the Cockerton Judgement of 1899. The school leaving age at this time was 10. The Judgement prompted the 1902 Education Act (Balfour Act). Compulsory education was extended to 12. The new Local Education Authorities (LEA)s that were formed from the school boards; started to open Higher Grade Elementary Schools (ISCED Level2) or county schools to supplement the endowed grammar schools. These LEAs were allowed to build second-grade secondary schools that in the main became the future secondary modern schools. 

In the ""1904 Regulations for Secondary Schools"", the Board of Education determined that secondary schools should offer a:
a four year subject-based course leading to a certificate in English language and literature, geography, history, a foreign language, mathematics, science, drawing, manual work, physical training, and, for girls, housewifery. 

The Education Act 1918 (Fisher Act) extended compulsory full-time education to 14, and recommended compulsory part-time education from 14–18.
The Hadlow report, "Education the Adolescent" (1926) proposed that there should be a break point at eleven, establishing primary schools and secondary schools.

The United Nations, founded in 1947, was committed to education for all but the definition was difficult to formulate.
The Universal Declaration of Human Rights (1948) declared that elementary and fundamental education, which it didn't define, was a right to be enjoyed by all. The Education Act 1944 (Butler Act) made sweeping changes to the funding of state education using the tripartite system, but wasn't allowed to tackle private schools. It introduced the GCE 'O'level at 16, and the 'A' at 18, but only raised the school leaving age until 15, making the exam inaccessible to the majority. But one year of ISCED Level 3 (Upper) secondary education was mandatory and free. 

In 1972 the school leaving was raised to 16. The Education and Skills Act 2008, when it came into force in the 2013 academic year, initially required participation in some form of education or training until the school year in which the child turned 17, followed by the age being raised to the young person's 18th birthday in 2015. This was referred to as raising the "participation age" to distinguish it from the school leaving age which remains at 16. Thus the UK is following the ISCED Level 3 (Upper) secondary education guideline.

The United Nations was strong in its commitment to education for all but fell into linguistic difficultly defining that right.

“Article I: Purposes and functions
1. The purpose of the Organization is to contribute to peace and security by promoting collaboration among the nations through education, science and culture in order to further universal respect for justice, for the rule of law and for the human rights and fundamental freedoms which are affirmed for the peoples of the world, without distinction of race, sex, language or religion, by the Charter of the United Nations.”

The Universal Declaration of Human Rights (1948) declared that elementary and fundamental education was a right to be enjoyed by all, but again could not define either elementary and fundamental education.
Article 26 :(1) Everyone has the right to education. Education shall be free, at least in the elementary and fundamental stages. Elementary education shall be compulsory. Technical and professional education shall be made generally available and higher education shall be equally accessible to all on the basis of merit.
It was assumed that elementary education was basic education, the entitlement for children- and fundamental education was a right for the working man, but for a lawyer the definition is neither qualitative (stating what education means) or quantitative saying when it starts and when it is completed. The term secondary is not defined or mentioned. Together this has enabled countries to terminate free, compulsory, basic education at 11 or only continue education past eleven to boys.

Article 28, of the Convention on the Rights of the Child (1989) stated that primary education should be free and compulsory while different forms of secondary education, including general and vocational education, should be available and accessible to every
child. Free education should be provided and financial assistance offered in case of need. 
In 1990, at Jomtien again tried to define the content basic education and how it should be delivered. ‘Basic education’ is defined as ‘action designed to meet ‘basic learning needs’. ‘primary schooling’ is considered as ‘the main delivery system of basic education’.
addressing the basic learning needs of all means: early childhood care and development opportunities; relevant, quality primary schooling or equivalent out-of-school education for children; and literacy, basic knowledge and life skills training for youth and adults.’

The assumption being made that basic knowledge and life skills training for youth was the function of secondary education. This was codified by the ISCED documents. The Dakar Framework for Action 2010 goal 2 states: Ensuring that by 2015 all children, particularly girls, children in difficult circumstances and those belonging to ethnic minorities, have access to and complete free and compulsory (primary in the sense basic) education of good quality. The Dakar Framework for Action 2010 goal 5 states: Eliminating gender disparities in primary and secondary education by 2005, and achieving gender equality in education by 2015, with a focus on ensuring girls’ full and equal access to and achievement in basic education of good quality. 

Malala Yousafzai, Nobel Peace Prize winner in a said in a 2017 interview that:
“My goal is to make sure every child, girl and boy, they get the opportunity to go to school." “It is their basic human right, so I will be working on that and I will never stop until I see the last child going to school.” 
UNESCO believes that in order to prepare young people for life and work in a rapidly changing world, secondary-level education systems need to be re-oriented to impart a broad repertoire of life-skills. These skills should include the key generic competencies, non occupation-specific practical capabilities, ICT, the ability to learn independently, to work in teams, entrepreneurship and civic responsibility.

They may be best instilled through a shared foundational learning period and by deferring the directing of students into academic and vocational streams for as long as possible, and then there should be flexibility to ensure the free movement of students between the streams depending on their aptitudes and inclinations. Accreditation in one stream should have equal recognition in the other as well as for access to higher education. This will equip young people with multiple skills so that they are prepared to enter and re-enter the workforce several times in their working lives, as wage employees or self-employed entrepreneurs, and to re-train themselves when their skills become obsolete.

It recognizes that there is no single model that will suit all countries, or even all communities in a given country. Secondary-level education policy should be under continuous review to keep in step with scientific and technological, economic and societal change.

Each country has developed the form of education most appropriate for them. There is an attempt to compare the effectiveness by using the results from the PISA that, each third year, assesses the scholastic performance on mathematics, science, and reading of a representative sample of 5000 fifteen year olds from each country.




</doc>
<doc id="29500" url="https://en.wikipedia.org/wiki?curid=29500" title="Serotonin syndrome">
Serotonin syndrome

Serotonin syndrome (SS) is a group of symptoms that may occur following use of certain serotonergic medications or drugs. The degree of symptoms can range from mild to severe. Symptoms include high body temperature, agitation, increased reflexes, tremor, sweating, dilated pupils, and diarrhea. Body temperature can increase to greater than . Complications may include seizures and extensive muscle breakdown.
Serotonin syndrome is typically caused by the use of two or more serotonergic medications or drugs. This may include selective serotonin reuptake inhibitor (SSRI), serotonin norepinephrine reuptake inhibitor (SNRI), monoamine oxidase inhibitor (MAOI), tricyclic antidepressants (TCAs), amphetamines, pethidine (meperidine), tramadol, dextromethorphan, buspirone, L-tryptophan, 5-HTP, St. John's wort, triptans, ecstasy (MDMA), metoclopramide, ondansetron, or cocaine. It occurs in about 15% of SSRI overdoses. It is a predictable consequence of excess serotonin on the central nervous system (CNS). Onset of symptoms is typically within a day of the extra serotonin.
Diagnosis is based on a person's symptoms and history of medication use. Other conditions that can produce similar symptoms such as neuroleptic malignant syndrome, malignant hyperthermia, anticholinergic toxicity, heat stroke, and meningitis should be ruled out. No laboratory tests can confirm the diagnosis.
Initial treatment consists of discontinuing medications which may be contributing. In those who are agitated benzodiazepines may be used. If this is not sufficient, a serotonin antagonist such as cyproheptadine may be used. In those with a high body temperature active cooling measures may be needed. The number of cases of serotonin syndrome that occur each year is unclear. With appropriate treatment the risk of death is less than one percent. The high-profile case of Libby Zion, who is generally accepted to have died from serotonin syndrome, resulted in changes to graduate medical education in New York State.

Symptom onset is usually rapid, often occurring within minutes of elevated serotonin levels. Serotonin syndrome encompasses a wide range of clinical findings. Mild symptoms may consist of increased heart rate, shivering, sweating, dilated pupils, myoclonus (intermittent jerking or twitching), as well as overresponsive reflexes. However, many of these symptoms may be side effects of the drug or drug interaction causing excessive levels of serotonin; not an effect of elevated serotonin itself. Tremor is a common side effect of MDMA's action on dopamine, whereas hyperreflexia is symptomatic of exposure to serotonin agonists. Moderate intoxication includes additional abnormalities such as hyperactive bowel sounds, high blood pressure and hyperthermia; a temperature as high as . The overactive reflexes and clonus in moderate cases may be greater in the lower limbs than in the upper limbs. Mental changes include hypervigilance or insomnia and agitation. Severe symptoms include severe increases in heart rate and blood pressure that may lead to shock. Temperature may rise to above in life-threatening cases. Other abnormalities include metabolic acidosis, rhabdomyolysis, seizures, renal failure, and disseminated intravascular coagulation; these effects usually arising as a consequence of hyperthermia.

The symptoms are often described as a clinical triad of abnormalities:


A large number of medications and street drugs can cause serotonin syndrome when taken alone at high doses or in combination with other serotonergic drugs. The table below lists some of these drugs.
Many cases of serotonin toxicity occur in patients who have ingested drug combinations that synergistically increase synaptic serotonin. It may also occur as a symptom of overdose of a single serotonergic agent. The combination of MAOIs with precursors such as L-tryptophan or 5-HTP pose a particularly acute risk of life-threatening serotonin syndrome. The case of combination of MAOIs with tryptamine agonists (commonly known as ayahuasca) can present similar dangers as their combination with precursors, but this phenomenon has been described in general terms as the "cheese effect". Many MAOIs irreversibly inhibit monoamine oxidase. It can take at least four weeks for this enzyme to be replaced by the body in the instance of irreversible inhibitors.

Many medications may have been incorrectly thought to cause serotonin syndrome. For example, some case reports have implicated atypical antipsychotics in serotonin syndrome, but it appears based on their pharmacology that they are unlikely to cause the syndrome. It has also been suggested that mirtazapine has no significant serotonergic effects, and is therefore not a dual action drug. Bupropion has also been suggested to cause serotonin syndrome, although as there is no evidence that it has any significant serotonergic activity, it is thought unlikely to produce the syndrome. In 2006 the United States Food and Drug Administration issued an alert suggesting that the combined use of SSRIs or SNRIs and triptan medications or sibutramine could potentially lead to severe cases of serotonin syndrome. This has been disputed by other researchers as none of the cases reported by the FDA met the Hunter criteria for serotonin syndrome. The condition has however occurred in surprising clinical situations, and because of phenotypic variations among individuals, it has been associated with unexpected drugs, including mirtazapine.

The relative risk and severity of serotonergic side effects and serotonin toxicity, with individual drugs and combinations, is complex. Serotonin syndrome has been reported in patients of all ages, including the elderly, children, and even newborn infants due to in utero exposure. The serotonergic toxicity of SSRIs increases with dose, but even in over-dose it is insufficient to cause fatalities from serotonin syndrome in healthy adults. Elevations of central nervous system serotonin will typically only reach potentially fatal levels when drugs with different mechanisms of action are mixed together. Various drugs, other than SSRIs, also have clinically significant potency as serotonin reuptake inhibitors, (e.g. tramadol, amphetamine, and MDMA) and are associated with severe cases of the syndrome.

Serotonin is a neurotransmitter involved in multiple states including aggression, pain, sleep, appetite, anxiety, depression, migraine, and vomiting. In humans the effects of excess serotonin were first noted in 1960 in patients receiving a monoamine oxidase inhibitor (MAOI) and tryptophan. The syndrome is caused by increased serotonin in the central nervous system. It was originally suspected that agonism of 5-HT receptors in central grey nuclei and the medulla was responsible for the development of the syndrome. Further study has determined that overstimulation of primarily the 5-HT receptors appears to contribute substantially to the condition. The 5-HT receptor may still contribute through a pharmacodynamic interaction in which increased synaptic concentrations of a serotonin agonist saturate all receptor subtypes. Additionally, noradrenergic CNS hyperactivity may play a role as CNS norepinephrine concentrations are increased in serotonin syndrome and levels appear to correlate with the clinical outcome. Other neurotransmitters may also play a role; NMDA receptor antagonists and GABA have been suggested as affecting the development of the syndrome. Serotonin toxicity is more pronounced following supra-therapeutic doses and overdoses, and they merge in a continuum with the toxic effects of overdose.

A postulated "spectrum concept" of serotonin toxicity emphasises the role that progressively increasing serotonin levels play in mediating the clinical picture as side effects merge into toxicity. The dose-effect relationship is the effects of progressive elevation of serotonin, either by raising the dose of one drug, or combining it with another serotonergic drug which may produce large elevations in serotonin levels. Some experts prefer the terms serotonin toxicity or serotonin toxidrome, to more accurately reflect that it is a form of poisoning.

There is no laboratory test for serotonin syndrome. Therefore, diagnosis is by symptom observation and investigation of the patient's history. Several diagnostic criteria have been proposed. The first rigorously evaluated criteria were introduced in 1991 by Harvey Sternbach, a professor of psychiatry at UCLA. Researchers in Australia later developed the Hunter Toxicity Criteria Decision Rules, which have better sensitivity and specificity, 84% and 97%, respectively, when compared with the gold standard of diagnosis by a medical toxicologist. As of 2007, Sternbach's criteria were still the most commonly used.

The most important symptoms for diagnosing serotonin syndrome are tremor, extreme aggressiveness, akathisia, or clonus (spontaneous, inducible and ocular). Physical examination of the patient should include assessment of deep-tendon reflexes and muscle rigidity, the dryness of the mucosa of the mouth, the size and reactivity of the pupils, the intensity of bowel sounds, skin color, and the presence or absence of sweating. The patient's history also plays an important role in diagnosis, investigations should include inquiries about the use of prescription and over-the-counter drugs, illicit substances, and dietary supplements, as all these agents have been implicated in the development of serotonin syndrome. To fulfill the Hunter Criteria, a patient must have taken a serotonergic agent and meet one of the following conditions:

Serotonin toxicity has a characteristic picture which is generally hard to confuse with other medical conditions, but in some situations it may go unrecognized because it may be mistaken for a viral illness, anxiety disorders, neurological disorder, anticholinergic
poisoning, sympathomimetic toxicity, or worsening psychiatric condition. The condition most often confused with serotonin syndrome is neuroleptic malignant syndrome (NMS). The clinical features of neuroleptic malignant syndrome and serotonin syndrome share some features which can make differentiating them difficult. In both conditions, autonomic dysfunction and altered mental status develop. However, they are actually very different conditions with different underlying dysfunction (serotonin excess vs dopamine blockade). Both the time course and the clinical features of NMS differ significantly from those of serotonin toxicity. Serotonin toxicity has a rapid onset after the administration of a serotonergic drug and responds to serotonin blockade such as drugs like chlorpromazine and cyproheptadine. Dopamine receptor blockade (NMS) has a slow onset and typically evolves over several days after administration of a neuroleptic drug and responds to dopamine agonists such as bromocriptine.

Differential diagnosis may become difficult in patients recently exposed to both serotonergic drugs and neuroleptic drugs. Features that are classically present in NMS, that are useful for differentiating the two, are bradykinesia and extrapyramidal "lead pipe" rigidity, whereas serotonin syndrome causes hyperkinesia and clonus.

Management is based primarily on stopping the usage of the precipitating drugs, the administration of serotonin antagonists such as cyproheptadine, and supportive care including the control of agitation, the control of autonomic instability, and the control of hyperthermia. Additionally, those who ingest large doses of serotonergic agents may benefit from gastrointestinal decontamination with activated charcoal if it can be administered within an hour of overdose. The intensity of therapy depends on the severity of symptoms. If the symptoms are mild, treatment may only consist of discontinuation of the offending medication or medications, offering supportive measures, giving benzodiazepines for myoclonus, and waiting for the symptoms to resolve. Moderate cases should have all thermal and cardiorespiratory abnormalities corrected and can benefit from serotonin antagonists. The serotonin antagonist cyproheptadine is the recommended initial therapy, although there have been no controlled trials demonstrating its efficacy for serotonin syndrome. Despite the absence of controlled trials, there are a number of case reports detailing apparent improvement after people have been administered cyproheptadine. Animal experiments also suggest a benefit from serotonin antagonists. Cyproheptadine is only available as tablets and therefore can only be administered orally or via a nasogastric tube; it is unlikely to be effective in people administered activated charcoal and has limited use in severe cases. Additional pharmacological treatment for severe case includes administering atypical antipsychotic drugs with serotonin antagonist activity such as olanzapine. Critically ill people should receive the above therapies as well as sedation or neuromuscular paralysis. People who have autonomic instability such as low blood pressure require treatment with direct-acting sympathomimetics such as epinephrine, norepinephrine, or phenylephrine. Conversely, hypertension or tachycardia can be treated with short-acting antihypertensive drugs such as nitroprusside or esmolol; longer acting drugs such as propranolol should be avoided as they may lead to hypotension and shock. The cause of serotonin toxicity or accumulation is an important factor in determining the course of treatment. Serotonin is catabolized by monoamine oxidase in the presence of oxygen, so if care is taken to prevent an unsafe spike in body temperature or metabolic acidosis, oxygenation will assist in dispatching the excess serotonin. The same principle applies to alcohol intoxication. In cases of serotonin syndrome caused by monoamine oxidase inhibitors oxygenation will not help to dispatch serotonin. In such instances, hydration is the main concern until the enzyme is regenerated.

Specific treatment for some symptoms may be required. One of the most important treatments is the control of agitation due to the extreme possibility of injury to the person themselves or caregivers, benzodiazepines should be administered at first sign of this. Physical restraints are not recommended for agitation or delirium as they may contribute to mortality by enforcing isometric muscle contractions that are associated with severe lactic acidosis and hyperthermia. If physical restraints are necessary for severe agitation they must be rapidly replaced with pharmacological sedation. The agitation can cause a large amount of muscle breakdown. This breakdown can cause severe damage to the kidneys through a condition called rhabdomyolysis.

Treatment for hyperthermia includes reducing muscle overactivity via sedation with a benzodiazepine. More severe cases may require muscular paralysis with vecuronium, intubation, and artificial ventilation. Suxamethonium is not recommended for muscular paralysis as it may increase the risk of cardiac dysrhythmia from hyperkalemia associated with rhabdomyolysis. Antipyretic agents are not recommended as the increase in body temperature is due to muscular activity, not a hypothalamic temperature set point abnormality.

Upon the discontinuation of serotonergic drugs, most cases of serotonin syndrome resolve within 24 hours, although in some cases delirium may persist for a number of days. Symptoms typically persist for a longer time frame in patients taking drugs which have a long elimination half-life, active metabolites, or a protracted duration of action.

Cases have reported muscle pain and weakness persisting for months, and antidepressant discontinuation may contribute to ongoing features. Following appropriate medical management, serotonin syndrome is generally associated with a favorable prognosis.

Epidemiological studies of serotonin syndrome are difficult as many physicians are unaware of the diagnosis or they may miss the syndrome due to its variable manifestations. In 1998 a survey conducted in England found that 85% of the general practitioners that had prescribed the antidepressant nefazodone were unaware of serotonin syndrome. The incidence may be increasing as a larger number of pro-serotonergic drugs (drugs which increase serotonin levels) are now being used in clinical practice. One postmarketing surveillance study identified an incidence of 0.4 cases per 1000 patient-months for patients who were taking nefazodone. Additionally, around 14 to 16 percent of persons who overdose on SSRIs are thought to develop serotonin syndrome.

The most widely recognized example of serotonin syndrome was the death of Libby Zion in 1984. Zion was a freshman at Bennington College at her death on March 5, 1984, at age 18. She died within 8 hours of her emergency admission to the New York Hospital Cornell Medical Center. She had an ongoing history of depression, and came to the Manhattan hospital on the evening of March 4, 1984, with a fever, agitation and "strange jerking motions" of her body. She also seemed disoriented at times. The emergency room physicians were unable to diagnose her condition definitively but admitted her for hydration and observation. Her death was caused by a combination of pethidine and phenelzine. A medical intern prescribed the pethidine. The case influenced graduate medical education and residency work hours. Limits were set on working hours for medical postgraduates, commonly referred to as interns or residents, in hospital training programs, and they also now require closer senior physician supervision.




</doc>
<doc id="29501" url="https://en.wikipedia.org/wiki?curid=29501" title="Sustainable development">
Sustainable development

Sustainable development is the organizing principle for meeting human development goals while at the same time sustaining the ability of natural systems to provide the natural resources and ecosystem services upon which the economy and society depend. The desired result is a state of society where living conditions and resource use continue to meet human needs without undermining the integrity and stability of the natural system. Sustainable development can be classified as development that meet the needs of the present without compromising the ability of future generations.

While the modern concept of sustainable development is derived mostly from the 1987 Brundtland Report, it is also rooted in earlier ideas about sustainable forest management and twentieth century environmental concerns. As the concept developed, it has shifted to focus more on economic development, social development and environmental protection for future generations. It has been suggested that "the term 'sustainability' should be viewed as humanity's target goal of human-ecosystem equilibrium (homeostasis), while 'sustainable development' refers to the holistic approach and temporal processes that lead us to the end point of sustainability". The modern economies are endeavouring to reconcile ambitious economic development and obligations of preserving the natural resources and ecosystem, the two are traditionally seen as of conflicting nature. Instead of holding climate change commitments and other sustainability measures as a drug to economic development, turning and leveraging them into market opportunities will do greater good. The economic development brought by such organized principles and practices in an economy is called Managed Sustainable Development (MSD).

The concept of sustainable development has been—and still is—subject to criticism. What, exactly, is to be sustained in sustainable development? It has been argued that there is no such thing as a sustainable use of a non-renewable resource, since any positive rate of exploitation will eventually lead to the exhaustion of earth's infinite stock.

Sustainability can be defined as the practice of maintaining processes of productivity indefinitely—natural or human made—by replacing resources used with resources of equal or greater value without degrading or endangering natural biotic systems. Sustainable development ties together concern for the carrying capacity of natural systems with the social, political, and economic challenges faced by humanity. Sustainability science is the study of the concepts of sustainable development and environmental science. There is an additional focus on the present generations' responsibility to regenerate, maintain and improve planetary resources for use by future generations.

Sustainable development has its roots in ideas about sustainable forest management which were developed in Europe during the seventeenth and eighteenth centuries. In response to a growing awareness of the depletion of timber resources in England, John Evelyn argued that "sowing and planting of trees had to be regarded as a national duty of every landowner, in order to stop the destructive over-exploitation of natural resources" in his 1662 essay "Sylva". In 1713 Hans Carl von Carlowitz, a senior mining administrator in the service of Elector Frederick Augustus I of Saxony published "Sylvicultura oeconomica", a 400-page work on forestry. Building upon the ideas of Evelyn and French minister Jean-Baptiste Colbert, von Carlowitz developed the concept of managing forests for sustained yield. His work influenced others, including Alexander von Humboldt and Georg Ludwig Hartig, eventually leading to the development of a science of forestry. This in turn influenced people like Gifford Pinchot, first head of the US Forest Service, whose approach to forest management was driven by the idea of wise use of resources, and Aldo Leopold whose land ethic was influential in the development of the environmental movement in the 1960s.

Following the publication of Rachel Carson's "Silent Spring" in 1962, the developing environmental movement drew attention to the relationship between economic growth and development and environmental degradation. Kenneth E. Boulding in his influential 1966 essay "The Economics of the Coming Spaceship Earth" identified the need for the economic system to fit itself to the ecological system with its limited pools of resources. One of the first uses of the term sustainable in the contemporary sense was by the Club of Rome in 1972 in its classic report on the "Limits to Growth", written by a group of scientists led by Dennis and Donella Meadows of the Massachusetts Institute of Technology. Describing the desirable "state of global equilibrium", the authors wrote: "We are searching for a model output that represents a world system that is sustainable without sudden and uncontrolled collapse and capable of satisfying the basic material requirements of all of its people."

In 1980 the International Union for the Conservation of Nature published a world conservation strategy that included one of the first references to sustainable development as a global priority and introduced the term "sustainable development". Two years later, the United Nations World Charter for Nature raised five principles of conservation by which human conduct affecting nature is to be guided and judged. In 1987 the United Nations World Commission on Environment and Development released the report "Our Common Future", commonly called the Brundtland Report. The report included what is now one of the most widely recognised definitions of sustainable development.

Since the Brundtland Report, the concept of sustainable development has developed beyond the initial intergenerational framework to focus more on the goal of "socially inclusive and environmentally sustainable economic growth". In 1992, the UN Conference on Environment and Development published the Earth Charter, which outlines the building of a just, sustainable, and peaceful global society in the 21st century. The action plan Agenda 21 for sustainable development identified information, integration, and participation as key building blocks to help countries achieve development that recognises these interdependent pillars. It emphasises that in sustainable development everyone is a user and provider of information. It stresses the need to change from old sector-centered ways of doing business to new approaches that involve cross-sectoral co-ordination and the integration of environmental and social concerns into all development processes. Furthermore, Agenda 21 emphasises that broad public participation in decision making is a fundamental prerequisite for achieving sustainable development.

Under the principles of the United Nations Charter the Millennium Declaration identified principles and treaties on sustainable development, including economic development, social development and environmental protection. Broadly defined, sustainable development is a systems approach to growth and development and to manage natural, produced, and social capital for the welfare of their own and future generations. The term sustainable development as used by the United Nations incorporates both issues associated with land development and broader issues of human development such as education, public health, and standard of living.

A 2013 study concluded that sustainability reporting should be reframed through the lens of four interconnected domains: ecology, economics, politics and culture.

In September 2015, the United Nations General Assembly formally adopted the "universal, integrated and transformative" 2030 Agenda for Sustainable Development, a set of 17 Sustainable Development Goals (SDGs). The goals are to be implemented and achieved in every country from the year 2016 to 2030.

Sustainable development, or sustainability, has been described in terms of three spheres, dimensions, domains or pillars, i.e. the environment, the economy and society. The three-sphere framework was initially proposed by the economist René Passet in 1979. It has also been worded as "economic, environmental and social" or "ecology, economy and equity". This has been expanded by some authors to include a fourth pillar of culture, institutions or governance, or alternatively reconfigured as four domains of the social - ecology, economics, politics and culture, thus bringing economics back inside the social, and treating ecology as the intersection of the social and the natural.

The ecological stability of human settlements is part of the relationship between humans and their natural, social and built environments. Also termed human ecology, this broadens the focus of sustainable development to include the domain of human health. Fundamental human needs such as the availability and quality of air, water, food and shelter are also the ecological foundations for sustainable development; addressing public health risk through investments in ecosystem services can be a powerful and transformative force for sustainable development which, in this sense, extends to all species.

Environmental sustainability concerns the natural environment and how it endures and remains diverse and productive. Since natural resources are derived from the environment, the state of air, water, and the climate are of particular concern. The IPCC Fifth Assessment Report outlines current knowledge about scientific, technical and socio-economic information concerning climate change, and lists options for adaptation and mitigation. Environmental sustainability requires society to design activities to meet human needs while preserving the life support systems of the planet. This, for example, entails using water sustainably, utilizing renewable energy, and sustainable material supplies (e.g. harvesting wood from forests at a rate that maintains the biomass and biodiversity).

An unsustainable situation occurs when natural capital (the sum total of nature's resources) is used up faster than it can be replenished. Sustainability requires that human activity only uses nature's resources at a rate at which they can be replenished naturally. Inherently the concept of sustainable development is intertwined with the concept of carrying capacity. Theoretically, the long-term result of environmental degradation is the inability to sustain human life. Such degradation on a global scale should imply an increase in human death rate until population falls to what the degraded environment can support. If the degradation continues beyond a certain tipping point or critical threshold it would lead to eventual extinction for humanity.

Integral elements for a sustainable development are research and innovation activities. A telling example is the European environmental research and innovation policy, which aims at defining and implementing a transformative agenda to greening the economy and the society as a whole so to achieve a truly sustainable development. Research and innovation in Europe is financially supported by the programme Horizon 2020, which is also open to participation worldwide. A promising direction towards sustainable development is to design systems that are flexible and reversible.

Pollution of the public resources is really not a different action, it just is a reverse tragedy of the commons, in that instead of taking something out, something is put into the commons. When the costs of polluting the commons are not calculated into the cost of the items consumed, then it becomes only natural to pollute, as the cost of pollution is external to the cost of the goods produced and the cost of cleaning the waste before it is discharged exceeds the cost of releasing the waste directly into the commons. So, the only way to solve this problem is by protecting the ecology of the commons by making it, through taxes or fines, more costly to release the waste directly into the commons than would be the cost of cleaning the waste before discharge.

So, one can try to appeal to the ethics of the situation by doing the right thing as an individual, but in the absence of any direct consequences, the individual will tend to do what is best for the person and not what is best for the common good of the public. Once again, this issue needs to be addressed. Because, left unaddressed, the development of the commonly owned property will become impossible to achieve in a sustainable way. So, this topic is central to the understanding of creating a sustainable situation from the management of the public resources that are used for personal use.

Sustainable agriculture consists of environment friendly methods of farming that allow the production of crops or livestock without damage to human or natural systems. It involves preventing adverse effects to soil, water, biodiversity, surrounding or downstream resources—as well as to those working or living on the farm or in neighboring areas. The concept of sustainable agriculture extends intergenerationally, passing on a conserved or improved natural resource, biotic, and economic base rather than one which has been depleted or polluted. Elements of sustainable agriculture include permaculture, agroforestry, mixed farming, multiple cropping, and crop rotation. It involves agricultural methods that do not undermine the environment, smart farming technologies that enhance a quality environment for humans to thrive and reclaiming and transforming deserts into farmlands(Herman Daly, 2017). 

Numerous sustainability standards and certification systems exist, including organic certification, Rainforest Alliance, Fair Trade, UTZ Certified, Bird Friendly, and the Common Code for the Coffee Community (4C).

It has been suggested that because of rural poverty and overexploitation, environmental resources should be treated as important economic assets, called natural capital. Economic development has traditionally required a growth in the gross domestic product. This model of unlimited personal and GDP growth may be over. Sustainable development may involve improvements in the quality of life for many but may necessitate a decrease in resource consumption.
According to ecological economist , ecological economics is defined by its focus on nature, justice, and time. Issues of intergenerational equity, irreversibility of environmental change, uncertainty of long-term outcomes, and sustainable development guide ecological economic analysis and valuation.

As early as the 1970s, the concept of sustainability was used to describe an economy "in equilibrium with basic ecological support systems". Scientists in many fields have highlighted "The Limits to Growth", and economists have presented alternatives, for example a 'steady-state economy'; to address concerns over the impacts of expanding human development on the planet. In 1987 the economist Edward Barbier published the study "The Concept of Sustainable Economic Development", where he recognised that goals of environmental conservation and economic development are not conflicting and can be reinforcing each other.

A World Bank study from 1999 concluded that based on the theory of genuine savings, policymakers have many possible interventions to increase sustainability, in macroeconomics or purely environmental. Several studies have noted that efficient policies for renewable energy and pollution are compatible with increasing human welfare, eventually reaching a golden-rule steady state.

The study, "Interpreting Sustainability in Economic Terms", found three pillars of sustainable development, interlinkage, intergenerational equity, and dynamic efficiency.

But Gilbert Rist points out that the World Bank has twisted the notion of sustainable development to prove that economic development need not be deterred in the interest of preserving the ecosystem. He writes: "From this angle, 'sustainable development' looks like a cover-up operation. ... The thing that is meant to be sustained is really 'development', not the tolerance capacity of the ecosystem or of human societies."

The World Bank, a leading producer of environmental knowledge, continues to advocate the win-win prospects for economic growth and ecological stability even as its economists express their doubts. Herman Daly, an economist for the Bank from 1988 to 1994, writes:
When authors of "WDR" '92 [the highly influential 1992 "World Development Report" that featured the environment] were drafting the report, they called me asking for examples of "win-win" strategies in my work. What could I say? None exists in that pure form; there are trade-offs, not "win-wins." But they want to see a world of "win-wins" based on articles of faith, not fact. I wanted to contribute because "WDR"s are important in the Bank, [because] task managers read [them] to find philosophical justification for their latest round of projects. But they did not want to hear about how things really are, or what I find in my work..."

A meta review in 2002 looked at environmental and economic valuations and found a lack of "sustainability policies". A study in 2004 asked if we consume too much. A study concluded in 2007 that knowledge, manufactured and human capital (health and education) has not compensated for the degradation of natural capital in many parts of the world. It has been suggested that intergenerational equity can be incorporated into a sustainable development and decision making, as has become common in economic valuations of climate economics. A meta review in 2009 identified conditions for a strong case to act on climate change, and called for more work to fully account of the relevant economics and how it affects human welfare. According to free-market environmentalist John Baden "the improvement of environment quality depends on the market economy and the existence of legitimate and protected property rights". They enable the effective practice of personal responsibility and the development of mechanisms to protect the environment. The State can in this context "create conditions which encourage the people to save the environment".

Misum, Mistra Center for Sustainable Markets, based at Stockholm School of Economics, aims to provide policy research and advice to Swedish and international actors on Sustainable Markets. Misum is a cross-disciplinary and multi-stakeholder knowledge center dedicated to sustainability and sustainable markets and contains three research platforms: Sustainability in Financial Markets (Mistra Financial Systems), Sustainability in Production and Consumption and Sustainable Socio-Economic Development.

The total environment includes not just the biosphere of earth, air, and water, but also human interactions with these things, with nature, and what humans have created as their surroundings.

As countries around the world continue to advance economically, they put a strain on the ability of the natural environment to absorb the high level of pollutants that are created as a part of this economic growth. Therefore, solutions need to be found so that the economies of the world can continue to grow, but not at the expense of the public good. In the world of economics the amount of environmental quality must be considered as limited in supply and therefore is treated as a scarce resource. This is a resource to be protected. One common way to analyze possible outcomes of policy decisions on the scarce resource is to do a cost-benefit analysis. This type of analysis contrasts different options of resource allocation and, based on an evaluation of the expected courses of action and the consequences of these actions, the optimal way to do so in the light of different policy goals can be elicited.

Benefit-cost analysis basically can look at several ways of solving a problem and then assigning the best route for a solution, based on the set of consequences that would result from the further development of the individual courses of action, and then choosing the course of action that results in the least amount of damage to the expected outcome for the environmental quality that remains after that development or process takes place. Further complicating this analysis are the interrelationships of the various parts of the environment that might be impacted by the chosen course of action. Sometimes it is almost impossible to predict the various outcomes of a course of action, due to the unexpected consequences and the amount of unknowns that are not accounted for in the benefit-cost analysis.

Sustainable energy is clean and can be used over a long period of time. Unlike fossil fuels and biofuels that provide the bulk of the worlds energy, renewable energy sources like hydroelectric, solar and wind energy produce far less pollution. Solar energy is commonly used on public parking meters, street lights and the roof of buildings. Wind power has expanded quickly, its share of worldwide electricity usage at the end of 2014 was 3.1%. Most of California's fossil fuel infrastructures are sited in or near low-income communities, and have traditionally suffered the most from California's fossil fuel energy system. These communities are historically left out during the decision-making process, and often end up with dirty power plants and other dirty energy projects that poison the air and harm the area. These toxicants are major contributors to health problems in the communities. As renewable energy becomes more common, fossil fuel infrastructures are replaced by renewables, providing better social equity to these communities.
Overall, and in the long run, sustainable development in the field of energy is also deemed to contribute to economic sustainability and national security of communities, thus being increasingly encouraged through investment policies.

Main article: Green manufacturing and Distributed manufacturing

One of the core concepts in sustainable development is that technology can be used to assist people meet their developmental needs. Technology to meet these sustainable development needs is often referred to as appropriate technology, which is an ideological movement (and its manifestations) originally articulated as intermediate technology by the economist E. F. Schumacher in his influential work, "Small is Beautiful." and now covers a wide range of technologies. Both Schumacher and many modern-day proponents of appropriate technology also emphasise the technology as people-centered. Today appropriate technology is often developed using open source principles, which have led to open-source appropriate technology (OSAT) and thus many of the plans of the technology can be freely found on the Internet. OSAT has been proposed as a new model of enabling innovation for sustainable development.

Transportation is a large contributor to greenhouse gas emissions. It is said that one-third of all gasses produced are due to transportation. Motorized transport also releases exhaust fumes that contain particulate matter which is hazardous to human health and a contributor to climate change.

Sustainable transport has many social and economic benefits that can accelerate local sustainable development. According to a series of reports by the Low Emission Development Strategies Global Partnership (LEDS GP), sustainable transport can help create jobs, improve commuter safety through investment in bicycle lanes and pedestrian pathways, make access to employment and social opportunities more affordable and efficient. It also offers a practical opportunity to save people's time and household income as well as government budgets, making investment in sustainable transport a 'win-win' opportunity.

Some Western countries are making transportation more sustainable in both long-term and short-term implementations. An example is the modification in available transportation in Freiburg, Germany. The city has implemented extensive methods of public transportation, cycling, and walking, along with large areas where cars are not allowed.

Since many Western countries are highly automobile-oriented, the main transit that people use is personal vehicles. About 80% of their travel involves cars. Therefore, California, is one of the highest greenhouse gases emitters in the United States. The federal government has to come up with some plans to reduce the total number of vehicle trips in order to lower greenhouse gases emission. Such as:


Other states and nations have built efforts to translate knowledge in behavioral economics into evidence-based sustainable transportation policies.

The most broadly accepted criterion for corporate sustainability constitutes a firm's efficient use of natural capital. This eco-efficiency is usually calculated as the economic value added by a firm in relation to its aggregated ecological impact. This idea has been popularised by the World Business Council for Sustainable Development (WBCSD) under the following definition: "Eco-efficiency is achieved by the delivery of competitively priced goods and services that satisfy human needs and bring quality of life, while progressively reducing ecological impacts and resource intensity throughout the life-cycle to a level at least in line with the earth's carrying capacity" (DeSimone and Popoff, 1997: 47).

Similar to the eco-efficiency concept but so far less explored is the second criterion for corporate sustainability. Socio-efficiency describes the relation between a firm's value added and its social impact. Whereas, it can be assumed that most corporate impacts on the environment are negative (apart from rare exceptions such as the planting of trees) this is not true for social impacts. These can be either positive (e.g. corporate giving, creation of employment) or negative (e.g. work accidents, mobbing of employees, human rights abuses). Depending on the type of impact socio-efficiency thus either tries to minimise negative social impacts (i.e. accidents per value added) or maximise positive social impacts (i.e. donations per value added) in relation to the value added.

Both eco-efficiency and socio-efficiency are concerned primarily with increasing economic sustainability. In this process they instrumentalise both natural and social capital aiming to benefit from win-win situations. However, as Dyllick and Hockerts point out the business case alone will not be sufficient to realise sustainable development. They point towards eco-effectiveness, socio-effectiveness, sufficiency, and eco-equity as four criteria that need to be met if sustainable development is to be reached.

CASI Global, New York "CSR & Sustainability together lead to sustainable development.
CSR as in corporate social responsibility is not what you do with your profits, but is the way you make profits. This means CSR is a part of every department of the company value chain and not a part of HR / independent department. Sustainability as in effects towards Human resources, Environment and Ecology has to be measured within each department of the company." http://casiglobal.us/

At the present time, sustainable development can reduce poverty. Sustainable development reduces poverty through financial (among other things, a balanced budget), environmental (living conditions), and social (including equality of income) means.

In sustainable architecture the recent movements of New Urbanism and New Classical architecture promote a sustainable approach towards construction, that appreciates and develops smart growth, architectural tradition and classical design. This in contrast to modernist and International Style architecture, as well as opposing to solitary housing estates and suburban sprawl, with long commuting distances and large ecological footprints. Both trends started in the 1980s. (It should be noted that sustainable architecture is predominantly relevant to the economics domain while architectural landscaping pertains more to the ecological domain.)

A study concluded that social indicators and, therefore, sustainable development indicators, are scientific constructs whose principal objective is to inform public policy-making. The International Institute for Sustainable Development has similarly developed a political policy framework, linked to a sustainability index for establishing measurable entities and metrics. The framework consists of six core areas, international trade and investment, economic policy, climate change and energy, measurement and assessment, natural resource management, and the role of communication technologies in sustainable development.

The United Nations Global Compact Cities Programme has defined sustainable political development in a way that broadens the usual definition beyond states and governance. The political is defined as the domain of practices and meanings associated with basic issues of social power as they pertain to the organisation, authorisation, legitimation and regulation of a social life held in common. This definition is in accord with the view that political change is important for responding to economic, ecological and cultural challenges. It also means that the politics of economic change can be addressed. They have listed seven subdomains of the domain of politics:


This accords with the Brundtland Commission emphasis on development that is guided by human rights principles (see above).

Working with a different emphasis, some researchers and institutions have pointed out that a fourth dimension should be added to the dimensions of sustainable development, since the triple-bottom-line dimensions of economic, environmental and social do not seem to be enough to reflect the complexity of contemporary society. In this context, the Agenda 21 for culture and the United Cities and Local Governments (UCLG) Executive Bureau lead the preparation of the policy statement "Culture: Fourth Pillar of Sustainable Development", passed on 17 November 2010, in the framework of the World Summit of Local and Regional Leaders – 3rd World Congress of UCLG, held in Mexico City. This document inaugurates a new perspective and points to the relation between culture and sustainable development through a dual approach: developing a solid cultural policy and advocating a cultural dimension in all public policies. The Circles of Sustainability approach distinguishes the four domains of economic, ecological, political and cultural sustainability.

Other organizations have also supported the idea of a fourth domain of sustainable development. The Network of Excellence "Sustainable Development in a Diverse World", sponsored by the European Union, integrates multidisciplinary capacities and interprets cultural diversity as a key element of a new strategy for sustainable development. The Fourth Pillar of Sustainable Development Theory has been referenced by executive director of IMI Institute at UNESCO Vito Di Bari in his manifesto of art and architectural movement Neo-Futurism, whose name was inspired by the 1987 United Nations’ report Our Common Future. The Circles of Sustainability approach used by Metropolis defines the (fourth) cultural domain as practices, discourses, and material expressions, which, over time, express continuities and discontinuities of social meaning.

The United Nations Conference on Sustainable Development (UNCSD; also known as Rio 2012) was the third international conference on sustainable development, which aimed at reconciling the economic and environmental goals of the global community. An outcome of this conference was the development of the Sustainable Development Goals that aim to promote sustainable progress and eliminate inequalities around the world. However, few nations met the World Wide Fund for Nature's definition of sustainable development criteria established in 2006. Although some nations are more developed than others, all nations are constantly developing because each nation struggles with perpetuating disparities, inequalities and unequal access to fundamental rights and freedoms.

In 2007 a report for the U.S. Environmental Protection Agency stated: "While much discussion and effort has gone into sustainability indicators, none of the resulting systems clearly tells us whether our society is sustainable. At best, they can tell us that we are heading in the wrong direction, or that our current activities are not sustainable. More often, they simply draw our attention to the existence of problems, doing little to tell us the origin of those problems and nothing to tell us how to solve them." Nevertheless, a majority of authors assume that a set of well defined and harmonised indicators is the only way to make sustainability tangible. Those indicators are expected to be identified and adjusted through empirical observations (trial and error).

The most common critiques are related to issues like data quality, comparability, objective function and the necessary resources. However a more general criticism is coming from the project management community: How can a sustainable development be achieved at global level if we cannot monitor it in any single project?

The Cuban-born researcher and entrepreneur Sonia Bueno suggests an alternative approach that is based upon the integral, long-term cost-benefit relationship as a measure and monitoring tool for the sustainability of every project, activity or enterprise. Furthermore, this concept aims to be a practical guideline towards sustainable development following the principle of conservation and increment of value rather than restricting the consumption of resources.

Reasonable qualifications of sustainability are seen U.S. Green Building Council's (USGBC) Leadership in Energy and Environmental Design (LEED). This design incorporates some ecological, economic, and social elements. The goals presented by LEED design goals are sustainable sites, water efficiency, energy and atmospheric emission reduction, material and resources efficiency, and indoor environmental quality. Although amount of structures for sustainability development is many, these qualification has become a standard for sustainable building.

Recent research efforts created also the SDEWES Index to benchmark the performance of cities across aspects that are related to energy, water and environment systems. The SDEWES Index consists of 7 dimensions, 35 indicators, and close to 20 sub-indicators. It is currently applied to 58 cities.

The sustainable development debate is based on the assumption that societies need to manage three types of capital (economic, social, and natural), which may be non-substitutable and whose consumption might be irreversible. Leading ecological economist and steady-state theorist Herman Daly, for example, points to the fact that natural capital can not necessarily be substituted by economic capital. While it is possible that we can find ways to replace some natural resources, it is much more unlikely that they will ever be able to replace eco-system services, such as the protection provided by the ozone layer, or the climate stabilizing function of the Amazonian forest. In fact natural capital, social capital and economic capital are often complementarities. A further obstacle to substitutability lies also in the multi-functionality of many natural resources. Forests, for example, not only provide the raw material for paper (which can be substituted quite easily), but they also maintain biodiversity, regulate water flow, and absorb CO2.

Another problem of natural and social capital deterioration lies in their partial irreversibility. The loss of biodiversity, for example, is often definitive. The same can be true for cultural diversity. For example, with globalisation advancing quickly the number of indigenous languages is dropping at alarming rates. Moreover, the depletion of natural and social capital may have non-linear consequences. Consumption of natural and social capital may have no observable impact until a certain threshold is reached. A lake can, for example, absorb nutrients for a long time while actually increasing its productivity. However, once a certain level of algae is reached lack of oxygen causes the lake's ecosystem to break down suddenly.

If the degradation of natural and social capital has such important consequence the question arises why action is not taken more systematically to alleviate it. Cohen and Winn point to four types of market failure as possible explanations: First, while the benefits of natural or social capital depletion can usually be privatised, the costs are often externalised (i.e. they are borne not by the party responsible but by society in general). Second, natural capital is often undervalued by society since we are not fully aware of the real cost of the depletion of natural capital. Information asymmetry is a third reason—often the link between cause and effect is obscured, making it difficult for actors to make informed choices. Cohen and Winn close with the realization that contrary to economic theory many firms are not perfect optimisers. They postulate that firms often do not optimise resource allocation because they are caught in a "business as usual" mentality.

"Main page: Education for sustainable development"

Education must be revisited in light of a renewed vision of sustainable human and social development that is both equitable and viable. This vision of sustainability must take into consideration the social, environmental and economic dimensions of human development and the various ways in which these relate to education: ‘An empowering education is one that builds the human resources we need to be productive, to continue to learn, to solve problems, to be creative, and to live together and with nature in peace and harmony. When nations ensure that such an education is accessible to all throughout their lives, a quiet revolution is set in motion: education becomes the engine of sustainable development and the key to a better world.’

Higher education in sustainability across education streams including engineering, finance, supply chain and operations is gaining weight-age. Multiple institutes including Wharton, Columbia, CASI Global New York offer certifications in Sustainability.
Corporate's prefer employees certified in sustainability. 
Reference
https://www.wharton.upenn.edu/
http://www.columbia.edu/
http://casiglobal.us/

It has been argued that since the 1960s, the concept of sustainable development has changed from "conservation management" to "economic development", whereby the original meaning of the concept has been stretched somewhat.

In the 1960s, the international community realised that many African countries needed national plans to safeguard wildlife habitats, and that rural areas had to confront the limits imposed by soil, climate and water availability. This was a strategy of conservation management. In the 1970s, however, the focus shifted to the broader issues of the provisioning of basic human needs, community participation as well as appropriate technology use throughout the developing countries (and not just in Africa). This was a strategy of economic development, and the strategy was carried even further by the Brundtland Commission's report on "Our Common Future" when the issues went from regional to international in scope and application. In effect, the conservationists were crowded out and superseded by the developers.

But shifting the focus of sustainable development from conservation to development has had the imperceptible effect of stretching the original forest management term of sustainable yield from the use of renewable resources only (like forestry), to now also accounting for the use of non-renewable resources (like minerals). This stretching of the term has been questioned. Thus, environmental economist Kerry Turner has argued that literally, there can be no such thing as overall "sustainable development" in an industrialised world economy that remains heavily dependent on the extraction of earth's finite stock of exhaustible mineral resources: "It makes no sense to talk about the sustainable use of a non-renewable resource (even with substantial recycling effort and use rates). Any positive rate of exploitation will eventually lead to exhaustion of the finite stock."

In effect, it has been argued that the industrial revolution as a whole is unsustainable.

One critic has argued that the Brundtland Commission promoted nothing but a business as usual strategy for world development, with the ambiguous and insubstantial concept of "sustainable development" attached as a public relations slogan: The report on "Our Common Future" was largely the result of a political bargaining process involving many special interest groups, all put together to create a common appeal of political acceptability across borders. After World War II, the notion of "development" had been established in the West to imply the projection of the American model of society onto the rest of the world. In the 1970s and 1980s, this notion was broadened somewhat to also imply human rights, basic human needs and finally, ecological issues. The emphasis of the report was on helping poor nations out of poverty and meeting the basic needs of their growing populations—as usual. This issue demanded more economic growth, also in the rich countries, who would then import more goods from the poor countries to help them out—as usual. When the discussion switched to , the obvious dilemma was left aside by calling for economic growth with improved resource efficiency, or what was termed "a change in the "quality" of growth". However, most countries in the West had experienced such improved resource efficiency since the early-20th century already and as usual; only, this improvement had been more than offset by continuing industrial expansion, to the effect that world resource consumption was now higher than ever before—and these two historical trends were completely ignored in the report. Taken together, the policy of perpetual economic growth for the entire planet remained virtually intact. Since the publication of the report, the ambiguous and insubstantial slogan of "sustainable development" has marched on worldwide.




</doc>
<doc id="29507" url="https://en.wikipedia.org/wiki?curid=29507" title="Scientific American">
Scientific American

Scientific American (informally abbreviated SciAm) is an American popular science magazine. Many famous scientists, including Albert Einstein, have contributed articles to it. It is the oldest continuously published monthly magazine in the United States (though it only became monthly in 1921).

"Scientific American" was founded by inventor and publisher Rufus M. Porter in 1845 as a four-page weekly newspaper. Throughout its early years, much emphasis was placed on reports of what was going on at the U.S. Patent Office. It also reported on a broad range of inventions including perpetual motion machines, an 1860 device for buoying vessels by Abraham Lincoln, and the universal joint which now can be found in nearly every automobile manufactured. Current issues include a "this date in history" section, featuring excerpts from articles originally published 50, 100, and 150 years earlier. Topics include humorous incidents, wrong-headed theories, and noteworthy advances in the history of science and technology.

Porter sold the publication to Alfred Ely Beach and Orson Desaix Munn a mere ten months after founding it. Until 1948, it remained owned by Munn & Company. Under Munn's grandson, Orson Desaix Munn III, it had evolved into something of a "workbench" publication, similar to the twentieth-century incarnation of "Popular Science".

In the years after World War II, the magazine fell into decline. In 1948, three partners who were planning on starting a new popular science magazine, to be called "The Sciences", purchased the assets of the old "Scientific American" instead and put its name on the designs they had created for their new magazine. Thus the partnerspublisher Gerard Piel, editor Dennis Flanagan, and general manager Donald H. Miller, Jr.essentially created a new magazine. Miller retired in 1979, Flanagan and Piel in 1984, when Gerard Piel's son Jonathan became president and editor; circulation had grown fifteen-fold since 1948. In 1986, it was sold to the Holtzbrinck group of Germany, which has owned it since.

In the fall of 2008, "Scientific American" was put under the control of Nature Publishing Group, a division of Holtzbrinck.

Donald Miller died in December 1998, Gerard Piel in September 2004 and Dennis Flanagan in January 2005. Mariette DiChristina is the current editor-in-chief, after John Rennie stepped down in June 2009.

"Scientific American" published its first foreign edition in 1890, the Spanish-language "La America Cientifica". Publication was suspended in 1905, and another 63 years would pass before another foreign-language edition appeared: In 1968, an Italian edition, "Le Scienze", was launched, and a Japanese edition, "Nikkei Science" (), followed three years later. A new Spanish edition, "Investigación y Ciencia" was launched in Spain in 1976, followed by a French edition, "", in France in 1977, and a German edition, "", in Germany in 1978. A Russian edition "V Mire Nauki" was launched in the Soviet Union in 1983, and continues in the present-day Russian Federation. "Kexue" (科学, "Science" in Chinese), a simplified Chinese edition launched in 1979, was the first Western magazine published in the People's Republic of China. Founded in Chongqing, the simplified Chinese magazine was transferred to Beijing in 2001. Later in 2005, a newer edition, "Global Science" (环球科学), was published instead of "Kexue", which shut down due to financial problems. A traditional Chinese edition, known as ("Scientist" in Chinese), was introduced to Taiwan in 2002. The Hungarian edition "Tudomány" existed between 1984 and 1992. In 1986, an Arabic edition, "Oloom magazine" (), was published. In 2002, a Portuguese edition was launched in Brazil.

Today, "Scientific American" publishes 18 foreign-language editions around the globe: Arabic, Brazilian Portuguese, Simplified Chinese, Traditional Chinese, Czech, Dutch, French, German, Greek, Hebrew, Italian, Japanese, Korean, Lithuanian (discontinued after 15 issues), Polish, Romanian, Russian, and Spanish.

From 1902 to 1911, "Scientific American" supervised the publication of the "Encyclopedia Americana", which during some of that period was known as "The Americana".

It originally styled itself "The Advocate of Industry and Enterprise" and "Journal of Mechanical and other Improvements". On the front page of the first issue was the engraving of "Improved Rail-Road Cars". The masthead had a commentary as follows:

The commentary under the illustration gives the flavor of its style at the time:
Also in the first issue is commentary on Signor Muzio Muzzi's proposed device for aerial navigation.



The Scientific American 50 award was started in 2002 to recognize contributions to science and technology during the magazine's previous year. The magazine's 50 awards cover many categories including agriculture, communications, defence, environment, and medical diagnostics. The complete list of each year's winners appear in the December issue of the magazine, as well as on the magazine's web site.

In March 1996, "Scientific American" launched its own website that includes articles from current and past issues, online-only features, daily news, weird science, special reports, trivia, "Scidoku" and more.

Notable features have included:

From 1990 to 2005 "Scientific American" also produced a television program on PBS called "Scientific American Frontiers".

From 1983 to 1997, "Scientific American" has produced an encyclopedia set of volumes from their publishing division, the Scientific American Library. These books were not sold in retail stores, but as a Book of the Month Club selection priced from $24.95 to $32.95. Topics covered dozens of areas of scientific knowledge and included in-depth essays on: The Animal Mind; Atmosphere, Climate, and Change; Beyond the Third Dimension; Cosmic Clouds; Cycles of Life • Civilization and the Biosphere; The Discovery Of Subatomic Particles; Diversity and the Tropical Rain Forest; Earthquakes and Geological Discovery; Exploring Planetary Worlds; Gravity's Fatal Attraction; Fire; Fossils And The History Of Life; From Quarks to the Cosmos; A Guided Tour Of The Living Cell; Human Diversity; Perception; The Solar System; Sun and Earth; The Science of Words (Linguistics); The Science Of Musical Sound; The Second Law (of Thermodynamics); Stars; Supercomputing and the Transformation of Science.

Scientific American launched a publishing imprint in 2010 in partnership with Farrar, Straus and Giroux.


In April 1950, the U.S. Atomic Energy Commission ordered "Scientific American" to cease publication of an issue containing an article by Hans Bethe that appeared to reveal classified information about the thermonuclear hydrogen bomb. Subsequent review of the material determined that the AEC had overreacted. The incident was important for the "new" "Scientific American"'s history, as the AEC's decision to burn 3000 copies of an early press-run of the magazine containing the offending material appeared to be "book burning in a free society" when publisher Gerard Piel leaked the incident to the press.

In its January 2002 issue, "Scientific American" published a series of criticisms of the Bjørn Lomborg book "The Skeptical Environmentalist". Cato Institute fellow Patrick J. Michaels said the attacks came because the book "threatens billions of taxpayer dollars that go into the global change kitty every year." Journalist Ronald Bailey called the criticism "disturbing" and "dishonest", writing, "The subhead of the review section, 'Science defends itself against "The Skeptical Environmentalist",' gives the show away: Religious and political views need to defend themselves against criticism, but science is supposed to be a process for determining the facts."

The May 2007 issue featured a column by Michael Shermer calling for a United States pullout from the Iraq War. In response, "Wall Street Journal" online columnist James Taranto jokingly called "Scientific American" "a liberal political magazine".

The publisher was criticized in 2009 when it notified collegiate libraries that subscribe to the journal that yearly subscription prices would increase by nearly 500% for print and 50% for online access to $1500 yearly.

An editorial in the September 2016 issue of Scientific American attacked U.S. presidential candidate Donald Trump for alleged "anti-science" attitudes and rhetoric. This marked the first time that the publication forayed into commenting on U.S. presidential politics.



In 2013, Danielle N. Lee, a female scientist who blogged at "Scientific American", was called a "whore" in an email by an editor at the science website "Biology Online" after refusing to write professional content without compensation. When Lee, outraged about the email, wrote a rebuttal on her "Scientific American" blog, the editor-in-chief of "Scientific American", Mariette DiChristina, removed the post, sparking an outrage by supporters of Lee. While DiChristina cited legal reasons for removing the blog, others criticized her for censoring Lee. The editor at Biology Online was fired after the incident.

The controversy widened in the ensuing days. The magazine's blog editor, Bora Zivkovic, was the subject of allegations of sexual harassment by another blogger, Monica Byrne. Although the alleged incident had occurred about a year earlier, editor Mariette DiChristina informed readers that the incident had been investigated and resolved to Ms. Byrne's satisfaction. However, the incident involving Dr. Lee had prompted Ms. Byrne to reveal the identity of Zivkovic, following the latter's support of Dr. Lee. Zivkovic responded on Twitter and his own blog, admitting the incident with Ms. Byrne had taken place. His blog post apologized to Ms. Byrne, and referred to the incident as "singular", stating that his behavior was not "engaged in before or since."

Due to the allegations, Zivkovic resigned from the board of Science Online, the popular science blogging conference that he helped establish. Following Zivkovic's admission, several prominent female bloggers, including other bloggers for the magazine, wrote their own accounts that contradicted Zivkovic's assertions, alleging additional incidents of sexual harassment. A day after these new revelations, Zivkovic resigned his position at "Scientific American", according to a press release from the magazine.




</doc>
<doc id="29511" url="https://en.wikipedia.org/wiki?curid=29511" title="Siouxsie and the Banshees">
Siouxsie and the Banshees

Siouxsie and the Banshees were an English rock band, formed in London in 1976 by vocalist Siouxsie Sioux and bass guitarist Steven Severin. They have been widely influential, both over their contemporaries and with later acts. "Mojo" rated guitarist John McGeoch in their list of "100 Greatest Guitarists of All Time" for his work on "Spellbound". "The Times" cited the group as "one of the most audacious and uncompromising musical adventurers of the post-punk era".

Initially associated with the punk scene, the band rapidly evolved to create "a form of post-punk discord full of daring rhythmic and sonic experimentation". Their debut album "The Scream" was released in 1978 to critical acclaim. In 1980, they changed their musical direction and became "almost a different band" with "Kaleidoscope", which peaked at number 5 in the UK Albums Chart. With "Juju" (1981) which also reached the top 10, they became an influence on the emerging gothic scene. In 1988, the band made a breakthrough in North America with the multifaceted album "Peepshow", which received critical praise. With substantial support from alternative rock radio stations, they achieved a mainstream hit in the US in 1991 with the single "Kiss Them for Me".

During their career, Siouxsie and the Banshees released 11 studio albums and 30 singles. The band experienced several line-up changes, with Siouxsie and Severin being the only constant members. They disbanded in 1996, with Siouxsie and drummer Budgie continuing to record music as the Creatures, a second band they had formed in the early 1980s. In 2004, Siouxsie began a solo career.

Siouxsie Sioux and Steven Severin met at a Roxy Music concert in September 1975, at a time when glam rock had faded and there was nothing new coming through with which they could identify. From February 1976, Siouxsie, Severin and some friends began to follow an unsigned band, the Sex Pistols. Journalist Caroline Coon dubbed them the "Bromley Contingent", as most of them came from the Bromley region of South London, a label Severin came to despise. "There was no such thing, it was just a bunch of people drawn together by the way they felt and they looked". They were all inspired by the Sex Pistols and their uncompromising attitude. When they learned that one of the bands scheduled to play the 100 Club Punk Festival, organised by Sex Pistols manager Malcolm McLaren, were pulling out from the bill at the last minute, Siouxsie suggested that she and Severin play, even though they had no band name or additional members. Two days later, the pair appeared at the festival held in London on 20 September 1976. With two borrowed musicians at their side, Marco Pirroni on guitar and John Simon Ritchie (already commonly known as Sid Vicious) on drums, their set consisted of a 20-minute improvisation based on "The Lord's Prayer".

While the band intended to split up after the gig, they were asked to play again. Two months later, Siouxsie and Severin recruited drummer Kenny Morris and guitarist Peter Fenton. After playing several gigs in early 1977, they realised that Fenton did not fit in because he was "a real rock guitarist". John McKay finally took his place in July. Their first live appearance on television took place in November on Manchester's Granada, on Tony Wilson's TV show "So It Goes". They then recorded their first John Peel session for BBC radio and appeared on the front cover of UK weekly "Sounds" magazine the following month.

While the band sold out venues in London in early 1978, they still had problems getting the right recording contract that could give them "complete artistic control". Polydor finally offered this guarantee and signed them in June. Their first single, "Hong Kong Garden", featuring a xylophone motif, reached the top 10 in the UK shortly after. A "NME" review hailed it as "a bright, vivid narrative, something like snapshots from the window of a speeding Japanese train, power charged by the most original, intoxicating guitar playing I heard in a long, long time".

The band released their debut album, "The Scream", in November 1978. Nick Kent of "NME" said of the record: "The band sounds like some unique hybrid of the Velvet Underground mated with much of the ingenuity of "Tago Mago"-era Can, if any parallel can be drawn". At the end of the article, he added this remark: "Certainly, the traditional three-piece sound has never been used in a more unorthodox fashion with such stunning results".

The Banshees' second album, "Join Hands", was released in 1979. In "Melody Maker", Jon Savage described "Poppy Day" as "a short, powerful evocation of the Great War graveyards", and "Record Mirror" described the whole record as a dangerous work that "should be heard". The Banshees embarked on a major tour to promote the album. A few dates into the tour in September, Morris and McKay left an in-store signing after an argument and quit the band. In need of replacements to fulfill tour dates, the Banshees' manager called drummer Budgie, formerly with the Slits, and asked him to audition. Budgie was hired, but Siouxsie and Severin had no success auditioning guitarists. Robert Smith of the Cure offered his services in case they could not find a guitarist (his group were already the support band on the tour), so the band held him to it after seeing too many "rock virtuosos". The tour resumed in September and after the last concert, Smith returned to the Cure.

Drummer Budgie became a permanent member, and the band entered the studios to record the single "Happy House" with guitarist John McGeoch, formerly of Magazine. Their third album, "Kaleidoscope", released in 1980, saw the Banshees exploring new musical territories with the use of other instruments like synthesizers, sitars and drum machines. The group initially had a concept of making each song sound completely different, without regard to whether or not the material could be performed in concert. "Melody Maker" described the result as "a kaleidoscope of sound and imagery, new forms, and content, flashing before our eyes". "Kaleidoscope" was a commercial success, peaking at number 5 in the UK album chart. This lineup, featuring McGeoch on guitar, toured the United States for the first time in support of the album, playing their first shows in New York City in November 1980.
For "Juju" (1981), the band took a different approach and practised the songs in concert first before recording them. "Juju", according to Severin, became an unintentional concept album that "drew on darker elements". "Sounds" hailed it as "intriguing, intense, brooding and powerfully atmospheric". The album later peaked at number 7 in the UK album chart and became one of their biggest sellers. McGeoch's guitar contributions on "Juju" would be later praised by Johnny Marr of the Smiths.

During the 1981 accompanying tour, Siouxsie and Budgie secretly became a couple. At the same time, they also began a drum-and-voice duo called the Creatures, releasing their first EP, "Wild Things".

The Banshees followed in 1982 with the psychedelic "A Kiss in the Dreamhouse". The record, featuring strings on several numbers, was an intentional contrast to their previous work, with Severin later describing it as a "sexy album". The British press greeted it enthusiastically. Richard Cook finished his "NME" review with this sentence: "I promise...this music will take your breath away". At that time, McGeoch was struggling with alcohol problems, and was hospitalised on his return to a promotional trip from Madrid. The band fired him shortly thereafter. Severin asked Robert Smith to take over guitarist duties again; Smith accepted and rejoined the group in November 1982.

During 1983, the band members worked on several side projects; Siouxsie and Budgie composed the first Creatures album, "Feast", while Severin and Smith recorded as the Glove. Smith then insisted on documenting his time with the Banshees, so the group released a cover version of the Beatles' "Dear Prudence" in September 1983. It became their biggest hit, reaching number 3 on the UK Singles Chart. They also released a live album, "Nocturne", and completed their sixth studio album, "Hyæna". Shortly before its release in May 1984, Smith left the group, citing health issues due to an overloaded schedule, being in two bands at once.

Ex-Clock DVA guitarist John Valentine Carruthers replaced him. The Banshees then reworked four numbers from their repertoire, augmented by a string section, for their "The Thorn" EP. "NME" praised the project at its release: "The power of a classical orchestra is the perfect foil for the band's grindingly insistent sounds". The new Banshees lineup spent much of 1985 working on a new record, "Tinderbox". The group finished the song "Cities in Dust" before the album, so they rushed its release as a single prior to their longest tour of the UK. "Tinderbox" was finally released in April 1986. "Sounds" magazine noted: ""Tinderbox" is a refreshing slant on the Banshees' disturbing perspective and restores their vivid shades to pop's pale palette". Due to the length of time spent working on "Tinderbox", the group desired spontaneity and decided to record an album of cover songs, "Through the Looking Glass", in 1987. "Mojo" magazine later praised their version of "Strange Fruit". After the album's release, the band realised Carruthers was no longer fitting in and decided to work on new material as a trio.

Following a lengthy break, the band recruited multi-instrumentalist Martin McCarrick and guitarist Jon Klein. The quintet recorded "Peepshow" in 1988, with non-traditional rock instrumentation including cello and accordion. "Q" magazine praised the album in its 5-star review: ""Peepshow" takes place in some distorted fairground of the mind where weird and wonderful shapes loom". The first single, "Peek-a-Boo", was seen by critics as a "brave move" with horns and dance elements. "Sounds" wrote: "The snare gets slapped, Siouxsie's voice meanders all around your head and it all comes magically together". "Peek-a-Boo" was their first real breakthrough in the United States. After the tour, the band decided to take a break, with Siouxsie and Budgie recording as the Creatures and releasing their most critically acclaimed album to date, "Boomerang", and Severin and McCarrick working on material together.

In 1991, Siouxsie and the Banshees returned with the single "Kiss Them for Me", mixing strings over a dance rhythm laced with exotica. The group collaborated with the then unknown Asian Tabla player Talvin Singh, who also sang during the bridge. The single received glowing reviews and later peaked in the "Billboard" Hot 100 at number 23, allowing them to reach a new audience. The album "Superstition" followed shortly afterwards, and the group toured the US as second headliners of the inaugural Lollapalooza tour. The following year, the Banshees were asked to compose "Face to Face" as a single for the film "Batman Returns" to Tim Burton's request.

In 1993, the Banshees recorded new songs based on string arrangements, but quickly stopped the sessions to play festivals abroad. On their return home, they hired former Velvet Underground member John Cale to produce the rest of the record. At its release, 1995's "The Rapture" was described by "Melody Maker" as "a fascinating, transcontinental journey through danger and exotica". A few weeks after its release, Polydor dropped the band from its roster and Klein was replaced on the band's last tour in 1995 by ex-Psychedelic Furs guitarist Knox Chandler. In April 1996, the band finally disbanded after 20 years of working together. Siouxsie and Budgie announced that they would carry on recording as the Creatures. In 1999, they released the album "Anima Animus" to critical acclaim.

In 2002, Universal Music kicked off the band's remastered back catalogue by releasing "The Best of Siouxsie and the Banshees". In April, Siouxsie, Severin, Budgie and Chandler reunited briefly for the Seven Year Itch tour, which spawned the "Seven Year Itch" live album and DVD in 2003. The day after their last concert in Tokyo, Japan, Siouxsie and Budgie stayed in town on their own and entered into a recording studio as the Creatures. Their fourth and final studio album, "Hái!", came out a few months later.

In 2004, "Downside Up", a box set that collected all of the Banshees' B-sides and "The Thorn" EP, was released. "The Times" wrote in its review: "for here is a group that never filled B-sides with inferior, throwaway tracks. Rather they saw them as an outlet for some of their most radical and challenging work".

In 2006, the band's first four records were remastered and compiled with previously unreleased bonus tracks. Several recordings made for the John Peel radio show from 1978 to 1986 were also compiled on "". AllMusic described the first session as "a fiery statement of intent" and qualified the other performances as "excellent". The second batch of remasters, concerning the 1982–1986 era, was issued in April 2009. It included four other reissues (including their highly regarded "A Kiss in the Dreamhouse" from 1982). The "At the BBC" box set, containing a DVD with all of the band's UK live television performances and three CDs with in-concert recordings, was also released in June of the same year.

In April 2014, their debut single "Hong Kong Garden" was reissued on double 7" vinyl. It was announced that this would be part of a three-year plan with Universal. In late October, their last four studio albums (1987's "Through the Looking Glass", 1988's "Peepshow", 1991's "Superstition" and 1995's "The Rapture") were reissued on CD in remastered versions with bonus tracks. Siouxsie and Severin curated a compilation CD called "It's a Wonderfull Life" for the monthly magazine "Mojo", issued on 30 September with Siouxsie on the front cover. On this CD, the pair honoured several composers of film music and classical music that had inspired them.

In 2015, after releasing another compilation called "Spellbound: The Collection", which included singles, album tracks and B-sides, the band reissued 1979's "Join Hands" on vinyl for Record Store Day, with different cover artwork. A CD box set titled "Classic Album Selection, Vol. 1" was released in January 2016, containing their first six albums newly remastered by Kevin Metcalfe. "Classic Album Selection, Vol. 2", including the other last six albums, followed in April. In November, a vinyl picture disc edition of "The Scream" was released.

Vinyl reissues of all of the band's albums, remastered from the original ¼” tapes and cut at half speed at Abbey Road studios by Miles Showell, are scheduled to be released beginning on 17 August 2018. The first batch includes "Tinderbox", "Juju", "Through the Looking Glass" and "Join Hands".

Siouxsie and the Banshees have been described as developing "a form of post-punk discord full of daring rhythmic and sonic experimentation". "The Times" wrote that "The Banshees stand proudly [... as] one of the most audacious and uncompromising musical adventurers of the post-punk era". With some of their darkest material, the band also helped spawn the gothic rock scene. The band are also considered as a new wave act.

They were also one of the first alternative bands; music historian Peter Buckley pointed out that they were at "the very front of the alternative-rock scene". In 1988, "Peek-a-Boo" was the very first track to top the US Modern Rock chart after "Billboard" launched this chart in the first week of September to list the most played songs on alternative and college radio stations. Simon Goddard wrote that the "Banshees - Mk II would become one of the biggest alternative pop groups of the 1980s". "Spin" described them as "alternative rockers" in 1991 when referring to their presence in the top 40 chart. Noting the band's participation in the first Lollapalooza festival, journalist Jim Gerr saw them as one of the "elements of the alternative rock community". "Mojo" retrospectively presented them as one of "alternative rock's iconic groups".

Siouxsie and the Banshees have influenced many later genres including post-punk, new wave, synth pop, gothic rock, alternative music, shoegazing and trip-hop, influencing a wide range of musicians including Joy Division, the Cure, the Smiths, Depeche Mode, PJ Harvey, Radiohead, Tricky and LCD Soundsystem.

Joy Division's Peter Hook, who saw the group in concert in Manchester in 1977, said: "Siouxsie and the Banshees were one of our big influences [...] The Banshees first LP was one of my favourite ever records, the way the guitarist and the drummer played was a really unusual way of playing". Joy Division producer Martin Hannett saw a difference between the Banshees' first main lineup and the other bands of 1977: "Any harmonies you got were stark, to say the least, except for the odd exception, like Siouxsie. They were interesting". The Cure's leader, Robert Smith, declared in 2003: "Siouxsie and the Banshees and Wire were the two bands I really admired. They meant something." He also pinpointed what the 1979 "Join Hands" tour brought him musically. "On stage that first night with the Banshees, I was blown away by how powerful I felt playing that kind of music. It was so different to what we were doing with the Cure. Before that, I'd wanted us to be like the Buzzcocks or Elvis Costello, the punk Beatles. Being a Banshee really changed my attitude to what I was doing".

The two songwriters of the Smiths cited the band; singer Morrissey said that "Siouxsie and the Banshees were excellent", and that "they were one of the great groups of the late 1970s, early 1980s". He also said in 1994, "If you study modern groups, those who gain press coverage and chart action, none of them are as good as Siouxsie and the Banshees at full pelt. That's not dusty nostalgia, that's fact". Guitarist Johnny Marr, mentioned his liking for Banshees guitarist John McGeoch and his contribution to the single "Spellbound". Marr qualified it as "clever" with a "really good picky thing going on which is very un-rock'n'roll". Smiths' historian Goddard wrote that Marr "praise[d] the McGeoch-era Banshees as a significant inspiration". U2 cited Siouxsie and the Banshees as a major influence and selected "Christine" for a "Mojo" compilation. The Edge was the presenter of an award given to Siouxsie at the "Mojo" ceremony in 2005. In December 1981, Dave Gahan of Depeche Mode named the Banshees as one of his three favourite bands along with Sparks and Roxy Music. Gahan later hailed the single "Candyman" at its release, saying, "This is a great Banshees record[...], I like their sound". Jim Reid of the Jesus and Mary Chain selected "Jigsaw Feeling" from "The Scream" as being among his favourite songs. Thurston Moore of Sonic Youth cited "Hong Kong Garden" in his top 25 all-time favourite songs, and Kevin Shields of My Bloody Valentine also mentioned them as being among his early influences. Dave Navarro of Jane's Addiction once noted a parallel between his band and the Banshees: "There are so many similar threads: melody, use of sound, attitude, sex-appeal. I always saw Jane's Addiction as the masculine Siouxsie and the Banshees". Primal Scream's Bobby Gillespie liked the group's ability to produce pop songs while transmitting something subversive. He said, "They were outsiders bringing outsider subjects to the mainstream. We’re not trying to rip off the Banshees, but that's kind of where we’re coming from".

The Banshees have been hailed by other acts. Thom Yorke related that seeing Siouxsie on stage in concert in 1985 inspired him to become a performer. Radiohead cited McGeoch-era Siouxsie records when mentioning the recording of the song "There There", and rehearsed Banshees' material prior to their 2008 tour. Jeff Buckley, who took inspiration from several female vocalists, covered "Killing Time" (from the "Boomerang" album) on various occasions. Buckley also owned all the Banshees' albums in his record collection. Suede singer Brett Anderson named "Juju" as one of his favourite records in 2011, and also cited three other albums by the band on his website: "The Scream", "Kaleidoscope" and "Tinderbox". Red Hot Chili Peppers performed "Christine" in concert, and their guitarist John Frusciante cited the Banshees in interviews. Garbage singer Shirley Manson stated, "I learned how to sing listening to "The Scream" and "Kaleidoscope". Today, I can see and hear the Banshees' influence all over the place". Siouxsie has also been praised by other female singers including PJ Harvey Courtney Love and Ana Matronic of Scissor Sisters. PJ Harvey has stated, "It's hard to beat Siouxsie Sioux, in terms of live performance. She is so exciting to watch, so full of energy and human raw quality", and selected Siouxsie's album "Anima Animus" in her top 10 albums of 1999. The band had a strong effect on two important trip hop acts. Tricky covered "Tattoo" to open his second album, "Nearly God"; the original 1983 proto-trip-hop version of that song aided Tricky in the creation of his style. Massive Attack, sampled "Metal Postcard" on the song "Superpredators", recorded prior to their "Mezzanine" album. Air's Jean-Benoît Dunckel cited the group as one of his three main influences. Billy Corgan of the Smashing Pumpkins cited the Banshees as an important influence on his music. Faith No More covered "Switch" in concert and cited "The Scream" as one of their influences.

The Banshees continue to influence younger musicians. Singer James Murphy was marked by certain Banshees albums during his childhood. His band LCD Soundsystem covered "Slowdive" as a B-side to the single "Disco Infiltrator". The Beta Band sampled "Painted Bird" on their track "Liquid Bird" from the "Heroes to Zeros" album. TV on the Radio said that they have always tried to make a song that begins like "Kiss Them for Me" where all of a sudden, there's an "element of surprise" with "a giant drum coming in". Santigold based one of her songs around the music of "Red Light". "'My Superman' is an interpolation of 'Red Light'". Indie folk group DeVotchKa covered the ballad "The Last Beat of My Heart" at the suggestion of Arcade Fire singer Win Butler; it was released on the "Curse Your Little Heart" EP. Gossip named the Banshees as one of their major influences during the promotion of their single "Heavy Cross". British indie band Bloc Party took inspiration from "Peek-a-Boo" and their singer Kele Okereke stated about that Banshees' single: "it sounded like nothing else on this planet. This is [...] a pop song that they put out in the middle of their career [...] to me it sounded like the most current but most futuristic bit of guitar-pop music I've heard". The Weeknd sampled different parts of "Happy House" for his song "House of Balloons", and also used the chorus of the initial version.






</doc>
<doc id="29513" url="https://en.wikipedia.org/wiki?curid=29513" title="Simula">
Simula

Simula is the name of two simulation programming languages, Simula I and Simula 67, developed in the 1960s at the Norwegian Computing Center in Oslo, by Ole-Johan Dahl and Kristen Nygaard. Syntactically, it is a fairly faithful superset of ALGOL 60.

Simula 67 introduced objects, classes, inheritance and subclasses, virtual procedures, coroutines, and discrete event simulation, and features garbage collection. Also other forms of subtyping (besides inheriting subclasses) were introduced in Simula derivatives.

Simula is considered the first object-oriented programming language. As its name suggests, Simula was designed for doing simulations, and the needs of that domain provided the framework for many of the features of object-oriented languages today.

Simula has been used in a wide range of applications such as simulating VLSI designs, process modeling, protocols, algorithms, and other applications such as typesetting, computer graphics, and education. The influence of Simula is often understated, and Simula-type objects are reimplemented in C++, Object Pascal, Java, C# and several other languages. Computer scientists such as Bjarne Stroustrup, creator of C++, and James Gosling, creator of Java, have acknowledged Simula as a major influence.

The following account is based on Jan Rune Holmevik's historical essay.

Kristen Nygaard started writing computer simulation programs in 1957. Nygaard saw a need for a better way to describe the heterogeneity and the operation of a system. To go further with his ideas on a formal computer language for describing a system, Nygaard realized that he needed someone with more computer programming skills than he had. Ole-Johan Dahl joined him on his work January 1962. The decision of linking the language up to ALGOL 60 was made shortly after. By May 1962 the main concepts for a simulation language were set. "SIMULA I" was born, a special purpose programming language for simulating discrete event systems.

Kristen Nygaard was invited to visit the Eckert–Mauchly Computer Corporation late May 1962 in connection with the marketing of their new UNIVAC 1107 computer. At that visit Nygaard presented the ideas of Simula to Robert Bemer, the director of systems programming at Univac. Bemer was a sworn ALGOL fan and found the Simula project compelling. Bemer was also chairing a session at the second international conference on information processing hosted by IFIP. He invited Nygaard, who presented the paper "SIMULA -- An Extension of ALGOL to the Description of Discrete-Event Networks".

The Norwegian Computing Center got a UNIVAC 1107 August 1963 at a considerable discount, on which Dahl implemented the SIMULA I under contract with UNIVAC. The implementation was based on the UNIVAC ALGOL 60 compiler. SIMULA I was fully operational on the UNIVAC 1107 by January 1965. In the following couple of years Dahl and Nygaard spent a lot of time teaching Simula. Simula spread to several countries around the world and SIMULA I was later implemented on Burroughs B5500 computers and the Russian URAL-16 computer.

In 1966 C. A. R. Hoare introduced the concept of record class construct, which Dahl and Nygaard extended with the concept of prefixing and other features to meet their requirements for a generalized process concept. Dahl and Nygaard presented their paper on Class and Subclass declarations at the IFIP Working Conference on simulation languages in Oslo, May 1967. This paper became the first formal definition of Simula 67. In June 1967 a conference was held to standardize the language and initiate a number of implementations. Dahl proposed to unify the type and the class concept. This led to serious discussions, and the proposal was rejected by the board. SIMULA 67 was formally standardized on the first meeting of the SIMULA Standards Group (SSG) in February 1968.

Simula was influential in the development of Smalltalk and later object-oriented programming languages. It also helped inspire the actor model of concurrent computation although Simula only supports coroutines and not true concurrency.

In the late sixties and the early seventies there were four main implementations of Simula:


These implementations were ported to a wide range of platforms. The TOPS-10 implemented the concept of public, protected, and private member variables and procedures, that later was integrated into Simula 87. Simula 87 is the latest standard and is ported to a wide range of platforms. There are mainly three implementations:


In November 2001 Dahl and Nygaard were awarded the IEEE John von Neumann Medal by the Institute of Electrical and Electronic Engineers "For the introduction of the concepts underlying object-oriented programming through the design and implementation of SIMULA 67". In April 2002 they received the 2001 A. M. Turing Award by the Association for Computing Machinery (ACM), with the citation: "For ideas fundamental to the emergence of object oriented programming, through their design of the programming languages Simula I and Simula 67." Unfortunately neither Dahl nor Nygaard could make it to the ACM Turing Award Lecture, scheduled to be delivered at the November 2002 OOPSLA conference in Seattle, as they died in June and August of that year, respectively.

Simula Research Laboratory is a research institute named after the Simula language, and Nygaard held a part-time position there from the opening in 2001. The new Computer Science building at the University of Oslo is named Ole Johan Dahl's House, in Dahl's honour, and the main auditorium is named Simula.

Simula is still used for various types of university courses, for instance, Jarek Sklenar teaches Simula to students at University of Malta.

The empty computer file is the minimal program in Simula, measured by the size of the source code.
It consists of one thing only; a dummy statement.

However, the minimal program is more conveniently represented as an empty block:

It begins executing and immediately terminates.
The language does not have any return value from the program itself.

An example of a Hello world program in Simula:

Simula is case-insensitive.

A more realistic example with use of classes, subclasses and virtual procedures:

The above example has one super class (Glyph) with two subclasses (Char and Line).
There is one virtual procedure with two implementations.
The execution starts by executing the main program.
Simula does not have the concept of abstract classes since classes with pure virtual procedures can be instantiated. This means that in the above example all classes can be instantiated. Calling a pure virtual procedure will however produce a run-time error.

Simula supports call by name so the Jensen's Device can easily be implemented.
However, the default transmission mode for simple parameter is call by value, contrary to ALGOL which used call by name.
The source code for the Jensen's Device must therefore specify call by name for the parameters when compiled by a Simula compiler.

Another much simpler example is the summation function formula_1 which can be implemented as follows:

The above code uses call by name for the controlling variable (k) and the expression (u).
This allows the controlling variable to be used in the expression.

Note that the Simula standard allows for certain restrictions on the controlling variable
in a for loop. The above code therefore uses a while loop for maximum portability.

The following:

formula_2

can then be implemented as follows:

Simula includes a simulation package for doing discrete event simulations. This simulation package is based on Simula's object oriented features and its coroutine concept.

Sam, Sally, and Andy are shopping for clothes. They have to share one fitting room. Each one of them is browsing the store for about 12 minutes and then uses the fitting room exclusively for about three minutes, each following a normal distribution. A simulation of their fitting room experience is as follows:

The main block is prefixed with codice_1 for enabling simulation. The simulation package can be used on any block and simulations can even be nested when simulating someone doing simulations.

The fitting room object uses a queue (codice_2) for getting access to the fitting room. When someone requests the fitting room and it's in use they must wait in this queue (codice_3). When someone leaves the fitting room the first one (if any) is released from the queue (codice_4) and accordingly removed from the door queue (codice_5).

Person is a subclass of Process and its activity is described using hold (time for browsing the store and time spent in the fitting room) and calls procedures in the fitting room object for requesting and leaving the fitting room.

The main program creates all the objects and activates all the person objects to put them into the event queue. The main program holds for 100 minutes of simulated time before the program terminates.




</doc>
<doc id="29515" url="https://en.wikipedia.org/wiki?curid=29515" title="SNOBOL">
SNOBOL

SNOBOL ("StriNg Oriented and symBOlic Language") is a series of computer programming languages developed between 1962 and 1967 at AT&T Bell Laboratories by David J. Farber, Ralph E. Griswold and Ivan P. Polonsky, culminating in SNOBOL4. It was one of a number of text-string-oriented languages developed during the 1950s and 1960s; others included COMIT and TRAC.

SNOBOL4 stands apart from most programming languages of its era by having patterns as a first-class data type ("i.e." a data type whose values can be manipulated in all ways permitted to any other data type in the programming language) and by providing operators for pattern concatenation and alternation. In later object-oriented languages, such as JavaScript, patterns are a type of object, and admit various manipulations. Further, strings generated during execution can be treated as programs and executed (as in the eval function of other languages).

SNOBOL4 was quite widely taught in larger US universities in the late 1960s and early 1970s and was widely used in the 1970s and 1980s as a text manipulation language in the humanities.

In the 1980s and 1990s its use faded as newer languages such as AWK and Perl made string manipulation by means of regular expressions fashionable. SNOBOL4 patterns subsume BNF grammars, which are equivalent to context-free grammars and more powerful than regular expressions. 
The "regular expressions" in current versions of AWK and Perl are in fact extensions of regular expressions in the traditional sense, but regular expressions, unlike SNOBOL4 patterns, are not recursive, which gives a distinct computational advantage to SNOBOL4 patterns. (Recursive expressions did appear in Perl 5.10, though, released in December 2007.)

One of the designers of SNOBOL, Ralph Griswold, designed successors to SNOBOL4 called SL5 and Icon, which combined the backtracking of SNOBOL4 pattern matching with more standard ALGOL-like structuring, as well as adding some features of their own.

The initial SNOBOL language was created as a tool to be used by its authors to work with the symbolic manipulation of polynomials. It was written in assembly language for the IBM 7090. It had a simple syntax, only one datatype, the string, no functions, and no declarations and very little error control. However, despite its simplicity and its "personal" nature its use began to spread to other groups. As a result, the authors decided to extend it and tidy it up. They rewrote it and added functions, both standard and user-defined, and released the result as SNOBOL3. SNOBOL2 did exist but it was a short-lived intermediate development version without user-defined functions and was never released. SNOBOL3 became quite popular and was rewritten for other computers than the IBM 7090 by other programmers. As a result, several incompatible dialects arose.

As SNOBOL3 became more popular the authors received more and more requests for extensions to the language. They also began to receive complaints about incompatibility and bugs in versions that they hadn't written. To address this and to take advantage of the new computers being introduced in the late 1960s, the decision was taken to develop SNOBOL4 with many extra datatypes and features but based on a virtual machine to allow improved portability across computers. The SNOBOL4 language translator was still written in assembly language. However the macro features of the assembler were used to define the virtual machine instructions of the SNOBOL Implementation Language, the SIL. This very much improved the portability of the language by making it relatively easy to port the virtual machine which hosted the translator by recreating its virtual instructions on any machine which included a macro assembler or indeed a high level language.

SNOBOL4 supports a number of built-in data types, such as integers and limited precision real numbers, strings, patterns, arrays, and tables (associative arrays), and also allows the programmer to define additional data types and new functions. SNOBOL4's programmer-defined data type facility was advanced at the time—it is similar to the earlier COBOL's and the later Pascal's records.

All SNOBOL command lines are of the form

Each of the five elements is optional. In general, the "subject" is matched against the "pattern". If the "object" is present, any matched portion is replaced by the "object" via rules for replacement. The "transfer" can be an absolute branch or a conditional branch dependent upon the success or failure of the subject evaluation, the pattern evaluation, the pattern match, the object evaluation or the final assignment. It can also be a transfer to code created and compiled by the program itself during a run.

A SNOBOL pattern can be very simple or extremely complex. A simple pattern is just a text string (e.g. "ABCD"), but a complex pattern may be a large structure describing, for example, the complete grammar of a computer language. It is possible to implement a language interpreter in SNOBOL almost directly from a Backus–Naur form expression of it, with few changes. Creating a macro assembler and an interpreter for a completely theoretical piece of hardware could take as little as a few hundred lines, with a new instruction being added with a single line.

Complex SNOBOL patterns can do things that would be impractical or impossible using the more primitive regular expressions used in most other pattern matching languages. Some of this power derives from the so-called "SPITBOL extensions" (which have since been incorporated in basically all modern implementations of the original SNOBOL 4 language too), although it is possible to achieve the same power without them. Part of this power comes from the side effects that it is possible to produce during the pattern matching operation, including saving numerous intermediate/tentative matching results and the ability to invoke user-written functions during the pattern match which can perform nearly any desired processing, and then influence the ongoing direction the interrupted pattern match takes, or even to indeed change the pattern itself during the matching operation. Patterns can be saved like any other first-class data item, and can be concatenated, used within other patterns, and used to create very complex and sophisticated pattern expressions. It is possible to write, for example, a SNOBOL4 pattern which matches "a complete name and international postal mailing address", which is well beyond anything that is practical to even attempt using regular expressions.

SNOBOL4 pattern-matching uses a backtracking algorithm similar to that used in the logic programming language Prolog, which provides pattern-like constructs via DCGs. This algorithm makes it easier to use SNOBOL as a logic programming language than is the case for most languages.

SNOBOL stores variables, strings and data structures in a single garbage-collected heap.

SNOBOL rivals APL for its distinctiveness in format and programming style, both being radically unlike more "standard" procedural languages such as BASIC, Fortran, or C.

The Hello World program might be as follows...
A simple program to ask for a user's name and then use it in an output sentence...

To choose between three possible outputs...
To continue requesting input until no more is forthcoming...

The classic implementation was on the PDP-10; it has been used to study compilers, formal grammars, and artificial intelligence, especially machine translation and machine comprehension of natural languages. The original implementation was on an IBM 7090 at Bell Labs, Holmdel, N.J. SNOBOL4 was specifically designed for portability; the first implementation was started on an IBM 7094 in 1966 but completed on an IBM 360 in 1967. It was rapidly ported to many other platforms.

It is normally implemented as an interpreter because of the difficulty in implementing some of its very high-level features, but there is a compiler, the SPITBOL compiler, which provides nearly all the facilities that the interpreter provides.

The Gnat Ada Compiler comes with a package (GNAT.Spitbol) which implements all of the Spitbol string manipulation semantics. This can be called from within an Ada program.

The file editor for the Michigan Terminal System (MTS) provided pattern matching based on SNOBOL4 patterns.

The JBOL modules library for the jq language contains a full implementation for the SNOBOL pattern matching sublanguage.

Several implementations are currently available. Macro SNOBOL4 in C written by Phil Budne is a free, open source implementation, capable of running on almost any platform. Catspaw, Inc provided a commercial implementation of the SNOBOL4 language for many different computer platforms, including DOS, Macintosh, Sun, RS/6000, and others, and these implementations are now available free from Catspaw. Minnesota SNOBOL4, by Viktors Berstis, the closest PC implementation to the original IBM mainframe version (even including Fortran-like FORMAT statement support) is also free.

Although SNOBOL itself has no structured programming features, a SNOBOL preprocessor called Snostorm was designed and implemented during the 1970s by Fred G. Swartz for use under the Michigan Terminal System (MTS) at the University of Michigan. Snostorm was used at the eight to fifteen sites that ran MTS. It was also available at University College London (UCL) between 1982 and 1984.

Snocone by Andrew Koenig adds block-structured constructs to the SNOBOL4 language. Snocone is a self-contained programming language, rather than a proper superset of SNOBOL4.

The SPITBOL implementation also introduced a number of features which, while not using traditional structured programming keywords, nevertheless can be used to provide many of the equivalent capabilities normally thought of as "structured programming", most notably nested if/then/else type constructs. These features have since been added to most recent SNOBOL4 implementations. After many years as a commercial product, in April 2009 SPITBOL was released as free software under the GNU General Public License.

According to Dave Farber, he, Griswold and Polonsky "finally arrived at the name Symbolic EXpression Interpreter SEXI."

Common backronyms of "SNOBOL" are 'String Oriented Symbolic Language' or (as a quasi-initialism) 'StriNg Oriented symBOlic Language'.





</doc>
<doc id="29518" url="https://en.wikipedia.org/wiki?curid=29518" title="Statistical physics">
Statistical physics

Statistical physics is a branch of physics that uses methods of probability theory and statistics, and particularly the mathematical tools for dealing with large populations and approximations, in solving physical problems. It can describe a wide variety of fields with an inherently stochastic nature. Its applications include many problems in the fields of physics, biology, chemistry, neurology, and even some social sciences, such as sociology. Its main purpose is to clarify the properties of matter in aggregate, in terms of physical laws governing atomic motion.

In particular, statistical mechanics develops the phenomenological results of thermodynamics from a probabilistic examination of the underlying microscopic systems. Historically, one of the first topics in physics where statistical methods were applied was the field of mechanics, which is concerned with the motion of particles or objects when subjected to a force.

Statistical mechanics provides a framework for relating the microscopic properties of individual atoms and molecules to the macroscopic or bulk properties of materials that can be observed in everyday life, therefore explaining thermodynamics as a natural result of statistics, classical mechanics, and quantum mechanics at the microscopic level. Because of this history, the statistical physics is often considered synonymous with statistical mechanics or statistical thermodynamics.

One of the most important equations in statistical mechanics (analogous to formula_1 in Newtonian mechanics, or the Schrödinger equation in quantum mechanics) is the definition of the partition function formula_2, which is essentially a weighted sum of all possible states formula_3 available to a system.

where formula_5 is the Boltzmann constant, formula_6 is temperature and formula_7 is energy of state formula_3. Furthermore, the probability of a given state, formula_3, occurring is given by

Here we see that very-high-energy states have little probability of occurring, a result that is consistent with intuition.

A statistical approach can work well in classical systems when the number of degrees of freedom (and so the number of variables) is so large that exact solution is not possible, or not really useful. Statistical mechanics can also describe work in non-linear dynamics, chaos theory, thermal physics, fluid dynamics (particularly at high Knudsen numbers), or plasma physics.

Although some problems in statistical physics can be solved analytically using approximations and expansions, most current research utilizes the large processing power of modern computers to simulate or approximate solutions. A common approach to statistical problems is to use a Monte Carlo simulation to yield insight into the dynamics of a complex system.

Quantum statistical mechanics is statistical mechanics applied to quantum mechanical systems. In quantum mechanics a statistical ensemble (probability distribution over possible quantum states) is described by a density operator "S", which is a non-negative, self-adjoint, trace-class operator of trace 1 on the Hilbert space "H" describing the quantum system. This can be shown under various mathematical formalisms for quantum mechanics. One such formalism is provided by quantum logic.

A significant contribution (at different times) in development of statistical physics was given by Satyendra Nath Bose, James Clerk Maxwell, Ludwig Boltzmann, J. Willard Gibbs, Albert Einstein, Enrico Fermi, Richard Feynman, L. Landau, Vladimir Fock, Werner Heisenberg, Nikolay Bogolyubov, Benjamin Widom, Lars Onsager, Benjamin and Jeremy Chubb (also inventors of the titanium sublimation pump), and others. Statistical physics is studied in the nuclear center at Los Alamos. Also, Pentagon has organized a large department for the study of turbulence at the University of Princeton. Work in this area is also being conducted by Saclay (Paris), Max Planck Institute, Netherlands Institute for Atomic and Molecular Physics and other research centers.

Statistical physics allowed us to explain and quantitatively describe superconductivity, superfluidity, turbulence, collective phenomena in solids and plasma, and the structural features of liquid. It underlies the modern astrophysics. It is statistical physics that helped us to create such intensively developing study of liquid crystals and to construct a theory of phase transition and critical phenomena. Many experimental studies of matter are entirely based on the statistical description of a system. These include the scattering of cold neutrons, X-ray, visible light, and more.
Statistical physics plays a major role in Physics of Solid State Physics, Materials Science, Nuclear Physics, Astrophysics, Chemistry, Biology and Medicine (e.g. study of the spread of infectious diseases), Information Theory and Technique but also in those areas of technology owing to their development in the evolution of Modern Physics. It still has important applications in theoretical sciences such as Sociology and Linguistics and is useful for researchers in higher education, corporate governance and industry.


Thermal and Statistical Physics (lecture notes, Web draft 2001) by Mallett M., Blumler P.
by Harald J W Müller-Kirsten (University of Kaiserslautern, Germany)


</doc>
<doc id="29519" url="https://en.wikipedia.org/wiki?curid=29519" title="Side effect (computer science)">
Side effect (computer science)

In computer science, a function or expression is said to have a side effect if it modifies some state outside its local environment or has an observable interaction with the outside world besides returning a value. Example side effects of a particular function might consist in performing I/O, modifying a non-local variable, modifying a static local variable, modifying an argument passed by reference, or calling other side-effect functions. In the presence of side effects, a program's behaviour may depend on history; that is, the order of evaluation matters. Understanding and debugging a function with side effects requires knowledge about the context and its possible histories. A function or expression without side effects is said to be pure.

Side effects are the most common way that a program interacts with the outside world (people, filesystems, other computers on networks). The degree to which side effects are used depends on the programming paradigm. Imperative programming is known for its frequent utilization of side effects. 

In functional programming, side effects are rarely used. The lack of side effects makes it easier to do formal verifications of a program. Functional languages such as Standard ML, Scheme and Scala do not restrict side effects, but it is customary for programmers to avoid them. The functional language Haskell expresses side effects such as I/O and other stateful computations using monadic actions.

Assembly language programmers must be aware of "hidden" side effects—instructions that modify parts of the processor state which are not mentioned in the instruction's mnemonic. A classic example of a hidden side effect is an arithmetic instruction that implicitly modifies condition codes (a hidden side effect) while it explicitly modifies a register (the overt effect). One potential drawback of an instruction set with hidden side effects is that, if many instructions have side effects on a single piece of state, like condition codes, then the logic required to update that state sequentially may become a performance bottleneck. The problem is particularly acute on some processors designed with pipelining (since 1990) or with out-of-order execution. Such a processor may require additional control circuitry to detect hidden side effects and stall the pipeline if the next instruction depends on the results of those effects.

Absence of side effects is a necessary, but not sufficient, condition for referential transparency. Referential transparency means that an expression (such as a function call) can be replaced with its value. This requires that the expression is stateless, that is to say the expression must be pure (have no side effects) and deterministic (always give the same value for the same input). A function without side effects can return different values according to its history or its environment, for example if its output depends on the value of a local static variable or a global variable respectively.

Side effects caused by the time taken for an operation to execute are usually ignored when discussing side effects and referential transparency. There are some cases, such as with hardware timing or testing, where operations are inserted specifically for their temporal side effects e.g. codice_1 or codice_2. These instructions do not change state other than taking an amount of time to complete.

A function codice_3 with side effects is said to be idempotent under sequential composition codice_4 if, when called twice with the same list of arguments, the second call has no side effects (assuming no other procedures were called between the end of the first call and the start of the second call).

For instance, consider the following Python code:

Here, codice_5 is idempotent because the second call to codice_5 (with the same argument) does not change the visible program state: codice_7 was already set to 5 in the first call, and is again set to 5 in the second call, thus keeping the same value. Note that this is distinct from idempotence under function composition codice_8. For example, the absolute value is idempotent under function composition:

One common demonstration of side effect behavior is that of the assignment operator in C++. For example, assignment returns the right operand and has the side effect of assigning that value to a variable. This allows for syntactically clean multiple assignment:

Because the operator right associates, this equates to

Where the result of assigning 3 into codice_9 then gets assigned into codice_10. This presents a potential hangup for novice programmers who may confuse

with



</doc>
<doc id="29523" url="https://en.wikipedia.org/wiki?curid=29523" title="List of science fiction editors">
List of science fiction editors

This is a list of science fiction editors, editors working for book and magazine publishing companies who have edited science fiction. Many have also edited works of fantasy and other related genres, all of which have been sometimes grouped under the name speculative fiction. 

Editors on this list should fulfill the conditions for in science fiction or related genres. Evidence for notability includes an existing wiki-biography, or evidence that one could be written. Borderline cases should be discussed on the article's talk page.




























</doc>
<doc id="29525" url="https://en.wikipedia.org/wiki?curid=29525" title="Square-free integer">
Square-free integer

In mathematics, a square-free integer (or squarefree integer) is an integer which is divisible by no perfect square other than 1. That is, its prime factorization has exactly one factor for each prime that appears in it. For example, is square-free, but is not, because 18 is divisible by . The smallest positive square-free numbers are

The radical of an integer is its largest square-free factor. An integer is square-free if and only if it is equal to its radical.

Any arbitrary positive integer can be represented in a unique way as the product of a powerful number (that is a integer such that is divisible by the square of every prime factor) and a square-free integer, which are coprime. The square-free factor, called the "square-free part" of the number, is the largest square-free divisor of that is coprime with . The square-free part of an integer may be smaller than the largest square-free divisor.

Any arbitrary positive integer can be represented in a unique way as the product of a square and a square-free integer :
In this factorization, is the largest divisor of " such that is a divisor of . 

In summary, there are three square-free factors that are naturally associated to every integer: the square-free part, the above factor , and the largest square-free factor. Each is a factor of the next one. All are easily deduced from a prime factorization: if
is the prime factorization of , where formula_3 are distinct prime numbers, then the square-free part is
The square-free factor such the quotient is a square is 
and the largest square-free factor is 

For example, if formula_7 the square-free part is , the square-free factor such that the quotient is a square is , and the largest square-free factor is .

No algorithm is known for computing any of these square-free factors, which is faster than computing the complete prime factorization. In particular, there is no known polynomial-time algorithm for computing the square-free part of an integer, and no known polynomial-time algorithm for determining whether a number is square-free. On the opposite, polynomial-time algorithms are known for primality testing. This is a major difference between the arithmetic of the integers, and the arithmetic of the univariate polynomials, as polynomial-time algorithms are known for square-free factorization of polynomials (in short, the largest square-free factor of a polynomial is its quotient by the greatest common divisor of the polynomial and its formal derivative).

A positive integer "n" is square-free if and only if in the prime factorization of "n", no prime factor occurs with an exponent larger than one. Another way of stating the same is that for every prime factor "p" of "n", the prime "p" does not evenly divide "n" / "p". Also "n" is square-free if and only if in every factorization "n" = "ab", the factors "a" and "b" are coprime. An immediate result of this definition is that all prime numbers are square-free.

A positive integer "n" is square-free if and only if all abelian groups of order "n" are isomorphic, which is the case if and only if any such group is cyclic. This follows from the classification of finitely generated abelian groups.

A integer "n" is square-free if and only if the factor ring Z / "nZ (see modular arithmetic) is a product of fields. This follows from the Chinese remainder theorem and the fact that a ring of the form Z / "kZ is a field if and only if "k" is a prime.

For every positive integer "n", the set of all positive divisors of "n" becomes a partially ordered set if we use divisibility as the order relation. This partially ordered set is always a distributive lattice. It is a Boolean algebra if and only if "n" is square-free.

A positive integer "n" is square-free if and only if μ("n") ≠ 0, where μ denotes the Möbius function.

The Dirichlet generating function for the square-free numbers is

This is easily seen from the Euler product

Let "Q"("x") denote the number of square-free integers between 1 and "x". For large "n", 3/4 of the positive integers less than "n" are not divisible by 4, 8/9 of these numbers are not divisible by 9, and so on. Because these events are independent, we obtain the approximation:

This argument can be made rigorous, and a very elementary estimate yields

(see pi and big O notation) since we use the above characterization to obtain
and, observing that the last summand is zero for formula_14, we have
By exploiting the largest known zero-free region of the Riemann zeta function, due to Ivan Matveyevich Vinogradov, and Hans-Egon Richert, the maximal size of the error term has been reduced
by Arnold Walfisz and we have
for some positive constant "c". Under the Riemann hypothesis, the error term can be further reduced to yield

The asymptotic/natural density of square-free numbers is therefore

where ζ is the Riemann zeta function and 1/ζ(2) is approximately 0.6079. Therefore over 3/5 of the integers are square-free.

Likewise, if "Q"("x","n") denotes the number of "n"-free integers (e.g. 3-free integers being cube-free integers) between 1 and "x", one can show

Since a multiple of 4 must have a square factor 4=2, it cannot occur that four consecutive integers are all square-free. On the other hand, there exist infinitely many integers "n" for which 4"n" +1, 4"n" +2, 4"n" +3 are all square-free. Otherwise, observing that 4"n" and at least one of 4"n" +1, 4"n" +2, 4"n" +3 among four could be non-square-free for sufficiently large "n", half of all positive integers minus finitely many must be non-square-free and therefore
contrary to the above asymptotic estimate for formula_21.

There exist sequences of consecutive non-square-free integers of arbitrary length. Indeed, if "n" satisfies a simultaneous congruence
for distinct primes formula_23, then each formula_24 is divisible by "p". On the other hand, the above-mentioned estimate formula_25 implies that, for some constant "c", there always exists a square-free integer between "x" and formula_26 for positive "x". Moreover, an elementary argument allows us to replace formula_26 by formula_28. The ABC conjecture would allow formula_29.

If we represent a square-free number as the infinite product

then we may take those formula_31 and use them as bits in a binary number with the encoding

The square-free number 42 has factorization 2 × 3 × 7, or as an infinite product 2 · 3  · 5 · 7 · 11 · 13 ··· Thus the number 42 may be encoded as the binary sequence ...001011 or 11 decimal. (Note that the binary digits are reversed from the ordering in the infinite product.)

Since the prime factorization of every number is unique, so also is every binary encoding of the square-free integers.

The converse is also true. Since every positive integer has a unique binary representation it is possible to reverse this encoding so that they may be decoded into a unique square-free integer.

Again, for example, if we begin with the number 42, this time as simply a positive integer, we have its binary representation 101010. This decodes to 2 · 3 · 5 · 7 · 11 · 13 = 3 × 7 × 13 = 273.

Thus binary encoding of squarefree numbers describes a bijection between the nonnegative integers and the set of positive squarefree integers.

The central binomial coefficient

is never squarefree for "n" > 4. This was proven in 1985 for all sufficiently large integers by András Sárközy, and for all integers > 4 in 1996 by Olivier Ramaré and Andrew Granville.

The multiplicative function formula_34 is defined
to map positive integers "n" to "t"-free numbers by reducing the
exponents in the prime power representation modulo "t":
The value set of formula_36, in particular, are the
square-free integers. Their Dirichlet generating functions are

OEIS representatives are ("t"=2), ("t"=3) and ("t"=4).



</doc>
<doc id="29530" url="https://en.wikipedia.org/wiki?curid=29530" title="Sentinel (comics)">
Sentinel (comics)

The Sentinels are a fictional variety of mutant-hunting robots appearing in American comic books published by Marvel Comics. They are typically depicted as antagonists to the X-Men. 

The Sentinels played a large role in the 1990s "X-Men" animated series and have been featured in several X-Men video games. The Sentinels are featured prominently in the 2014 film "" while simulated versions made brief appearances in the 2006 film "" and the 2016 film "". In 2009, The Sentinels was ranked as IGN's 38th Greatest Comic Book Villain of All Time.

Created by Stan Lee and Jack Kirby, they first appeared in "The X-Men" #14 (November 1965).

Sentinels are programmed to locate mutants and capture or kill them. Though several types of Sentinels have been introduced, the typical Sentinel is three stories tall, is capable of flight, projects energy blasts, and can detect mutants.

Sentinels are designed to hunt mutants. While many are capable of tactical thought, only a handful are self-aware.

Sentinels are technologically advanced, and have exhibited a wide variety of abilities. They are armed (primarily with energy weapons and restraining devices), capable of flight, and can detect mutants at long range. They possess vast physical strength, and their bodies are highly resistant to damage. Some are able to alter their physical forms or re-assemble and reactivate themselves after they have been destroyed.

Some Sentinel variants have the ability to learn from their experiences, developing their defenses during an engagement. Several groups of Sentinels have been created and/or led by a single massive Sentinel called Master Mold. Some Sentinels are also equipped with an inconspicuous logic loop in case they should go rogue to convince them that they are mutants as demonstrated in the Tri-Sentinel.



The following are alternative versions of the Sentinels, which appear outside of regular Marvel canon.

In the "Age of Apocalypse" timeline, Bolivar Trask created the Sentinels with his wife Moira. These Sentinels are equipped with several body-mounted gun turrets, and their primary directive is to protect humans rather than to hunt mutants. They are capable of cooperating with mutants in order to further this mission. Later the Sentinels are adapted by Weapon Omega to serve a reverse purpose, and now aid in the hunting of the human race.

In the "Days of Future Past" timeline, which takes place in an alternate future, the "Omega Sentinels" have advanced technologically and become the "de facto" rulers of the United States. The most powerful among them is Nimrod.

In the joke comic "Fred Hembeck Destroys the Marvel Universe", the X-Men are killed by silent, black, man-sized "Ninja Sentinels".

In the "Here Comes Tomorrow" future timeline, a Sentinel named Rover is Tom Skylark's companion and protector. After more than 150 years of being active, Rover has become self-aware and, possibly, capable of emotion.

In the "House of M" storyline, Magneto is victorious in a mutant/human war. The Sentinels are adapted by Sebastian Shaw, now the director of S.H.I.E.L.D., to serve a reverse purpose, and now aid in the hunting of sapien rebels.

In the MC2 timeline, Wild Thing encounters a Prime Sentinel that has accidentally been activated by a faulty microwave.

In the alternate reality of "X-Men: Ronin", the story is played out in Japan. A police unit called "Sentinel Force" designs, builds and pilots the robots. These are aesthetically similar to regular Sentinels, but each is subtly different from the others.

In the comic crossover "X-Men/Star Trek: Second Contact", the X-Men work with the crew of the "Enterprise"-E to battle Kang the Conqueror. An away team composed of Captain Picard, Deanna Troi, Nightcrawler and Colossus encounter an approximation of the "Days of Future Past" timeline, in which the Sentinels have merged with the Borg.

In "Ultimate X-Men", the Sentinels, created by the Ultimate Marvel version of Bolivar Trask, were already in action at the beginning of the first story arc, hunting down and killing mutants on the streets, in a program apparently openly and publicly acknowledged by the U.S. government. Later on, there were also the "New Sentinels" that were sixty of S.H.I.E.L.D.'s top agents in Sentinel battle armor that was described as having enough hardware to take on a fleet of the old Sentinel models. A new breed of Sentinel robots, created by Trask under orders from the Fenris twins, was later created.

After the events of the Ultimatum Wave, a new model of Sentinel (Nimrod Sentinels) was deployed to hunt, capture or kill mutants that refused to turn themselves in. William Stryker, Jr. using Sentinel tech, later displayed an ability to summon a fleet of Sentinels after being attacked by the Shroud.




Sentinels have appeared as major antagonists in almost every video game to feature the X-Men:


Several different toys of Sentinels have been made since their introduction. One is the X-Men Classics 10" Sentinel by Toybiz. A "Build-A-Figure" version of the character was made in wave ten of the "Marvel Legends" line. The most recent Sentinel toy is made by Hasbro as part of the Marvel Universe line. Along with a large, unposeable statue, two Minimates figures have been made of the Sentinels. The first, a classic version, came with Rachel Summers in either her Phoenix or Marvel Girl guises. The second, based on "", comes with a red-haired "First Appearance" figure of Ryu.
In 2014, The Lego group released a set in the Marvel Super Heroes line titled "X-Men vs. the Sentinel", featuring the sentinel as a buildable figure, also including the Blackbird, Magneto, Wolverine, Storm, and Cyclops.



</doc>
<doc id="29532" url="https://en.wikipedia.org/wiki?curid=29532" title="Sebastian Shaw">
Sebastian Shaw

Sebastian Shaw is the name of:



</doc>
<doc id="29533" url="https://en.wikipedia.org/wiki?curid=29533" title="Savage Land">
Savage Land

The Savage Land is a hidden fictional prehistoric land appearing in American comic books published by Marvel Comics. It is a tropical preserve hidden in Antarctica. Throughout time, it has served as a basis for many story arcs in "Uncanny X-Men" as well as in related books.

The Savage Land first appeared in "X-Men" #10 (March 1965) and was created by Stan Lee and Jack Kirby.

The Savage Land was created by the alien Nuwali at the behest of the other-dimensional, nigh-omnipotent aliens known as the Beyonders who sought to observe the process of evolution under relatively controlled conditions and had the Nuwali set up a number of game preserves on several planets. One of these planets was Earth during the Triassic period where the Nuwali chose a valley in Antarctica surrounded by active volcanoes, where they installed a number of advanced technological devices in order to maintain a tropical climate. The aliens then stocked the area with all manner of Earth life over the following several millennia. They also brought over the Man-Apes, earlier hominid ancestors of "Homo sapiens".

The Beyonders eventually grew bored with the experiment, and the Nuwali stopped maintaining the Savage Land during the Late Pleistocene (the Ice Age era). However, the self-maintaining technology that allowed the pocket of tropical climate was left running, and many species which became extinct in other areas of the Earth continued to thrive within the Savage Land.

Later on, a group of human survivors from Atlantis sailed to Antarctica before the "Great Cataclysm" which sank Atlantis into the ocean. There, they discovered a cavern where they found an immense climate-controlling device and harnessed the technology used to keep the Savage Land's volcanoes working. They named their location "Pangea", which is Atlantean for "paradise".

They mastered genetic engineering, which had been used on the Man-Apes when the Nuwali were still maintaining the Savage Land area. They used their genetic engineering techniques to transform other Savage Land inhabitants like the Golden People, the Lizard Men, the Reptile Men, the Tubantis, and others. The Atlanteans then forced them to work for them until these animal people revolted. After a time of war, the animal people demanded civil rights and the Atlanteans used technology to expand the Savage Land's surface area for the animal people to live in. When the Great Cataclysm struck, the Atlantean empire fell and thanks to the machines, the Savage Land locations were spared from sinking into the sea.

In more recent years, the Savage Land was rediscovered by Lord Robert Plunder, who took back a sample of the metal known as "anti-metal" or "Antarctic vibranium" with him. This mysterious metal had the ability to produce vibrations which would liquefy all other metals. Fleeing from those who sought to steal this discovery, Plunder took his eldest son Kevin with him for a second trip into the Savage Land. Unfortunately, the elder Plunder was killed by a local tribe of Man-Apes.

Kevin survived, thanks to the timely intervention of the orphaned sabretooth tiger later known as Zabu. He grew to adulthood in the Savage Land, becoming the adventurer known as Ka-Zar. Ka-Zar had many team-ups with the X-Men, who first revealed the Savage Land's existence, Spider-Man, and many other superheroes who had visited the Savage Land. He later met and married Shanna the She-Devil.

The Savage Land's existence is common knowledge throughout the world. At one time, there were press junkets, sponsored by the oil company Roxxon. "Daily Bugle" photographer Peter Parker was sent and helped uncover Roxxon's unethical and dangerous manipulation of the local resources.

At one point, Spider-Man teamed up with Ka-Zar to save Gwen Stacy from Kraven the Hunter and Gog at the time when her class and J. Jonah Jameson were visiting the Savage Land.

Many villains have threatened the Savage Land, including Sauron, Garokk, Magneto, and Thanos.

In issue #257 of "The Avengers" the Savage Land was decimated by an evil alien named Terminus (or one of his pawns) when he destroyed the machines that maintained the tropical climate. Many of the Savage Land's native people were saved from the ensuing destruction by M'rin: The Warlord of The Skies who took them into her own native dimension to safety. Ka-Zar, Shanna, and Zabu wandered until the High Evolutionary (with help from the X-Men, M'rin and Garokk) restored the region and its creatures, allowing them to return to the Savage Land with their newborn son. The other natives who had taken refuge in M'rin's dimension returned as well.

Sometime after that, Spider-Man had Devil Dinosaur and Moon-Boy emigrated to the Savage Land after rescuing them from Ringmaster.

Evidence in the pages of the "New Avengers" suggests that S.H.I.E.L.D. is operating in the Savage Land, mining vibranium while using the indigenous population as slave labor, but these operations have been classified, and the operation was apparently decimated by a missile strike from the Helicarrier during an attack by the New Avengers. The team only survived thanks to Iron Man's force field.

The Savage Land is featured in the limited series "Claws", serving as a place of revenge for Wolverine and Black Cat on Arcade and White Rabbit. After defeating the two villains, the heroes left them stranded.

In "", Cyclops and Emma Frost were vacationing there until Archangel contacted them about San Francisco looking like the 1960s.

Alyosha Kravinoff fled to the Savage Land after Punisher sabotaged his zoo.

During the "Secret Invasion" storyline, Ka-Zar and Shanna discover Skrulls mining for vibranium. The New Avengers and the Mighty Avengers head toward the Savage Land where a downed Skrull ship was sighted. Luke Cage opens the downed Skrull ship and a large group of Marvel superheroes with older appearances and costumes come out, speaking as if they believe themselves to be authentic. They soon break out into a fight where the Spider-Man from the ship is killed by a Tyrannosaurus and regresses to a Skrull. The Hawkeye from the ship is killed by Ronin and regresses to a Skrull. This causes the superheroes from the ship to scatter into the jungle. The New Avengers' Spider-Man is knocked away by a Tyrannosaurus and ends up confronting Ka-Zar, Shanna, Zabu, and Sauron as well as some of the other locals (ranging from the Sun People, the Swamp Men, and the Tree People). At the point where Spider-Man accuses Ka-Zar and Shanna for being Skrulls, the Captain America from the ship attacks who thinks the same thing for Spider-Man. When the Captain America is hit by a dart coated in some type of poison, it regresses to a Skrull named Pit'o Nilli and is then killed by Shanna. The ship's Beast is trapped underground with Wonder Man. The two try to escape together, but Beast betrays Wonder Man as the two are about to return to the surface. During this, Iron Man uses an abandoned scientific facility nearby to try and recreate his original armor. When it came to the confrontation with both Avengers teams, the Savage Land natives, and the heroes from the ship, Mister Fantastic and Abigail Brand used a laser to identify the heroes from the ship as Skrulls. Ka-Zar joined the Avengers teams into fighting the Skrulls in New York while Shanna and the other Savage Land natives hunted down the remaining Skrulls hiding out in the Savage Land.

After the events of "Second Coming" during the "Heroic Age" storyline, Cyclops takes some time off to go hunting in the Savage Land during which he encounters Steve Rogers. Steve Rogers suggests to Cyclops that he brings the X-Men out of the shadows and into the light as heroes. Steve Rogers also arranges to have the president award Scott the Presidential Medal of Freedom which sways the people of San Francisco to welcome the X-Men back.

Around the same time following their defeat after the hunt for "spiders" in the "Grim Hunt" storyline, the Kravinoff Family are also currently residing in the Savage Land.

It is later revealed that Miek and the other Imperials and Natives from Sakaar that came with Hulk back in "World War Hulk" had settled in the Savage Land constructing a village called New Imperia.

During the "Avengers vs. X-Men" storyline, Captain America ends up fighting Gambit in the Savage Land.

As part of the "Marvel NOW!" event, some of The Garden's evolution seeds had fallen into the Savage Land. While working to get it under control, the Avengers find that A.I.M. is also there where they test the extracted formula from one of the pods and tests it on their intern Dr. Jema. The formula puts a strain on Dr. Jema just as the Avengers arrive.

As part of the "All-New, All-Different Marvel", Magneto led a new team of X-Men to protect mutant-kind at all costs with their base in the Savage Land.

The Marvel Universe's version of the United Nations considers the Savage Land an international wildlife preserve and forbids any commercial exploitation of its resources.

There are some famous locations in the Savage Land:


There are many types of races in the Savage Land and Pangea. The Nuwali transported primitive man now known as the Man-Apes, which unlike the rest of the world thrived until the 21st century. The next arrivals were the Ancient Atlanteans who added the region as part of their empire. They used the Nuwali technology to mutate the Man-Apes into various Beast-Men to perform certain tasks. These slaves rebelled after the great Cataclysm and made Pangea their home. Many Atlanteans remained and their decedents became the various human tribes, with some clinging to the old ways and technology but most forget and resort to more primitive hunter-gatherer societies. Among the Savage Land races are:


In the "Age of Apocalypse" reality, the Savage Land houses Avalon, a secret haven for humans and mutants. A method to reach it exists, but it will only cost the refugee everything they own and even then, there is no guarantee of arriving alive. It is led by Destiny, a pacifist Juggernaut and Douglas Ramsey, the latter of whom provides a field that allows everybody to understand each other despite speaking different languages. Avalon was eventually found by Apocalypse forces and destroyed by the Shadow King who mind-controlled its inhabitants into killing each other. He was defeated, but casualties were high.

During the "Age of Ultron" storyline, the superhero resistance against Ultron had relocated to the Savage Land to come up with a plan to defeat Ultron.

In "Marvel Zombies Return", the Savage Land, like everywhere else on Earth, has been eaten by the superhuman zombies, with the surviving zombies musing that the Savage Land was their 'number one' meal in the aftermath, as it contained such an abundance of food that they were actually full for a full hour after eating there, as opposed to the usual ravenous hunger they feel. It is also the location of the final battle between the zombies and 'New Avengers'- three zombies who have beaten their hunger and the cyborg James Rhodes- at the storyline's conclusion, with Rhodes using one of his fingers to lure the zombies into an ambush.

In the "Earth X" universe, the Savage Land is where Magneto built his sanctuary called Sentinel City.

In the "House of M" reality created by an insane Scarlet Witch, the Savage Land was known as "Pangea." It is also known that Kevin Plunder has been granted political asylum in the United States for his human rights activism in this prehistoric land.

In the alternate future depicted in Marvel 2099, an alien attack floods much of the earth rendering the Savage Land the only habitable space. Thousands of refugees (including Miguel O'Hara and most of X-Nation and X-Men) make new homes here. It is not without its own dangers.

In the "Transformers" Marvel comics continuity, shortly after the "Ark"' spacecraft crashed on Earth 4 million years before the present day, the computer aboard the Ark detected Shockwave landing on the prehistoric Savage Land. The "Ark" used the last of its capabilities to revive the five Autobot warriors by scanning the Savage Land's dominant lifeform: dinosaurs, and rebuild them into the Dinobots. The Dinobots fought Shockwave, a battle that ended in permanent stalemate when Snarl brought down the mountain that Shockwave stood upon, knocking all of them into a tar pit. They remained deactivated until the year 1984.

In the Ultimate Marvel universe, the Savage Land is a large island somewhere in the southern hemisphere. It was originally said to have been created by Magneto, using theories and methods developed by Professor X, as the site for genetic experiments. Magneto's goal there was to create a new human race who would be less trouble to rule than the current one, that he decided to restart evolution from scratch, and control the process to his own specifications. As a result of this, at its current level of advancement, it has dinosaurs and that Magneto has shown no further interest in advancing the evolution of the Savage Land. It has remained in its dinosaur state since the departure of Professor X. This story is later revealed as false (see below).

Magneto's original base was on the Savage Land. When it was destroyed in the first arc of "Ultimate X-Men", the computer controlling the base gained self-awareness, and hijacked the genetic experiment project to create an army of nanotech-enhanced, zombie-like thralls. It planned to take over the world, but was stopped by Wolverine, Cyclops, and Kitty Pryde.

The Savage Land is now the home of Longshot, who managed to get there in a small boat which launched from Genosha. Longshot recently aided Magneto in breaking out of prison, and the two may be planning something.

In "Ultimates 3", it is revealed that the dinosaurs were conjured by Scarlet Witch as a result of her reality warping abilities and not by Magneto's creation. The aboriginal inhabitants were wiped out and only a small tribe of survivors including Ka-Zar and Shanna remain.

The inhabitants help the Ultimates remove the last of Magneto's forces as of "Ultimatum".

The Savage Land appears in a "What If" story where the Savage Land was terraforming and has taken over New York. Both Ka-Zar and Parnival sacrifice themselves to return New York to normal, with Shanna the only survivor of his "family."

Additionally, in the "What If" issues involving alternative outcomes to the Age of Ultron, a group composed of Wolverine, the Hulk, Peter Parker and a Ghost Rider venture to the Savage Land in order to prevent a Master Mold under the control of a future version of Ezekiel Stane from unleashing a wave of Stark armors on the world.







</doc>
<doc id="29536" url="https://en.wikipedia.org/wiki?curid=29536" title="Stephen Schneider">
Stephen Schneider

Stephen Henry Schneider (February 11, 1945 – July 19, 2010) was Professor of Environmental Biology and Global Change at Stanford University, a Co-Director at the Center for Environment Science and Policy of the Freeman Spogli Institute for International Studies and a Senior Fellow in the Stanford Woods Institute for the Environment. Schneider served as a consultant to federal agencies and White House staff in the Richard Nixon, Jimmy Carter, Ronald Reagan, George H. W. Bush, Bill Clinton, George W. Bush and Barack Obama administrations.

Schneider's research included modeling of the atmosphere, climate change, and the effect of global climate change on biological systems. Schneider was the founder and editor of the journal "Climatic Change" and authored or co-authored over 450 scientific papers and other publications. He was a Coordinating Lead Author in Working Group II Intergovernmental Panel on Climate Change (IPCC) Third Assessment Report and was engaged as a co-anchor of the Key Vulnerabilities Cross-Cutting Theme for the Fourth Assessment Report (AR4) at the time of his death. During the 1980s, Schneider emerged as a leading public advocate of sharp reductions of greenhouse gas emissions to combat global warming. In 2006 Professor Schneider was an Adelaide Thinker in Residence advising the South Australian Government of Premier Mike Rann on climate change and renewable energy policies. In ten years South Australia went from zero to 31% of its electricity generation coming from renewables.

An annual award for outstanding climate science communication was created in Schneider's honor after his death, by the Commonwealth Club of California. The Stephen Schneider Memorial Lecture of the American Geophysical Union honors Schneider's life and work. 

Schneider grew up on Long Island, New York. He studied engineering at Columbia University, receiving his bachelor's degree in mechanical engineering in 1966. In 1971, he earned a Ph.D. in mechanical engineering and plasma physics. Schneider studied the role of greenhouse gases and suspended particulate material on climate as a postdoctoral fellow at NASA's Goddard Institute for Space Studies.

In 1971, Schneider was second author on a "Science" paper with S. I. Rasool titled "Atmospheric Carbon Dioxide and Aerosols: Effects of Large Increases on Global Climate" ("Science" 173, 138–141). This paper used a one-dimensional radiative transfer model to examine the competing effects of cooling from aerosols and warming from CO. The paper concluded that:

Carbon dioxide was predicted to have only a minor role. However, the model was very simple and the calculation of the CO effect was lower than other estimates by a factor of about three, as noted in a footnote to the paper.

The story made headlines in the "New York Times". Shortly afterwards, Schneider became aware that he had overestimated the cooling effect of aerosols, and underestimated the warming effect of CO by a factor of about three. He had mistakenly assumed that measurements of air particles he had taken near the source of pollution applied worldwide. He also found that much of the effect was due to natural aerosols which would not be affected by human activities, so the cooling effect of changes in industrial pollution would be much less than he had calculated. Having found that recalculation showed that global warming was the more likely outcome, he published a retraction of his earlier findings in 1974.

In a 1976 book "The Genesis Strategy" he discusses both long-term warming due to carbon dioxide and short-term cooling due to aerosols, and advocated for adopting policies that are resilient to future changes in climate.

Schneider was a frequent contributor to commercial and noncommercial print and broadcast media on climate and environmental issues, e.g., "Nova", "Planet Earth", "Nightline", "Today Show", "The Tonight Show", Bill Maher's shows, "Good Morning America", "Dateline", The Discovery Channel, as well as appearances on the British, Canadian and Australian Broadcasting Corporations.

Schneider has commented about the frustrations and difficulties involved with assessing and communicating scientific ideas.

In a January 2002 "Scientific American" article Schneider wrote:
In 1989, Schneider addressed the challenge scientists face trying to communicate complex, important issues without adequate time during media interviews. This citation sometimes was used by his critics to accuse him of supporting misuse of science for political goals:

For the original, together with Schneider's commentary on its misrepresentation, see also American Physical Society, "APS News" August/September 1996.


Schneider was married to the biologist Terry Root. Schneider was a survivor of an aggressive cancer, mantle cell lymphoma. He documented his struggle to conquer the condition, including applying his own knowledge of science to design his own treatment regime, in a self-published 2005 book, "The Patient from Hell". He died unexpectedly on July 19, 2010 after suffering a pulmonary embolism while returning from a scientific meeting in , Sweden.






</doc>
<doc id="29537" url="https://en.wikipedia.org/wiki?curid=29537" title="Scientific misconduct">
Scientific misconduct

Scientific misconduct is the violation of the standard codes of scholarly conduct and ethical behavior in the publication of professional scientific research. A "Lancet" review on "Handling of Scientific Misconduct in Scandinavian countries" provides the following sample definitions: (reproduced in The COPE report 1999.)

The consequences of scientific misconduct can be damaging for perpetrators and journal audience and for any individual who exposes it. In addition there are public health implications attached to the promotion of medical or other interventions based on false or fabricated research findings.

Three percent of the 3,475 research institutions that report to the US Department of Health and Human Services' Office of Research Integrity, indicate some form of scientific misconduct. However the ORI will only investigate allegations of impropriety where research was funded by federal grants. They routinely monitor such research publication for red flags and their investigation is subject to a statute of limitations. Other private organizations like the Committee of Medical Journal Editors (COJE) can only police their own members.

The validity of the methods and results of scientific papers are often scrutinized in journal clubs. In this venue, members can decide amongst themselves with the help of peers if a scientific paper's ethical standards are met.

According to David Goodstein of Caltech, there are motivators for scientists to commit misconduct, which are briefly summarised here.

The U.S. National Science Foundation defines three types of research misconduct: fabrication, falsification, and plagiarism.
Other types of research misconduct are also recognized:

Compared to other forms of scientific misconduct, image fraud (manipulation of images to distort their meaning) is of particular interest since it can frequently be detected by external parties. In 2006, the "Journal of Cell Biology" gained publicity for instituting tests to detect photo manipulation in papers that were being considered for publication. This was in response to the increased usage of programs such as Adobe Photoshop by scientists, which facilitate photo manipulation. Since then more publishers, including the Nature Publishing Group, have instituted similar tests and require authors to minimize and specify the extent of photo manipulation when a manuscript is submitted for publication. However, there is little evidence to indicate that such tests are applied rigorously. One Nature paper published in 2009 has subsequently been reported to contain around 20 separate instances of image fraud.

Although the type of manipulation that is allowed can depend greatly on the type of experiment that is presented and also differ from one journal to another, in general the following manipulations are not allowed:

All authors of a scientific publication are expected to have made reasonable attempts to check findings submitted to academic journals for publication.

Simultaneous submission of scientific findings to more than one journal or duplicate publication of findings is usually regarded as misconduct, under what is known as the Ingelfinger rule, named after the editor of the New England Journal of Medicine 1967-1977, Franz Ingelfinger.

Guest authorship (where there is stated authorship in the absence of involvement, also known as gift authorship) and ghost authorship (where the real author is not listed as an author) are commonly regarded as forms of research misconduct. In some cases coauthors of faked research have been accused of inappropriate behavior or research misconduct for failing to verify reports authored by others or by a commercial sponsor. Examples include the case of Gerald Schatten who co-authored with Hwang Woo-Suk, the case of Professor Geoffrey Chamberlain named as guest author of papers fabricated by Malcolm Pearce, (Chamberlain was exonerated from collusion in Pearce's deception) – and the coauthors with Jan Hendrik Schön at Bell Laboratories. More recent cases include that of Charles Nemeroff, then the editor-in-chief of "Neuropsychopharmacology", and a well-documented case involving the drug Actonel.

Authors are expected to keep all study data for later examination even after publication. The failure to keep data may be regarded as misconduct. Some scientific journals require that authors provide information to allow readers to determine whether the authors might have commercial or non-commercial conflicts of interest. Authors are also commonly required to provide information about ethical aspects of research, particularly where research involves human or animal participants or use of biological material. Provision of incorrect information to journals may be regarded as misconduct. Financial pressures on universities have encouraged this type of misconduct. The majority of recent cases of alleged misconduct involving undisclosed conflicts of interest or failure of the authors to have seen scientific data involve collaborative research between scientists and biotechnology companies (Nemeroff, Blumsohn).

In general, defining whether an individual is guilty of misconduct requires a detailed investigation by the individual's employing academic institution. Such investigations require detailed and rigorous processes and can be extremely costly. Furthermore, the more senior the individual under suspicion, the more likely it is that conflicts of interest will compromise the investigation. In many countries (with the notable exception of the United States) acquisition of funds on the basis of fraudulent data is not a legal offence and there is consequently no regulator to oversee investigations into alleged research misconduct. Universities therefore have few incentives to investigate allegations in a robust manner, or act on the findings of such investigations if they vindicate the allegation.

Well publicised cases illustrate the potential role that senior academics in research institutions play in concealing scientific misconduct. A King's College (London) internal investigation showed research findings from one of their researchers to be 'at best unreliable, and in many cases spurious' but the college took no action, such as retracting relevant published research or preventing further episodes from occurring. It was only 10 years later, when an entirely separate form of misconduct by the same individual was being investigated by the General Medical Council, that the internal report came to light.

In a more recent case an internal investigation at the National Centre for Cell Science (NCCS), Pune determined that there was evidence of misconduct by Dr. Gopal Kundu, but an external committee was then organised which dismissed the allegation, and the NCCS issued a memorandum exonerating the authors of all charges of misconduct. Undeterred by the NCCS exoneration, the relevant journal ("Journal of Biological Chemistry") withdrew the paper based on its own analysis.

Some academics believe that scientific colleagues who suspect scientific misconduct should consider taking informal action themselves, or reporting their concerns. This question is of great importance since much research suggests that it is very difficult for people to act or come forward when they see unacceptable behavior, unless they have help from their organizations. A "User-friendly Guide," and the existence of a confidential organizational ombudsman may help people who are uncertain about what to do, or afraid of bad consequences for their speaking up.

Journals are responsible for safeguarding the research record and hence have a critical role in dealing with suspected misconduct. This is recognised by the Committee on Publication Ethics (COPE) which has issued clear guidelines on the form (e.g. retraction) that concerns over the research record should take.

Evidence emerged in 2012 that journals learning of cases where there is strong evidence of possible misconduct, with issues potentially affecting a large portion of the findings, frequently fail to issue an expression of concern or correspond with the host institution so that an investigation can be undertaken. In one case the Journal of Clinical Oncology issued a Correction despite strong evidence that the original paper was invalid. In another case, Nature allowed a Corrigendum to be published despite clear evidence of image fraud. Subsequent Retraction of the paper required the actions of an independent whistleblower.

The cases of Joachim Boldt and Yoshitaka Fujii in anaesthesiology focussed attention on the role that journals play in perpetuating scientific fraud as well as how they can deal with it. In the Boldt case, the Editors-in-Chief of 18 specialist journals (generally anaesthesia and intensive care) made a joint statement regarding 88 published clinical trials conducted without Ethics Committee approval. In the Fujii case, involving nearly 200 papers, the journal Anesthesia & Analgesia, which published 24 of Fujii's papers, has accepted that its handling of the issue was inadequate. Following publication of a Letter to the Editor from Kranke and colleagues in April 2000, along with a non-specific response from Dr. Fujii, there was no follow-up on the allegation of data manipulation and no request for an institutional review of Dr. Fujii's research. Anesthesia & Analgesia went on to publish 11 additional manuscripts by Dr. Fujii following the 2000 allegations of research fraud, with Editor Steven Shafer stating in March 2012 that subsequent submissions to the Journal by Dr. Fujii should not have been published without first vetting the allegations of fraud. In April 2012 Shafer led a group of editors to write a joint statement, in the form of an ultimatum made available to the public, to a large number of academic institutions where Fujii had been employed, offering these institutions the chance to attest to the integrity of the bulk of the allegedly fraudulent papers.

The consequences of scientific fraud vary based on the severity of the fraud, the level of notice it receives, and how long it goes undetected. For cases of fabricated evidence, the consequences can be wide-ranging, with others working to confirm (or refute) the false finding, or with research agendas being distorted to address the fraudulent evidence. The Piltdown Man fraud is a case in point: The significance of the bona-fide fossils that were being found was muted for decades because they disagreed with Piltdown Man and the preconceived notions that those faked fossils supported. In addition, the prominent paleontologist Arthur Smith Woodward spent time at Piltdown each year until he died, trying to find more Piltdown Man remains. The misdirection of resources kept others from taking the real fossils more seriously and delayed the reaching of a correct understanding of human evolution. (The Taung Child, which should have been the death knell for the view that the human brain evolved first, was instead treated very critically because of its disagreement with the Piltdown Man evidence.)

In the case of Prof Don Poldermans, the misconduct occurred in reports of trials of treatment to prevent death and myocardial infarction in patients undergoing operations. The trial reports were relied upon to issue guidelines that applied for many years across North America and Europe.

In the case of Dr Alfred Steinschneider, two decades and tens of millions of research dollars were lost trying to find the elusive link between infant sleep apnea, which Steinschneider said he had observed and recorded in his laboratory, and sudden infant death syndrome (SIDS), of which he stated it was a precursor. The cover was blown in 1994, 22 years after Steinschneider's 1972 "Pediatrics" paper claiming such an association, when Waneta Hoyt, the mother of the patients in the paper, was arrested, indicted and convicted on 5 counts of second-degree murder for the smothering deaths of her five children. While that in itself was bad enough, the paper, presumably written as an attempt to save infants' lives, ironically was ultimately used as a defense by parents suspected in multiple deaths of their own children in cases of Münchausen syndrome by proxy. The 1972 "Pediatrics" paper was cited in 404 papers in the interim and is still listed on Pubmed without comment.

The potentially severe consequences for individuals who are found to have engaged in misconduct also reflect on the institutions that host or employ them and also on the participants in any peer review process that has allowed the publication of questionable research. This means that a range of actors in any case may have a motivation to suppress any evidence or suggestion of misconduct. Persons who expose such cases, commonly called whistleblowers, can find themselves open to retaliation by a number of different means. These negative consequences for exposers of misconduct have driven the development of whistle blowers charters – designed to protect those who raise concerns. A whistleblower is almost always alone in their fight – their career becomes completely dependent on the decision about alleged misconduct. If the accusations prove false, their career is completely destroyed, but even in case of positive decision the career of the whistleblower can be under question: their reputation of "troublemaker" will prevent many employers from hiring them. There is no international body where a whistleblower could give their concerns. If a university fails to investigate suspected fraud or provides a fake investigation to save their reputation the whistleblower has no right of appeal.

With the advancement of the internet, there are now several tools available to aid in the detection of plagiarism and multiple publication within biomedical literature. One tool developed in 2006 by researchers in Dr. Harold Garner's laboratory at the University of Texas Southwestern Medical Center at Dallas is Déjà vu, an open-access database containing several thousand instances of duplicate publication. All of the entries in the database were discovered through the use of text data mining algorithm eTBLAST, also created in Dr. Garner's laboratory. The creation of Déjà vu and the subsequent classification of several hundred articles contained therein have ignited much discussion in the scientific community concerning issues such as ethical behavior, journal standards, and intellectual copyright. Studies on this database have been published in journals such as "Nature" and "Science", among others.

Other tools which may be used to detect fraudulent data include error analysis. Measurements generally have a small amount of error, and repeated measurements of the same item will generally result in slight differences in readings. These differences can be analyzed, and follow certain known mathematical and statistical properties. Should a set of data appear to be too faithful to the hypothesis, i.e., the amount of error that would normally be in such measurements does not appear, a conclusion can be drawn that the data may have been forged. Error analysis alone is typically not sufficient to prove that data have been falsified or fabricated, but it may provide the supporting evidence necessary to confirm suspicions of misconduct.

Kirby Lee and Lisa Bero suggest, "Although reviewing raw data can be difficult, time-consuming and expensive, having such a policy would hold authors more accountable for the accuracy of their data and potentially reduce scientific fraud or misconduct."

Andrew Wakefield, who claimed links between the MMR vaccine, autism and inflammatory bowel disease. He was found guilty of dishonesty in his research and banned from medicine by the UK General Medical Council following an investigation by Brian Deer of the London Sunday Times.




</doc>
<doc id="29538" url="https://en.wikipedia.org/wiki?curid=29538" title="Set (card game)">
Set (card game)

Set is a real-time card game designed by Marsha Falco in 1974 and published by Set Enterprises in 1991. The deck consists of 81 cards varying in four features: number (one, two, or three); symbol (diamond, squiggle, oval); shading (solid, striped, or open); and color (red, green, or purple). Each possible combination of features (e.g., a card with three striped green diamonds) appears precisely once in the deck.

The game evolved out of a coding system that the designer used in her job as a geneticist. "Set" won American Mensa's "Mensa Select" award in 1991 and placed 9th in the 1995 "Deutscher Spiele Preis".

Several games can be played with these cards, all involving the concept of a "set". A set consists of three cards satisfying "all" of these conditions:

The rules of "Set" are summarized by: If you can sort a group of three cards into "two of ____ and one of ____", then it is not a set.

For example, these three cards form a set:

Given any two cards from the deck, there is one and only one other card that forms a set with them.

In the standard Set game, the dealer lays out cards on the table until either twelve are laid down or someone sees a set and calls "Set!". The player who called "Set" takes the cards in the set, and the dealer continues to deal out cards until twelve are on the table. A player who sees a set among the twelve cards calls "Set" and takes the three cards, and the dealer lays three more cards on the table. (To call out "set" and not pick one up quickly enough results in a penalty.) It is possible that there is no set among the twelve cards; in this case, the dealer deals out three more cards to make fifteen dealt cards, or eighteen or more, as necessary. This process of dealing by threes and finding sets continues until the deck is exhausted and there are no more sets on the table. At this point, whoever has collected the most sets wins.

Variants were included with the Set game that involve different mechanics to find sets, as well as different player interaction. Additional variants continue to be created by avid players of the game.



</doc>
<doc id="29539" url="https://en.wikipedia.org/wiki?curid=29539" title="Silver Star">
Silver Star

The Silver Star Medal, unofficially the Silver Star, is the United States Armed Forces's third-highest personal decoration for valor in combat. The Silver Star Medal is awarded primarily to members of the United States Armed Forces for gallantry in action against an enemy of the United States.

The Silver Star Medal (SSM) is the successor award to the "Citation Star" ( silver star) which was established by an Act of Congress on July 9, 1918, during World War I. On July 19, 1932, the Secretary of War approved the conversion of the "Citation Star" to the SSM with the original "Citation Star" incorporated into the center of the medal.

Authorization for the Silver Star Medal was placed into law by an Act of Congress for the U.S. Navy on August 7, 1942, and an Act of Congress for the U.S. Army on December 15, 1942. The current statutory authorization for the medal is Title 10 of the United States Code, for the U.S. Army, for the U.S. Air Force, and for the U.S. Navy.

The U.S. Army and Air Force award the medal as the "Silver Star". The U.S. Navy, Marine Corps, and Coast Guard continue to award the medal as the "Silver Star Medal". Since 21 December 2016, the Department of Defense (DoD) refers to the decoration as the Silver Star Medal.

The Silver Star Medal is awarded for gallantry, so long as the action does not justify the award of one of the next higher valor awards: the Distinguished Service Cross, the Navy Cross, or the Air Force Cross. The gallantry displayed must have taken place while in action against an enemy of the United States, while engaged in military operations involving conflict with an opposing foreign force, or while serving with friendly foreign forces engaged in an armed conflict against an opposing armed force in which the United States is not a belligerent party.

The Silver Star Medal is awarded for singular acts of valor or heroism over a brief period, such as one or two days of a battle.

Air Force pilots and combat systems officers and Navy/Marine Corps naval aviators and flight officers flying fighter aircraft, are often considered eligible to receive the Silver Star upon becoming an ace (i.e., having five or more confirmed aerial kills), which entails the pilot and, in multi-seat fighters, the weapons system officer or radar intercept officer, intentionally and successfully risking his life multiple times under combat conditions and emerging victorious. However, during the Vietnam War, the last conflict to produce U.S. fighter aces: an Air Force pilot and two navigators/weapon systems officers (who were later retrained as Air Force pilots), a naval aviator and a naval flight officer/radar intercept officer who had achieved this distinction, were eventually awarded the Air Force Cross and Navy Cross, respectively, in addition to SSMs previously awarded for earlier aerial kills.


The Silver Star Medal is a gold five-pointed star, in circumscribing diameter with a laurel wreath encircling rays from the center and a diameter silver star superimposed in the center. The pendant is suspended from a rectangular shaped metal loop with rounded corners. The reverse has the inscription "FOR GALLANTRY IN ACTION". The ribbon is wide and consists of the following stripes: Old Glory red (center stripe); proceeding outward in pairs white; ultramarine blue; white; and ultramarine blue.

Second and subsequent awards of the Silver Star Medal are denoted by bronze or silver oak leaf clusters in the Army and Air Force and by gold or silver inch stars in the Navy, Marine Corps, and Coast Guard.

The Department of Defense does not keep extensive records for the Silver Star Medal. Independent groups estimate that between 100,000 and 150,000 SSMs have been awarded since the decoration was established. Colonel David Hackworth who was awarded ten SSMs while serving in the Army during the Korean War and Vietnam War, is likely to be the person awarded the most SSMs.

Three Army nurses that served in World War I were cited in 1919 and 1920 with Citation Stars for gallantry in attending to the wounded while under artillery fire in July 1918. In 2007, it was discovered that they had never been awarded their Citation Stars. The three nurses (Army nurses served without rank until 1920) were awarded the Silver Star Medal posthumously:


An unknown number of servicewomen received the award in World War II. Four Army nurses serving in Italy during the war—First Lieutenant Mary Roberts, Second Lieutenant Elaine Roe, Second Lieutenant Rita Virginia Rourke, and Second Lieutenant Ellen Ainsworth (posthumous)—became the first women recipients of the Silver Star, all cited for their bravery in evacuating the 33rd Field Hospital at Anzio on February 10, 1944. Later that same year, Corporal Magdalena Leones, a Filipino American, received the medal for clandestine activities on Luzon; , she is the only female Asian American to receive a Silver Star.

The next known servicewomen to receive the Silver Star is Army National Guard Sergeant Leigh Ann Hester in 2005, for gallantry during an insurgent ambush on a convoy in Iraq and Army Specialist Monica Lin Brown in March 2008, for extraordinary heroism as a combat medic in the War in Afghanistan.

Notable recipients include:

















</doc>
<doc id="29540" url="https://en.wikipedia.org/wiki?curid=29540" title="Single UNIX Specification">
Single UNIX Specification

The Single UNIX Specification (SUS) is the collective name of a family of standards for computer operating systems, compliance with which is required to qualify for using the "UNIX" trademark. The core specifications of the SUS are developed and maintained by the Austin Group, which is a joint working group of IEEE, ISO JTC 1 SC22 and The Open Group. If an operating system is submitted to The Open Group for certification, and passes conformance tests, then it is termed to be compliant with a UNIX standard such as UNIX 98 or UNIX 03.

Very few BSD and Linux-based operating systems are submitted for compliance with the Single UNIX Specification, although system developers generally aim for compliance with POSIX standards, which form the core of the Single UNIX Specification.

The SUS emerged from a mid-1980s project to standardize operating system interfaces for software designed for variants of the Unix operating system. The need for standardization arose because enterprises using computers wanted to be able to develop programs that could be used on the computer systems of different manufacturers without reimplementing the programs. Unix was selected as the basis for a standard system interface partly because it was manufacturer-neutral.

In 1988, these standards became IEEE 1003 (also registered as ISO/IEC 9945), or POSIX, which loosely stands for Portable Operating System Interface.

In the early 1990s, a separate effort known as the Common API Specification or Spec 1170 was initiated by several major vendors, who formed the COSE alliance in the wake of the Unix wars. This specification became more popular because it was available at no cost, whereas the IEEE charged a substantial fee for access to the POSIX specification. Management over these specifications was assigned to X/Open who also received the Unix trademark from Novell in 1993. Unix International (UI) merged into Open Software Foundation (OSF) in 1994 only to merge with X/Open to form The Open Group in 1996.

This was a repackaging of the X/Open Portability Guide (XPG), Issue 4, Version 2.

In 1995, the Open Group released the Single UNIX Specification Version 1, 1995 Edition.

This specification consisted of:
and was at the core of the UNIX 95 brand.

In 1997, the Open Group released the Single UNIX Specification Version 2.

This specification consisted of:
and was at the core of the UNIX 98 brand.

Beginning in 1998, a joint working group known as the Austin Group began to develop the combined standard that would be known as the Single UNIX Specification Version 3 and as POSIX:2001 (formally: IEEE Std 1003.1-2001). It was released on January 30, 2002.

This standard consisted of:
and is at the core of the UNIX 03 brand.

In 2004, a new edition of the POSIX:2001 standard was released, incorporating two technical corrigenda. It is called POSIX:2004 (formally: IEEE Std 1003.1-2004).

In December 2008, the Austin Group published a new major revision, known as POSIX:2008 (formally: IEEE Std 1003.1-2008). This is the core of the Single UNIX Specification, Version 4 (SUSv4).

This standard consists of:

The Technical Corrigendum 1 is mostly targeting internationalization and it introduces a role-based access model. It was published in 2012 for the Unix Base specification and it is registered as the 2013 Edition of POSIX 2008. A trademark "UNIX V7" (not to be confused with V7 UNIX, the version of Research Unix from 1979) has been created to mark compliance with SUS Version 4.

The Technical Corrigendum 2 has been published in September 2016, leading into "IEEE Std 1003.1-2008, 2016 Edition" and "Single UNIX Specification, Version 4, 2016 Edition".

In January 2018 an "administrative rollup" edition, susv4-2018, was released. It incorporates Single UNIX Specification version 4 TC1 and TC2, and is technically identical to the 2016 edition.

SUSv3 totals some 3700 pages, which are thematically divided into four main parts:


The standard user command line and scripting interface is the POSIX shell, an extension of the Bourne Shell based on an early version of the Korn Shell. Other user-level programs, services and utilities include awk, echo, ed, vi, and hundreds of others. Required program-level services include basic I/O (file, terminal, and network) services. A test suite accompanies the standard. It is called PCTS or the POSIX Certification Test Suite.

Additionally, SUS includes CURSES (XCURSES) specification, which specifies 372 functions and 3 header files. All in all, SUSv3 specifies 1742 interfaces.

Note that a system need not include source code derived in any way from AT&T Unix to meet the specification. For instance, IBM OS/390, now z/OS, qualifies as a "Unix" despite having no code in common.

There are two official marks for conforming systems

Older UNIX standards (superseded)

AIX 5L V5.2 with some updates, AIX 5L V5.3 and AIX 6.1, are registered as UNIX 03 compliant. AIX 5L V5.2 is registered as UNIX 98 compliant.

EulerOS 2.0 for the x86-64 architecture were certified as UNIX 03 compliant. The UNIX 03 conformance statement shows that the standard C compiler is from the GNU Compiler Collection (gcc), and that the system is a Linux distribution of the Red Hat family.

HP-UX 11i V3 Release B.11.31 is registered as UNIX 03 compliant. Previous releases are registered as UNIX 95.

HP-UX 11i features also provide partial conformance to the UNIX 98 specification.

Inspur K-UX 2.0 and 3.0 for the x86-64 architecture were certified as UNIX 03 compliant. The UNIX 03 conformance statement for Inspur K-UX 2.0 and 3.0 shows that the standard C compiler is from the GNU Compiler Collection (gcc), and that the system is a Linux distribution of the Red Hat family.

Apple's macOS (previously known as OS X) is a UNIX 03 registered product,
first becoming registered with Mac OS X 10.5 "Leopard" on October 26, 2007 (when run on Macs with Intel processors). All newer versions of macOS (except Mac OS X 10.7 "Lion") have been registered.

Solaris 11 complies with the Single UNIX Specification. Solaris 10 is registered as UNIX 03 compliant on 32-bit and 64-bit x86 (X86-64) and SPARC systems. Solaris 8 and 9 are registered as UNIX 98 compliant on 32-bit x86 and SPARC systems; 64-bit x86 systems are not supported.

Solaris 2.5.1 was also registered as UNIX 95 compliant on the PReP PowerPC platform in 1996, but the product was withdrawn before more than a few dozen copies had been sold.

IBM z/OS 1.2 and higher is registered as UNIX 95 compliant.
z/OS 1.9, released on September 28, 2007, and subsequent releases "better align" with UNIX 03.

The last Reliant UNIX versions were registered as UNIX 95 compliant (XPG4 hard branding).

UnixWare 7.1.3 is registered as UNIX 95 compliant.
SCO OpenServer 5 is registered as UNIX 93 compliant.

Tru64 UNIX V5.1A and later are registered as UNIX 98 compliant.

Other operating systems registered as UNIX 95 or UNIX 93 compliant:

Developers and vendors of Unix-like operating systems such as Linux, FreeBSD, and MINIX, typically do not certify their distributions and do not install full POSIX utilities by default. Sometimes, SUS compliance can be improved by installing additional packages, but very few Linux systems can be configured to be completely conformant.

Darwin, the open source subset of macOS, has behavior that can be set to comply with UNIX 03.

FreeBSD previously had a "C99 and POSIX Conformance Project" which aimed for compliance with a subset of the Single UNIX Specification, and documentation where there were differences.

For Linux, the Linux Standard Base was formed in 2001 as an attempt to standardize the internal structures of Linux-based systems for increased compatibility. It is based on the POSIX specifications, the Single UNIX Specification, and other open standards, and also extends them in several areas; but there are some conflicts between the LSB and The POSIX standards. However, although these standards are commonly accepted, few Linux distributions actually go through certification as LSB compliant.




</doc>
<doc id="29544" url="https://en.wikipedia.org/wiki?curid=29544" title="Scientific Revolution">
Scientific Revolution

The Scientific Revolution was a series of events that marked the emergence of modern science during the early modern period, when developments in mathematics, physics, astronomy, biology (including human anatomy) and transformed the views of society about nature. The Scientific Revolution took place in Europe towards the end of the Renaissance period and continued through the late 18th century, influencing the intellectual social movement known as the Enlightenment. While its dates are debated, the publication in 1543 of Nicolaus Copernicus's "De revolutionibus orbium coelestium" ("On the Revolutions of the Heavenly Spheres") is often cited as marking the beginning of the Scientific Revolution.

The concept of a scientific revolution taking place over an extended period emerged in the eighteenth century in the work of Jean Sylvain Bailly, who saw a two-stage process of sweeping away the old and establishing the new. The beginning of the Scientific Revolution, the "Scientific Renaissance", was focused on the recovery of the knowledge of the ancients; this is generally considered to have ended in 1632 with publication of Galileo's "Dialogue Concerning the Two Chief World Systems". The completion of the Scientific Revolution is attributed to the "grand synthesis" of Isaac Newton's 1687 "Principia". The work formulated the laws of motion and universal gravitation thereby completing the synthesis of a new cosmology. By the end of the 18th century, the Scientific Revolution had given way to the "Age of Reflection."

Great advances in science have been termed "revolutions" since the 18th century. In 1747, Clairaut wrote that "Newton was said in his own lifetime to have created a revolution". The word was also used in the preface to Lavoisier's 1789 work announcing the discovery of oxygen. "Few revolutions in science have immediately excited so much general notice as the introduction of the theory of oxygen ... Lavoisier saw his theory accepted by all the most eminent men of his time, and established over a great part of Europe within a few years from its first promulgation."

In the 19th century, William Whewell described the revolution in science itself—the scientific method—that had taken place in the 15th–16th century. "Among the most conspicuous of the revolutions which opinions on this subject have undergone, is the transition from an implicit trust in the internal powers of man's mind to a professed dependence upon external observation; and from an unbounded reverence for the wisdom of the past, to a fervid expectation of change and improvement." This gave rise to the common view of the Scientific Revolution today:

The Scientific Revolution is traditionally assumed to start with the Copernican Revolution (initiated in 1543) and to be complete in the "grand synthesis" of Isaac Newton's 1687 "Principia". Much of the change of attitude came from Francis Bacon whose "confident and emphatic announcement" in the modern progress of science inspired the creation of scientific societies such as the Royal Society, and Galileo who championed Copernicus and developed the science of motion.

In the 20th century, Alexandre Koyré introduced the term "scientific revolution", centering his analysis on Galileo. The term was popularized by Butterfield in his "Origins of Modern Science". Thomas Kuhn's 1962 work "The Structure of Scientific Revolutions" emphasized that different theoretical frameworks—such as Einstein's relativity theory and Newton's theory of gravity, which it replaced—cannot be directly compared.

The period saw a fundamental transformation in scientific ideas across mathematics, physics, astronomy, and biology in institutions supporting scientific investigation and in the more widely held picture of the universe. The Scientific Revolution led to the establishment of several modern sciences. In 1984, Joseph Ben-David wrote:

Many contemporary writers and modern historians claim that there was a revolutionary change in world view. In 1611 the English poet, John Donne, wrote:
Mid-20th-century historian Herbert Butterfield was less disconcerted, but nevertheless saw the change as fundamental:
The history professor Peter Harrison attributes Christianity to having contributed to the rise of the Scientific Revolution:

The Scientific Revolution was built upon the foundation of ancient Greek learning and science in the Middle Ages, as it had been elaborated and further developed by Roman/Byzantine science and medieval Islamic science. Some scholars have noted a direct tie between "particular aspects of traditional Christianity" and the rise of science. 
The "Aristotelian tradition" was still an important intellectual framework in the 17th century, although by that time natural philosophers had moved away from much of it. Key scientific ideas dating back to classical antiquity had changed drastically over the years, and in many cases been discredited. The ideas that remained, which were transformed fundamentally during the Scientific Revolution, include:

It is important to note that ancient precedent existed for alternative theories and developments which prefigured later discoveries in the area of physics and mechanics; but in light of the limited number of works to survive translation in a period when many books were lost to warfare, such developments remained obscure for centuries and are traditionally held to have had little effect on the re-discovery of such phenomena; whereas the invention of the printing press made the wide dissemination of such incremental advances of knowledge commonplace. Meanwhile, however, significant progress in geometry, mathematics, and astronomy was made in medieval times.

It is also true that many of the important figures of the Scientific Revolution shared in the general Renaissance respect for ancient learning and cited ancient pedigrees for their innovations. Nicolaus Copernicus (1473–1543), Galileo Galilei (1564–1642), Kepler (1571–1630) and Newton (1642–1727), all traced different ancient and medieval ancestries for the heliocentric system. In the Axioms Scholium of his "Principia," Newton said its axiomatic three laws of motion were already accepted by mathematicians such as Huygens (1629–1695), Wallace, Wren and others. While preparing a revised edition of his "Principia", Newton attributed his law of gravity and his to a range of historical figures.

Despite these qualifications, the standard theory of the history of the Scientific Revolution claims that the 17th century was a period of revolutionary scientific changes. Not only were there revolutionary theoretical and experimental developments, but that even more importantly, the way in which scientists worked was radically changed. For instance, although intimations of the concept of inertia are suggested sporadically in ancient discussion of motion,
the salient point is that Newton's theory differed from ancient understandings in key ways, such as an external force being a requirement for violent motion in Aristotle's theory.

Under the scientific method as conceived in the 17th century, natural and artificial circumstances were set aside as a research tradition of systematic experimentation was slowly accepted by the scientific community. The philosophy of using an inductive approach to obtain knowledge — to abandon assumption and to attempt to observe with an open mind — was in contrast with the earlier, Aristotelian approach of deduction, by which analysis of known facts produced further understanding. In practice, many scientists and philosophers believed that a healthy mix of both was needed — the willingness to question assumptions, yet also to interpret observations assumed to have some degree of validity.

By the end of the Scientific Revolution the qualitative world of book-reading philosophers had been changed into a mechanical, mathematical world to be known through experimental research. Though it is certainly not true that Newtonian science was like modern science in all respects, it conceptually resembled ours in many ways. Many of the hallmarks of modern science, especially with regard to its institutionalization and professionalization, did not become standard until the mid-19th century.

The Aristotelian scientific tradition's primary mode of interacting with the world was through observation and searching for "natural" circumstances through reasoning. Coupled with this approach was the belief that rare events which seemed to contradict theoretical models were aberrations, telling nothing about nature as it "naturally" was. During the Scientific Revolution, changing perceptions about the role of the scientist in respect to nature, the value of evidence, experimental or observed, led towards a scientific methodology in which empiricism played a large, but not absolute, role.

By the start of the Scientific Revolution, empiricism had already become an important component of science and natural philosophy. Prior thinkers, including the early 14th century nominalist philosopher William of Ockham, had begun the intellectual movement toward empiricism.

The term British empiricism came into use to describe philosophical differences perceived between two of its founders Francis Bacon, described as empiricist, and René Descartes, who was described as a rationalist. Thomas Hobbes, George Berkeley, and David Hume were the philosophy's primary exponents, who developed a sophisticated empirical tradition as the basis of human knowledge.

An influential formulation of empiricism was John Locke's "An Essay Concerning Human Understanding" (1689), in which he maintained that the only true knowledge that could be accessible to the human mind was that which was based on experience. He wrote that the human mind was created as a "tabula rasa", a "blank tablet," upon which sensory impressions were recorded and built up knowledge through a process of reflection.

The philosophical underpinnings of the Scientific Revolution were laid out by Francis Bacon, who has been called the father of empiricism. His works established and popularised inductive methodologies for scientific inquiry, often called the "Baconian method", or simply the scientific method. His demand for a planned procedure of investigating all things natural marked a new turn in the rhetorical and theoretical framework for science, much of which still surrounds conceptions of proper methodology today.

Bacon proposed a great reformation of all process of knowledge for the advancement of learning divine and human, which he called "Instauratio Magna" (The Great Instauration). For Bacon, this reformation would lead to a great advancement in science and a progeny of new inventions that would relieve mankind's miseries and needs. His "Novum Organum" was published in 1620. He argued that man is "the minister and interpreter of nature", that "knowledge and human power are synonymous", that "effects are produced by the means of instruments and helps", and that "man while operating can only apply or withdraw natural bodies; nature internally performs the rest", and later that "nature can only be commanded by obeying her". Here is an abstract of the philosophy of this work, that by the knowledge of nature and the using of instruments, man can govern or direct the natural work of nature to produce definite results. Therefore, that man, by seeking knowledge of nature, can reach power over it – and thus reestablish the "Empire of Man over creation", which had been lost by the Fall together with man's original purity. In this way, he believed, would mankind be raised above conditions of helplessness, poverty and misery, while coming into a condition of peace, prosperity and security.

For this purpose of obtaining knowledge of and power over nature, Bacon outlined in this work a new system of logic he believed to be superior to the old ways of syllogism, developing his scientific method, consisting of procedures for isolating the formal cause of a phenomenon (heat, for example) through eliminative induction. For him, the philosopher should proceed through inductive reasoning from fact to axiom to physical law. Before beginning this induction, though, the enquirer must free his or her mind from certain false notions or tendencies which distort the truth. In particular, he found that philosophy was too preoccupied with words, particularly discourse and debate, rather than actually observing the material world: "For while men believe their reason governs words, in fact, words turn back and reflect their power upon the understanding, and so render philosophy and science sophistical and inactive."

Bacon considered that it is of greatest importance to science not to keep doing intellectual discussions or seeking merely contemplative aims, but that it should work for the bettering of mankind's life by bringing forth new inventions, having even stated that "inventions are also, as it were, new creations and imitations of divine works". He explored the far-reaching and world-changing character of inventions, such as the printing press, gunpowder and the compass.

Bacon first described the experimental method.
William Gilbert was an early advocate of this method. He passionately rejected both the prevailing Aristotelian philosophy and the Scholastic method of university teaching. His book "De Magnete" was written in 1600, and he is regarded by some as the father of electricity and magnetism. In this work, he describes many of his experiments with his model Earth called the terrella. From these experiments, he concluded that the Earth was itself magnetic and that this was the reason compasses point north.

"De Magnete" was influential not only because of the inherent interest of its subject matter, but also for the rigorous way in which Gilbert described his experiments and his rejection of ancient theories of magnetism. According to Thomas Thomson, "Gilbert['s]... book on magnetism published in 1600, is one of the finest examples of inductive philosophy that has ever been presented to the world. It is the more remarkable, because it preceded the "Novum Organum" of Bacon, in which the inductive method of philosophizing was first explained."

Galileo Galilei has been called the "father of modern observational astronomy", the "father of modern physics", the "father of science", and "the Father of Modern Science". His original contributions to the science of motion were made through an innovative combination of experiment and mathematics.

Galileo was one of the first modern thinkers to clearly state that the laws of nature are mathematical. In "The Assayer" he wrote "Philosophy is written in this grand book, the universe ... It is written in the language of mathematics, and its characters are triangles, circles, and other geometric figures;..." His mathematical analyses are a further development of a tradition employed by late scholastic natural philosophers, which Galileo learned when he studied philosophy. He ignored Aristotelianism. In broader terms, his work marked another step towards the eventual separation of science from both philosophy and religion; a major development in human thought. He was often willing to change his views in accordance with observation. In order to perform his experiments, Galileo had to set up standards of length and time, so that measurements made on different days and in different laboratories could be compared in a reproducible fashion. This provided a reliable foundation on which to confirm mathematical laws using inductive reasoning.

Galileo showed an appreciation for the relationship between mathematics, theoretical physics, and experimental physics. He understood the parabola, both in terms of conic sections and in terms of the ordinate (y) varying as the square of the abscissa (x). Galilei further asserted that the parabola was the theoretically ideal trajectory of a uniformly accelerated projectile in the absence of friction and other disturbances. He conceded that there are limits to the validity of this theory, noting on theoretical grounds that a projectile trajectory of a size comparable to that of the Earth could not possibly be a parabola, but he nevertheless maintained that for distances up to the range of the artillery of his day, the deviation of a projectile's trajectory from a parabola would be only very slight.

Scientific knowledge, according to the Aristotelians, was concerned with establishing true and necessary causes of things. To the extent that medieval natural philosophers used mathematical problems, they limited social studies to theoretical analyses of local speed and other aspects of life. The actual measurement of a physical quantity, and the comparison of that measurement to a value computed on the basis of theory, was largely limited to the mathematical disciplines of astronomy and optics in Europe.

In the 16th and 17th centuries, European scientists began increasingly applying quantitative measurements to the measurement of physical phenomena on the Earth. Galileo maintained strongly that mathematics provided a kind of necessary certainty that could be compared to God's: "...with regard to those few [mathematical propositions] which the human intellect does understand, I believe its knowledge equals the Divine in objective certainty..."

Galileo anticipates the concept of a systematic mathematical interpretation of the world in his book "Il Saggiatore":

Aristotle recognized four kinds of causes, and where applicable, the most important of them is the "final cause". The final cause was the aim, goal, or purpose of some natural process or man-made thing. Until the Scientific Revolution, it was very natural to see such aims, such as a child's growth, for example, leading to a mature adult. Intelligence was assumed only in the purpose of man-made artifacts; it was not attributed to other animals or to nature.

In "mechanical philosophy" no field or action at a distance is permitted, particles or corpuscles of matter are fundamentally inert. Motion is caused by direct physical collision. Where natural substances had previously been understood organically, the mechanical philosophers viewed them as machines. As a result, Isaac Newton's theory seemed like some kind of throwback to "spooky action at a distance". According to Thomas Kuhn, Newton and Descartes held the teleological principle that God conserved the amount of motion in the universe:

Gravity, interpreted as an innate attraction between every pair of particles of matter, was an occult quality in the same sense as the scholastics' "tendency to fall" had been... By the mid eighteenth century that interpretation had been almost universally accepted, and the result was a genuine reversion (which is not the same as a retrogression) to a scholastic standard. Innate attractions and repulsions joined size, shape, position and motion as physically irreducible primary properties of matter.

Newton had also specifically attributed the inherent power of inertia to matter, against the mechanist thesis that matter has no inherent powers. But whereas Newton vehemently denied gravity was an inherent power of matter, his collaborator Roger Cotes made gravity also an inherent power of matter, as set out in his famous preface to the "Principia's" 1713 second edition which he edited, and contradicted Newton himself. And it was Cotes's interpretation of gravity rather than Newton's that came to be accepted.

The first moves towards the institutionalization of scientific investigation and dissemination took the form of the establishment of societies, where new discoveries were aired, discussed and published. The first scientific society to be established was the Royal Society of London. This grew out of an earlier group, centred around Gresham College in the 1640s and 1650s. According to a history of the College:

The scientific network which centred on Gresham College played a crucial part in the meetings which led to the formation of the Royal Society.

These physicians and natural philosophers were influenced by the "new science", as promoted by Francis Bacon in his "New Atlantis", from approximately 1645 onwards. A group known as "The Philosophical Society of Oxford" was run under a set of rules still retained by the Bodleian Library.

On 28 November 1660, the 1660 committee of 12 announced the formation of a "College for the Promoting of Physico-Mathematical Experimental Learning", which would meet weekly to discuss science and run experiments. At the second meeting, Robert Moray announced that the King approved of the gatherings, and a Royal charter was signed on 15 July 1662 creating the "Royal Society of London", with Lord Brouncker serving as the first President. A second Royal Charter was signed on 23 April 1663, with the King noted as the Founder and with the name of "the Royal Society of London for the Improvement of Natural Knowledge"; Robert Hooke was appointed as Curator of Experiments in November. This initial royal favour has continued, and since then every monarch has been the patron of the Society.

The Society's first Secretary was Henry Oldenburg. Its early meetings included experiments performed first by Robert Hooke and then by Denis Papin, who was appointed in 1684. These experiments varied in their subject area, and were both important in some cases and trivial in others. The society began publication of "Philosophical Transactions" from 1665, the oldest and longest-running scientific journal in the world, which established the important principles of scientific priority and peer review.

The French established the Academy of Sciences in 1666. In contrast to the private origins of its British counterpart, the Academy was founded as a government body by Jean-Baptiste Colbert. Its rules were set down in 1699 by King Louis XIV, when it received the name of 'Royal Academy of Sciences' and was installed in the Louvre in Paris.

As the Scientific Revolution was not marked by any single change, the following new ideas contributed to what is called the Scientific Revolution. Many of them were revolutions in their own fields.


For almost five millennia, the geocentric model of the Earth as the center of the universe had been accepted by all but a few astronomers. In Aristotle's cosmology, Earth's central location was perhaps less significant than its identification as a realm of imperfection, inconstancy, irregularity and change, as opposed to the "heavens" (Moon, Sun, planets, stars), which were regarded as perfect, permanent, unchangeable, and in religious thought, the realm of heavenly beings. The Earth was even composed of different material, the four elements "earth", "water", "fire", and "air", while sufficiently far above its surface (roughly the Moon's orbit), the heavens were composed of different substance called "aether". The heliocentric model that replaced it involved not only the radical displacement of the earth to an orbit around the sun, but its sharing a placement with the other planets implied a universe of heavenly components made from the same changeable substances as the Earth. Heavenly motions no longer needed to be governed by a theoretical perfection, confined to circular orbits.

Copernicus' 1543 work on the heliocentric model of the solar system tried to demonstrate that the sun was the center of the universe. Few were bothered by this suggestion, and the pope and several archbishops were interested enough by it to want more detail. His model was later used to create the calendar of Pope Gregory XIII. However, the idea that the earth moved around the sun was doubted by most of Copernicus' contemporaries. It contradicted not only empirical observation, due to the absence of an observable stellar parallax, but more significantly at the time, the authority of Aristotle.

The discoveries of Johannes Kepler and Galileo gave the theory credibility. Kepler was an astronomer who, using the accurate observations of Tycho Brahe, proposed that the planets move around the sun not in circular orbits, but in elliptical ones. Together with his other laws of planetary motion, this allowed him to create a model of the solar system that was an improvement over Copernicus' original system. Galileo's main contributions to the acceptance of the heliocentric system were his mechanics, the observations he made with his telescope, as well as his detailed presentation of the case for the system. Using an early theory of inertia, Galileo could explain why rocks dropped from a tower fall straight down even if the earth rotates. His observations of the moons of Jupiter, the phases of Venus, the spots on the sun, and mountains on the moon all helped to discredit the Aristotelian philosophy and the Ptolemaic theory of the solar system. Through their combined discoveries, the heliocentric system gained support, and at the end of the 17th century it was generally accepted by astronomers.

This work culminated in the work of Isaac Newton. Newton's "Principia" formulated the laws of motion and universal gravitation, which dominated scientists' view of the physical universe for the next three centuries. By deriving Kepler's laws of planetary motion from his mathematical description of gravity, and then using the same principles to account for the trajectories of comets, the tides, the precession of the equinoxes, and other phenomena, Newton removed the last doubts about the validity of the heliocentric model of the cosmos. This work also demonstrated that the motion of objects on Earth and of celestial bodies could be described by the same principles. His prediction that the Earth should be shaped as an oblate spheroid was later vindicated by other scientists. His laws of motion were to be the solid foundation of mechanics; his law of universal gravitation combined terrestrial and celestial mechanics into one great system that seemed to be able to describe the whole world in mathematical formulae.

As well as proving the heliocentric model, Newton also developed the theory of gravitation. In 1679, Newton began to consider gravitation and its effect on the orbits of planets with reference to Kepler's laws of planetary motion. This followed stimulation by a brief exchange of letters in 1679–80 with Robert Hooke, who had been appointed to manage the Royal Society's correspondence, and who opened a correspondence intended to elicit contributions from Newton to Royal Society transactions. Newton's reawakening interest in astronomical matters received further stimulus by the appearance of a comet in the winter of 1680–1681, on which he corresponded with John Flamsteed. After the exchanges with Hooke, Newton worked out proof that the elliptical form of planetary orbits would result from a centripetal force inversely proportional to the square of the radius vector (see Newton's law of universal gravitation – History and "De motu corporum in gyrum"). Newton communicated his results to Edmond Halley and to the Royal Society in "De motu corporum in gyrum", in 1684. This tract contained the nucleus that Newton developed and expanded to form the "Principia".

The "Principia" was published on 5 July 1687 with encouragement and financial help from Edmond Halley. In this work, Newton stated the three universal laws of motion that contributed to many advances during the Industrial Revolution which soon followed and were not to be improved upon for more than 200 years. Many of these advancements continue to be the underpinnings of non-relativistic technologies in the modern world. He used the Latin word "gravitas" (weight) for the effect that would become known as gravity, and defined the law of universal gravitation.

Newton's postulate of an invisible force able to act over vast distances led to him being criticised for introducing "occult agencies" into science. Later, in the second edition of the "Principia" (1713), Newton firmly rejected such criticisms in a concluding General Scholium, writing that it was enough that the phenomena implied a gravitational attraction, as they did; but they did not so far indicate its cause, and it was both unnecessary and improper to frame hypotheses of things that were not implied by the phenomena. (Here Newton used what became his famous expression "hypotheses non fingo").

The writings of Greek physician Galen had dominated European medical thinking for over a millennium. The Flemish scholar Vesalius demonstrated mistakes in the Galen's ideas. Vesalius dissected human corpses, whereas Galen dissected animal corpses. Published in 1543, Vesalius' "De humani corporis fabrica" was a groundbreaking work of human anatomy. It emphasized the priority of dissection and what has come to be called the "anatomical" view of the body, seeing human internal functioning as an essentially corporeal structure filled with organs arranged in three-dimensional space. This was in stark contrast to many of the anatomical models used previously, which had strong Galenic/Aristotelean elements, as well as elements of astrology.

Besides the first good description of the sphenoid bone, he showed that the sternum consists of three portions and the sacrum of five or six; and described accurately the vestibule in the interior of the temporal bone. He not only verified the observation of Etienne on the valves of the hepatic veins, but he described the vena azygos, and discovered the canal which passes in the fetus between the umbilical vein and the vena cava, since named ductus venosus. He described the omentum, and its connections with the stomach, the spleen and the colon; gave the first correct views of the structure of the pylorus; observed the small size of the caecal appendix in man; gave the first good account of the mediastinum and pleura and the fullest description of the anatomy of the brain yet advanced. He did not understand the inferior recesses; and his account of the nerves is confused by regarding the optic as the first pair, the third as the fifth and the fifth as the seventh.

Further groundbreaking work was carried out by William Harvey, who published "De Motu Cordis" in 1628. Harvey made a detailed analysis of the overall structure of the heart, going on to an analysis of the arteries, showing how their pulsation depends upon the contraction of the left ventricle, while the contraction of the right ventricle propels its charge of blood into the pulmonary artery. He noticed that the two ventricles move together almost simultaneously and not independently like had been thought previously by his predecessors.

In the eighth chapter, Harvey estimated the capacity of the heart, how much blood is expelled through each pump of the heart, and the number of times the heart beats in a half an hour. From these estimations, he demonstrated that according to Gaelen's theory that blood was continually produced in the liver, the absurdly large figure of 540 pounds of blood would have to be produced every day. Having this simple mathematical proportion at hand – which would imply a seemingly impossible role for the liver – Harvey went on to demonstrate how the blood circulated in a circle by means of countless experiments initially done on serpents and fish: tying their veins and arteries in separate periods of time, Harvey noticed the modifications which occurred; indeed, as he tied the veins, the heart would become empty, while as he did the same to the arteries, the organ would swell up.

This process was later performed on the human body (in the image on the left): the physician tied a tight ligature onto the upper arm of a person. This would cut off blood flow from the arteries and the veins. When this was done, the arm below the ligature was cool and pale, while above the ligature it was warm and swollen. The ligature was loosened slightly, which allowed blood from the arteries to come into the arm, since arteries are deeper in the flesh than the veins. When this was done, the opposite effect was seen in the lower arm. It was now warm and swollen. The veins were also more visible, since now they were full of blood.

Various other advances in medical understanding and practice were made. French physician Pierre Fauchard started dentistry science as we know it today, and he has been named "the father of modern dentistry". Surgeon Ambroise Paré (c.1510–1590) was a leader in surgical techniques and battlefield medicine, especially the treatment of wounds, and Herman Boerhaave (1668–1738) is sometimes referred to as a "father of physiology" due to his exemplary teaching in Leiden and his textbook "Institutiones medicae" (1708).

Chemistry, and its antecedent alchemy, became an increasingly important aspect of scientific thought in the course of the 16th and 17th centuries. The importance of chemistry is indicated by the range of important scholars who actively engaged in chemical research. Among them were the astronomer Tycho Brahe, the chemical physician Paracelsus, Robert Boyle, Thomas Browne and Isaac Newton. Unlike the mechanical philosophy, the chemical philosophy stressed the active powers of matter, which alchemists frequently expressed in terms of vital or active principles—of spirits operating in nature.

Practical attempts to improve the refining of ores and their extraction to smelt metals were an important source of information for early chemists in the 16th century, among them Georg Agricola (1494–1555), who published his great work "De re metallica" in 1556. His work describes the highly developed and complex processes of mining metal ores, metal extraction and metallurgy of the time. His approach removed the mysticism associated with the subject, creating the practical base upon which others could build.

English chemist Robert Boyle (1627–1691) is considered to have refined the modern scientific method for alchemy and to have separated chemistry further from alchemy. Although his research clearly has its roots in the alchemical tradition, Boyle is largely regarded today as the first modern chemist, and therefore one of the founders of modern chemistry, and one of the pioneers of modern experimental scientific method. Although Boyle was not the original discover, he is best known for Boyle's law, which he presented in 1662: the law describes the inversely proportional relationship between the absolute pressure and volume of a gas, if the temperature is kept constant within a closed system.

Boyle is also credited for his landmark publication "The Sceptical Chymist" in 1661, which is seen as a cornerstone book in the field of chemistry. In the work, Boyle presents his hypothesis that every phenomenon was the result of collisions of particles in motion. Boyle appealed to chemists to experiment and asserted that experiments denied the limiting of chemical elements to only the classic four: earth, fire, air, and water. He also pleaded that chemistry should cease to be subservient to medicine or to alchemy, and rise to the status of a science. Importantly, he advocated a rigorous approach to scientific experiment: he believed all theories must be tested experimentally before being regarded as true. The work contains some of the earliest modern ideas of atoms, molecules, and chemical reaction, and marks the beginning of the history of modern chemistry.


Important work was done in the field of optics. Johannes Kepler published "Astronomiae Pars Optica" ("The Optical Part of Astronomy") in 1604. In it, he described the inverse-square law governing the intensity of light, reflection by flat and curved mirrors, and principles of pinhole cameras, as well as the astronomical implications of optics such as parallax and the apparent sizes of heavenly bodies. "Astronomiae Pars Optica" is generally recognized as the foundation of modern optics (though the law of refraction is conspicuously absent).

Willebrord Snellius (1580–1626) found the mathematical law of refraction, now known as Snell's law, in 1621. Subsequently René Descartes (1596–1650) showed, by using geometric construction and the law of refraction (also known as Descartes' law), that the angular radius of a rainbow is 42° (i.e. the angle subtended at the eye by the edge of the rainbow and the rainbow's centre is 42°). He also independently discovered the law of reflection, and his essay on optics was the first published mention of this law.

Christiaan Huygens (1629–1695) wrote several works in the area of optics. These included the "Opera reliqua" (also known as "Christiani Hugenii Zuilichemii, dum viveret Zelhemii toparchae, opuscula posthuma") and the "Traité de la lumière".

Isaac Newton investigated the refraction of light, demonstrating that a prism could decompose white light into a spectrum of colours, and that a lens and a second prism could recompose the multicoloured spectrum into white light. He also showed that the coloured light does not change its properties by separating out a coloured beam and shining it on various objects. Newton noted that regardless of whether it was reflected or scattered or transmitted, it stayed the same colour. Thus, he observed that colour is the result of objects interacting with already-coloured light rather than objects generating the colour themselves. This is known as Newton's theory of colour. From this work he concluded that any refracting telescope would suffer from the dispersion of light into colours. The interest of the Royal Society encouraged him to publish his notes "On Colour" (later expanded into "Opticks"). Newton argued that light is composed of particles or "corpuscles" and were refracted by accelerating toward the denser medium, but he had to associate them with waves to explain the diffraction of light.

In his "Hypothesis of Light" of 1675, Newton posited the existence of the ether to transmit forces between particles. In 1704, Newton published "Opticks", in which he expounded his corpuscular theory of light. He considered light to be made up of extremely subtle corpuscles, that ordinary matter was made of grosser corpuscles and speculated that through a kind of alchemical transmutation "Are not gross Bodies and Light convertible into one another, ...and may not Bodies receive much of their Activity from the Particles of Light which enter their Composition?"

Dr. William Gilbert, in "De Magnete", invented the New Latin word "electricus" from "" ("elektron"), the Greek word for "amber". Gilbert undertook a number of careful electrical experiments, in the course of which he discovered that many substances other than amber, such as sulphur, wax, glass, etc., were capable of manifesting electrical properties. Gilbert also discovered that a heated body lost its electricity and that moisture prevented the electrification of all bodies, due to the now well-known fact that moisture impaired the insulation of such bodies. He also noticed that electrified substances attracted all other substances indiscriminately, whereas a magnet only attracted iron. The many discoveries of this nature earned for Gilbert the title of "founder of the electrical science". By investigating the forces on a light metallic needle, balanced on a point, he extended the list of electric bodies, and found also that many substances, including metals and natural magnets, showed no attractive forces when rubbed. He noticed that dry weather with north or east wind was the most favourable atmospheric condition for exhibiting electric phenomena—an observation liable to misconception until the difference between conductor and insulator was understood.

Robert Boyle also worked frequently at the new science of electricity, and added several substances to Gilbert's list of electrics. He left a detailed account of his researches under the title of "Experiments on the Origin of Electricity". Boyle, in 1675, stated that electric attraction and repulsion can act across a vacuum. One of his important discoveries was that electrified bodies in a vacuum would attract light substances, this indicating that the electrical effect did not depend upon the air as a medium. He also added resin to the then known list of electrics.

This was followed in 1660 by Otto von Guericke, who invented an early electrostatic generator. By the end of the 17th Century, researchers had developed practical means of generating electricity by friction with an electrostatic generator, but the development of electrostatic machines did not begin in earnest until the 18th century, when they became fundamental instruments in the studies about the new science of electricity. The first usage of the word "electricity" is ascribed to Sir Thomas Browne in his 1646 work, "Pseudodoxia Epidemica". In 1729 Stephen Gray (1666–1736) demonstrated that electricity could be "transmitted" through metal filaments.

As an aid to scientific investigation, various tools, measuring aids and calculating devices were developed in this period.

John Napier introduced logarithms as a powerful mathematical tool. With the help of the prominent mathematician Henry Briggs their logarithmic tables embodied a computational advance that made calculations by hand much quicker. His Napier's bones used a set of numbered rods as a multiplication tool using the system of lattice multiplication. The way was opened to later scientific advances, particularly in astronomy and dynamics.

At Oxford University, Edmund Gunter built the first analog device to aid computation. The 'Gunter's scale' was a large plane scale, engraved with various scales, or lines. Natural lines, such as the line of chords, the line of sines and tangents are placed on one side of the scale and the corresponding artificial or logarithmic ones were on the other side. This calculating aid was a predecessor of the slide rule. It was William Oughtred (1575–1660) who first used two such scales sliding by one another to perform direct multiplication and division, and thus is credited as the inventor of the slide rule in 1622.

Blaise Pascal (1623–1662) invented the mechanical calculator in 1642. The introduction of his Pascaline in 1645 launched the development of mechanical calculators first in Europe and then all over the world. Gottfried Leibniz (1646–1716), building on Pascal's work, became one of the most prolific inventors in the field of mechanical calculators; he was the first to describe a pinwheel calculator, in 1685, and invented the Leibniz wheel, used in the arithmometer, the first mass-produced mechanical calculator. He also refined the binary number system, foundation of virtually all modern computer architectures.

John Hadley (1682–1744) was the inventor of the octant, the precursor to the sextant (invented by John Bird), which greatly improved the science of navigation.

Denis Papin (1647–1712) was best known for his pioneering invention of the steam digester, the forerunner of the steam engine. The first working steam engine was patented in 1698 by the inventor Thomas Savery, as a "...new invention for raising of water and occasioning motion to all sorts of mill work by the impellent force of fire, which will be of great use and advantage for drayning mines, serveing townes with water, and for the working of all sorts of mills where they have not the benefitt of water nor constant windes." The invention was demonstrated to the Royal Society on 14 June 1699 and the machine was described by Savery in his book "The Miner's Friend; or, An Engine to Raise Water by Fire" (1702), in which he claimed that it could pump water out of mines. Thomas Newcomen (1664–1729) perfected the practical steam engine for pumping water, the Newcomen steam engine. Consequently, Thomas Newcomen can be regarded as a forefather of the Industrial Revolution.

Abraham Darby I (1678–1717) was the first, and most famous, of three generations of the Darby family who played an important role in the Industrial Revolution. He developed a method of producing high-grade iron in a blast furnace fueled by coke rather than charcoal. This was a major step forward in the production of iron as a raw material for the Industrial Revolution.

Refracting telescopes first appeared in the Netherlands in 1608, apparently the product of spectacle makers experimenting with lenses. The inventor is unknown but Hans Lippershey applied for the first patent, followed by Jacob Metius of Alkmaar. Galileo was one of the first scientists to use this new tool for his astronomical observations in 1609.

The reflecting telescope was described by James Gregory in his book "Optica Promota" (1663). He argued that a mirror shaped like the part of a conic section, would correct the spherical aberration that flawed the accuracy of refracting telescopes. His design, the "Gregorian telescope", however, remained un-built.

In 1666, Isaac Newton argued that the faults of the refracting telescope were fundamental because the lens refracted light of different colors differently. He concluded that light could not be refracted through a lens without causing chromatic aberrations. From these experiments Newton concluded that no improvement could be made in the refracting telescope. However, he was able to demonstrate that the angle of reflection remained the same for all colors, so he decided to build a reflecting telescope. It was completed in 1668 and is the earliest known functional reflecting telescope.

50 years later, John Hadley developed ways to make precision aspheric and parabolic objective mirrors for reflecting telescopes, building the first parabolic Newtonian telescope and a Gregorian telescope with accurately shaped mirrors. These were successfully demonstrated to the Royal Society.

The invention of the vacuum pump paved the way for the experiments of Robert Boyle and Robert Hooke into the nature of vacuum and atmospheric pressure. The first such device was made by Otto von Guericke in 1654. It consisted of a piston and an air gun cylinder with flaps that could suck the air from any vessel that it was connected to. In 1657, he pumped the air out of two conjoined hemispheres and demonstrated that a team of sixteen horses were incapable of pulling it apart. The air pump construction was greatly improved by Robert Hooke in 1658.

Evangelista Torricelli (1607–1647) was best known for his invention of the mercury barometer. The motivation for the invention was to improve on the suction pumps that were used to raise water out of the mines. Torricelli constructed a sealed tube filled with mercury, set vertically into a basin of the same substance. The column of mercury fell downwards, leaving a Torricellian vacuum above.

Surviving instruments from this period, tend to be made of durable metals such as brass, gold, or steel, although examples such as telescopes made of wood, pasteboard, or with leather components exist. Those instruments that exist in collections today tend to be robust examples, made by skilled craftspeople for and at the expense of wealthy patrons. These may have been commissioned as displays of wealth. In addition, the instruments preserved in collections may not have received heavy use in scientific work; instruments that had visibly received heavy use were typically destroyed, deemed unfit for display, or excluded from collections altogether. It is also postulated that the scientific instruments preserved in many collections were chosen because they were more appealing to collectors, by virtue of being more ornate, more portable, or made with higher-grade materials.

Intact air pumps are particularly rare. The pump at right included a glass sphere to permit demonstrations inside the vacuum chamber, a common use. The base was wooden, and the cylindrical pump was brass. Other vacuum chambers that survived were made of brass hemispheres.

Instrument makers of the late seventeenth and early eighteenth century were commissioned by organizations seeking help with navigation, surveying, warfare, and astronomical observation. The increase in uses for such instruments, and their widespread use in global exploration and conflict, created a need for new methods of manufacture and repair, which would be met by the Industrial Revolution.

People and key ideas that emerged from the 16th and 17th centuries:

The idea that modern science took place as a kind a revolution has been debated among historians. A weakness of the idea of scientific revolution is the lack of a systematic approach to the question of knowledge in the period comprehended between the 14th and 17th centuries, leading to misunderstandings on the value and role of modern authors. From this standpoint, the continuity thesis is the hypothesis that there was no radical discontinuity between the intellectual development of the Middle Ages and the developments in the Renaissance and early modern period and has been deeply and widely documented by the works of scholars like Pierre Duhem, John Hermann Randall, Alistair Crombie and William A. Wallace, who proved the preexistence of a wide range of ideas used by the followers of the Scientific Revolution thesis to substantiate their claims. Thus, the idea of a scientific revolution following the Renaissance is—according to the continuity thesis—a myth. Some continuity theorists point to earlier intellectual revolutions occurring in the Middle Ages, usually referring to either a European Renaissance of the 12th century or a medieval Muslim scientific revolution, as a sign of continuity.

Another contrary view has been recently proposed by Arun Bala in his dialogical history of the birth of modern science. Bala proposes that the changes involved in the Scientific Revolution—the mathematical realist turn, the mechanical philosophy, the atomism, the central role assigned to the Sun in Copernican heliocentrism—have to be seen as rooted in multicultural influences on Europe. He sees specific influences in Alhazen's physical optical theory, Chinese mechanical technologies leading to the perception of the world as a machine, the Hindu-Arabic numeral system, which carried implicitly a new mode of mathematical atomic thinking, and the heliocentrism rooted in ancient Egyptian religious ideas associated with Hermeticism.

Bala argues that by ignoring such multicultural impacts we have been led to a Eurocentric conception of the Scientific Revolution. However, he clearly states: "The makers of the revolution – Copernicus, Kepler, Galileo, Descartes, Newton, and many others – had to selectively appropriate relevant ideas, transform them, and create new auxiliary concepts in order to complete their task... In the ultimate analysis, even if the revolution was rooted upon a multicultural base it is the accomplishment of Europeans in Europe." Critics note that lacking documentary evidence of transmission of specific scientific ideas, Bala's model will remain "a working hypothesis, not a conclusion".

A third approach takes the term "Renaissance" literally as a "rebirth". A closer study of Greek philosophy and Greek mathematics demonstrates that nearly all of the so-called revolutionary results of the so-called scientific revolution were in actuality restatements of ideas that were in many cases older than those of Aristotle and in nearly all cases at least as old as Archimedes. Aristotle even explicitly argues against some of the ideas that were espoused during the Scientific Revolution, such as heliocentrism. The basic ideas of the scientific method were well known to Archimedes and his contemporaries, as demonstrated in the well-known discovery of buoyancy. Atomism was first thought of by Leucippus and Democritus. Lucio Russo claims that science as a unique approach to objective knowledge was born in the Hellenistic period (c. 300 B.C), but was extinguished with the advent of the Roman Empire. This approach to the Scientific Revolution reduces it to a period of relearning classical ideas that is very much an extension of the Renaissance. This view does not deny that a change occurred but argues that it was a reassertion of previous knowledge (a renaissance) and not the creation of new knowledge. It cites statements from Newton, Copernicus and others in favour of the Pythagorean worldview as evidence.

In more recent analysis of the Scientific Revolution during this period, there has been criticism of not only the Eurocentric ideologies spread, but also of the dominance of male scientists of the time. Science as we know it today, and the original theories that we base modern science on, was built by males, regardless of the input women might have made. The incorporation of women's work in the sciences during this time tends to be obscured. Scholars have tried to look into the participation of women in the 17th century in science, and even with sciences as simple as domestic knowledge women were making advances. With the limited history provided from texts of the period we are not completely aware if women were helping these scientists develop the ideas they did. Another idea to consider is the way this period influenced even the women scientists of the periods following it. Annie Jump Cannon was an astronomer who benefitted from the laws and theories developed from this period; she made several advances in the century following the Scientific Revolution. It was an important period for the future of science, including the incorporation of women into fields using the developments made.




</doc>
<doc id="29545" url="https://en.wikipedia.org/wiki?curid=29545" title="Salian dynasty">
Salian dynasty

The Salian dynasty (; also known as the Frankish dynasty after the family's origin and position as dukes of Franconia) was a dynasty in the High Middle Ages. The dynasty provided four German Kings (1024–1125), all of whom went on to be crowned Holy Roman Emperor (1027–1125); as such, the term "Salic dynasty" is also used to refer to the Holy Roman Empire of the time as a separate term.

After the death of the last Saxon of the Ottonian Dynasty in 1024, the elective titles of King of the Germans and then three years later Holy Roman Emperor both passed to the first monarch of the Salian dynasty in the person of Conrad II, the only son of Count Henry of Speyer and Adelheid of Alsace (both territories in the Franconia of the day). He was elected German King in 1024 and crowned Holy Roman Emperor on 26 March 1027.

The four Salian kings of the dynasty—Conrad II, Henry III, Henry IV, and Henry V—ruled the Holy Roman Empire from 1027 to 1125, and firmly established their monarchy as a major European power. They achieved the development of a permanent administrative system based on a class of public officials answerable to the crown.

Werner of Worms and his son Duke Conrad the Red of Lorraine, who died in 955, founded the ancestral dynasty. Conrad the Red married Liutgarde, a daughter of Emperor Otto I. Their son Otto I, Duke of Carinthia ruled Carinthia from 978 to 1004.

Duke Otto had three sons: Bruno, who became Pope Gregory V; Conrad; and Henry, count of Speyer. Henry was the father of the first Salian Emperor Conrad II.

Pope Leo IX (in office 1049 to 1054) also had family ties to the dynasty, since his grandfather Hugo III was the brother of Adelheid, the grandmother of Henry III.

After the death of the last Saxon Emperor Henry II the first Salian regent Conrad II was elected by the majority of the Prince-electors and was crowned German king in Mainz on 8 September 1024. Early in 1026 Conrad went to Milan, where Ariberto, archbishop of Milan, crowned him king of Italy. When Rudolph III, King of Burgundy died 1032, Conrad II also claimed this kingship on the basis of an inheritance Henry II had extorted from the former in 1006. Despite some opposition, the Burgundian and Provençal nobles paid homage to Conrad in Zürich in 1034. This Kingdom of Burgundy would become known as the Kingdom of Arles under Conrad's successors.

Already in 1028 Conrad II had his son Henry III elected and anointed king of Germany. Henry's tenure led to an overstatement of previously unknown sacral kingship. So during this reign Speyer Cathedral was expanded to be the largest church in Western Christendom. Henry's conception of a legitimate power of royal disposition in the duchies was successful against the dukes, and thus secured royal control. However, in Lorraine, this led to years of conflict, from which Henry emerged as the winner. But also in southern Germany a powerful opposition group was formed in the years 1052–1055. 1046 Henry ended the papal schism, freed the Papacy from dependence on the Roman nobility, and laid the basis for its universal applicability. His early death in 1056 was long regarded as a disaster for the Empire.

The early Salians owed much of their success to their alliance with the Church, a policy begun by Otto I, which gave them the material support they needed to subdue rebellious dukes. In time, however, the Church came to regret this close relationship. The alliance broke down in 1075 during what came to be known as the Investiture Controversy (or "Investiture Dispute"), a struggle in which the reformist Pope, Gregory VII, demanded that Emperor Henry IV renounce his rights over the Church in Germany. The pope also attacked the concept of monarchy by divine right and gained the support of significant elements of the German nobility interested in limiting imperial absolutism. More important, the pope forbade ecclesiastical officials under pain of excommunication to support Henry as they had so freely done in the past. In the end, Henry IV journeyed to Canossa in northern Italy in 1077 to do penance and to receive absolution from the pope. However, he resumed the practice of lay investiture (appointment of religious officials by civil authorities) and arranged the election of an antipope (Antipope Clement III) in 1080.

The monarch's struggle with the papacy resulted in a war that ravaged through the Holy Roman Empire from 1077 until the Concordat of Worms in 1122. The reign of the last ruler of the Salian dynasty Henry V coincided with the final phase of the great Investiture Controversy, which had pitted pope against emperor. By the settlement of the Concordat of Worms, Henry V surrendered to the demands of the second generation of Gregorian reformers. This agreement stipulated that the pope would appoint high church officials but gave the German king the right to veto the papal choices. Imperial control of Italy was lost for a time, and the imperial crown became dependent on the political support of competing aristocratic factions. Feudalism also became more widespread as freemen sought protection by swearing allegiance to a lord. These powerful local rulers, having thereby acquired extensive territories and large military retinues, took over administration within their territories and organized it around an increasing number of castles. The most powerful of these local rulers came to be called princes rather than dukes.

According to the laws of the feudal system of the Holy Roman Empire, the king had no claims on the vassals of the other princes, only on those living within his family's territory. Lacking the support of the formerly independent vassals and weakened by the increasing hostility of the Church, the monarchy lost its pre-eminence. Thus the Investiture Contest strengthened local power in the Holy Roman Empire – in contrast to the trend in France and England, where centralized royal power grew. The Investiture Contest had an additional effect. The long struggle between emperor and pope hurt the Holy Roman Empire's intellectual life, in this period largely confined to monasteries, and the empire no longer led or even kept pace with developments occurring in France and Italy. For instance, no universities were founded in the Holy Roman Empire until the fourteenth century.

The first Hohenstaufen king Conrad III was a grandson of the Salian Henry IV, Holy Roman Emperor. (Agnes, Henry IV's daughter and Henry V's sister, was the heiress of Salian dynasty's lands: her first marriage produced the royal and imperial Hohenstaufen dynasty and her second marriage the ducal Babenberg potentates of Duchy of Austria which was elevated much due to such connections Privilegium Minus.)


Their regnal dates as emperor take into account elections and subsequent coronations.




</doc>
<doc id="29549" url="https://en.wikipedia.org/wiki?curid=29549" title="Self-replication">
Self-replication

Self-replication is any behavior of a dynamical system that yields construction of an identical copy of itself. Biological cells, given suitable environments, reproduce by cell division. During cell division, DNA is replicated and can be transmitted to offspring during reproduction. Biological viruses can replicate, but only by commandeering the reproductive machinery of cells through a process of infection. Harmful prion proteins can replicate by converting normal proteins into rogue forms. Computer viruses reproduce using the hardware and software already present on computers. Self-replication in robotics has been an area of research and a subject of interest in science fiction. Any self-replicating mechanism which does not make a perfect copy will experience genetic variation and will create variants of itself. These variants will be subject to natural selection, since some will be better at surviving in their current environment than others and will out-breed them.

Early research by John von Neumann established that replicators have several parts:


Exceptions to this pattern are possible. For example, scientists have come close to constructing RNA that copies itself in an "environment" that is a solution of RNA monomers and transcriptase. In this case, the body is the genome, and the specialized copy mechanisms are external.

However, the simplest possible case is that only a genome exists. Without some specification of the self-reproducing steps, a genome-only system is probably better characterized as something like a crystal.

Recent research has begun to categorize replicators, often based on the amount of support they require.


The design space for machine replicators is very broad. A comprehensive study to date by Robert Freitas and Ralph Merkle has identified 137 design dimensions grouped into a dozen separate categories, including: (1) Replication Control, (2) Replication Information, (3) Replication Substrate, (4) Replicator Structure, (5) Passive Parts, (6) Active Subunits, (7) Replicator Energetics, (8) Replicator Kinematics, (9) Replication Process, (10) Replicator Performance, (11) Product Structure, and (12) Evolvability.

In computer science a quine is a self-reproducing computer program that, when executed, outputs its own code. For example, a quine in the Python programming language is:

A more trivial approach is to write a program that will make a copy of any stream of data that it is directed to, and then direct it at itself. In this case the program is treated as both executable code, and as data to be manipulated. This approach is common in most self-replicating systems, including biological life, and is simpler as it does not require the program to contain a complete description of itself.

In many programming languages an empty program is legal, and executes without producing errors or other output. The output is thus the same as the source code, so the program is trivially self-reproducing.

In geometry a self-replicating tiling is a tiling pattern in which several congruent tiles may be joined together to form a larger tile that is similar to the original. This is an aspect of the field of study known as tessellation. The "sphinx" hexiamond is the only known self-replicating pentagon. For example, four such concave pentagons can be joined together to make one with twice the dimensions. Solomon W. Golomb coined the term rep-tiles for self-replicating tilings.

In 2012, Lee Sallows identified rep-tiles as a special instance of a self-tiling tile set or setiset. A setiset of order "n" is a set of "n" shapes that can be assembled in "n" different ways so as to form larger replicas of themselves. Setisets in which every shape is distinct are called 'perfect'. A rep-"n" rep-tile is just a setiset composed of "n" identical pieces.

It is a long-term goal of some engineering sciences to achieve a clanking replicator, a material device that can self-replicate. The usual reason is to achieve a low cost per item while retaining the utility of a manufactured good. Many authorities say that in the limit, the cost of self-replicating items should approach the cost-per-weight of wood or other biological substances, because self-replication avoids the costs of labor, capital and distribution in conventional manufactured goods.

A fully novel artificial replicator is a reasonable near-term goal.
A NASA study recently placed the complexity of a clanking replicator at approximately that of Intel's Pentium 4 CPU. That is, the technology is achievable with a relatively small engineering group in a reasonable commercial time-scale at a reasonable cost.

Given the currently keen interest in biotechnology and the high levels of funding in that field, attempts to exploit the replicative ability of existing cells are timely, and may easily lead to significant insights and advances.

A variation of self replication is of practical relevance in compiler construction, where a similar bootstrapping problem occurs as in natural self replication. A compiler (phenotype) can be applied on the compiler's own source code (genotype) producing the compiler itself. During compiler development, a modified (mutated) source is used to create the next generation of the compiler. This process differs from natural self-replication in that the process is directed by an engineer, not by the subject itself.

An activity in the field of robots is the self-replication of machines. Since all robots (at least in modern times) have a fair number of the same features, a self-replicating robot (or possibly a hive of robots) would need to do the following:


On a nano scale, assemblers might also be designed to self-replicate under their own power. This, in turn, has given rise to the "grey goo" version of Armageddon, as featured in such science fiction novels as "Bloom", "Prey", and "Recursion".

The Foresight Institute has published guidelines for researchers in mechanical self-replication. The guidelines recommend that researchers use several specific techniques for preventing mechanical replicators from getting out of control, such as using a broadcast architecture.

For a detailed article on mechanical reproduction as it relates to the industrial age see mass production.

Research has occurred in the following areas:


The goal of self-replication in space systems is to exploit large amounts of matter with a low launch mass. For example, an autotrophic self-replicating machine could cover a moon or planet with solar cells, and beam the power to the Earth using microwaves. Once in place, the same machinery that built itself could also produce raw materials or manufactured objects, including transportation systems to ship the products. Another model of self-replicating machine would copy itself through the galaxy and universe, sending information back.

In general, since these systems are autotrophic, they are the most difficult and complex known replicators. They are also thought to be the most hazardous, because they do not require any inputs from human beings in order to reproduce.

A classic theoretical study of replicators in space is the 1980 NASA study of autotrophic clanking replicators, edited by Robert Freitas.

Much of the design study was concerned with a simple, flexible chemical system for processing lunar regolith, and the differences between the ratio of elements needed by the replicator, and the ratios available in regolith. The limiting element was Chlorine, an essential element to process regolith for Aluminium. Chlorine is very rare in lunar regolith, and a substantially faster rate of reproduction could be assured by importing modest amounts.

The reference design specified small computer-controlled electric carts running on rails. Each cart could have a simple hand or a small bull-dozer shovel, forming a basic robot.

Power would be provided by a "canopy" of solar cells supported on pillars. The other machinery could run under the canopy.

A "casting robot" would use a robotic arm with a few sculpting tools to make plaster molds. Plaster molds are easy to make, and make precise parts with good surface finishes. The robot would then cast most of the parts either from non-conductive molten rock (basalt) or purified metals. An electric oven melted the materials.

A speculative, more complex "chip factory" was specified to produce the computer and electronic systems, but the designers also said that it might prove practical to ship the chips from Earth as if they were "vitamins".

Nanotechnologists in particular believe that their work will likely fail to reach a state of maturity until human beings design a self-replicating assembler of nanometer dimensions .

These systems are substantially simpler than autotrophic systems, because they are provided with purified feedstocks and energy. They do not have to reproduce them. This distinction is at the root of some of the controversy about whether molecular manufacturing is possible or not. Many authorities who find it impossible are clearly citing sources for complex autotrophic self-replicating systems. Many of the authorities who find it possible are clearly citing sources for much simpler self-assembling systems, which have been demonstrated. In the meantime, a Lego-built autonomous robot able to follow a pre-set track and assemble an exact copy of itself, starting from four externally provided components, was demonstrated experimentally in 2003 .

Merely exploiting the replicative abilities of existing cells is insufficient, because of limitations in the process of protein biosynthesis (also see the listing for RNA).
What is required is the rational design of an entirely novel replicator with a much wider range of synthesis capabilities.

In 2011, New York University scientists have developed artificial structures that can self-replicate, a process that has the potential to yield new types of materials. They have demonstrated that it is possible to replicate not just molecules like cellular DNA or RNA, but discrete structures that could in principle assume many different shapes, have many different functional features, and be associated with many different types of chemical species.

For a discussion of other chemical bases for hypothetical self-replicating systems, see alternative biochemistry.





</doc>
<doc id="29550" url="https://en.wikipedia.org/wiki?curid=29550" title="Shmuel Yosef Agnon">
Shmuel Yosef Agnon

Shmuel Yosef Agnon () (July 17, 1888 – February 17, 1970) was a Nobel Prize laureate writer and was one of the central figures of modern Hebrew fiction. In Hebrew, he is known by the acronym Shai Agnon (ש"י עגנון). In English, his works are published under the name S. Y. Agnon.

Agnon was born in Polish Galicia, then part of the Austro-Hungarian Empire, and later immigrated to Mandatory Palestine, and died in Jerusalem, Israel.

His works deal with the conflict between the traditional Jewish life and language and the modern world. They also attempt to recapture the fading traditions of the European "shtetl" (village). In a wider context, he also contributed to broadening the characteristic conception of the narrator's role in literature. Agnon shared the Nobel Prize with the poet Nelly Sachs in 1966.

Shmuel Yosef Halevi Czaczkes (later Agnon) was born in Buczacz (Polish spelling, pronounced "Buchach") or Butschatsch (German spelling), Polish Galicia (then within the Austro-Hungarian Empire), now Buchach, Ukraine. Officially, his date of birth on the Hebrew calendar was 18 Av 5648 (July 26), but he always said his birthday was on the Jewish fast day of Tisha B'Av, the Ninth of Av.

His father, Shalom Mordechai Halevy, was ordained as a rabbi, but worked in the fur trade, and had many connections among the Hasidim, His mother's side had ties to the Mitnagdim.

He did not attend school and was schooled by his parents. In addition to studying Jewish texts, Agnon studied writings of the Haskalah, and was also tutored in German. At the age of eight, he began to write in Hebrew and Yiddish, At the age of 15, he published his first poem – a Yiddish poem about the Kabbalist Joseph della Reina. He continued to write poems and stories in Hebrew and Yiddish, which were published in Galicia.

In 1908, he moved to Jaffa in Ottoman Palestine. The first story he published there was "Agunot" ("Forsaken Wives"), which appeared that same year in the journal "Ha`omer." He used the pen name "Agnon," derived from the title of the story, which he adopted as his official surname in 1924. In 1910, "Forsaken Wives" was translated into German. In 1912, at the urging of Yosef Haim Brenner, he published a novella, "Vehaya Ha'akov Lemishor" ("The Crooked Shall Be Made Straight").

In 1913, Agnon moved to Germany, where he met Esther Marx (1889-1973). They married in 1920 and had two children. In Germany he lived in Berlin and Bad Homburg vor der Höhe (1921–24). Salman Schocken, a businessman and later also publisher, became his literary patron and freed him from financial worries. From 1931 on, his work was published by Schocken Books, and his short stories appeared regularly in the newspaper "Haaretz", also owned by the Schocken family. In Germany, he continued to write short stories and collaborated with Martin Buber on an anthology of Hasidic stories. Many of his early books appeared in Buber's "Jüdischer Verlag" (Berlin). The mostly assimilated, secular German Jews, Buber and Franz Rosenzweig among them, considered Agnon to be a legitimate relic, being a religious man, familiar with Jewish scripture. Gershom Scholem called him "the Jews' Jew".

In 1924, a fire broke out in his home, destroying his manuscripts and rare book collection. This traumatic event crops up occasionally in his stories. Later that year, Agnon returned to Palestine and settled with his family in the Jerusalem neighborhood of Talpiot. In 1929, his library was destroyed again during anti-Jewish riots.

When his novel "Hachnasat Kalla" ("The Bridal Canopy") appeared in 1931 to great critical acclaim, Agnon's place in Hebrew literature was assured. In 1935, he published "Sippur Pashut" ("A Simple Story"), a novella set in Buczacz at the end of the 19th century. Another novel, "Tmol Shilshom" ("Only Yesterday"), set in Eretz Yisrael (Israel) of the early 20th century, appeared in 1945.

Agnon's writing has been the subject of extensive academic research. Many leading scholars of Hebrew literature have published books and papers on his work, among them Baruch Kurzweil, Dov Sadan, Nitza Ben-Dov, Dan Miron, Dan Laor and Alan Mintz. Agnon writes about Jewish life, but with his own unique perspective and special touch. In his Nobel acceptance speech, Agnon claimed "Some see in my books the influences of authors whose names, in my ignorance, I have not even heard, while others see the influences of poets whose names I have heard but whose writings I have not read." He went on to detail that his primary influences were the stories of the Bible. Agnon acknowledged that he was also influenced by German literature and culture, and European literature in general, which he read in German translation. A collection of essays on this subject, edited in part by Hillel Weiss, with contributions from Israeli and German scholars, was published in 2010: "Agnon and Germany: The Presence of the German World in the Writings of S.Y. Agnon". The budding Hebrew literature also influenced his works, notably that of his friend, Yosef Haim Brenner. In Germany, Agnon also spent time with the Hebraists Hayim Nahman Bialik and Ahad Ha'am.

The communities he passed through in his life are reflected in his works:

Nitza Ben-Dov writes about Agnon's use of allusiveness, free-association and imaginative dream-sequences, and discusses how seemingly inconsequential events and thoughts determine the lives of his characters.

Some of Agnon's works, such as "The Bridal Canopy", "And the Crooked Shall Be Made Straight", and "The Doctor's Divorce", have been adapted for theatre. A play based on Agnon's letters to his wife, "Esterlein Yakirati", was performed at the Khan Theater in Jerusalem.

Agnon's writing often used words and phrases that differed from what would become established modern Hebrew. His distinct language is based on traditional Jewish sources, such as the Torah and the Prophets, Midrashic literature, the Mishnah, and other Rabbinic literature. Some examples include:

Bar-Ilan University has made a computerized concordance of his works in order to study his language.

Agnon was twice awarded the Bialik Prize for literature (1934 and 1950). He was also twice awarded the Israel Prize, for literature (1954 and 1958).

In 1966, he was awarded the Nobel Prize in Literature "for his profoundly characteristic narrative art with motifs from the life of the Jewish people". The prize was shared with German Jewish author Nelly Sachs. In his speech at the award ceremony, Agnon introduced himself in Hebrew: "As a result of the historic catastrophe in which Titus of Rome destroyed Jerusalem and Israel was exiled from its land, I was born in one of the cities of the Exile. But always I regarded myself as one who was born in Jerusalem".

In later years, Agnon's fame was such that when he complained to the municipality that traffic noise near his home was disturbing his work, the city closed the street to cars and posted a sign that read: "No entry to all vehicles, writer at work!"

 
Agnon died in Jerusalem on February 17, 1970. His daughter, Emuna Yaron, has continued to publish his work posthumously. Agnon's archive was transferred by the family to the National Library in Jerusalem. His home in Talpiot, built in 1931 in the Bauhaus style, was turned into a museum, "Beit Agnon." The study where he wrote many of his works was preserved intact. Agnon's image, with a list of his works and his Nobel Prize acceptance speech, appeared on the fifty-shekel bill, second series, in circulation from 1985 to 2014. The main street in Jerusalem's Givat Oranim neighborhood is called Sderot Shai Agnon, and a synagogue in Talpiot, a few blocks from his home, is named after him. Agnon is also memorialized in Buchach, now in Ukraine, where he was born. There is an extensive (relative to the size of the museum) exhibition in the Historical Museum in Buchach and, just a few yards away, a bust of Agnon is mounted on a pedestal in a plaza across the street from the house where he lived. The house itself is preserved and marked as the home where Agnon lived from birth till the age of (approximately) 19; the street that runs in front of the house is named "Agnon Street" (in Ukrainian).

Agnotherapy is a method developed in Israel to help elderly people express their feelings.

After Agnon's death, the former mayor of Jerusalem Mordechai Ish-Shalom initiated the opening of his home to the public. In the early 1980s, the kitchen and family dining room were turned into a lecture and conference hall, and literary and cultural evenings were held there. In 2005, the Agnon House Association in Jerusalem renovated the building, which reopened in January 2009. The house was designed by the German-Jewish architect Fritz Korenberg, who was also his neighbor.






In 1977 the Hebrew University published "Yiddish Works", a collection of stories and poems that Agnon wrote in Yiddish during 1903–1906.





</doc>
<doc id="29551" url="https://en.wikipedia.org/wiki?curid=29551" title="Steve Ditko">
Steve Ditko

Stephen J. Ditko (; November 2, 1927 – June 29, 2018) was an American comics artist and writer best known as the artist and co-creator, with Stan Lee, of the Marvel Comics superheroes Spider-Man and Doctor Strange.

Ditko studied under Batman artist Jerry Robinson at the Cartoonist and Illustrators School in New York City. He began his professional career in 1953, working in the studio of Joe Simon and Jack Kirby, beginning as an inker and coming under the influence of artist Mort Meskin. During this time, he then began his long association with Charlton Comics, where he did work in the genres of science fiction, horror, and mystery. He also co-created the superhero Captain Atom in 1960.

During the 1950s, Ditko also drew for Atlas Comics, a forerunner of Marvel Comics. He went on to contribute much significant work to Marvel. In 1966, after being the exclusive artist on "The Amazing Spider-Man" and the "Doctor Strange" feature in "Strange Tales", Ditko left Marvel for reasons he never specified.

Ditko continued to work for Charlton and also DC Comics, including a revamp of the long-running character the Blue Beetle, and creating or co-creating the Question, the Creeper, Shade the Changing Man, and Hawk and Dove. Ditko also began contributing to small independent publishers, where he created Mr. A, a hero reflecting the influence of Ayn Rand's philosophy of Objectivism. Ditko largely declined to give interviews, saying he preferred to communicate through his work.

Ditko was inducted into the comics industry's Jack Kirby Hall of Fame in 1990, and into the Will Eisner Award Hall of Fame in 1994.

Stephen J. Ditko was born on November 2, 1927 in Johnstown, Pennsylvania, the son of first-generation Americans of Slovak descent: Stephen Ditko, an artistically talented master carpenter at a steel mill, and Anna, a homemaker. The second-eldest child in a working-class family, he was preceded by sister Anna Marie, and followed by sister Elizabeth and brother Patrick. Inspired by his father's love of newspaper comic strips, particularly Hal Foster's "Prince Valiant", Ditko found his interest in comics accelerated by the introduction of superhero Batman in 1940, and by Will Eisner's "The Spirit", which appeared in a tabloid-sized comic-book insert in Sunday newspapers.

Ditko in junior high school was part of a group of students who crafted wooden models of German airplanes to aid civilian World War II aircraft-spotters. Upon graduating from Johnstown High School in 1945, he enlisted in the U.S. Army on October 26, 1945, and did military service in postwar Germany, where he drew comics for an Army newspaper.

Following his discharge, Ditko learned that his idol, Batman artist Jerry Robinson, was teaching at the Cartoonists and Illustrators School (later the School of Visual Arts) in New York City. Moving there in 1950, he enrolled in the art school under the G.I. Bill. Robinson found the young student "a very hard worker who really focused on his drawing" and someone who "could work well with other writers as well as write his own stories and create his own characters", and he helped Ditko acquire a scholarship for the following year. "He was in my class for two years, four or five days a week, five hours a night. It was very intense." Robinson, who invited artists and editors to speak with his class, once brought in Stan Lee, then editor of Marvel Comics' 1950s precursor Atlas Comics and, "I think that was when Stan first saw Steve's work."

Ditko began professionally illustrating comic books in early 1953, drawing writer Bruce Hamilton's science-fiction story "Stretching Things" for the Key Publications imprint Stanmor Publications, which sold the story to Ajax/Farrell, where it finally found publication in "Fantastic Fears" #5 (cover-dated Feb. 1954). Ditko's first published work was his second professional story, the six-page "Paper Romance" in "Daring Love" #1 (Oct. 1953), published by the Key imprint Gillmor Magazines.

Shortly afterward, Ditko found work at the studio of writer-artists Joe Simon and Jack Kirby, who had created Captain America and other characters. Beginning as an inker on backgrounds, Ditko was soon working with and learning from Mort Meskin, an artist whose work he had long admired. "Meskin was fabulous," Ditko once recalled. "I couldn't believe the ease with which he drew: strong compositions, loose pencils, yet complete; detail without clutter. I loved his stuff". Ditko's known assistant work includes aiding inker Meskin on the Jack Kirby pencil work of Harvey Comics' "Captain 3-D" #1 (Dec. 1953). For his own third published story, Ditko penciled and inked the six-page "A Hole in His Head" in "Black Magic" vol. 4, #3 (Dec. 1953), published by Simon & Kirby's Crestwood Publications imprint Prize Comics.

Ditko then began a long association with the Derby, Connecticut publisher Charlton Comics, a low-budget division of a company best known for song-lyric magazines. Beginning with the cover of "The Thing!" #12 (Feb. 1954) and the eight-page vampire story "Cinderella" in that issue, Ditko would continue to work intermittently for Charlton until the company's demise in 1986, producing science fiction, horror and mystery stories, as well as co-creating Captain Atom, with writer Joe Gill, in "Space Adventures" #33 (March 1960). He first went on hiatus from the company, and comics altogether, in mid-1954, when he contracted tuberculosis and returned to his parents' home in Johnstown to recuperate.

After he recovered and moved back to New York City in late 1955, Ditko began drawing for Atlas Comics, the 1950s precursor of Marvel Comics, beginning with the four-page "There'll Be Some Changes Made" in "Journey into Mystery" #33 (April 1956); this debut tale would be reprinted in Marvel's "Curse of the Weird" #4 (March 1994). Ditko would go on to contribute a large number of stories, many considered classic, to Atlas/Marvel's "Strange Tales" and the newly launched "Amazing Adventures", "Strange Worlds", "Tales of Suspense" and "Tales to Astonish", issues of which would typically open with a Kirby-drawn monster story, followed by one or two twist-ending thrillers or sci-fi tales drawn by Don Heck, Paul Reinman, or Joe Sinnott, all capped by an often-surreal, sometimes self-reflexive short by Ditko and writer-editor Stan Lee.

These Lee-Ditko short stories proved so popular that "Amazing Adventures" was reformatted to feature such stories exclusively beginning with issue #7 (Dec. 1961), when the comic was rechristened "Amazing Adult Fantasy", a name intended to reflect its more "sophisticated" nature, as likewise the new tagline "The magazine that respects your intelligence". Lee in 2009 described these "short, five-page filler strips that Steve and I did together", originally "placed in any of our comics that had a few extra pages to fill", as "odd fantasy tales that I'd dream up with O. Henry-type endings." Giving an early example of what would later be known as the "Marvel Method" of writer-artist collaboration, Lee said, "All I had to do was give Steve a one-line description of the plot and he'd be off and running. He'd take those skeleton outlines I had given him and turn them into classic little works of art that ended up being far cooler than I had any right to expect."

After Marvel Comics editor-in-chief Stan Lee obtained permission from publisher Martin Goodman to create a new "ordinary teen" superhero named "Spider-Man", Lee originally approached his leading artist, Jack Kirby. Kirby told Lee about his own 1950s character conception, variously called the Silver Spider and Spiderman, in which an orphaned boy finds a magic ring that gives him super powers. Comics historian Greg Theakston says Lee and Kirby "immediately sat down for a story conference" and Lee afterward directed Kirby to flesh out the character and draw some pages. "A day or two later", Kirby showed Lee the first six pages, and, as Lee recalled, "I hated the way he was doing it. Not that he did it badly — it just wasn't the character I wanted; it was too heroic".

Lee turned to Ditko, who developed a visual motif Lee found satisfactory, although Lee would later replace Ditko's original cover with one penciled by Kirby. Ditko said, "The Spider-Man pages Stan showed me were nothing like the (eventually) published character. In fact, the only drawings of Spider-Man were on the splash <nowiki>[</nowiki>i.e., page 1] and at the end [where] Kirby had the guy leaping at you with a web gun... Anyway, the first five pages took place in the home, and the kid finds a ring and turns into Spider-Man."

Ditko also recalled that, "One of the first things I did was to work up a costume. A vital, visual part of the character. I had to know how he looked ... before I did any breakdowns. For example: A clinging power so he wouldn't have hard shoes or boots, a hidden wrist-shooter versus a web gun and holster, etc. ... I wasn't sure Stan would like the idea of covering the character's face but I did it because it hid an obviously boyish face. It would also add mystery to the character..."

Much earlier, in a rare contemporaneous account, Ditko described his and Lee's contributions in a mail interview with Gary Martin published in "Comic Fan" #2 (Summer 1965): "Stan Lee thought the name up. I did costume, web gimmick on wrist & spider signal". He added he would continue drawing Spider-Man "[i]f nothing better comes along." That same year, he expressed to the fanzine "Voice of Comicdom", regarding a poll of "Best Liked" fan-created comics, "It seems a shame, since comics themselves have so little variety of stories and styles that you would deliberately restrict your own creative efforts to professional comics['] shallow range. What is 'Best Liked' by most readers is what they are most familiar in seeing and any policy based on readers likes has to end up with a lot of look-a-like (sic) strips. You have a great opportunity to show everyone a whole new range of ideas, unlimited types of stories and styles—why FLUB it!"

From 1958 to either 1966, or 1968 (accounts differ), Ditko shared a Manhattan studio at 43rd Street and Eighth Avenue with noted fetish artist Eric Stanton, an art-school classmate. When either artist was under deadline pressure, it was not uncommon for them to pitch in and help the other with his assignment. Ditko biographer Blake Bell, without citing sources, said, "At one time in history, Ditko denied ever touching Stanton's work, even though Stanton himself said they would each dabble in each other's art; mainly spot-inking", and the introduction to one book of Stanton's work says, "Eric Stanton drew his pictures in India ink, and they were then hand-coloured by Ditko". In a 1988 interview with Theakston, Stanton recalled that although his contribution to Spider-Man was "almost nil", he and Ditko had "worked on storyboards together and I added a few ideas. But the whole thing was created by Steve on his own... I think I added the business about the webs coming out of his hands".

Spider-Man debuted in "Amazing Fantasy" #15 (Aug. 1962), the final issue of that science-fiction/fantasy anthology series. When the issue proved to be a top seller, Spider-Man was given his own series, "The Amazing Spider-Man". Lee and Ditko's collaboration on the series saw the creation of many of the character's best known antagonists including Doctor Octopus in issue #3 (July 1963); the Sandman in #4 (Sept. 1963); the Lizard in #6 (Nov. 1963); Electro in #9 (March 1964); and the Green Goblin in #14 (July 1964). Ditko eventually demanded credit for the plotting he was contributing under the Marvel Method. Lee concurred, and starting with #25 (June 1965), Ditko received plot credit for the stories.

One of the most celebrated issues of the Lee-Ditko run is #33 (Feb. 1966), the third part of the story arc "If This Be My Destiny...!", and featuring the dramatic scene of Spider-Man, through force of will and thoughts of family, escaping from being pinned by heavy machinery. Comics historian Les Daniels noted, "Steve Ditko squeezes every ounce of anguish out of Spider-Man's predicament, complete with visions of the uncle he failed and the aunt he has sworn to save." Peter David observed, "After his origin, this two-page sequence from "Amazing Spider-Man" #33 is perhaps the best-loved sequence from the Stan Lee/Steve Ditko era." Steve Saffel stated the "full page Ditko image from "The Amazing Spider-Man" #33 is one of the most powerful ever to appear in the series and influenced writers and artists for many years to come." Matthew K. Manning wrote that "Ditko's illustrations for the first few pages of this Lee story included what would become one of the most iconic scenes in Spider-Man's history." The story was chosen as #15 in the 100 Greatest Marvels of All Time poll of Marvel's readers in 2001. Editor Robert Greenberger wrote in his introduction to the story, "These first five pages are a modern-day equivalent to Shakespeare as Parker's soliloquy sets the stage for his next action. And with dramatic pacing and storytelling, Ditko delivers one of the great sequences in all comics."

After drawing the final issue of "The Incredible Hulk" (#6, March 1963), Ditko created the supernatural hero Doctor Strange, in "Strange Tales" #110 (July 1963). Ditko and Lee shortly thereafter relaunched a Hulk series as a short feature in the anthology "Tales to Astonish", beginning with issue #60 (Oct. 1964). Ditko, inked by George Roussos, penciled the feature through #67 (May 1965). Ditko designed the Hulk's primary antagonist, the Leader, in #62 (Dec. 1964).

Ditko also penciled the Iron Man feature in "Tales of Suspense" #47–49 (Nov. 1963 – Jan. 1964), with various inkers. The first of these debuted the initial version of Iron Man's modern red-and-golden armor, though whether Ditko or cover-penciler and principal character designer Jack Kirby designed the costume is uncertain.

Though often overshadowed by his "Amazing Spider-Man" work, Ditko's "Doctor Strange" artwork has been equally acclaimed, for its surrealistic mystical landscapes and increasingly psychedelic visuals that helped make the feature a favorite of college students. "People who read 'Doctor Strange' thought people at Marvel must be heads [i.e. drug users]," recalled then-associate editor and former Doctor Strange writer Roy Thomas in 1971, "because they had had similar experiences high on mushrooms. But ... I don't use hallucinogens, nor do I think any artists do."

Eventually Lee & Ditko would take Strange into ever-more-abstract realms. In an epic 17-issue story arc in "Strange Tales" #130–146 (March 1965 – July 1966), Lee and Ditko introduced the cosmic character Eternity, who personified the universe and was depicted as a silhouette whose outlines are filled with the cosmos. As historian Bradford W. Wright describes,
The cartoonist and fine artist Seth in 2003 described Ditko's style as "oddball for mainstream comics. Whereas Kirby's stuff clearly appealed to a boy's sensibility because there was so much raw power, Ditko's work was really delicate and cartoony. There was a sense of design to it. You can always recognize anything that Ditko designed because it's always flowery. There is a lot of embroidered detail in the art, which is almost psychedelic."

Whichever feature he drew, Ditko's idiosyncratic, cleanly detailed, instantly recognizable art style, emphasizing mood and anxiety, found great favor with readers. The character of Spider-Man and his troubled personal life meshed well with Ditko's own interests, which Lee eventually acknowledged by giving the artist plotting credits on the latter part of their 38-issue run. But after four years on the title, Ditko left Marvel; he and Lee had not been on speaking terms for some time, with art and editorial changes handled through intermediaries. The details of the rift remain uncertain, even to Lee, who confessed in 2003, "I never really knew Steve on a personal level." Ditko later claimed it was Lee who broke off contact and disputed the long-held belief that the disagreement was over the true identity of the Green Goblin: "Stan never knew what he was getting in my Spider-Man stories and covers until after [production manager] Sol Brodsky took the material from me ... so there couldn't have been any disagreement or agreement, no exchanges ... no problems between us concerning the Green Goblin or anything else from before issue #25 to my final issues". Spider-Man successor artist John Romita, in a 2010 deposition, recalled that Lee and Ditko "ended up not being able to work together because they disagreed on almost everything, cultural, social, historically, everything, they disagreed on characters..." A friendly farewell was given to Ditko in the "Bullpen Bulletins" of comics cover-dated July 1966, including "Fantastic Four" #52: "Steve recently told us he was leaving for personal reasons. After all these years, we're sorry to see him go, and we wish the talented guy success with his future endeavors."

Regardless, said Lee in 2007, "Quite a few years ago I met him up at the Marvel offices when I was last in New York. And we spoke; he's a hell of a nice guy and it was very pleasant. ... I haven't heard from him since that meeting."

Back at Charlton—where the page rate was low but creators were allowed greater freedom—Ditko worked on such characters as the Blue Beetle (1967–1968), the Question (1967–1968), and Captain Atom (1965–1967), returning to the character he'd co-created in 1960. In addition, in 1966 and 1967, he drew 16 stories, most of them written by Archie Goodwin, for Warren Publishing's horror-comic magazines "Creepy" and "Eerie", generally using an ink-wash technique.

In 1967, Ditko gave his Objectivist ideas ultimate expression in the form of Mr. A, published in Wally Wood's independent title "witzend" # 3. Ditko's hard line against criminals was controversial and he continued to produce Mr. A stories and one-pagers until the end of the 1970s. Ditko returned to Mr. A in 2000 and in 2009.

Ditko moved to DC Comics in 1968, where he co-created the Creeper in "Showcase" #73 (April 1968) with Don Segall, under editor Murray Boltinoff. DC Comics writer and executive Paul Levitz observed that Ditko's art on the "Creeper" stories made "them look unlike anything else being published by DC at the time." Ditko co-created the team Hawk and Dove in "Showcase" #75 (June 1968), with writer Steve Skeates. Around this time, he penciled the lead story, written and inked by Wally Wood, in Wood's early mature-audience, independent-comics publication "Heroes, Inc. Presents Cannon" (1969).

Ditko's stay at DC was short—he would work on all six issues of the Creeper's own title, "Beware the Creeper" (June 1968 – April 1969), though leaving midway through the final one—and the reasons for his departure uncertain. But while at DC, Ditko recommended Charlton staffer Dick Giordano to the company, who would go on to become a top DC penciller, inker, editor, and ultimately, in 1981, the managing editor.

From this time up through the mid-1970s, Ditko worked exclusively for Charlton and various small press/independent publishers. Frank McLaughlin, Charlton's art director during this period, describes Ditko as living "in a local hotel in Derby for a while. He was a very happy-go-lucky guy with a great sense of humor at that time, and always supplied the [female] color separators with candy and other little gifts".

For Charlton in 1974 he did Liberty Belle backup stories in "E-Man" and conceived Killjoy. Ditko produced much work for Charlton's science-fiction and horror titles, as well as for former Marvel publisher Martin Goodman's start-up line Atlas/Seaboard Comics, where he co-created the superhero the Destructor with writer Archie Goodwin, and penciled all four issues of the namesake series (Feb.–Aug. 1975), the first two of which were inked by Wally Wood. Ditko worked on the second and third issues of "Tiger-Man" and the third issue of "Morlock 2001", with Bernie Wrightson inking.

Ditko returned to DC Comics in 1975, creating a short-lived title, "Shade, the Changing Man" (1977–1978). Shade was later revived, without Ditko's involvement, in DC's mature-audience imprint Vertigo. With writer Paul Levitz, he co-created the four issue sword and sorcery series "Stalker" (1975–1976). Ditko and writer Gerry Conway produced the first issue of a two–issue "Man-Bat" series. He also revived the Creeper and did such various other jobs as a short Demon backup series in 1979 and stories in DC's horror and science-fiction anthologies. Editor Jack C. Harris hired Ditko as guest artist on several issues of "The Legion of Super-Heroes", a decision which garnered a mixed reaction from the title's readership. Ditko also drew the Prince Gavyn version of Starman in "Adventure Comics" #467–478 (1980). He then decamped to do work for a variety of publishers, briefly contributing to DC again in the mid-1980s, with four pinups of his characters for "Who's Who: The Definitive Directory of the DC Universe" and a pinup for "Superman" #400 (Oct. 1984) and its companion portfolio.

Ditko returned to Marvel in 1979, taking over Jack Kirby's "Machine Man", drawing "The Micronauts" and Captain Universe, and continuing to freelance for the company into the late 1990s. Starting in 1984, he penciled the last two years of the space-robot series "Rom". A Godzilla story by Ditko and Marv Wolfman was changed into a Dragon Lord story published in "Marvel Spotlight". Ditko and writer Tom DeFalco introduced the Speedball character in "The Amazing Spider-Man Annual" #22 (1988) and Ditko drew a ten-issue series based on the character.

In 1982, he also began freelancing for the early independent comics label Pacific Comics, beginning with "Captain Victory and the Galactic Rangers" #6 (Sept. 1982), in which he introduced the superhero Missing Man, with Mark Evanier scripting to Ditko's plot and art. Subsequent Missing Man stories appeared in "Pacific Presents" #1–3 (Oct. 1982 – March 1984), with Ditko scripting the former and collaborating with longtime friend Robin Snyder on the script for the latter two. Ditko also created The Mocker for Pacific, in "Silver Star" #2 (April 1983).

For Eclipse Comics, he contributed a story featuring his character Static (no relation to the later Milestone Comics character) in "Eclipse Monthly" #1–3 (Aug.–Oct. 1983), introducing supervillain the Exploder in #2. With writer Jack C. Harris, Ditko drew the backup feature "The Faceless Ones" in First Comics' "Warp" #2–4 (April–June 1983). Working with that same writer and others, Ditko drew a handful of the Fly, Fly-Girl and Jaguar stories for "The Fly" #2–8 (July 1983 – Aug. 1984), for Archie Comics' short-lived 1980s superhero line; in a rare latter-day instance of Ditko inking another artist, he inked penciler Dick Ayers on the Jaguar story in "The Fly" #9 (Oct. 1984). Western Publishing in 1982 announced a series by Ditko and Harris would appear in a new science-fiction comic, "Astral Frontiers", but that title never materialized.

In 1992 Ditko worked with writer Will Murray to produce one of his last original characters for Marvel Comics, the superheroine Squirrel Girl, who debuted in "Marvel Super-Heroes" vol. 2, #8, a.k.a. "Marvel Super-Heroes Winter Special" (Jan. 1992).

In 1993, he did the Dark Horse Comics one-shot "The Safest Place in the World". For the Defiant Comics series "Dark Dominion," he drew issue #0, which was released as a set of trading cards. In 1995, he pencilled a four-issue series for Marvel based on the "Phantom 2040" animated TV series. This included a poster that was inked by John Romita Sr. "Steve Ditko's Strange Avenging Tales" was announced as a quarterly series from Fantagraphics Books, although it only ran one issue (Feb. 1997) due to publicly unspecified disagreements between Ditko and the publisher.

"The New York Times" assessed in 2008 that, "By the '70s he was regarded as a slightly old-fashioned odd-ball; by the '80s he was a commercial has-been, picking up wretched work-for-hire gigs. ...following the example of [Ayn] Rand's John Galt, Ditko hacked out moneymaking work, saving his care for the crabbed Objectivist screeds he published with tiny presses. And boy, could Ditko hack: seeing samples of his Transformers coloring book and his Big Boy comic is like hearing Orson Welles sell frozen peas."

Ditko retired from mainstream comics in 1998. His later work for Marvel and DC included such established superheroes as the Sub-Mariner (in "Marvel Comics Presents") and newer, licensed characters such as the "Mighty Morphin Power Rangers". The last mainstream character he created was Marvel's Longarm in "Shadows & Light" #1 (Feb. 1998), in a self-inked, 12-page Iron Man story "A Man's Reach...", scripted by Len Wein. His final mainstream work was a five-page New Gods story for DC Comics, "Infinitely Gentle Infinitely Suffering", inked by Mick Gray and believed to be intended for the 2000–2002 "Orion" series but not published until the 2008 trade paperback "Tales of the New Gods".

Since then, Ditko's solo work has been published intermittently by Robin Snyder, who was his editor at Charlton, Archie Comics, and Renegade Press in the 1980s. The Snyder publications have included a number of original books as well as reprints such as "Static", "The Missing Man", "The Mocker" and, in 2002, "Avenging World", a collection of stories and essays spanning 30 years.

In 2008, Ditko and Snyder released "The Avenging Mind", a 32-page essay publication featuring several pages of new artwork; and "Ditko, Etc...", a 32-page comic book composed of brief vignettes and editorial cartoons. Releases have continued in that format, with stories introducing such characters as the Hero, Miss Eerie, the Cape, the Madman, the Grey Negotiator, the !? and the Outline. He said in 2012 of his self-published efforts, “I do those because that’s all they’ll let me do."

In addition to the new material, Ditko and Snyder have reprinted earlier Ditko material. In 2010 they published a new edition of the 1973 "Mr. A" comic and a selection of Ditko covers in "The Cover Series". In 2011 they published a new edition of the 1975 comic "...Wha...!? Ditko's H. Series".

Two "lost" stories drawn by Ditko in 1978 have been published by DC in hardcover collections of the artist's work. A Creeper story scheduled for the never published "Showcase" #106 appears in "The Creeper by Steve Ditko" (2010) and an unpublished "Shade, the Changing Man" story appears in "The Steve Ditko Omnibus Vol. 1" (2011). A Hulk and the Human Torch story written by Jack C. Harris and drawn by Ditko in the 1980s was published by Marvel as "Incredible Hulk and the Human Torch: From the Marvel Vault" #1 in August 2011.

As of 2012, Ditko continued to work in Manhattan's Midtown West neighborhood. He mostly declined to give interviews or make public appearances, explaining in 1969 that, "When I do a job, it's not my personality that I'm offering the readers but my artwork. It's not what I'm like that counts; it's what I did and how well it was done. I produce a product, a comic art story. Steve Ditko is the brand name". However, he did contribute numerous essays to Robin Snyder's fanzine "The Comics".

Ditko was an ardent supporter of Objectivism.

He had a nephew who became an artist, also named Steve Ditko. As far as it is known, he never married and had no surviving children at the time of his death. Will Eisner stated that Ditko had a son out of wedlock, but this may have been a confused reference to the nephew.

Ditko said in 2012 that he had made no income on the four "Spider-Man" films released to that time. However, a neighbor of Ditko's stated that he received royalty checks. Those involved with creating the "Doctor Strange" film purposely declined to contact him during production, believing they would not be welcome.

Ditko was found unresponsive in his apartment in New York City on June 29, 2018. Police said he had died within the previous two days. He was pronounced dead at age 90, with the cause of death initially deemed as a result of a myocardial infarction, brought on by arteriosclerotic and hypertensive cardiovascular disease.


In September 2007, presenter Jonathan Ross hosted a one-hour documentary for BBC Four titled "In Search of Steve Ditko". The program covers Ditko's work at Marvel, DC, and Charlton Comics and at Wally Wood's "witzend", as well as his following of Objectivism. It includes testimonials by Alan Moore, Mark Millar, Jerry Robinson and Stan Lee, among others. Ross, accompanied by writer Neil Gaiman, met Ditko briefly at his New York office, but he declined to be filmed, interviewed or photographed. He did, however, give the two a selection of some comic books. At the end of the show, Ross said he has since spoken to Ditko on the telephone and, as a joke, that he was now on first name terms with him.

As penciller (generally but not exclusively self-inked), unless otherwise noted

Marvel Comics

DC Comics

Charlton Comics

Warren Publishing

Independent

Ace Comics

Atlas/Seaboard

Star*Reach Productions

Renegade Press

Dark Horse Comics

Fantagraphics Books

Robin Snyder



</doc>
<doc id="29555" url="https://en.wikipedia.org/wiki?curid=29555" title="List of tourist attractions in Sardinia">
List of tourist attractions in Sardinia

This is a list of the most famous tourist destinations of Sardinia. Minor islands are included from Olbia, clockwise — industrial sites are not included.




</doc>
<doc id="29556" url="https://en.wikipedia.org/wiki?curid=29556" title="List of people from Sardinia">
List of people from Sardinia

Sardinia is the second-largest island in the Mediterranean Sea, with a population of about 1.6 million people. The list includes notable natives of Sardinia, as well as those who were born elsewhere but spent a large part of their active life in Sardinia. People of Sardinian heritage and descent are in a separate section of this article. 










Emanuela Loi


























</doc>
<doc id="29558" url="https://en.wikipedia.org/wiki?curid=29558" title="Gavinus">
Gavinus

"Saint Gavinus () is a Christian saint who is greatly celebrated in Sardinia, Italy, as one of the Martyrs of Torres"' (), along with his companions SS Protus and Januarius'.

He was probably a Roman soldier martyred for the Christian faith during the persecution of Diocletian in 304 in the city of Porto Torres (), according to the legend on the orders of the governor ("preside") of Sardinia and Corsica, a certain Barbarus.

The well-known Romanesque church of Gavoi is dedicated to him, as is the town of San Gavino Monreale, and a number of communes in Corsica.

The 11th-century Basilica of San Gavino in Porto Torres, Sassari, is also dedicated to this saint. It was built by Comita or Gomida, Judge of Torres, and contains the relics, discovered in 1614, not only of Saint Gavinus, but also of his companions, Saints Protus and Januarius.

His feast day is given in the Roman Martyrology as 30 May.




</doc>
<doc id="29559" url="https://en.wikipedia.org/wiki?curid=29559" title="Sienna">
Sienna

Sienna (from , "Siena earth") is an earth pigment containing iron oxide and manganese oxide. In its natural state, it is yellow-brown and is called raw sienna. When heated, it becomes a reddish brown and is called burnt sienna. It takes its name from the city-state of Siena, where it was produced during the Renaissance. Along with ochre and umber, it was one of the first pigments to be used by humans, and is found in many cave paintings. Since the Renaissance, it has been one of the brown pigments most widely used by artists.

The first recorded use of "sienna" as a colour name in English was in 1760.

Like the other earth colours, such as yellow ochre and umber, sienna is a clay containing iron oxide, called limonite, which in its natural state has a yellowish colour. In addition to iron oxide, natural or raw sienna also contains about five percent of manganese oxide, which makes it darker than ochre. When heated, the iron oxide is dehydrated and turns partially to haematite, which gives it a reddish-brown colour. 
Sienna is lighter in shade than raw umber, which is also clay with iron oxide, but which has a higher content of manganese (5 to 20 percent) which makes it greenish brown or dark brown. When heated, raw umber becomes burnt umber, a very dark brown.
The pigment sienna was known and used, in its natural form, by the ancient Romans. It was mined near Arcidosso, formerly under Sienese control, now in the province of Grosseto, on Monte Amiata in southern Tuscany. It was called "terra rossa" (red earth), "terra gialla", or terra di Siena"." During the Renaissance, it was noted by the most widely read author about painting techniques, Giorgio Vasari, under the name terra rossa. It became, along with umber and yellow ochre, one of the standard browns used by artists from the 16th to 19th centuries, including Caravaggio (1571-1610) and Rembrandt (1606-1669), who used all the earth colours, including ochre, sienna and umber, in his palette.

By the 1940s, the traditional sources in Italy were nearly exhausted. Much of today's sienna production is carried out in the Italian islands of Sardinia and Sicily, while other major deposits are found in the Appalachian Mountains, where it is often found alongside the region's iron deposits. It is also still produced in the French Ardennes, in the small town of Bonne Fontaine near Ecordal.

In the 20th century, pigments began to be produced using synthetic iron oxide rather than the natural earth. The labels on paint tubes indicate whether they contain natural or synthetic ingredients. PY-43 indicates natural raw sienna, PR-102 indicates natural burnt sienna.

There is no single agreed standard for the colour of sienna, and the name is used today for a wide variety of hues and shades. They vary by country and colour list, and there are many proprietary variations offered by paint companies. The colour box at the top of the article shows one variation from the ISCC-NBS colour list.

Raw sienna is a yellowish-brown natural earth pigment, composed primarily of iron oxide hydroxide. The box shows the colour of the pigment in its natural, or raw state. It contains a large quantity of iron oxide and a small quantity (about five percent) of manganese oxide.

This kind of pigment is known as yellow ochre, yellow earth, limonite, or terra gialla. The pigment name for natural raw sienna from the Colour Index International, shown on the labels of oil paints, is PY-43.

This box at rights shows a variation of raw sienna from the Italian Ferrario 1919 colour list. 

Burnt sienna contains a large proportion of anhydrous iron oxide. It is made by heating raw sienna, which dehydrates the iron oxide, changing it partially to haematite, giving it rich reddish-brown colour.

The pigment is also known as red earth, red ochre, and terra rossa. On the Colour Index International, the pigment is known as PR-102.

This version is from the Italian Ferrario 1919 colour list.

The first recorded use of "burnt sienna" as a colour name in English was in 1853.

This variation of burnt sienna is from the Maerz and Paul "A Dictionary of Color" from 1930. It is considerably lighter than most other versions of burnt sienna. It was a mix of burnt orange and raw sienna.

This infobox shows the colour dark sienna. This variation is from the ISCC-NBS colour list. A similar dark sienna paint was frequently used on Bob Ross' TV show, "The Joy of Painting".

The web colour sienna is defined by the list of X11 colours used in web browsers and web design.


</doc>
<doc id="29564" url="https://en.wikipedia.org/wiki?curid=29564" title="Super Bowl XXXVI">
Super Bowl XXXVI

Super Bowl XXXVI was an American football game between the National Football Conference (NFC) champion St. Louis Rams and the American Football Conference (AFC) champion New England Patriots to decide the National Football League (NFL) champion for the 2001 season. The Patriots defeated the Rams by the score of 20–17. It was New England's first Super Bowl championship, and the franchise's first league championship of any kind, having suffered two previous losses. The game was also notable for snapping the AFC East's long streak of not being able to win a Super Bowl championship, as the division's teams had lost eight Super Bowls in total (prior to the Patriots victory in XXXVI).

The game was played at the Louisiana Superdome in New Orleans, on February 3, 2002. Following the September 11 attacks earlier in the season, the NFL postponed a week of regular season games and moved the league's playoff schedule back. As a result, Super Bowl XXXVI was rescheduled from the original date of January 27 to February 3, becoming the first Super Bowl played in February. The pregame ceremonies and the halftime show headlined by the Irish rock band U2 honored the victims of the September 11 attacks. Due to heightened security measures following the terrorist attacks, this was the first Super Bowl designated as a National Special Security Event (NSSE) by the Office of Homeland Security (OHS). The OHS later established the practice of naming each subsequent Super Bowl an NSSE.

This game marked the Rams' third Super Bowl appearance in franchise history and the second in three seasons. St. Louis posted an NFL-best 14–2 regular season record, led by quarterback Kurt Warner and "The Greatest Show on Turf" offense. The Patriots clinched their third Super Bowl berth after posting an 11–5 regular season record, led by second-year quarterback Tom Brady and a defense that ended the regular season ranked sixth in scoring.

Although the Rams out-gained the Patriots 427–267 in total yards, New England built a 17–3 third-quarter lead off of three St. Louis turnovers. After a holding penalty in the fourth quarter negated a Patriots fumble return for a touchdown, Warner scored a 2-yard touchdown run and threw a 26-yard touchdown pass to tie the game, 17–17 with 1:30 remaining. Without any timeouts, Brady led his team down the field to set up kicker Adam Vinatieri's game-winning 48-yard field goal as time expired. Brady, who completed 16 of 27 passes for 145 yards and a touchdown, was named Super Bowl MVP.

After their Super Bowl-winning 1999 season, the Rams offense again dominated the league in 2000, leading the NFL in passing, scoring, and total yards. However, the Rams had one of the worst defenses in the league, ranking last in points allowed (471). This, along with injury problems and a coaching change from Super Bowl winning coach Dick Vermeil, who left the team to Mike Martz, caused the Rams to slip to a 10–6 record in 2000. The season ended with a disappointing loss to the New Orleans Saints in the wild card round of the playoffs.

After signing several new defensive players in the off-season, and hiring new defensive coordinator Lovie Smith, the Rams finished the 2001 season with the NFL's best regular season record at 14–2. They led the league in both total offensive yards (6,930) and scoring (503). This was the Rams' third consecutive season with over 500 points, an NFL record. On defense, they only allowed 271 points, improving their 31st ranking in 2000 to 7th in 2001.

The Rams' 1999–2001 offense, nicknamed "The Greatest Show on Turf", is widely considered one of the best in NFL history. The team possessed an incredible amount of offensive talent at nearly every position. In 2001, quarterback Kurt Warner was awarded his second NFL Most Valuable Player Award after throwing for 4,830 yards and 36 touchdowns, with 22 interceptions, and earned a league high 101.4 passer rating. Wide receivers Torry Holt and Isaac Bruce each amassed over 1,100 receiving yards, combining for 142 receptions, 2,469 yards, and 13 touchdowns. Wide receiver Ricky Proehl caught 40 passes for 563 yards and 5 touchdowns. Tight end Ernie Conwell caught 38 passes for 431 yards and 4 touchdowns. Wide receiver Az-Zahir Hakim caught 39 passes for 374 yards, and added another 333 yards returning punts.

Running back Marshall Faulk won NFL Offensive Player of the Year Award for the third year in a row in 2001. He rushed for 1,382 yards, caught 83 passes for 765 yards, scored 21 touchdowns, and became the first NFL player ever to gain more than 2,000 combined rushing and receiving yards for 4 consecutive seasons. Running back Trung Canidate was also a major contributor, rushing for 441 yards, catching 17 passes for 154 yards, returning kickoffs for 748 yards, and scoring 6 touchdowns. The Rams offensive line was led by guard Adam Timmerman and offensive tackle Orlando Pace, who was selected to the Pro Bowl for the third consecutive year.

The Rams also had a solid defense, ranking third in the league in fewest yards allowed (4,733). The line was anchored by Pro Bowl defensive end Leonard Little, who led the team with 14.5 sacks and recovered a fumble, and defensive end Grant Wistrom, who recorded 9 sacks, 2 interceptions, and 1 fumble recovery. The Rams linebackers unit were led by London Fletcher, who had 4.5 sacks, 2 interceptions, and 4 forced fumbles. St. Louis also had an outstanding secondary, led by Dré Bly (6 interceptions, 150 return yards, and 2 touchdowns), Pro Bowl selection Aeneas Williams (4 interceptions, 69 return yards, 2 touchdowns), and Dexter McCleon (4 interceptions, 66 yards).

The Patriots' chances for a Super Bowl appearance seemed bleak shortly after the season had begun. Before the season even started, quarterbacks coach Dick Rehbein died of a heart attack at the age of 45. The Patriots, coached by Bill Belichick, lost their first two games. In the second loss, at home to the New York Jets, starting quarterback Drew Bledsoe suffered a sheared blood vessel on a hit by Jets linebacker Mo Lewis that caused him to miss several weeks. His replacement was second-year quarterback Tom Brady, a sixth-round draft pick who had thrown only 3 passes in 2000. Also, midway through the season, wide receiver Terry Glenn, the team's leading receiver in 2000, was benched due to off-the-field problems. He had been suspended for the first four games for failing a drug test and after serving it he played in just four more before injuries and disputes with the coaching staff caused Belichick to deactivate him for good.
Upon assuming the role of starting quarterback, Brady enjoyed immediate success in the regular season, leading New England to an 11–5 record. He completed 63.9 percent of his passes for 2,843 yards and 18 touchdowns with 12 interceptions and was selected to the Pro Bowl. Veteran Pro Bowl wide receiver Troy Brown was the main receiving threat, recording 101 receptions for 1,199 yards and 5 touchdowns, while also adding another 413 yards and 2 touchdowns returning punts. His 14.2 yards per punt return average led the NFL. Wide receiver David Patten also was productive, catching 51 passes for 749 yards and 4 touchdowns. Running back Antowain Smith provided the team with a stable running game, rushing for 1,157 yards, catching 19 passes for 192 yards, and scoring 13 touchdowns.

New England was outstanding on defense as well. Up front, linemen Bobby Hamilton (7 sacks, 1 fumble recovery) and rookie Richard Seymour excelled at pressuring quarterbacks and stuffing the run. Behind them, the Patriots had three outstanding linebackers: Mike Vrabel (2 interceptions, 3 sacks), Willie McGinest (5 sacks), and Tedy Bruschi (2 interceptions). The secondary also featured outstanding talent such as defensive back Otis Smith, who led the team with 5 interceptions for 181 yards and 2 touchdowns. Cornerback Ty Law intercepted 3 passes, returning them for 91 yards and 2 touchdowns. Safety Lawyer Milloy had 2 interceptions during the season, and was selected along with Law to represent the New England defense in the Pro Bowl. The defense ended the season ranked 6th in scoring, but 24th in total yards allowed.

During the 2001 regular season, the Patriots hosted the Rams in a nationally televised ESPN Sunday night game on November 18. Although the Patriots jumped out to an early lead, a critical turnover before the end of the first half that led to a Rams score proved costly. In the second half, the Rams wore New England down and won 24–17. The Rams lost four of their defensive players with injuries. The Patriots' physical play led Rams coach Mike Martz to say after the game that the Patriots were "a Super Bowl–caliber team." After the loss, the Patriots dropped to 5–5, but did not lose again the rest of the season to clinch a first-round bye in the AFC playoffs.

Coincidentally, this was the third straight time that the New England Patriots' Super Bowl appearance was hosted in New Orleans. The Patriots did not appear in a Super Bowl hosted by another city until the team played in Super Bowl XXXVIII two years later in Houston, Texas. They joined the Dallas Cowboys as the only teams to play three different Super Bowls in one stadium. The Cowboys played three at the old Miami Orange Bowl in the 1970s.

The Rams began their postseason run with a 45–17 win over the Green Bay Packers in the divisional round. Expected to be a close shootout between Warner and Packers quarterback Brett Favre, the Rams defense dominated the Packers by intercepting a playoff record 6 passes from Favre and returning 3 of them for touchdowns. The Rams offense also racked up 24 points on 2 touchdown passes by Warner, a touchdown run by Faulk, and a field goal by Jeff Wilkins, helping St. Louis put the game away by the end of the third quarter.

One week later, the Rams advanced to the Super Bowl with a 29–24 win over the Philadelphia Eagles in the NFC Championship Game. Philadelphia managed to build a 17–13 halftime lead, but St. Louis scored 16 consecutive second half points (2 touchdown runs by Faulk and a Wilkins field goal) to earn the win, limiting the Eagles to only one touchdown pass in the second half. Warner finished the game with 22 of 33 pass completions for 212 yards and a touchdown, with no interceptions, while Faulk rushed for 159 yards and 2 touchdowns.

In the AFC, the Patriots defeated the Oakland Raiders 16–13 during a raging New England snowstorm in the last game ever played at Foxboro Stadium. The signature moment of the game was a controversial ruling by referee Walt Coleman in the fourth quarter that caused this game to be commonly known as the "Tuck Rule Game." While the Patriots possessed the ball, trailing the Raiders 13–10 with under two minutes left in regulation and no time outs, Brady was sacked by defensive back Charles Woodson, and appeared to fumble the ball. The fumble was recovered by Raiders linebacker Greg Biekert, presumably ending the game with a Raiders victory. After reviewing the play using instant replay, Coleman reversed the call on the field pursuant to the "tuck rule", where a loose ball is ruled an incomplete pass if lost while "tucking" the ball. Most of the controversy centered on whether Brady was still trying to tuck the ball away when he lost control. Brady then led his team to the Raiders 27-yard line, where kicker Adam Vinatieri made a 45-yard field goal which barely cleared the crossbar to send the game into overtime. The Patriots won the toss in overtime and won on another Vinatieri field goal from 23 yards; per the overtime rules in place at that time. Oakland's offense never regained possession.

In the AFC Championship Game, the Patriots traveled to Heinz Field to face the Pittsburgh Steelers, who were coming off a 27–10 win over the previous season's Super Bowl champion Baltimore Ravens. New England scored first with a 55-yard punt return touchdown by Brown, but in the second quarter, Brady was knocked out of the game with a sprained ankle. He was replaced by Bledsoe in Bledsoe's first game action since being injured in September. Upon entering the game, Bledsoe quickly moved the Patriots down the field and threw an 11-yard touchdown pass to Patten to give the Patriots a 14–3 halftime lead.

Early in the second half, the Steelers moved from their own 32 to the New England 16, where they lined up for a field goal by Kris Brown. However, Brandon Mitchell blocked the kick, Brown picked up the ball at the 40 and ran 11 yards before lateraling to Antwan Harris, who took it 49 yards for a touchdown that made the score 21–3. But Pittsburgh scored two third-quarter touchdowns to make the score 21–17. The Patriots ended the comeback attempt by scoring a field goal in the fourth quarter and intercepting 2 passes from Steelers quarterback Kordell Stewart in the final 3 minutes of the game.

New Orleans had been preparing for Super Bowl XXXVI ever since the city was awarded the game on October 28, 1998 during the NFL's meetings in Kansas City, Missouri, beating out San Diego as host city. However, the September 11, 2001 terrorist attacks led the league to postpone its September 16 games and play them a week after the scheduled conclusion of the regular season. This caused the playoffs and Super Bowl to be delayed by one week. Rescheduling Super Bowl XXXVI from January 27 to February 3 proved extraordinarily difficult. In addition to rescheduling the game itself, all related events and activities had to be accommodated. This marked the first time in NFL history that the Super Bowl was played in the month of February; all subsequent Super Bowls (excluding Super Bowl XXXVII) after that have been played in February.

Historically, the NFL made allowance for an open weekend between the Conference Championship games and the Super Bowl. However, there wasn't one scheduled for 2001, due to the NFL's decision beginning in the 1999 season to move the opening week of games to the weekend after Labor Day. Because the date of the Super Bowl had been set through 2003, the bye week prior to the Super Bowl did not return until 2004.

The NFL and New Orleans officials worked diligently to put together a deal to reschedule the game. The league considered a number of options, including shortening the regular season, shortening the playoffs, condensing the three playoff rounds in two weeks, and moving the game to the Rose Bowl in Pasadena, California. It was eventually decided to make every effort to maintain a full regular season and playoff, and push the Super Bowl back to February 3. Also, due to the Super Bowl being sent back a week, the first week of New Orleans Mardi Gras parades rolled one week earlier than normal.

One of the most significant logistical challenges was accommodating the National Automobile Dealers Association (NADA) Convention, which was originally slated to occupy the Superdome on February 3. On October 3, 2001, the NFL announced its intentions to hold the game on February 3, even though no agreement had been reached with NADA. Several weeks later, the three parties came to an accord in which the NADA agreed to move its convention date to the original Super Bowl week in exchange for financial and other considerations, including promotional spots shown during selected regular season NFL games. This agreement permitted the NFL to move the game back to February 3, and allowed for a full standard playoff tournament.
Initially, the original logo for Super Bowl XXXVI had a style that reflected the host city, and was distributed on some memorabilia items during 2001. However, after the 9/11 attacks, a new logo reflecting American pride was designed. It featured the shape of the 48 contiguous states and the American flag colors of red, white, and blue.

Janet Jackson was originally scheduled to perform during the Halftime Show, but allowed U2 to perform to tribute the events of September 11.

This was the final Super Bowl played on the old-style AstroTurf. From 2000 to 2005, NFL stadiums phased out the short-pile AstroTurf in favor of natural grass or other, newer artificial surfaces which closely simulate grass, like FieldTurf.

Prior to Super Bowl XXXVI, Superdome officials considered installing natural grass for the game. The proposed installation method was comparable to what had been used at the Silverdome during the 1994 FIFA World Cup, and at Giants Stadium from 2000 to 2002. The plan called for large trays of grass to be grown and cultivated outdoors, then brought inside the dome and placed on the field for the game. In the end, cost and quality concerns prompted stadium and league officials to abandon the project.

The Rams were entering as 14 point favorites. This was partly because Rams quarterback Kurt Warner statistically had his best year of his career, with a quarterback rating of 101.4, a 68.7 percent completion rate, and threw for 4,830 yards. Many had believed that the Patriots' Cinderella story was simply a fluke, especially after beating the veteran Oakland Raiders in a controversial playoff game in which a recovered fumble by the Raiders was reversed by the tuck rule.

There had been speculation on whether longtime starter Drew Bledsoe might start the game. As stated above, Bledsoe replaced an injured Brady against the Steelers in the AFC Championship game. Eventually, though, Brady was named starter.

The game was broadcast in the United States by Fox; the telecast was presented in a 480p enhanced-definition format marketed as "Fox Widescreen". While promoted as having better quality than standard-definition, and being the first U.S. sporting event produced in a widescreen format with the same production as the main feed for standard-definition viewers (rather than using a separate production for the widescreen feed), it was not true high definition, but still matched the aspect ratio of HDTV sets.

The game was called by play-by-play announcer Pat Summerall and color commentator John Madden. Pam Oliver and Ron Pitts served as sideline reporters. This was Summerall's 26th and final Super Bowl broadcast on television or radio. It was also the eighth and final Super Bowl telecast (and final NFL telecast of any kind) for the Summerall and Madden announcing team. The two had become the NFL's most famous broadcast duo since they were paired together in 1981 on CBS. After this game, Summerall retired from broadcasting and Madden moved to ABC. As a result, Madden was the first person to announce Super Bowls on different networks in consecutive years when he called Super Bowl XXXVII on ABC with Al Michaels.

James Brown hosted all the events with help from his fellow "Fox NFL Sunday" cast members Terry Bradshaw, Howie Long, and Cris Collinsworth. Jillian Barberie served as the weather and entertainment reporter during the pre-game show.

Memorable television commercials that aired during the game included Sony Pictures' trailer for "Spider-Man", Budweiser's "Picking a Card", and Super Bowl Ad Meter commercial of the year winners Bud Light "Satin Sheets." The best commercial of the year from Adbowl M&M's "Chocolate on our Pillow or Hotel Check In" and EA Sports' Madden NFL 2002 which aired during the game three days after Madden NFL 2002 start selling in Japan by Electronic Arts Square.

Before the game, an ensemble of singers featured Barry Manilow, Yolanda Adams, James Ingram, Wynonna Judd, and Patti LaBelle performing Manilow's song "Let Freedom Ring."

In a video segment, past and present NFL players read excerpts from the Declaration of Independence, which has become a part of all subsequent Super Bowls carried by Fox Sports. Super Bowls XXXIX, XLII, and XLV used different active and former players (and a player's widow) reading the Declaration for each version. Former U.S. presidents Gerald Ford, Jimmy Carter, George H. W. Bush, and Bill Clinton appeared in another videotaped segment and recited some of the speeches by Abraham Lincoln. Because Ronald Reagan had Alzheimer's disease, his wife Nancy appeared on the segment in place of him.

Singers Mary J. Blige and Marc Anthony, along with the Boston Pops Orchestra, performed "America the Beautiful". Paul McCartney then sang his post-9/11 song "Freedom". Afterwards, singer Mariah Carey, accompanied by the Boston Pops Orchestra, performed the national anthem.

George H. W. Bush became the first president, past or present, to participate in a Super Bowl coin toss in person (Ronald Reagan participated in the Super Bowl XIX coin toss via satellite from the White House in 1985). Bush was joined by former Dallas Cowboys Hall of Fame quarterback Roger Staubach. Staubach played at the United States Naval Academy and was the Most Valuable Player of Super Bowl VI, which was played 30 years prior at New Orleans' Tulane Stadium.

As was customary at the time, the Rams' individual offensive starters were introduced first, as the Rams were considered the visitors. However, when it came time to introduce the Patriots' starters, Pat Summerall, making the public address announcement, revealed that the Patriots chose "to be introduced as a team." According to David Halberstam's book, "The Education of a Coach", Belichick was given a choice by the NFL to introduce either the offense or defense. Belichick chose neither, asking that the team be introduced all at once in the spirit of unity. Although this was initially rejected by the NFL, Belichick held his ground and the NFL honored his request. The full team introduction demonstrated solidarity, and struck a chord with the audience in the wake of the 9/11 attacks. Since the next Super Bowl game, both Super Bowl participants are introduced collectively as a team, a precedent which has continued.

The halftime show featured a three-song set from Irish rock band U2, who had just completed their successful Elevation Tour. After a rendition of "Beautiful Day", the band played "MLK" and "Where the Streets Have No Name" as the names of the victims from the September 11 attacks were projected onto a sheet behind the stage. While singing "Where the Streets Have No Name", the group's lead singer Bono replaced the lyrics "take shelter from the poison rain" with "dance in the Louisiana rain", "high on a desert plain" with "where there's no sorrow or pain", and the final line "it's all I can do" with "it's all we can do". At the conclusion of the song, Bono opened his jacket to reveal an American flag printed into the lining. U2's halftime show captivated the audience as a poignant tribute to those who had been lost in the attacks. In 2009, SI.com ranked it as the best halftime show in Super Bowl history, while it was rated the second-greatest by "Askmen.com".

Janet Jackson was originally selected to perform at the Halftime Show, but she instead allowed U2 to perform a tribute to the events of September 11 and due to traveling concerns following the tragedy. She performed again for the Super Bowl halftime two years later, when her highly controversial Super Bowl Halftime Show performance incident occurred.

The Rams scored first midway through the first quarter, with quarterback Kurt Warner completing 6-of-7 passes for 43 yards on a 48-yard, 10-play drive to set up a 50-yard field goal by kicker Jeff Wilkins. At the time, the field goal was the third longest in Super Bowl history. While the rest of the quarter was scoreless, the Patriots were stifling the typically high powered Rams offense by playing physical man coverage with the Rams receivers, forcing them into long drives that would end in punts or field goal attempts.

Early in the second quarter, the Rams drove to New England's 34-yard line, but Warner threw an incompletion on third down, and Wilkins' subsequent 52-yard field goal attempt sailed wide left.

With 8:49 left in the second quarter, a blitz by linebacker Mike Vrabel led Warner to be intercepted by Patriots defensive back Ty Law on a pass that was intended for wide receiver Isaac Bruce, Law then scored on a 47-yard return to give the Patriots a 7–3 lead. With less than two minutes left in the first half, Warner completed a pass to receiver Ricky Proehl at the Rams 40-yard line, but New England defensive back Antwan Harris tackled him, and forced a fumble which was recovered by Patriots defensive back Terrell Buckley. Patriots quarterback Tom Brady started off the Patriots drive with a 16-yard completion to Troy Brown and finished it with an 8-yard touchdown pass to receiver David Patten with 31 seconds left in the half. By halftime, New England owned a surprising 14–3 lead. It was the first time in the entire 2001 season that the Rams fell behind by more than eight points in a game.

The Patriots received the opening kickoff of the second half, but could only reach the St. Louis 43-yard line before being forced to punt. Aided by a 20-yard reception by wide receiver Az-Zahir Hakim, a 22-yard reception by Bruce, and a defensive pass interference penalty on Patriots defensive back Otis Smith, the Rams advanced to the New England 41-yard line. However, on the next play, Vrabel and defensive lineman Richard Seymour sacked Warner for a 9-yard loss. Warner then threw 2 consecutive incomplete passes, which resulted in the Rams punting.

Later in the third quarter, Smith intercepted a pass intended for Rams wide receiver Torry Holt after Holt slipped while coming off the line of scrimmage, and returned the ball 30 yards to the Rams 33-yard line. Though St. Louis' defense did not give up a touchdown to the Patriots, kicker Adam Vinatieri made a 37-yard field goal to increase New England's lead to 17–3.

The Rams responded by driving to the Patriots' 3-yard line on their ensuing drive. On fourth-and-goal, the Rams attempted to score a touchdown. Warner went back to pass and finding no one open scrambled to his right trying to run the ball in for a touchdown. Warner fumbled the ball while being tackled by linebacker Roman Phifer, which was recovered by defensive back Tebucky Jones who returned it 97 yards for a touchdown that would have increased the Patriots lead to 23–3. However, the play was nullified by a holding penalty on linebacker Willie McGinest, who illegally hugged Rams running back Marshall Faulk and prevented him from becoming an eligible receiver. This gave the Rams a first down on the 1-yard line. On second down, Warner scored on a 2-yard touchdown run to cut the Patriots' lead to 17–10.

After Warner's touchdown, the Rams defense forced the Patriots to a three-and-out. St. Louis then drove from own 7-yard line to the New England 36-yard line, aided by a 30-yard reception by Proehl. However, McGinest sacked Warner for a 16-yard loss on second down, pushing the Rams back to their 46-yard line. St. Louis punted after Warner's third down pass was incomplete.

The Rams forced New England to another three-and-out, and got the ball back on their own 45-yard line with 1:51 left in the game. Warner threw three consecutive completions: an 18-yard pass to Hakim, an 11-yard one to wide receiver Yo Murphy, and finally a 26-yard touchdown completion to Proehl that tied the game 17–17 with 1:30 left in the fourth quarter.

The Patriots had no timeouts left for their ensuing drive, which led Fox color commentator John Madden to initially suggest that the Patriots should run out the clock and attempt to win in overtime. Instead, New England attempted to get the winning score in regulation on the final drive. Bill Belichick conferred with offensive coordinator Charlie Weis and they agreed to go for it. Belichick later stated, "With a quarterback like Brady, going for the win is not that dangerous, because he's not going to make a mistake." Brady opened the drive with three dump-off completions to running back J. R. Redmond, who got out of bounds on the last one and moved the ball to their 41-yard line with 33 seconds left. At this point, Madden admitted on the air that he now liked what the Patriots were doing. After an incomplete pass, Brady completed a 23-yard pass underneath the Rams' zone defense to wide receiver Troy Brown--who also got out of bounds--and followed it up with a 6-yard completion to tight end Jermaine Wiggins to advance to the Rams' 30-yard line. Brady then spiked the ball with seven seconds left, which set up Vinatieri's 48-yard field goal attempt. Vinatieri's game-winning kick was successful, marking the first time in Super Bowl history that a game was won by a score on the final play.

Warner finished the game with 28 completions out of 44 passes for 365 yards, 1 touchdown, and 2 interceptions, and rushed 3 times for 6 yards and a touchdown. Warner's 365 passing yards were the second highest total in Super Bowl history behind his own record of 414 yards set in Super Bowl XXXIV. Hakim was the top receiver of the game with 5 catches for 90 yards, and also rushed once for 5 yards. Faulk led the team with 76 rushing yards, and also caught 4 passes for 54 yards.

Patriots running back Antowain Smith was the top rusher of the game with 92 yards, and caught a pass for 4 yards. Troy Brown was the Patriots leading receiver with 6 catches for 89 yards. Brown also had a 15-yard kickoff return, and a 4-yard punt return, which gave him 108 total yards. Although the Rams outgained the Patriots 427–267 in total yards, New England forced three turnovers that were converted into 17 points. The Patriots, on the other hand, committed no turnovers.


Sources: NFL.com Super Bowl XXXVI, Super Bowl XXXVI Play Finder NE, Super Bowl XXXVI Play Finder StL

Completions/attempts
Carries
Long gain
Receptions
Times targeted

The following records were set in Super Bowl XXXVI, according to the official NFL.com boxscore, the 2016 NFL Record & Fact Book and the ProFootball reference.com game summary.

Records Tied

Source:

Four hours after the game ended, Tom Brady visited Bill Belichick's hotel room where, as per team rules, he had to get his coach's permission to miss the team flight and instead travel to Disney World in Orlando. Belichick gave him a perplexed look, and after a few seconds of dead silence, responded, "Of course you can go. How many times do you win the Super Bowl?"

The Patriots finished the 2002 NFL season 9-7, missing the playoffs. But they went on to win Super Bowl XXXVIII, Super Bowl XXXIX, thus winning three Super Bowls in four years. Then, they won their fourth and fifth Super Bowls (Super Bowl XLIX and Super Bowl LI) a decade after their third. Brady also won three more Super Bowl MVP awards in Super Bowl XXXVIII, Super Bowl XLIX, and Super Bowl LI, making him the only player to be named Super Bowl MVP four times. Super Bowl XXXVI later became part of the wider 2007 New England Patriots videotaping controversy, also known as "Spygate". In addition to other videotaping allegations, the "Boston Herald" reported, citing an unnamed source, that the Patriots had also taped the Rams' walkthrough practice prior to the game. After further investigations, the league determined that no tape of the Rams' Super Bowl walkthrough was made, and the "Herald" later issued an apology in 2008 for their article about the alleged walkthrough tape. Nevertheless, the Patriots finished the 2007 regular season with a perfect 16–0 record, but failed to record an undefeated 19–0 championship season after losing Super Bowl XLII to the New York Giants. And at the conclusion of the 2015 NFL season, the Patriots held the NFL's best record since Spygate, compiling a 96-32 record from 2008 to 2015.
The Patriots' win in this Super Bowl, beyond just serving as a springboard to four more championships, also became the starting point for a decade of success in Boston sports, with the city's teams winning seven championships in the four major North American sports leagues (the NFL, the NBA, the NHL and MLB), including at least one in each league. Over the next fifteen years, in addition to the Patriots' four additional Super Bowls:

Following the Bruins winning the 2011 Stanley Cup Finals, "Boston Globe" columnist Dan Shaughnessy ranked all seven championships from the past decade and ranked the Patriots winning Super Bowl XXXVI as the second-greatest Boston sports championship of the decade behind only the Red Sox winning the 2004 World Series.

After the Patriots won their first championship in franchise history, it started a run of a team in American sports from NCAA and the four major sports winning their first (or next) franchise championship with a wait of 17 years or more between titles. This streak is still continuing in 2018 after Philadelphia Eagles and Washington Capitals winning their first titles in their franchise histories.

Beginning with the Rams' appearance in Super Bowl XXXVI, 10 different NFC teams appeared in the Super Bowl over the next 10 years. This trend was broken when the New York Giants earned a trip to Super Bowl XLVI after participating in Super Bowl XLII four years earlier. (The Giants defeated the Patriots in both games.) The loss signaled the beginning of the end of The Greatest Show on Turf era. The Rams finished with a 7-9 record the following year and have won only one playoff game since, following the 2004 season. Kurt Warner suffered a concussion on opening day in 2003, and was later demoted to backup quarterback for the rest of that season. He then signed with the New York Giants in 2004 as a caretaker quarterback, eventually losing the starting job to rookie quarterback Eli Manning. Warner later joined the Arizona Cardinals in 2005 and eventually led that team to an appearance in Super Bowl XLIII following the 2008 season. Super Bowl XXXVI ended up being the last Super Bowl that the Rams participated while based in St. Louis; they relocated back to Los Angeles in 2016.




</doc>
<doc id="29570" url="https://en.wikipedia.org/wiki?curid=29570" title="Scansano">
Scansano

Scansano is a town and comune, of medieval origin, in the province of Grosseto, Tuscany, central Italy. The area which Scansano lies within is called Maremma.

Scansano area is home to the production of Morellino di Scansano, a type of wine.

<BR>


</doc>
<doc id="29574" url="https://en.wikipedia.org/wiki?curid=29574" title="List of maritime explorers">
List of maritime explorers

This is a list of maritime explorers.

The list includes explorers which had contributed, and continue to contribute to human knowledge of the planet's geography, weather, biodiversity, human cultures, the expansion of trade, or established communication between diverse populations.



</doc>
<doc id="29577" url="https://en.wikipedia.org/wiki?curid=29577" title="Wednesday Morning, 3 A.M.">
Wednesday Morning, 3 A.M.

Wednesday Morning, 3 A.M. is the debut studio album by American folk rock duo Simon & Garfunkel. Following their early gig as "Tom and Jerry", Columbia Records signed the two in late 1963. It was produced by Tom Wilson and engineered by Roy Halee. The cover and the label include the subtitle "exciting new sounds in the folk tradition". Recorded in March 1964, the album was released on October 19.

The album was initially unsuccessful, so Paul Simon moved to London, England, and Art Garfunkel continued his studies at Columbia University in their native New York City, before reuniting in late 1965. "Wednesday Morning, 3 A.M." was re-released in January 1966 (to capitalize on their newly found radio success because of the overdubbing of the song "The Sound of Silence" in June 1965, adding electric guitars, bass guitar and a drum kit), and reached #30 on the Billboard 200. It was belatedly released in the UK two years later (in 1968) in both mono and stereo formats.

The song "He Was My Brother" was dedicated to Andrew Goodman, who was their friend and a classmate of Simon at Queens College. Andrew Goodman volunteered in Freedom Summer during 1964 and was abducted and killed in the murders of Chaney, Goodman, and Schwerner.

The album is included in its entirety as part of the Simon & Garfunkel box sets "Collected Works" and "The Columbia Studio Recordings (1964–1970)".

The album was produced by Tom Wilson and engineered by Roy Halee between March 10-31, 1964. 

"Benedictus" was arranged and adapted from two-part "a capella" motet by Orlande de Lassus. The text, in Latin, is "benedictus qui venit in nomine Domini" (KJV: "Blessed be he that cometh in the name of the Lord"). The song is set for two voices with cello and sparse guitar accompaniment.

The album's cover photo was shot at the Fifth Avenue / 53rd Street subway station in New York City. In several concerts, Art Garfunkel related that during the photo session, several hundred pictures were taken that were unusable due to the "old familiar suggestion" on the wall in the background, which inspired Paul Simon to write the song "A Poem on the Underground Wall" for the duo's later "Parsley, Sage, Rosemary and Thyme" album.

The album was initially unsuccessful, having been released in the shadow of the British Invasion. This resulted in Paul Simon moving to England and Art Garfunkel continuing his studies at Columbia University in New York City. Following the success of "The Sound of Silence," the album peaked at #30 on the "Billboard" album chart in 1966.


</doc>
<doc id="29578" url="https://en.wikipedia.org/wiki?curid=29578" title="Sheldon Rampton">
Sheldon Rampton

Sheldon Rampton (born August 4, 1957) is an American editor and author. He was editor of "PR Watch", and is the author of several books that criticize the public relations industry and what he sees as other forms of corporate and government propaganda.

Rampton was born in Long Beach, California. At the age of one, his family moved to Las Vegas, Nevada, where his father worked as a musician. Raised as a member of The Church of Jesus Christ of Latter-day Saints (LDS Church), he spent two years in Japan as a Latter-day Saint missionary from 1976 to 1978. Upon returning to the United States, however, he left the LDS Church, influenced in part by Mormon feminist Sonia Johnson.

As an undergraduate student at Princeton University, Rampton studied writing under Joyce Carol Oates, E. L. Doctorow and John McPhee.

Upon graduation in 1982, Rampton worked as a newspaper reporter before becoming a peace activist. During the 1980s and 1990s, he worked closely with the Wisconsin Coordinating Council on Nicaragua (WCCN), which opposed the Reagan administration's military interventions in Central America and works to promote economic development, human rights, and mutual friendship between the people of the United States and Nicaragua. At WCCN, Rampton helped establish the Nicaraguan Credit Alternatives Fund (NICA Fund) in 1992, which channels loans from US investors to support microcredit and other "alternative credit" programs in Nicaragua.

In 1995, Rampton teamed with John Stauber as co-editors of PR Watch, a publication of the Center for Media and Democracy (CMD). They were described as liberal, and their writings are regarded by some members of the public relations industry as one-sided and hostile. ActivistCash, a website hosted by Washington lobbyist Richard Berman, has castigated them as "self-anointed watchdogs," "scare-mongers," "reckless" and "left-leaning." Rampton and Stauber have in turn argued that the ActivistCash critique contains a number of "demonstrably false" claims.

Rampton is also a contributor to the Wikipedia open content project, and was the person who coined the name "Wikimedia" which later became the name of the foundation that manages Wikipedia and its sister projects. Inspired by Wikipedia's collaborative writing model, Rampton founded Disinfopedia (now known as SourceWatch), another CMD project, to complement his PR Watch work to expose what Rampton perceives as deceptive and misleading public relations campaigns.

Rampton left the Center for Media and Democracy in October 2009.




</doc>
<doc id="29579" url="https://en.wikipedia.org/wiki?curid=29579" title="Miller test">
Miller test

The Miller test, also called the three-prong obscenity test, is the United States Supreme Court's test for determining whether speech or expression can be labeled obscene, in which case it is not protected by the First Amendment to the United States Constitution and can be prohibited.

The Miller test was developed in the 1973 case "Miller v. California". It has three parts:

The work is considered obscene only if "all three" conditions are satisfied.

The first two prongs of the Miller test are held to the standards of the community, and the last prong is held to what is reasonable to a person of the United States as a whole. The national reasonable person standard of the third prong acts as a check on the community standard of the first two prongs, allowing protection for works that in a certain community might be considered obscene but on a national level might have redeeming value.

For legal scholars, several issues are important. One is that the test allows for community standards rather than a national standard. What offends the average person in Manhattan, Kansas, may differ from what offends the average person in Manhattan, New York. The relevant community, however, is not defined.

Another important issue is that the Miller Test asks for an interpretation of what the "average" person finds offensive, rather than what the more sensitive persons in the community are offended by, as obscenity was defined by the previous test, the Hicklin test, stemming from the English precedent.

In practice, pornography showing genitalia and sexual acts is not "ipso facto" obscene according to the Miller test. For instance, in 2000, a jury in Provo, Utah, took only a few minutes to clear Larry Peterman, owner of a Movie Buffs video store, in Utah County, Utah, a region which had often boasted of being one of the most conservative areas in the United States. Researchers had shown that guests at the local Marriott Hotel were disproportionately large consumers of pay-per-view pornographic material, accessing far more material than the store was distributing.

Because it allows for community standards and demands "serious" value, Justice Douglas worried in his dissent that this test would make it easier to suppress speech and expression. "Miller" replaced a previous test asking whether the speech or expression was "utterly without redeeming social value". As used, however, the test generally makes it difficult to outlaw any form of expression. Many works decried as pornographic have been successfully argued to have some artistic or literary value, most publicly in the context of the National Endowment for the Arts in the 1990s.

The advent of the Internet has made the "community standards" part of the test even more difficult to judge; as material published on a web server in one place can be read by a person residing anywhere else, there is a question as to which jurisdiction should apply. In "United States of America v. Extreme Associates", a pornography distributor from North Hollywood, California, was judged to be held accountable to the community standards applying in western Pennsylvania, where the Third Circuit made its ruling, because the materials were available via Internet in that area. The United States Court of Appeals for the Ninth Circuit has ruled in "United States v. Kilbride" that a "national community standard" should be used for the internet, but this has yet to be upheld at the national level.



</doc>
<doc id="29580" url="https://en.wikipedia.org/wiki?curid=29580" title="Set-top box">
Set-top box

A set-top box (STB) or set-top unit (STU) (one type also colloquially known as a cable box) is an information appliance device that generally contains a TV-tuner input and displays output to a television set and an external source of signal, turning the source signal into content in a form that then be displayed on the television screen or other display device. They are used in cable television, satellite television, and over-the-air television systems, as well as other uses.

The signal source might be an Ethernet cable, a satellite dish, a coaxial cable (see cable television), a telephone line (including DSL connections), broadband over power lines (BPL), or even an ordinary VHF or UHF antenna. Content, in this context, could mean any or all of video, audio, Internet web pages, interactive video games, or other possibilities. Satellite and microwave-based services also require specific external receiver hardware, so the use of set-top boxes of various formats has never completely disappeared. Set-top boxes can also enhance source signal quality.

Before the All-Channel Receiver Act of 1962 required US television receivers to be able to tune the entire VHF and UHF range (which in North America was NTSC-M channels 2 through 83 on 54 to 890 MHz), a set-top box known as a UHF converter would be installed at the receiver to shift a portion of the UHF-TV spectrum onto low-VHF channels for viewing. As some 1960s-era 12-channel TV sets remained in use for many years, and Canada and Mexico were slower than the US to require UHF tuners to be factory-installed in new TVs, a market for these converters continued to exist for much of the 1970s.

Cable television represented a possible alternative to deployment of UHF converters as broadcasts could be frequency-shifted to VHF channels at the cable head-end instead of the final viewing location. However, most cable systems could not accommodate the full 54-890 MHz VHF/UHF frequency range and the twelve channels of VHF space were quickly exhausted on most systems. Adding any additional channels therefore needed to be done by inserting the extra signals into cable systems on nonstandard frequencies, typically either below VHF channel 7 (midband) or directly above VHF channel 13 (superband).

These frequencies corresponded to non-television services (such as two-way radio) over-the-air and were therefore not on standard TV receivers. Before cable-ready TV sets became common in the late 1980s, an electronic tuning device called a cable converter box was needed to receive the additional analog cable TV channels and transpose or convert the selected channel to analog radio frequency (RF) for viewing on a regular TV set on a single channel, usually VHF channel 3 or 4. The box allowed an analog non-cable-ready television set to receive analog encrypted cable channels and was a prototype topology for later date digital encryption devices. Newer televisions were then converted to be analog cypher cable-ready, with the standard converter built-in for selling premium television (aka pay per view). Several years later and slowly marketed, the advent of digital cable continued and increased the need for various forms of these devices. Block conversion of the entire affected frequency band onto UHF, while less common, was used by some models to provide full VCR compatibility and the ability to drive multiple TV sets, albeit with a somewhat nonstandard channel numbering scheme.

Newer television receivers greatly reduced the need for external set-top boxes, although cable converter boxes continue to be used to descramble premium cable channels according to carrier-controlled access restrictions, and to receive digital cable channels, along with using interactive services like video on demand, pay per view, and home shopping through television.

Set-top boxes were also made to enable closed captioning on older sets in North America, before this became a mandated inclusion in new TV sets. Some have also been produced to mute the audio (or replace it with noise) when profanity is detected in the captioning, where the offensive word is also blocked. Some also include a V-chip that allows only programs of some television content ratings. A function that limits children's time watching TV or playing video games may also be built in, though some of these work on main electricity rather than the video signal.

The transition to digital terrestrial television after the turn of the millennium left many existing television receivers unable to tune and display the new signal directly. In the United States, where analog shutdown was completed in 2009 for full-service broadcasters, a federal subsidy was offered for coupon-eligible converter boxes with deliberately limited capability which would restore signals lost to digital transition.

Professional set-top boxes are referred to as IRDs or integrated receiver/decoders in the professional broadcast audio/video industry. They are designed for more robust field handling and rack mounting environments. IRDs are capable of outputting uncompressed serial digital interface signals, unlike consumer STBs which usually don't, mostly because of copyright reasons.

Hybrid set-top boxes, such as those used for Smart TV programming, enable viewers to access multiple TV delivery methods (including terrestrial, cable, internet, and satellite); like IPTV boxes, they include video on demand, time-shifting TV, Internet applications, video telephony, surveillance, gaming, shopping, TV-centric electronic program guides, and e-government. By integrating varying delivery streams, hybrids (sometimes known as "TV-centric") enable pay-TV operators more flexible application deployment, which decreases the cost of launching new services, increases speed to market, and limits disruption for consumers.

As examples, Hybrid Broadcast Broadband TV (HbbTV) set-top boxes allow traditional TV broadcasts, whether from terrestrial (DTT), satellite, or cable providers, to be brought together with video delivered over the Internet and personal multimedia content. Advanced Digital Broadcast (ADB) launched its first hybrid DTT/IPTV set-top box in 2005, which provided Telefónica with the digital TV platform for its Movistar TV service by the end of that year. In 2009, ADB provided Europe's first three-way hybrid digital TV platform to Polish digital satellite operator n, which enables subscribers to view integrated content whether delivered via satellite, terrestrial, or internet.

UK based Inview Technology has over 8M STBs deployed in the UK for Teletext and an original push VOD service for Top Up TV.

In IPTV networks, the set-top box is a small computer providing two-way communications on an IP network and decoding the video streaming media. IP set-top boxes have a built-in home network interface that can be Ethernet, Wireless (802.11 g,n,ac), or one of the existing wire home networking technologies such as HomePNA or the ITU-T G.hn standard, which provides a way to create a high-speed (up to 1Gbit/s) local area network using existing home wiring (power lines, phone lines, and coaxial cables).

In the US and Europe, telephone companies use IPTV (often on ADSL or optical fiber networks) as a means to compete with traditional local cable television monopolies.

This type of service is distinct from Internet television, which involves third-party content over the public Internet not controlled by the local system operator.

Electronic program guides and interactive program guides provide users of television, radio, and other media applications with continuously updated menus displaying broadcast programming or scheduling information for current and upcoming programming. Some guides, such as ITV, also feature backward scrolling to promote their catch-up content.

This feature allows the user to choose preferred channels, making them easier and quicker to access; this is handy with the wide range of digital channels on offer. The concept of favourite channels is superficially similar to that of the "bookmark" function offered in many Web browsers.

The timer allows the user to program and enable the box to switch between channels at certain times: this is handy to record from more than one channel while the user is out. The user still needs to program the VCR or DVD recorder.

Some models have controls on the box, as well as on the remote control. This is useful should the user lose the remote or if the batteries age.

Some remote controls can also control some basic functions of various brands of TVs. This allows the user to use just one remote to turn the TV on and off, adjust volume, or switch between digital and analog TV channels or between terrestrial and internet channels.

The parental lock or content filters allow users over 18 years old to block access to channels that are not appropriate for children, using a personal identification number. Some boxes simply block all channels, while others allow the user to restrict access to chosen channels not suitable for children below certain ages.

As complexity and potential programming faults of the set-top box increase, software such as MythTV, Select-TV and Microsoft's Media Center have developed features comparable to those of set-top boxes, ranging from basic DVR-like functionality to DVD copying, home automation, and housewide music or video playback.

Almost all modern set-top boxes feature automatic firmware update processes. The firmware update is typically provided by the service provider.

With the advent of flat-panel televisions, set-top boxes are now deeper in profile than the tops of most modern TV sets. Because of this, set-top boxes are often placed beneath televisions, and the term set-top box has become something of a misnomer, possibly helping the adoption of the term "digibox". Additionally, newer set-top boxes that sit at the edge of IP-based distribution networks are often called net-top boxes or NTBs, to differentiate between IP and RF inputs. The Roku LT is around the size of a pack of cards and delivers Smart TV to conventional sets.

The distinction between external tuner or demodulator boxes (traditionally considered to be "set-top boxes") and storage devices (such as VCR, DVD, or disc-based PVR units) is also blurred by the increasing deployment of satellite and cable tuner boxes with hard disk, network or USB interfaces built-in.

Devices with the capabilities of computer terminals, such as the WebTV thin client, also fall into the grey area that could invite the term "NTB".

In Europe, a set-top box does not necessarily contain a tuner of its own. A box connected to a television (or VCR) SCART connector is fed with the baseband television signal from the set's tuner, and can have the television display the returned processed signal instead.
This SCART feature had been used for connection to analogue decoding equipment by pay TV operators in Europe, and in the past was used for connection to teletext equipment before the decoders became built-in. The outgoing signal could be of the same nature as the incoming signal, or RGB component video, or even an "insert" over the original signal, due to the "fast switching" feature of SCART.

In case of analogue pay-TV, this approach avoided the need for a second remote control. The use of digital television signals in more modern pay-TV schemes requires that decoding take place before the digital-to-analogue conversion step, rendering the video outputs of an analogue SCART connector no longer suitable for interconnection to decryption hardware. Standards such as DVB's Common Interface and ATSC's CableCARD therefore use a PCMCIA-like card inserted as part of the digital signal path as their alternative to a tuner-equipped set-top box.

In June 2011 a report from the American National Resources Defense Council brought attention to the energy efficiency of set-top boxes, and the US Department of Energy announced plans to consider the adoption of energy efficiency standards for set-top boxes. In November 2011, the National Cable & Telecommunications Association announced a new energy efficiency initiative that commits the largest American cable operators to the purchase of set-top boxes that meet Energy Star standards and the development of sleep modes that will use less energy when the set-top box is not being used to watch or record video.



</doc>
<doc id="29582" url="https://en.wikipedia.org/wiki?curid=29582" title="Scatology">
Scatology

In medicine and biology, scatology or coprology is the study of feces.

Scatological studies allow one to determine a wide range of biological information about a creature, including its diet (and thus where it has been), health and diseases such as tapeworms. The word derives from the Greek ( ) meaning "dung, feces"; "coprology" derives from the Greek of similar meaning.

A comprehensive study of scatology was documented by John Gregory Bourke under the title " Rites of All Nations" (1891). An abbreviated version of the work (with a foreword by Sigmund Freud), was published as "The Portable Scatalog" in 1994.

In psychology, a scatology is an obsession with excretion or excrement, or the study of such obsessions.

In sexual fetishism, scatology (usually abbreviated "scat") refers to coprophilia, when a person is sexually aroused by fecal matter, whether in the use of feces in various sexual acts, watching someone defecating, or simply seeing the feces. Entire subcultures in sexuality are devoted to this fetish.

In literature, "scatological" is a term to denote the literary trope of the grotesque body. It is used to describe works that make particular reference to excretion or excrement, as well as to toilet humor. A common example is John Dryden's "Mac Flecknoe", a poem that employs extensive scatological imagery to ridicule Dryden's contemporary Thomas Shadwell. In German literature in particular is a wealth of scatological texts and references, which includes such books as Collofino's "Non Olet". A case which has provoked an unusual amount of comment in the academic literature is Mozart's scatological humour. Smith, in his review of English literature's representations of scatology from the Middle Ages to the 18th century, notes two attitudes towards scatology. One of these emphasises the merry and the carnivalesque. This is found in Chaucer and Shakespeare. The other attitude is one of self-disgust and misanthropy. This is found in the works of the Earl of Rochester and Jonathan Swift.




</doc>
<doc id="29586" url="https://en.wikipedia.org/wiki?curid=29586" title="Sigma-algebra">
Sigma-algebra

In mathematical analysis and in probability theory, a σ-algebra (also σ-field) on a set "X" is a collection Σ of subsets of "X" that includes the empty subset, is closed under complement, and is closed under countable unions and countable intersections. The pair ("X", Σ) is called a measurable space or Borel space.

A σ-algebra is a type of algebra of sets. An algebra of sets needs only to be closed under the union or intersection of "finitely" many subsets, which is a weaker condition.

The main use of σ-algebras is in the definition of measures; specifically, the collection of those subsets for which a given measure is defined is necessarily a σ-algebra. This concept is important in mathematical analysis as the foundation for Lebesgue integration, and in probability theory, where it is interpreted as the collection of events which can be assigned probabilities. Also, in probability, σ-algebras are pivotal in the definition of conditional expectation.

In statistics, (sub) σ-algebras are needed for the formal mathematical definition of a sufficient statistic, particularly when the statistic is a function or a random process and the notion of conditional density is not applicable.

If one possible σ-algebra on "X" is where ∅ is the empty set. In general, a finite algebra is always a σ-algebra.

If {"A", "A", "A", …} is a countable partition of "X" then the collection of all unions of sets in the partition (including the empty set) is a σ-algebra.

A more useful example is the set of subsets of the real line formed by starting with all open intervals and adding in all countable unions, countable intersections, and relative complements and continuing this process (by transfinite iteration through all countable ordinals) until the relevant closure properties are achieved (a construction known as the Borel hierarchy).

There are at least three key motivators for σ-algebras: defining measures, manipulating limits of sets, and managing partial information characterized by sets.

A measure on "X" is a function that assigns a non-negative real number to subsets of "X"; this can be thought of as making precise a notion of "size" or "volume" for sets. We want the size of the union of disjoint sets to be the sum of their individual sizes, even for an infinite sequence of disjoint sets.

One would like to assign a size to "every" subset of "X", but in many natural settings, this is not possible. For example, the axiom of choice implies that when the size under consideration is the ordinary notion of length for subsets of the real line, then there exist sets for which no size exists, for example, the Vitali sets. For this reason, one considers instead a smaller collection of privileged subsets of "X". These subsets will be called the measurable sets. They are closed under operations that one would expect for measurable sets, that is, the complement of a measurable set is a measurable set and the countable union of measurable sets is a measurable set. Non-empty collections of sets with these properties are called σ-algebras.

Many uses of measure, such as the probability concept of almost sure convergence, involve limits of sequences of sets. For this, closure under countable unions and intersections is paramount. Set limits are defined as follows on σ-algebras.

In much of probability, especially when conditional expectation is involved, one is concerned with sets that represent only part of all the possible information that can be observed. This partial information can be characterized with a smaller σ-algebra which is a subset of the principal σ-algebra; it consists of the collection of subsets relevant only to and determined only by the partial information. A simple example suffices to illustrate this idea.

Imagine you and another person are betting on a game that involves flipping a coin repeatedly and observing whether it comes up Heads ("H") or Tails ("T"). Since you and your opponent are each infinitely wealthy, there is no limit to how long the game can last. This means the sample space Ω must consist of all possible infinite sequences of "H" or "T":

However, after "n" flips of the coin, you may want to determine or revise your betting strategy in advance of the next flip. The observed information at that point can be described in terms of the 2 possibilities for the first "n" flips. Formally, since you need to use subsets of Ω, this is codified as the σ-algebra

Observe that then

where formula_8 is the smallest σ-algebra containing all the others.

Let "X" be some set, and let formula_9 represent its power set. Then a subset formula_10 is called a "σ"-algebra if it satisfies the following three properties:


From these properties, it follows that the σ-algebra is also closed under countable intersections (by applying De Morgan's laws).

It also follows that the empty set ∅ is in Σ, since by (1) "X" is in Σ and (2) asserts that its complement, the empty set, is also in Σ. Moreover, since } satisfies condition (3) as well, it follows that } is the smallest possible σ-algebra on "X". The largest possible σ-algebra on "X" is 2.

Elements of the "σ"-algebra are called measurable sets. An ordered pair , where "X" is a set and Σ is a "σ"-algebra over "X", is called a measurable space. A function between two measurable spaces is called a measurable function if the preimage of every measurable set is measurable. The collection of measurable spaces forms a category, with the measurable functions as morphisms. Measures are defined as certain types of functions from a "σ"-algebra to [0, ∞].

A σ-algebra is both a π-system and a Dynkin system (λ-system). The converse is true as well, by Dynkin's theorem (below).

This theorem (or the related monotone class theorem) is an essential tool for proving many results about properties of specific σ-algebras. It capitalizes on the nature of two simpler classes of sets, namely the following.

Dynkin's π-λ theorem says, if "P" is a π-system and "D" is a Dynkin system that contains "P" then the σ-algebra σ("P") generated by "P" is contained in "D". Since certain π-systems are relatively simple classes, it may not be hard to verify that all sets in "P" enjoy the property under consideration while, on the other hand, showing that the collection "D" of all subsets with the property is a Dynkin system can also be straightforward. Dynkin's π-λ Theorem then implies that all sets in σ("P") enjoy the property, avoiding the task of checking it for an arbitrary set in σ("P").

One of the most fundamental uses of the π-λ theorem is to show equivalence of separately defined measures or integrals. For example, it is used to equate a probability for a random variable "X" with the Lebesgue-Stieltjes integral typically associated with computing the probability:

where "F"("x") is the cumulative distribution function for "X", defined on R, while formula_12 is a probability measure, defined on a σ-algebra Σ of subsets of some sample space Ω.

Suppose formula_13 is a collection of σ-algebras on a space "X".



Suppose "Y" is a subset of "X" and let ("X", Σ) be a measurable space.

A "σ"-algebra Σ is just a "σ"-ring that contains the universal set "X". A "σ"-ring need not be a "σ"-algebra, as for example measurable subsets of zero Lebesgue measure in the real line are a "σ"-ring, but not a "σ"-algebra since the real line has infinite measure and thus cannot be obtained by their countable union. If, instead of zero measure, one takes measurable subsets of finite Lebesgue measure, those are a ring but not a "σ"-ring, since the real line can be obtained by their countable union yet its measure is not finite.

"σ"-algebras are sometimes denoted using calligraphic capital letters, or the Fraktur typeface. Thus may be denoted as formula_22 or formula_23.

A separable σ-algebra (or separable σ-field) is a σ-algebra formula_24 that is a separable space when considered as a metric space with metric formula_25 for formula_26 and a given measure formula_27 (and with formula_28 being the symmetric difference operator). Note that any σ-algebra generated by a countable collection of sets is separable, but the converse need not hold. For example, the Lebesgue σ-algebra is separable (since every Lebesgue measurable set is equivalent to some Borel set) but not countably generated (since its cardinality is higher than continuum).

A separable measure space has a natural pseudometric that renders it separable as a pseudometric space. The distance between two sets is defined as the measure of the symmetric difference of the two sets. Note that the symmetric difference of two distinct sets can have measure zero; hence the pseudometric as defined above need not to be a true metric. However, if sets whose symmetric difference has measure zero are identified into a single equivalence class, the resulting quotient set can be properly metrized by the induced metric. If the measure space is separable, it can be shown that the corresponding metric space is, too.

Let "X" be any set.

A stopping time formula_29 can define a formula_30-algebra formula_31, the
so-called , which in a filtered probability space describes the information up to the random time formula_29 in the sense that, if the filtered probability space is interpreted as a random experiment, the maximum information that can be found out about the experiment from arbitrarily often repeating it until the time formula_29 is formula_31.

Let "F" be an arbitrary family of subsets of "X". Then there exists a unique smallest σ-algebra which contains every set in "F" (even though "F" may or may not itself be a σ-algebra). It is, in fact, the intersection of all σ-algebras containing "F". (See intersections of σ-algebras above.) This σ-algebra is denoted σ("F") and is called the σ-algebra generated by "F".

If "F" is empty, then σ("F")=}. Otherwise σ("F") consists of all the subsets of "X" that can be made from elements of "F" by a countable number of complement, union and intersection operations.

For a simple example, consider the set "X" = {1, 2, 3}. Then the σ-algebra generated by the single subset {1} is </nowiki>}}. By an abuse of notation, when a collection of subsets contains only one element, "A", one may write σ("A") instead of σ({"A"}); in the prior example σ({1}) instead of σ(<nowiki></nowiki>). Indeed, using to mean is also quite common.

There are many families of subsets that generate useful σ-algebras. Some of these are presented here.

If formula_35 is a function from a set formula_36 to a set formula_37 and formula_38 is a formula_30-algebra of subsets of formula_37, then the formula_30-algebra generated by the function formula_35, denoted by formula_43, is the collection of all inverse images formula_44 of the sets formula_45 in formula_38. i.e.

A function "f" from a set "X" to a set "Y" is measurable with respect to a σ-algebra Σ of subsets of "X" if and only if σ("f") is a subset of Σ.

One common situation, and understood by default if "B" is not specified explicitly, is when "Y" is a metric or topological space and "B" is the collection of Borel sets on "Y".

If "f" is a function from "X" to R then σ("f") is generated by the family of subsets which are inverse images of intervals/rectangles in R:

A useful property is the following. Assume "f" is a measurable map from ("X", Σ) to ("S", Σ) and "g" is a measurable map from ("X", Σ) to ("T", Σ). If there exists a measurable map "h" from ("T", Σ) to ("S", Σ) such that "f"("x") = "h"("g"("x")) for all "x", then σ("f") ⊂ σ("g"). If "S" is finite or countably infinite or, more generally, ("S", Σ) is a standard Borel space (e.g., a separable complete metric space with its associated Borel sets), then the converse is also true. Examples of standard Borel spaces include R with its Borel sets and R with the cylinder σ-algebra described below.

An important example is the Borel algebra over any topological space: the σ-algebra generated by the open sets (or, equivalently, by the closed sets). Note that this σ-algebra is not, in general, the whole power set. For a non-trivial example that is not a Borel set, see the Vitali set or Non-Borel sets.

On the Euclidean space R, another σ-algebra is of importance: that of all Lebesgue measurable sets. This σ-algebra contains more sets than the Borel σ-algebra on R and is preferred in integration theory, as it gives a complete measure space.

Let formula_49 and formula_50 be two measurable spaces. The σ-algebra for the corresponding product space formula_51 is called the product σ-algebra and is defined by

Observe that formula_53 is a π-system.

The Borel σ-algebra for R is generated by half-infinite rectangles and by finite rectangles. For example,

For each of these two examples, the generating family is a π-system.

Suppose

is a set of real-valued functions. Let formula_56 denote the Borel subsets of R. A cylinder subset of is a finitely restricted set defined as

Each

is a π-system that generates a σ-algebra formula_59. Then the family of subsets

is an algebra that generates the cylinder σ-algebra for . This σ-algebra is a subalgebra of the Borel σ-algebra determined by the product topology of formula_61 restricted to .

An important special case is when formula_62 is the set of natural numbers and is a set of real-valued sequences. In this case, it suffices to consider the cylinder sets

for which

is a non-decreasing sequence of σ-algebras.

Suppose formula_65 is a probability space. If formula_66 is measurable with respect to the Borel σ-algebra on R then is called a random variable ("n = 1") or random vector ("n" > 1). The σ-algebra generated by is

Suppose formula_65 is a probability space and formula_69 is the set of real-valued functions on formula_62. If formula_71 is measurable with respect to the cylinder σ-algebra formula_72 (see above) for then is called a stochastic process or random process. The σ-algebra generated by is

the σ-algebra generated by the inverse images of cylinder sets.




</doc>
<doc id="29587" url="https://en.wikipedia.org/wiki?curid=29587" title="Second Battle of El Alamein">
Second Battle of El Alamein

The Second Battle of El Alamein (23 October – 11 November 1942) was a battle of the Second World War that took place near the Egyptian railway halt of El Alamein. With the Allies victorious, it was the watershed of the Western Desert Campaign. The First Battle of El Alamein had prevented the Axis from advancing further into Egypt. In August 1942, Lieutenant-General Sir Bernard Law Montgomery took command of the Eighth Army following the sacking of General Claude Auchinleck and the death of his replacement Lieutenant-General William Gott in an air crash.

The Allied victory turned the tide in the North African Campaign and ended the Axis threat to Egypt, the Suez Canal and the Middle Eastern and Persian oil fields via North Africa. The Second Battle of El Alamein revived the morale of the Allies, being the first big success against the Axis since Operation Crusader in late 1941. The battle coincided with the Allied invasion of French North Africa in Operation Torch, which started on 8 November, the Battle of Stalingrad and the Guadalcanal Campaign.

The Panzer Army Africa ("Panzerarmee Afrika"), composed of German and Italian infantry and mechanised units under "Generalfeldmarschall" Erwin Rommel, had struck deep into Egypt by 12 July 1942 after its success at the Battle of Gazala. This threatened the British Empire's control of the Suez Canal and Mandatory Palestine. General Claude Auchinleck withdrew the Eighth Army to within of Alexandria to a point where the Qattara Depression came to within of El Alamein on the coast. This gave the defenders a short front to defend and provided secure flanks because tanks could not traverse the Depression. The Axis advance was halted here in early July in the First Battle of El Alamein.

The Eighth Army counter-offensives during July failed, as Rommel had dug in to allow his exhausted troops to regroup. Auchinleck called off all offensive action at the end of July to allow rebuilding the Eighth Army's strength. In early August, the British Prime Minister, Winston Churchill, and General Sir Alan Brooke—the Chief of the Imperial General Staff (CIGS)—visited Cairo and replaced Auchinleck as Commander-in-chief (C-in-C) Middle East Command with General Sir Harold Alexander. Lieutenant-General William Gott was appointed to command of the Eighth Army, but he was killed when the transport plane he was travelling in was shot down by Luftwaffe fighters; Lieutenant-General Bernard Montgomery was then appointed commander of the Eighth Army.

Faced with long supply lines and lacking reinforcements, and well aware of massive Allied reinforcements in men and materiel on the way, Rommel decided to strike the Allies while their build-up was incomplete. The two armoured divisions of the "Afrika Korps", together with a force made up of the reconnaissance units of Panzer Army Africa, led the attack but the Allies stopped them at the Alam el Halfa ridge and Point 102 on 30 August 1942. The attack failed in this second battle at the Alamein line, better known as the Battle of Alam el Halfa (commonly, but incorrectly, Alam Halfa); expecting a counter-attack by Montgomery's Eighth Army, Panzer Army Africa dug in.

The factors that had favoured the Eighth Army's defensive plan in the First Battle of El Alamein, the short front line and the secure flanks, now favoured the Axis defence. Rommel, furthermore, had plenty of time to prepare his defensive positions and lay extensive minefields (laying approximately 500,000 mines) and barbed wire. Alexander and Montgomery were determined to establish a superiority of forces sufficient not only to achieve a breakthrough but also to exploit it and destroy Panzer Army Africa. In all the previous swings of the pendulum in the Western Desert Campaign since 1941, neither side had ever had the strength after achieving victory in an offensive battle to exploit it decisively: the losing side had always been able to withdraw and regroup closer to its main supply bases.

The British had an intelligence advantage: signals intelligence from Ultra and local sources exposed the Axis order of battle, its supply position, force disposition and intentions. A reorganisation of the intelligence function in Africa in July had also improved the integration of intelligence received from all sources and the speed of its dissemination. With rare exceptions, intelligence identified the supply ships destined for North Africa, their location or routing and in most cases their cargoes, allowing them to be attacked. By 25 October, Panzer Army fuel stocks were down to three days' supply, of which only two days' worth were east of Tobruk. "The Panzer Army... did not possess the operational freedom of movement that was absolutely essential in consideration of the fact that the British offensive can be expected to start any day".

Submarine and air transport somewhat eased the shortage of ammunition and by late October, stocks amounting to 16 days supply were held in forward areas. After six more weeks, the Eighth Army was ready, 195,000 men and 1,029 tanks began the offensive against the 116,000 men and 547 tanks of Panzer Army Africa.

Montgomery's plan was for a main attack to the north of the line and a secondary attack to the south, involving XXX Corps (Lieutenant-General Oliver Leese) and XIII Corps (Lieutenant-General Brian Horrocks), while X Corps (Lieutenant-General Herbert Lumsden) was to exploit the success. With Operation Lightfoot, Montgomery intended to cut two corridors through the Axis minefields in the north. One corridor was to run south-west through the 2nd New Zealand Division sector towards the centre of Miteirya Ridge, while the second was to run west, passing north of the west end of the Miteirya Ridge across the 9th Australian and 51st (Highland) Division sectors. Tanks would then pass through and defeat the German armour. Diversions at Ruweisat Ridge in the centre and also the south of the line would keep the rest of the Axis forces from moving northwards. Montgomery expected a 12-day battle in three stages: the break-in, the dogfight and the final breaking of the enemy.

For the first night of the offensive, Montgomery planned for four infantry divisions of XXX Corps to advance on a front to the Oxalic Line, over-running the forward Axis defences. Engineers would clear and mark the two lanes through the minefields, through which the armoured divisions from X Corps would pass to gain the Pierson Line. They would rally and consolidate their position just west of the infantry positions, blocking an Axis tank counter-attack. The British tanks would then advance to "Skinflint", astride the north–south Rahman Track deep in the Axis defensive system, to challenge the Axis armour. The infantry battle would continue as the Eighth Army infantry "crumbled" the deep Axis defensive fortifications (three successive lines of fortification had been constructed) and destroy any tanks that attacked them.

The Commonwealth forces practised a number of deceptions in the months before the battle to confuse the Axis command as to the whereabouts of the forthcoming battle and when the battle was likely to occur. This operation was codenamed Operation Bertram. In September, they dumped waste materials (discarded packing cases, etc.) under camouflage nets in the northern sector, making them appear to be ammunition or ration dumps. The Axis naturally noticed these but, as no offensive action immediately followed and the "dumps" did not change in appearance, they were subsequently ignored. This allowed Eighth Army to build up supplies in the forward area unnoticed by the Axis, by replacing the rubbish with ammunition, petrol or rations at night. Meanwhile, a dummy pipeline was built, hopefully leading the Axis to believe the attack would occur much later than it, in fact, did and much further south. To further the illusion, dummy tanks consisting of plywood frames placed over jeeps were constructed and deployed in the south. In a reverse feint, the tanks destined for battle in the north were disguised as supply trucks by placing removable plywood superstructures over them.

As a preliminary, the 131st (Queen's) Infantry Brigade of the 44th (Home Counties) Infantry Division, supported by tanks from the 4th Armoured Brigade, launched Operation Braganza attacking the 185th Airborne Division Folgore on the night of 29/30 September in an attempt to capture the Deir el Munassib area. The Italian paratroopers repelled the attack, killing or capturing over 300 of the attackers. It was wrongly assumed that "Fallschirmjäger" (German paratroopers) had manned the defences and been responsible for the British reverse. The "Afrika Korps" war diary notes that the Italian paratroops "bore the brunt of the attack. It fought well and inflicted heavy losses on the enemy."

With the failure of their offensive at Alam el Halfa, the Axis forces were now on the defensive, but losses had not been excessive. German and Italian supply lines were over-stretched; the Axis had been relying on captured Allied supplies and equipment that had long since been consumed. Rommel had been advised by both the German and Italian staffs that his army could not be properly supplied so far from the ports of Tripoli and Benghazi. Despite these warnings, Rommel pressed ahead with his advance to Alamein and as predicted, the supply echelons could not deliver the required supplies from the ports to the front. On the other hand, the British Commonwealth forces were being re-supplied with men and materials from the United Kingdom, India, Australia and New Zealand, as well as with trucks and the newly-introduced Sherman tanks from the United States. Rommel continued to request equipment, supplies and fuel, but the main focus of the German war machine was on the Eastern Front, and very limited supplies reached North Africa.
Furthermore, Rommel was ill. In early September, arrangements were made for him to return to Germany on sick leave and for "General der Panzertruppe" Georg Stumme to transfer from the Russian front to take his place. Before he left for Germany on 23 September, Rommel organised the planned defence and wrote a long appreciation of the situation to the German High Command, once again setting out the essential needs of the Panzer Army.

Rommel knew that the British Commonwealth forces would soon be strong enough to launch an offensive against his army. His only hope now relied on the German forces fighting in the Battle of Stalingrad to quickly defeat the Soviet forces and moving south through the Trans-Caucasus and threatening Iran (Persia) and the Middle East. This would require large numbers of British Commonwealth forces to be sent from the Egyptian front to reinforce British forces in Iran, leading to the postponement of any offensive against his army. Using this delay, Rommel hoped to convince the German High Command to reinforce his forces for the eventual link-up between Panzer Army Africa and the German armies battling their way through southern Russia, enabling them finally to defeat the British and Commonwealth armies in North Africa and the Middle East.

In the meantime, his forces dug in and waited for the eventual attack by the British Commonwealth forces or the defeat of the Soviet Army at Stalingrad. Rommel added depth to his defences by creating at least two belts of mines about apart which were connected at intervals to create boxes which would restrict enemy penetration and deprive British armour of room for manoeuvre. The front face of each box was lightly held by battle outposts and the rest of the box was unoccupied but sowed with mines and explosive traps and covered by enfilading fire. These became known as the Devil's gardens. The main defensive positions were built to a depth of at least behind the second mine belt. The Axis laid around half a million mines, mostly Teller anti-tank mines with some smaller anti-personnel types (such as the S-mine). (Many of these mines were British, and had been captured at Tobruk). To lure enemy vehicles into the minefields, the Italians had a trick of dragging an axle and tyres through the fields using a long rope to create what appeared to be well-used tracks.

Rommel was concerned with not letting the British armour break out into the open because he had neither the strength of numbers nor fuel to match them in a battle of manoeuvre. He therefore had to try to restrict the battle to his defended zones and counter any breakthrough both quickly and vigorously. Rommel therefore stiffened his forward lines by alternating German and Italian infantry formations. Because the Allied deception measures had confused the Axis as to their likely point of attack, Rommel departed from his usual practice of holding his armoured strength in a single concentrated reserve and split it into a northern group (15th Panzer and "Littorio" Division) and a southern group (21st Panzer and "Ariete" Division), each organised into battle groups in order to be able to make a quick armoured intervention wherever the blow fell and so prevent any narrow breakthroughs from being enlarged. The effect, however, was that a significant proportion of his armoured reserve was dispersed and held unusually far forward. The 15th Panzer Division had 125 operational tanks (16 Pz.IIs, 43 Pz.III Ausf H, 43 Pz.III Ausf J, 6 Pz.IV Ausf D, 15 Pz.IV Ausf F) while the 21st Panzer Division had 121 operational combat vehicles (12 Pz.IIs, 38 Pz.III Ausf H, 43 Pz.III Ausf J, 2 Pz.IV Ausf D, 15 Pz.IV Ausf F) Further back, however, Rommel did have the 90th Light and "Trieste" Motorised Divisions in reserve near the coast. Rommel believed that when the main thrust came, he could manoeuvre his troops faster than the Allies to concentrate his defences at the battle's centre of gravity. However, having concentrated his defence, he would not be able to move his forces again because of lack of fuel.

As a result of their intelligence advantage, the British were well aware that Rommel would be unable to mount a defence based on his usual battle-of-manoeuvre tactics. However, no clear picture emerged of how he would fight the battle and, in the event, British plans seriously underestimated the Axis defences and the Panzer Army's power of resistance.

The Battle of El Alamein is usually divided into five phases, consisting of the break-in (23–24 October), the crumbling (24–25 October), the counter (26–28 October), Operation Supercharge (1–2 November) and the break-out (3–7 November). No name is given to the period from 29–31 October, when the battle was at a standstill.

Prior to the main barrage, there was a diversion by the 24th Australian Brigade, which involved the 15th Panzer Division being subjected to heavy fire for a few minutes. Then at 21:40 (Egyptian Summer Time) on 23 October on a calm, clear evening under the bright sky of a full moon, Operation Lightfoot began with a 1,000-gun barrage. The fire plan had been arranged so that the first rounds from the 882 guns from the field and medium batteries would land along the front at the same time. After 20 minutes of general bombardment, the guns switched to precision targets in support of the advancing infantry. The shelling plan continued for five and a half hours, by the end of which each gun had fired about 600 rounds, about 529,000 shells.

Operation Lightfoot alluded to the infantry attacking first. Anti-tank mines would not be tripped by soldiers stepping on them since they were too light. As the infantry advanced, engineers had to clear a path for the tanks coming behind. Each gap was to be wide, which was just enough to get tanks through in single file. The engineers had to clear a route through the Devil's Gardens. It was a difficult task that was not achieved because of the depth of the Axis minefields.
At 22:00, the four infantry divisions of XXX Corps began to move. The objective was to establish a bridgehead before dawn at the imaginary line in the desert where the strongest enemy defences were situated, on the far side of the second mine belt. Once the infantry reached the first minefields, the mine sweepers, including Reconnaissance Corps troops and sappers, moved in to create a passage for the armoured divisions of X Corps. Progress was slower than planned but at 02:00, the first of the 500 tanks crawled forward. By 04:00, the lead tanks were in the minefields, where they stirred up so much dust that there was no visibility at all, traffic jams developed and tanks bogged down. Only about half of the infantry attained their objectives and none of the tanks broke through.
The 7th Armoured Division (with one Free French Brigade under command) from XIII Corps (Lieutenant-General Brian Horrocks) made a secondary attack to the south. The main attack aimed to achieve a breakthrough, engage and pin down the 21st Panzer Division and the "Ariete" Armoured Division around Jebel Kalakh, while the Free French on the far left were to secure Qaret el Himeimat and the el Taqa plateau. The right flank of the attack was to be protected by 44th Infantry Division with the 131st Infantry Brigade. The attack met determined resistance, mainly from the 185 Airborne Division "Folgore", part of the Ramcke Parachute Brigade and the Keil Group. The minefields were deeper than anticipated and clearing paths through them was impeded by Axis defensive fire. By dawn on 24 October, paths still had not been cleared through the second minefield to release 22nd and 4th Light Armoured Brigades into the open to make their planned turn north into the rear of enemy positions west of Deir el Munassib.

Further north along the XIII Corps front, the 50th Infantry Division achieved a limited and costly success against determined resistance from the "Pavia" Division, "Brescia" Division and elements of the 185th Airborne Division "Folgore". The 4th Indian Infantry Division, on the far left of the XXX Corps front at Ruweisat Ridge, made a mock attack and two small raids intended to deflect attention to the centre of the front.

Dawn aerial reconnaissance showed little change in Axis disposition, so Montgomery gave his orders for the day: the clearance of the northern corridor should be completed and the New Zealand Division supported by 10th Armoured should push south from Miteirya Ridge. 9th Australian Division, in the north, should plan a crumbling operation for that night, while in the southern sector, 7th Armoured should continue to try to break through the minefields with support, if necessary, from 44th Division. "Panzer" units counter-attacked the 51st Highland Division just after sunrise, only to be stopped in their tracks.
The morning of Saturday 24 October brought disaster for the German headquarters. The reports that Stumme had received that morning showed the attacks had been on a broad front but that such penetration as had occurred should be containable by local units. He went forward himself to observe the state of affairs and, finding himself under fire, suffered a heart attack and died. Temporary command was given to Major-General Wilhelm Ritter von Thoma. Hitler had already decided that Rommel should leave his sanatorium and return to North Africa. Rommel flew to Rome early on 25 October to press the "Comando Supremo" for more fuel and ammunition and then on to North Africa to resume command that night of the Panzer Army Africa, which that day was renamed the German-Italian Panzer Army ("Deutsch-Italienische Panzerarmee").

There was little activity during the day pending more complete clearance of paths through the minefields. The armour was held at "Oxalic". Artillery and the Allied Desert Air Force, making over 1,000 sorties, attacked Axis positions all day to aid the 'crumbling' of the Axis forces. By 16:00 there was little progress.

At dusk, with the sun at their backs, Axis tanks from the 15th Panzer Division and Italian "Littorio" Division swung out from the Kidney feature (also known to the Germans and Italians as Hill 28), often wrongly called a ridge as it was actually a depression, to engage the 1st Armoured Division and the first major tank battle of El Alamein began. Over 100 tanks were involved and half were destroyed by dark. Neither position was altered.

At around 10:00, Axis aircraft had destroyed a convoy of 25 Allied vehicles carrying petrol and ammunition, setting off a night-long blaze; Lumsden wanted to call off the attack, but Montgomery made it clear that his plans were to be carried out. The thrust that night by 10th Armoured Division from Miteirya Ridge failed. The lifting of mines on the Miteirya Ridge and beyond took far longer than planned and the leading unit, 8th Armoured Brigade, was caught on their start line at 22:00—zero hour—by an air attack and were scattered. By the time they had reorganised they were well behind schedule and out of touch with the creeping artillery barrage. By daylight the brigade was out in the open taking considerable fire from well sited tanks and anti-tank guns. Meanwhile 24th Armoured Brigade had pushed forward and reported at dawn they were on the Pierson line, although it turned out that, in the dust and confusion, they had mistaken their position and were well short.

The attack in the XIII Corps sector to the south fared no better. 44th Division's 131st Infantry Brigade cleared a path through the mines, but when 22nd Armoured Brigade passed through, they came under heavy fire and were repulsed, with 31 tanks disabled. Allied air activity that night focused on Rommel's northern armoured group, where of bombs were dropped. To prevent a recurrence of 8th Armoured Brigade's experience from the air, attacks on Axis landing fields were also stepped up.

The initial thrust had ended by Sunday. The Allies had advanced through the minefields in the west to make a wide and deep inroad. They now sat atop Miteirya Ridge in the south-east. Axis forces were firmly entrenched in most of their original battle positions and the battle was at a standstill. Montgomery decided that the planned advance southward from Miteirya Ridge by the New Zealanders would be too costly and instead decided that XXX Corps—while keeping firm hold of Miteirya—should strike northward toward the coast with 9th Australian Division. Meanwhile, 1st Armoured Division—on the Australians' left—should continue to attack west and north-west, and activity to the south on both Corps fronts would be confined to patrolling. The battle would be concentrated at the Kidney feature and Tel el Eisa until a breakthrough occurred.
By early morning, the Axis forces launched a series of attacks using 15th Panzer and "Littorio" divisions. The Panzer Army was probing for a weakness, but without success. When the sun set the Allied infantry went on the attack. Around midnight, 51st Division launched three attacks, but no one knew exactly where they were. Pandemonium and carnage ensued, resulting in the loss of over 500 Allied troops, and leaving only one officer among the attacking forces.

While the 51st Highland Division was operating around Kidney, the Australians were attacking Point 29, a high Axis artillery observation post south-west of Tel el Eisa, in an attempt to surround the Axis coastal salient containing the German 164th Light Division and large numbers of Italian infantry. This was the new northern thrust Montgomery had devised earlier in the day, and was to be the scene of heated battle for some days. The Australian 26th Brigade attacked at midnight, supported by artillery and 30 tanks of 40th Royal Tank Regiment. They took the position and 240 prisoners. Fighting continued in this area for the next week, as the Axis tried to recover the small hill that was so important to their defence.

Meanwhile, the air force night bombers dropped of bombs on targets in the battlefield and on the "Stuka" base at Sidi Haneish, while night fighters flew patrols over the battle area and the Axis forward landing grounds. In the south, the 4th Armoured Brigade and 69th Infantry Brigade attacked the "Folgore" ("187th regiment") at Deir Munassib, but lost about 20 tanks gaining only the forward positions.

Rommel, on his return to North Africa on the evening of 25 October, immediately assessed the battle. Casualties, particularly in the north, as a result of incessant artillery and air attack, had been heavy. He found that the Italian "Trento" Division had lost 50% of its infantry and most of its artillery, 164th Light Division had lost two battalions and although the 15th Panzer and "Littorio" Divisions had held off the Allied armour, this had proved costly; 15th Panzer had a mere 31 tanks remaining. Most other units were under strength, all men were on half rations, a large number were sick, and the entire Axis army had only enough fuel for three days.

Rommel was convinced by this time that the main assault would come in the north and determined to retake Point 29. He ordered a counter-attack against it by 15th Panzer, 164th Light Divisions and elements of Italian XX Corps to begin at 15:00 but (according to the British official history) under heavy artillery and air attack this came to nothing. According to Rommel this attack did meet some success, with the Italians recapturing part of what he calls Hill 28: "Attacks were now launched on Hill 28 by elements of the 15th Panzer Division, the Littorio and a Bersaglieri Battalion, supported by the concentrated fire of all the local artillery and AA. In the evening part of the Bersaglieri Battalion succeeded in occupying the eastern and western edges of the hill".

The bulk of the Australian 2/17th Battalion, which had defended the position, was in fact forced to pull back. During the day, Rommel reversed his policy of distributing his armour across the front, ordering 90th Light Division forward from Ed Daba and 21st Panzer north along with one third of the "Ariete" Division and half the artillery from the southern sector to concentrate with 15th Panzer and Littorio in the north at what was becoming the focal point of the battle. The "Trieste" Division were ordered from Fuka to replace 90th Light at Ed Daba. 21st Panzer and the "Ariete" made slow progress during the night as they were heavily bombed. Rommel was aware that having moved 21st Panzer north he would be unable to move it back south because of a lack of fuel.

Back at the Kidney feature, the British failed to take advantage of the missing tanks. Each time they tried to move forward they were stopped by anti-tank guns. The Allied offensive was stalled. Churchill railed, "Is it really impossible to find a general who can win a battle?"

On a brighter note for the British, three Vickers Wellington torpedo night bombers of No.38 Squadron destroyed the oil tanker "Tergestea" at Tobruk and Bristol Beaufort torpedo bombers of No. 42 Squadron RAF, attached to No. 47 Squadron, sank the tanker "Proserpina" at Tobruk, removing the last hope for refuelling Rommel's army. Rommel himself noted in his diary that with the sinking of "Tergestea" and "Proserpina" the battle was lost.

Montgomery was concerned that the impetus of the offensive was waning. Although by 26 October XXX Corps' infantry had completed the capture of the planned bridgehead west of the second mine belt, the armour of X Corps, although established just beyond the infantry, had failed to break through the enemy's anti-tank defences. He therefore decided that over the next two days, while continuing the process of attrition, he would thin out his front line to create a reserve with which to restore his momentum. The reserve was to include the New Zealand Division (with 9th Armoured Brigade under command), 10th Armoured Division and 7th Armoured Division.
The attacks in the south, which lasted three days and caused considerable losses without achieving a breakthrough, were suspended.

By this time, the main battle was concentrated around Tel el Aqqaqir and the Kidney feature at the end of 1st Armoured Division's path through the minefield. A mile north-west of the feature was Outpost Woodcock and roughly the same distance south-west lay Outpost Snipe. An attack was planned on these areas using two battalions from 7th Motor Brigade. At 23:00 on 26 October 2 Battalion, The Rifle Brigade would attack Snipe and 2nd Battalion King's Royal Rifle Corps (KRRC) would attack Woodcock. The plan was for 2nd Armoured Brigade to pass round the north of Woodcock the following dawn and 24th Armoured Brigade round the south of Snipe. The attack was to be supported by all the available artillery of both X and XXX Corps.

Both battalions had difficulty finding their way in the dark and dust. At dawn, the KRRC had not reached its objective and had to find cover and dig in some distance from Woodcock. 2nd Rifle Brigade had had better fortune and after following the shell bursts of the supporting artillery dug in when they concluded they had reached their objective having encountered little opposition.

At 06:00, the 2nd Armoured Brigade commenced its advance and ran into such stiff opposition that, by noon, it had still not linked with the KRRC. The 24th Armoured Brigade started a little later and was soon in contact with the Rifle Brigade (having shelled them in error for a while). Some hours of confused fighting ensued involving tanks from the "Littorio" and troops and anti-tank guns from 15th Panzer which managed to keep the British armour at bay in spite of the support of the Rifle Brigade battlegroup's anti-tank guns. Rommel had decided to make two counter-attacks using his fresh troops. 90th Light Division was to make a fresh attempt to capture Point 29 and 21st Panzer were targeted at Snipe (the "Ariete" detachment had returned south).

At Snipe, mortar and shellfire was constant all day long. At 16:00, Rommel launched his major attack. German and Italian tanks moved forward. Against them the Rifle Brigade had 13 6-pounder anti-tank guns along with six more from the supporting 239th Anti-Tank Battery, RA. Although on the point of being overrun more than once they held their ground, destroying 22 German and 10 Italian tanks. The Germans gave up but in error the British battle group was withdrawn without being replaced that evening. Its CO, Lieutenant-Colonel Victor Buller Turner was awarded the Victoria Cross. Only one anti-tank gun—from 239 Battery—was brought back.

When it was discovered that neither Woodcock nor Snipe was in Eighth Army hands, 133rd Lorried Infantry Brigade was sent to capture them. By 01:30 on 28 October, the 4th battalion Royal Sussex Regiment judged they were on Woodcock and dug in. At dawn, 2nd Armoured Brigade moved up in support but before contact could be made 4th Royal Sussex were counter-attacked and overrun with many losses. Meanwhile, the Lorried Brigade's two other battalions had moved on Snipe and dug in, only to find out the next day that they were in fact well short of their objective.

Further north, the 90th Light Division's attack on Point 29 during the afternoon of 27 October failed under heavy artillery and bombing which broke up the attack before it had closed with the Australians. The action at Snipe was an episode of the Battle of El Alamein described by the regiment's historian as the most famous day of the regiment's war. Lucas-Phillips, in his "Alamein" records that:

On 28 October, 15th and 21st Panzer made a determined attack on the X Corps front but were halted by sustained artillery, tank and anti-tank gun fire. In the afternoon, they paused to regroup to attack again but they were bombed for two and a half hours and were prevented from even forming up. This proved to be Rommel's last attempt to take the initiative and as such his defeat here represented a turning point in the battle.

At this point, Montgomery ordered the X Corps formations in the Woodcock-Snipe area to go over to defence while he focused his army's attack further to the north. Late on 27 October, the British 133rd Brigade was sent forward to recover lost positions but the next day, a good part of this force was overrun by German and Italian tanks from the Littorio and supporting 12th Bersaglieri Regiment and several hundred British soldiers were captured. On the night of 28/29 October, the 9th Australian Division was ordered to make a second set-piece attack. The 20th Australian Infantry Brigade with 40th R.T.R. in support would push north-west from Point 29 to form a base for 26th Australian Infantry Brigade with 46th R.T.R. in support, to attack north-east to an Axis location south of the railway known as Thompson's Post and then over the railway to the coast road, where they would advance south-east to close on the rear of the Axis troops in the coastal salient. An attack by the third brigade would then be launched on the salient from the south-east.

The 20th Brigade took its objectives with little trouble but 26th Brigade had more trouble. Because of the distances involved, the troops were riding on 46th R.T.R. Valentine tanks as well as carriers, which mines and anti-tank guns soon brought to grief, forcing the infantry to dismount. The infantry and tanks lost touch with each other in fighting with the 125th "Panzergrenadier" Regiment and a battalion of 7th "Bersaglieri" Regiment sent to reinforce the sector and the advance came to a halt. The Australians suffered 200 casualties in that attack and suffered 27 killed and 290 wounded. The German and Italian forces that had participated in the counter-attack formed an outpost and held on until the arrival of German reinforcements on 1 November.
It became clear that there were no longer enough hours of darkness left to reform, continue the attack and see it to its conclusion, so the operation was called off. By the end of these engagements in late October, the British had 800 tanks still in operation, while the "Panzerarmee" day report for 28 October (intercepted and read by Eighth Army the following evening) recorded 81 serviceable German tanks and 197 Italian. With the help of signals intelligence information the "Proserpina" (carrying 4,500 tonnes of fuel) and "Tergestea" (carrying 1,000 tonnes of fuel and 1,000 tonnes of ammunition) had been destroyed on 26 October and the tanker "Luisiano" (carrying 2,500 tonnes of fuel) had been sunk off the west coast of Greece by a torpedo from a Wellington bomber on 28 October. Rommel told his commanders, "It will be quite impossible for us to disengage from the enemy. There is no gasoline for such a manoeuvre. We have only one choice and that is to fight to the end at Alamein."

These actions by the Australians and British had alerted Montgomery that Rommel had committed his reserve in the form of 90th Light Division to the front and that its presence in the coastal sector suggested that Rommel was expecting the next major Eighth Army offensive in this sector. Montgomery determined therefore that it would take place further south on a front south of Point 29. The attack was to take place on the night of 31 October/1 November, as soon as he had completed the reorganisation of his front line to create the reserves needed for the offensive (although in the event it was postponed by 24 hours). To keep Rommel's attention on the coastal sector, Montgomery ordered the renewal of the 9th Australian Division operation on the night of 30/31 October.

The night of 30 October saw a continuation of previous Australian plans, their third attempt to reach the paved road. Although not all the objectives were achieved, by the end of the night they were astride the road and the railway, making the position of the Axis troops in the salient precarious. Rommel brought up a battlegroup from "21. Panzer-Division" and on 31 October, launched four successive attacks against "Thompson's Post". The fighting was intense and often hand-to-hand, but no ground was gained by the Axis forces. One of the Australians killed was Sergeant William Kibby (2/48th Infantry Battalion) who, for his heroic actions from the 23rd until his death on the 31st – including a lone attack on a machine-gun position at his own initiative – was awarded the Victoria Cross.

Again, on Sunday, 1 November Rommel tried to dislodge the Australians, but the brutal, desperate fighting resulted in nothing but lost men and equipment. He did however regain contact with "Panzergrenadier-Regiment 125" in the nose of the salient, and the supporting "10° battaglione Bersaglieri" – that fought well according to German and Allied sources; the "Bersaglieri" had resisted several Australian attacks even though they were (in the words of military historian Niall Barr) "surrounded on all sides, short of ammunition, food and water, [and] unable to evacuate their many wounded".

By now, it had become obvious to Rommel that the battle was lost. His fuel state continued to be critical: on 1 November, two more supply ships—the "Tripolino" and the "Ostia"—had been torpedoed and sunk from the air north-west of Tobruk. The shortage forced him to rely increasingly on fuel flown in from Crete on the orders of Albert Kesselring, Luftwaffe "Oberbefehlshaber Süd" ("OB Süd", Supreme Commander South), despite the restrictions imposed by heavy bombing of the airfields in Crete and the Desert Air Force's efforts to intercept the transport aircraft.

Rommel began to plan a retreat anticipating retiring to Fuka, some west, as he had only 90 tanks remaining in stark contrast with the Allies' 800. Large amounts of fuel arrived at Benghazi after the German forces had started to retreat, but little of it reached the front, a fact Kesselring tried to change by delivering it more closely to the fighting forces.

This phase of the battle began at 01:00 on 2 November, with the objective of destroying enemy armour, forcing the enemy to fight in the open, reducing the Axis stock of petrol, attacking and occupying enemy supply routes, and causing the disintegration of the enemy army. The intensity and the destruction in Supercharge were greater than anything witnessed so far during this battle. The objective of this operation was Tel el Aqqaqir, the base of the Axis defence roughly north-west of the Kidney feature and situated on the Rahman lateral track.

The initial thrust of Supercharge was to be carried out by 2nd New Zealand Division. The division's commander — Lieutenant-General Sir Bernard Freyberg — had tried to free them of this task, as they had lost 1,405 men in just three days, at El Ruweisat Ridge in July. However, in addition to its own 5th New Zealand Infantry Brigade and 28th (Maori) Infantry Battalion, the division was to have had placed under its command 151st (Durham) Brigade from 50th Division, 152nd (Seaforth and Camerons) Brigade from 51st Division and the 133rd Royal Sussex Lorried Infantry Brigade. In addition, the division was to have British 9th Armoured Brigade under command.

As in Operation Lightfoot, it was planned that two infantry brigades (the 151st on the right and 152nd on the left) each this time supported by a regiment of tanks—the 8th and 50th Royal Tank Regiments—would advance and clear a path through the mines. Once they reached their objectives, distant, 9th Armoured Brigade would pass through supported by a heavy artillery barrage and break open a gap in the Axis defences on and around the Rahman track, some further forward, which the 1st Armoured Division, following behind, would pass through into the open to take on Rommel's armoured reserves. Rommel had ordered 21st Panzer Division from the front line on 31 October to form a mobile counterattacking force. The division had left behind a "panzergrenadier" regiment which would bolster the "Trieste" Division which had been ordered forward to replace it. Rommel had also interspersed formations from the "Trieste" and 15th Panzer Divisions to "corset" his weaker forces in the front line. On 1 November the two German armoured divisions had 102 effective tanks to face Supercharge and the "Littorio" and "Trieste" Divisions had 65 tanks between them.

Supercharge started with a seven-hour aerial bombardment focused on Tel el Aqqaqir and Sidi Abd el Rahman, followed by a four and a half hour barrage of 360 guns firing 15,000 shells. The two assault brigades started their attack at 01:05 on 2 November and gained most of their objectives to schedule and with moderate losses. On the right of the main attack 28th (Maori) battalion captured positions to protect the right flank of the newly formed salient and 133rd Lorried Infantry did the same on the left. New Zealand engineers cleared five lines through the mines allowing the Royal Dragoons armoured car regiment to slip out into the open and spend the day raiding the Axis communications.

The 9th Armoured Brigade had started its approach march at 20:00 on 1 November from El Alamein railway station with around 130 tanks and arrived at its start line with only 94 runners (operational tanks). The brigade was to have started its attack towards Tel el Aqqaqir at 05:45 behind a barrage; the attack was postponed for 30 minutes while the brigade regrouped on Currie's orders. At 06:15, 30 minutes before dawn, the three regiments of the brigade advanced towards the gun line.

Brigadier Currie had tried to get the brigade out of doing this job, stating that he believed the brigade would be attacking on too wide a front with no reserves and that they would most likely have 50 percent losses.

The reply came from Freyberg that Montgomery

The German and Italian anti-tank guns (mostly Pak38 and Italian 47 mm guns, along with 24 of the formidable 88 mm flak guns) opened fire upon the charging tanks silhouetted by the rising sun. German tanks, which had penetrated between the Warwickshire Yeomanry and Royal Wiltshire Yeomanry, also caused many casualties. British tanks attacking the "Folgore" sector were fought off with petrol bombs and mortar fire as well as with the obsolete Italian 47 mm cannons. The Axis gun screen started to inflict a steady amount of damage upon the advancing tanks but was unable to stop them; over the course of the next 30 minutes, around 35 guns were destroyed and several hundred prisoners taken. The 9th Armoured Brigade had started the attack with 94 tanks and was reduced to only 14 operational tanks and of the 400 tank crew involved in the attack, 230 were killed, wounded or captured.

After the Brigade's action, Brigadier Gentry of 6th New Zealand Brigade went ahead to survey the scene. On seeing Brigadier Currie asleep on a stretcher, he approached him saying, "Sorry to wake you John, but I'd like to know where your tanks are?" Currie waved his hand at a group of tanks around him and replied "There they are". Gentry said "I don't mean your headquarters tanks, I mean your armoured regiments. Where are they?" Currie waved his arm and again replied, "There are my armoured regiments, Bill".

The brigade had sacrificed itself upon the gun line and caused great damage but had failed to create the gap for the 1st Armoured Division to pass through; however, soon after dawn 1st Armoured Division started to deploy and the remains of 9th Armoured Brigade came under its command. 2nd Armoured Brigade came up behind the 9th, and by mid-morning 8th Armoured Brigade had come up on its left, ordered to advance to the south-west. In heavy fighting during the day the British armour made little further progress. At 11:00 on 2 November, the remains of 15th Panzer, 21st Panzer and "Littorio" Armoured Divisions counter-attacked 1st Armoured Division and the remains of 9th Armoured Brigade, which by that time had dug in with a screen of anti-tank guns and artillery together with intensive air support. The counter-attack failed under a blanket of shells and bombs, resulting in a loss of some 100 tanks.
Although X Corps had failed in its attempt to break out, it had succeeded in its objective of finding and destroying enemy tanks. Although tank losses were approximately equal, this represented only a portion of the total British armour, but most of Rommel's tanks; the "Afrika Korps" strength of tanks fit for battle fell by 70 while in addition to the losses of the 9th Armoured Brigade, the 2nd and 8th Armoured Brigades lost 14 tanks in the fighting, with another 40 damaged or broken down. The fighting was later termed the "Hammering of the Panzers". In the late afternoon and early evening, the 133rd Lorried and 151st Infantry Brigades—by this time back under command of 51st Infantry Division—attacked respectively the Snipe and Skinflint (about a mile west of Snipe) positions in order to form a base for future operations. The heavy artillery concentration which accompanied their advance suppressed the opposition from the "Trieste" Division and the operation succeeded with few casualties.

On the night of 2 November, Montgomery once again reshuffled his infantry in order to bring four brigades (5th Indian, 151st, 5th New Zealand and 154th) into reserve under XXX Corps to prepare for the next thrust. He also reinforced X Corps by moving 7th Armoured Division from army reserve and sending 4th Light Armoured Brigade from XIII Corps in the south. General von Thoma's report to Rommel that night said he would have at most 35 tanks available to fight the next day and his artillery and anti-tank weapons had been reduced to ⅓ of their strength at the start of the battle. Rommel concluded that to forestall a breakthrough and the resulting destruction of his whole army he must start withdrawing to the planned position at Fuka. He called up "Ariete" from the south to join the mobile Italian XX Corps around Tel el Aqqaqir. His mobile forces (XX Corps, "Afrika Korps", 90th Light Division and 19th "Flak" Division) were ordered to make a fighting withdrawal while his other formations were to withdraw as best they could with the limited transport available.

At 20:30 on 2 November, Lumsden decided that one more effort by his X Corps would see the gun screen on the Rahman track defeated and ordered 7th Motor Brigade to seize the track along a front north of Tell el Aqqaqir. The 2nd and 8th Armoured Brigades would then pass through the infantry to a distance of about . On the morning of 3 November 7 Armoured Division would pass through and swing north heading for the railway at Ghazal station. 7th Motor Brigade set off at 01:15 on 3 November, but having received its orders late, had not had the chance to reconnoitre the battle area in daylight. This combined with stiff resistance led to the failure of their attack. As a consequence, the orders for the armour were changed and 2nd Armoured Brigade was tasked to support the forward battalion of 133rd Lorried Brigade (2nd King's Royal Rifle Corps) and 8th Armoured Brigade was to push south-west. Fighting continued throughout 3 November, but 2nd Armoured was held by elements of the "Afrika Korps" and tanks of the "Littorio" Division. Further south, 8th Armoured Brigade was held off by anti-tank units helped later by tanks of the arriving "Ariete" Division.

On 2 November, Rommel let Hitler know that: "The army's strength was so exhausted after its ten days of battle that it was not now capable of offering any effective opposition to the enemy's next break-through attempt ... With our great shortage of vehicles an orderly withdrawal of the non-motorised forces appeared impossible ... In these circumstances we had to reckon, at the least, with the gradual destruction of the army." At 13.30 on 3 November Rommel received a reply:

"To Field Marshal Rommel. It is with trusting confidence in your leadership and the courage of the German-Italian troops under your command that the German people and I are following the heroic struggle in Egypt. In the situation which you find yourself there can be no other thought but to stand fast, yield not a yard of ground and throw every gun and every man into the battle. Considerable air force reinforcements are being sent to C.-in-C South. The "Duce" and the "Comando Supremo" are also making the utmost efforts to send you the means to continue the fight. Your enemy, despite his superiority, must also be at the end of his strength. It would not be the first time in history that a strong will has triumphed over the bigger battalions. As to your troops, you can show them no other road than that to victory or death. Adolf Hitler".

Rommel thought the order (similar to one that had been given at the same time by Benito Mussolini through the "Comando Supremo") "demanded the impossible. ... We were completely stunned, and for the first time in the African campaign I did not know what to do. A kind of apathy took hold of us as we issued orders for all existing positions to be held on instructions from the highest authority."

Rommel decided to compromise: X and XXI Italian Corps and 90th Light Division would stand firm while the "Afrika Korps" would withdraw approximately west during the night of 3 November with XX Italian Corps and the "Ariete" Division conforming to their position. He then replied to Hitler confirming his determination to hold the battlefield. The Desert Air Force continued to apply huge pressure. In what was its biggest day of the battle, it flew 1,208 sorties and dropped of bombs in the 24 hours of 3 November.

On the night of 3 November, Montgomery launched at the Rahman track three of the infantry brigades he had gathered into reserve as a prelude to a massive armoured break out. At 17:45, 152nd Infantry Brigade—with 8th RTR in support—attacked about south of Tel el Aqqaqir. 5th Indian Infantry Brigade would attack the track south during the early hours of 4 November, and at 06:15, 154th Infantry Brigade would attack Tel el Aqqaqir. The first of these attacks—having been mistakenly told the enemy had withdrawn from their objectives—met stiff resistance. Failed communications compounded problems and the forward infantry elements ended up dug in well short of their objective. By the time 5th Indian Brigade set off, the defenders had started to withdraw and their objective was taken with virtually no opposition. By the time 154th Brigade moved forward, although they met some shelling, the enemy had left.

On 4 November, Eighth Army's plan for pursuit was set in motion at dawn. There were no fresh units available for the chase so 1st and 7th Armoured Division were to swing northward to roll up the Axis units still in the forward lines and 2nd New Zealand Division with two lorry borne infantry brigades and 9th Armoured and 4th Light Armoured Brigades under command would head west along desert tracks to the escarpment above Fuka, some away. The New Zealanders got off to a bad start because the units involved were dispersed after the recent fighting and took time to concentrate. The paths through the minefields were very congested and broken up, which delayed matters further. By dark, Freyberg had leaguered his force only west of the Rahman track, although 9th Armoured Brigade was still at the track and 6th New Zealand Brigade even further back.

1st and 7th Armoured Divisions' plan to trap 90th Light Division also hit trouble. The 1st Armoured came into contact with the remnants of 21st Panzer and had to spend most of the day pushing them back . Meanwhile, 7th Armoured was being held up by the "Ariete" Armoured Division which in the course of the day was decimated while giving stout resistance. This action is described by Rommel in his diary: This day also saw the destruction of the "Littorio" Armoured Division and the "Trieste" Motorised Division. Berlin radio claimed that in this sector the "British were made to pay for their penetration with enormous losses in men and material. The Italians fought to the last man."
The British, however, took many prisoners, since the remnants of Italian infantry divisions were not motorised and could not escape from encirclement. Private Sid Martindale, 1st Battalion Argyll & Sutherland Highlanders, wrote about the "Bologna" Division, which had taken the full weight of the British armoured attack:"Bologna" and the remainder of "Trento" Division tried to fight their way out of Alamein and marched in the desert without water, food, or transport before surrendering exhausted and dying from dehydration. It was reported that Colonel Arrigo Dall'Olio, commanding the 40th Infantry Regiment of the "Bologna", surrendered saying, "We have ceased firing not because we haven't the desire but because we have spent every round." In a symbolic act of final defiance, no one in 40th "Bologna" Infantry Regiment raised their hands. Harry Zinder of "Time" magazine noted that the Italians fought better than had been expected, and commented that for the Italians

By late morning on 4 November, Rommel realised his situation was dire: "The picture in the early afternoon of the 4th was as follows: powerful enemy armoured forces ... had burst a 19-kilometre hole in our front, through which strong bodies of tanks were moving to the west. As a result of this, our forces in the north were threatened with encirclement by enemy formations 20 times their number in tanks ... There were no reserves, as every available man and gun had been put into the line. So now it had come, the thing we had done everything in our power to avoid – our front broken and the fully motorised enemy streaming into our rear. Superior orders could no longer count. We had to save what there was to be saved."

Rommel telegraphed Hitler for permission to fall back on Fuka. As further Allied blows fell, von Thoma was captured and reports came in from the "Ariete" and "Trento" that they were encircled. At 17:30, unable to wait any longer for a reply from Hitler, Rommel gave orders to retreat.

Due to insufficient transportation, most of the Italian infantry formations were abandoned and left to their fate. Any chance of getting them away with an earlier move had been spoiled by the dictator's insistence that Rommel hold his ground, obliging him to keep the un-motorised Italian units well forward until it was too late. To deepen the armoured thrusts, 1st Armoured Division was directed at El Daba, some down the coast and 7th Armoured towards Galal, a further west along the railway. Meanwhile, the New Zealand group had hoped to reach their objective by mid-morning on 5 November, but was held up by shell fire when picking their way through what turned out to be a dummy minefield and 15th Panzer were able to get there first.

Montgomery now realised that in order to finish the enemy off he would need to make even deeper armoured thrusts. 7th Armoured was ordered across country to intercept the coastal road at Sidi Haneish, west of the Rahman track while 1st Armoured, at that time west of El Dada, was ordered to take a wide detour through the desert to Bir Khalda, west of the Rahman track preparatory to swinging up to cut the road at Mersa Matruh. Neither move proved successful. 7th Armoured finished the day short of its objective. 1st Armoured determined to make up time with a night march, but in the darkness the armour became separated from their support vehicles and as a consequence ran out of fuel at dawn on 6 November, short of Bir Khalda. The Air Force continued to fly in support but because of the wide spread of the various X Corps units it was difficult to establish firm "bomb lines" demarcating areas in which troops and vehicles could be assumed to be those of the enemy and so free to be attacked.

By 11:00 on 6 November, the "B" Echelon vehicles were starting to reconnect with 1st Armoured Division, but only enough partly to refuel two of the armoured regiments which set off again hoping to be in time to cut off the enemy. However, they ran out of fuel again, south-west of Mersa Matruh. A fuel convoy had set out from Alamein on the evening of 5 November, but progress was slow as the tracks had become very cut up. By midday on the 6th, rain had started to fall and the convoy became bogged down, still from the planned meeting point with the 1st Armoured Division "B" echelon support vehicles.

On the morning of 6 November 2 New Zealand Division advanced toward Sidi Haneish while 10th Armoured Division's 8th Armoured Brigade had moved west from Galal to occupy the landing fields at Fuka and the escarpment. Roughly south-west of Sidi Haneish, 7th Armoured Division had come upon 21st Panzer and the Voss Reconnaissance Group that morning. There was a series of clashes during the day during which 21st Panzer lost 16 tanks and numerous guns. They narrowly escaped encirclement, however, and escaped on wheels that evening to Mersa Matruh. Once again, it proved difficult to firmly identify targets for the air force but during the day US heavy bombers attacked Tobruk, sinking "Etiopia" () and later attacked Benghazi, sinking the "Mars" and setting the tanker "Portofino" (6,572 GRT), alight.

On 7 November, poor ground conditions after the rain and lack of fuel saw 1st and 7th Armoured Divisions remaining quiet. 10th Armoured Division, with the benefit of working on the coastal road and with ample fuel, pushed its tanks on to Mersa Matruh while its infantry mopped up on the road west of Galal.

Rommel intended to fight a delaying action at Sidi Barrani, west of Matruh, to give his retreating forces time to get through the bottleneck through the escarpment passes at Halfya and Sollum. The last rearguards left Matruh on the night of 7/8 November but were only able to hold Sidi Barrani until the evening of the 9th. By the evening of 10 November the New Zealand Division, heading for Sollum, had 4th Light Armoured Brigade at the foot of the Halfya Pass while 7th Armoured Division was conducting another detour to the south aiming to swing round and take Fort Capuzzo and Sidi Azeiz. On the morning of 11 November, 5th New Zealand Infantry Brigade stormed the pass taking 600 Italian prisoners.

By the end of the day on the 11th, the Egyptian border area was clear, but Montgomery was forced to order that the pursuit should—for the time being—be continued by armoured cars and artillery only because of the difficulty in supplying larger formations west of Bardia until the supply infrastructure could catch up.

El Alamein was an Allied victory, although Rommel did not lose hope until the end of the Tunisia Campaign. Churchill said,

The Allies frequently had numerical superiority in the Western Desert but never had it been so complete in quantity and quality. With the arrival of Sherman tanks, 6-pounder anti-tank guns and Spitfires in the Western Desert, the Allies gained a comprehensive superiority. Montgomery envisioned the battle as an attrition operation, similar to those fought in World War I and correctly predicted the length of the battle and the number of Allied casualties. Allied artillery was superbly handled and Allied air support was excellent, in contrast to the "Luftwaffe" and "Regia Aeronautica", which offered little or no support to ground forces, preferring to engage in air-to-air combat. Air supremacy had a huge effect on the battle and not only because of its physical impact. As Montgomery later wrote,

In 2005, Barr wrote that the "Panzerarmee" casualties, was an estimate because of the chaos of the Axis retreat. British figures, based on Ultra intercepts, gave German casualties as and captured. Italian losses were and captured. By 11 November, the number of Axis prisoners had risen to In a note to "The Rommel Papers", Fritz Bayerlein (quoting figures obtained from "Offizieller Bericht des Oberkommandos Afrika") instead estimated German losses in the battle as 1,100 killed, 3,900 wounded and 7,900 prisoners and Italian losses as 1,200 killed, 1,600 wounded and 20,000 prisoners.

According to the official history of the Italian Army, Axis losses during the battle were 4,000 to 5,000 killed or missing, 7,000 to 8,000 wounded and 17,000 prisoners; during the retreat the losses rose to 9,000 killed or missing, 15,000 wounded and 35,000 prisoners. According to the writings of General Giuseppe Rizzo, total Axis casualties included 25,000 men killed or wounded (including 5,920 Italians killed) and 30,000 prisoners (20,000 Italians and 10,724 Germans), as well as 510 tanks and 2,000 field guns, anti-tank guns, anti-aircraft guns. Axis tank losses were on 4 November, only tanks were left out of the the beginning of the battle. About half of the tanks had been lost and most of the remainder were knocked out on the next day by the 7th Armoured Division. About guns were lost, along with and aircraft.

The Eighth Army had of whom had been killed, and were missing; of the casualties were British, Australian, New Zealanders, South African, Indian and were Allied forces. The Eighth Army lost from tanks, although by the end of the battle, had already been repaired. The artillery lost and the DAF lost and aircraft.

The Eighth Army was surprised by Rommel's withdrawal and confusion caused by redeployments between the three corps meant they were slow in pursuit, failing to cut off Rommel at Fuka and Mersa Matruh. The Desert Air Force failed to make a maximum effort to bomb a disorganised and retreating opponent, which on 5 November was within range and confined to the coast road. Supply shortages and a belief that the "Luftwaffe" were about to get strong reinforcements, led the DAF to be cautious, reduce the number of offensive sorties on 5 November and protect the Eighth Army.

The Axis made a fighting withdrawal to El Agheila but Rommel's troops found themselves exhausted and with few replacements, while Montgomery had planned to transport material over great distances, to provide the Eighth Army with of supplies per day. Huge quantities of engineer stores had been collected to repair transport infrastructure and the railway line from El Alamein to Fort Capuzzo, despite having been blown up in over 200 places, was quickly repaired. In the month after Eighth Army reached Capuzzo, the railway carried of supplies. Benghazi handled a day by the end of December, rather than the expected .

Mindful of Axis counter-strokes from El Agheila, Montgomery paused for three weeks to concentrate his forces and prepare an assault. On 11 December, Montgomery launched the 51st (Highland) Division along the line of the coast road with 7th Armoured Division on the inland flank. On 12 December the 2nd New Zealand Division started a deeper flanking manouevre to cut the Axis line of retreat on coast road in the rear of the Mersa Brega position. The Highland Division made a slow and costly advance and 7th Armoured met stiff resistance from the "Ariete" Combat Group (the remains of the "Ariete" Armoured Division). Rommel's army had lost roughly 75,000 men, 1,000 guns and 500 tanks since the Second battle of Alamein and withdrew. By 15 December, the New Zealanders had reached the coast road but the firm terrain allowed Rommel to break his forces into smaller units and withdraw off-road, through the gaps between the New Zealanders positions.

Rommel conducted a text-book retreat, destroying all equipment and infrastructure left behind and peppering the land behind him with mines and booby traps. Eighth Army reached Sirte on 25 December but west of Sirte, were forced to pause to consolidate their strung out formations, to prepare an attack at Wadi Zemzem near Buerat east of Tripoli. Rommel had, with the agreement of Field Marshal Bastico, sent a request to the Italian "Comando Supremo" in Rome to withdraw to Tunisia where the terrain would better suit a defensive action and where he could link with the Axis army forming there, in response to the Operation Torch landings. Mussolini replied on 19 December that the Panzer Army must resist to the last man at Buerat.

On 15 January 1943, General Montgomery launched the 51st (Highland) Division in a frontal attack while sending the 2nd New Zealand Division and the 7th Armoured Division around the inland flank of the Axis line. Weakened by the withdrawal of 21st Panzer Division to Tunisia to strengthen von Arnim's Fifth Panzer Army ("5. Panzerarmee"), Rommel conducted a fighting retreat. The port of Tripoli, some further west, was taken on 23 January as Rommel continued to withdraw to the French-built southern defences of Tunisia, the Mareth Line.

Rommel was by this time in contact with von Arnim's Fifth Panzer Army, which had been fighting against the multi-national British First Army in northern Tunisia, since shortly after Operation Torch the previous autumn. Hitler was determined to retain hold of Tunisia and Rommel finally started to receive replacement men and materials. The Axis now faced a war in Africa on two fronts with Eighth Army approaching from the east and the British, French and Americans from the west. Rommel's German-Italian Panzer Army was renamed the Italian First Army under General Giovanni Messe and Rommel assumed command of the new Army Group Africa, responsible for both fronts. The two Allied armies were placed under 18th Army Group with Harold Alexander in command. The failure of British First Army forces in the run for Tunis in December 1942 led to a prolongation of the North African campaign which would not end until the Italian-German forces in North Africa capitulated in May 1943.





</doc>
<doc id="29588" url="https://en.wikipedia.org/wiki?curid=29588" title="Sextant">
Sextant

A sextant is a doubly reflecting navigation instrument that measures the angular distance between two visible objects. The primary use of a sextant is to measure the angle between an astronomical object and the horizon for the purposes of celestial navigation. The estimation of this angle, the altitude, is known as "sighting" or "shooting" the object, or "taking a sight". The angle, and the time when it was measured, can be used to calculate a position line on a nautical or aeronautical chart—for example, sighting the Sun at noon or Polaris at night (in the Northern Hemisphere) to estimate latitude. Sighting the height of a landmark can give a measure of "distance off" and, held horizontally, a sextant can measure angles between objects for a position on a chart. A sextant can also be used to measure the lunar distance between the moon and another celestial object (such as a star or planet) in order to determine Greenwich Mean Time and hence longitude. The principle of the instrument was first implemented around 1731 by John Hadley (1682–1744) and Thomas Godfrey (1704–1749), but it was also found later in the unpublished writings of Isaac Newton (1643–1727). Additional links can be found to Bartholomew Gosnold (1571–1607) indicating that the use of a sextant for nautical navigation predates Hadley's implementation. In 1922, it was modified for aeronautical navigation by Portuguese navigator and naval officer .

This section discusses navigators' sextants. Most of what is said about these specific sextants applies equally to other types of sextants. Navigators' sextants were primarily used for ocean navigation.

Like the Davis quadrant, the sextant allows celestial objects to be measured relative to the horizon, rather than relative to the instrument. This allows excellent precision. However, unlike the backstaff, the sextant allows direct observations of stars. This permits the use of the sextant at night when a backstaff is difficult to use. For solar observations, filters allow direct observation of the sun.

Since the measurement is relative to the horizon, the measuring pointer is a beam of light that reaches to the horizon. The measurement is thus limited by the angular accuracy of the instrument and not the sine error of the length of an alidade, as it is in a mariner's astrolabe or similar older instrument.

A sextant does not require a completely steady aim, because it measures a relative angle. For example, when a sextant is used on a moving ship, the image of both horizon and celestial object will move around in the field of view. However, the relative position of the two images will remain steady, and as long as the user can determine when the celestial object touches the horizon, the accuracy of the measurement will remain high compared to the magnitude of the movement.

The sextant is not dependent upon electricity (unlike many forms of modern navigation) or anything human-controlled (like GPS satellites). For these reasons, it is considered an eminently practical back-up navigation tool for ships.

The frame of a sextant is in the shape of a sector which is approximately of a circle (60°), hence its name ("sextāns, -antis" is the Latin word for "one sixth"). Both smaller and larger instruments are (or were) in use: the octant, quintant (or pentant) and the (doubly reflecting) quadrant span sectors of approximately of a circle (45°), of a circle (72°) and of a circle (90°), respectively. All of these instruments may be termed "sextants".

Attached to the frame are the "horizon mirror", an "index arm" which moves the "index mirror", a sighting telescope, sun shades, a graduated scale and a micrometer drum gauge for accurate measurements. The scale must be graduated so that the marked degree divisions register twice the angle through which the index arm turns. The scales of the octant, sextant, quintant and quadrant are graduated from below zero to 90°, 120°, 140° and 180° respectively. For example, the sextant shown alongside has a scale graduated from −10° to 142°, so that is basically a quintant: the frame is a sector of a circle subtending an angle of 76° (not 72°) at the pivot of the index arm.

The necessity for the doubled scale reading follows by consideration of the relations of the fixed ray (between the mirrors), the object ray (from the sighted object) and the direction of the normal perpendicular to the index mirror. When the index arm moves by an angle, say 20°, the angle between the fixed ray and the normal also increases by 20°. But the angle of incidence equals the angle of reflection so the angle between the object ray and the normal must also increase by 20°. The angle between the fixed ray and the object ray must therefore increase by 40°. This is the case shown in the graphic alongside.

There are two types of horizon mirrors on the market today. Both types give good results.

Traditional sextants have a half-horizon mirror, which divides the field of view in two. On one side, there is a view of the horizon; on the other side, a view of the celestial object. The advantage of this type is that both the horizon and celestial object are bright and as clear as possible. This is superior at night and in haze, when the horizon can be difficult to see. However, one has to sweep the celestial object to ensure that the lowest limb of the celestial object touches the horizon.

Whole-horizon sextants use a half-silvered horizon mirror to provide a full view of the horizon. This makes it easy to see when the bottom limb of a celestial object touches the horizon. Since most sights are of the sun or moon, and haze is rare without overcast, the low-light advantages of the half-horizon mirror are rarely important in practice.

In both types, larger mirrors give a larger field of view, and thus make it easier to find a celestial object. Modern sextants often have 5 cm or larger mirrors, while 19th-century sextants rarely had a mirror larger than 2.5 cm (one inch). In large part, this is because precision flat mirrors have grown less expensive to manufacture and to silver.

An artificial horizon is useful when the horizon is invisible, as occurs in fog, on moonless nights, in a calm, when sighting through a window or on land surrounded by trees or buildings. Professional sextants can mount an artificial horizon in place of the horizon-mirror assembly. An artificial horizon is usually a mirror that views a fluid-filled tube with a bubble.

Most sextants also have filters for use when viewing the sun and reducing the effects of haze. The filters usually consist of a series of progressively darker glasses that can be used singly or in combination to reduce haze and the sun's brightness. However, sextants with adjustable polarizing filters have also been manufactured, where the degree of darkness is adjusted by twisting the frame of the filter.

Most sextants mount a 1 or 3-power monocular for viewing. Many users prefer a simple sighting tube, which has a wider, brighter field of view and is easier to use at night. Some navigators mount a light-amplifying monocular to help see the horizon on moonless nights. Others prefer to use a lit artificial horizon.

Professional sextants use a click-stop degree measure and a worm adjustment that reads to a minute, 1/60 of a degree. Most sextants also include a vernier on the worm dial that reads to 0.1 minute. Since 1 minute of error is about a nautical mile, the best possible accuracy of celestial navigation is about . At sea, results within several nautical miles, well within visual range, are acceptable. A highly skilled and experienced navigator can determine position to an accuracy of about .

A change in temperature can warp the arc, creating inaccuracies. Many navigators purchase weatherproof cases so that their sextant can be placed outside the cabin to come to equilibrium with outside temperatures. The standard frame designs (see illustration) are supposed to equalise differential angular error from temperature changes. The handle is separated from the arc and frame so that body heat does not warp the frame. Sextants for tropical use are often painted white to reflect sunlight and remain relatively cool. High-precision sextants have an invar (a special low-expansion steel) frame and arc. Some scientific sextants have been constructed of quartz or ceramics with even lower expansions. Many commercial sextants use low-expansion brass or aluminium. Brass is lower-expansion than aluminium, but aluminium sextants are lighter and less tiring to use. Some say they are more accurate because one's hand trembles less. Solid brass frame sextants are less susceptible to wobbling in high winds or when the vessel is working in heavy seas, but as noted are substantially heavier. Sextants with aluminum frames and brass arcs have also been manufactured. Essentially, a sextant is intensely personal to each navigator, and he or she will choose whichever model has the features which suit them best.

Aircraft sextants are now out of production, but had special features. Most had artificial horizons to permit taking a sight through a flush overhead window. Some also had mechanical averagers to make hundreds of measurements per sight for compensation of random accelerations in the artificial horizon's fluid. Older aircraft sextants had two visual paths, one standard and the other designed for use in open-cockpit aircraft that let one view from directly over the sextant in one's lap. More modern aircraft sextants were periscopic with only a small projection above the fuselage. With these, the navigator pre-computed his sight and then noted the difference in observed versus predicted height of the body to determine his position.

A "sight" (or "measure") of the angle between the sun, a star, or a planet, and the horizon is done with the 'star telescope' fitted to the sextant using a visible horizon. On a vessel at sea even on misty days a sight may be done from a low height above the water to give a more definite, better horizon. Navigators hold the sextant by its handle in the right hand, avoiding touching the arc with the fingers.

For a sun sight, a filter is used to overcome the glare such as "shades" covering both index mirror and the horizon mirror designed to prevent eye damage. By setting the index bar to zero, the sun can be viewed through the telescope. Releasing the index bar (either by releasing a clamping screw, or on modern instruments, using the quick-release button), the image of the sun can be brought down to about the level of the horizon. It is necessary to flip back the horizon mirror shade to be able to see the horizon, and then the fine adjustment screw on the end of the index bar is turned until the bottom curve (the "lower limb") of the sun just touches the horizon. 'Swinging' the sextant about the axis of the telescope ensures that the reading is being taken with the instrument held vertically. The angle of the sight is then read from the scale on the arc, making use of the micrometer or vernier scale provided. The exact time of the sight must also be noted simultaneously, and the height of the eye above sea-level recorded.

An alternative method is to estimate the current altitude (angle) of the sun from navigation tables, then set the index bar to that angle on the arc, apply suitable shades only to the index mirror, and point the instrument directly at the horizon, sweeping it from side to side until a flash of the sun's rays are seen in the telescope. Fine adjustments are then made as above. This method is less likely to be successful for sighting stars and planets.

Star and planet sights are normally taken during nautical twilight at dawn or dusk, while both the heavenly bodies and the sea horizon are visible. There is no need to use shades or to distinguish the lower limb as the body appears as a mere point in the telescope. The moon can be sighted, but it appears to move very fast, appears to have different sizes at different times, and sometimes only the lower or upper limb can be distinguished due to its phase.

After a sight is taken, it is reduced to a position by looking at several mathematical procedures. The simplest sight reduction is to draw the equal-altitude circle of the sighted celestial object on a globe. The intersection of that circle with a dead-reckoning track, or another sighting, gives a more precise location.

Sextants can be used very accurately to measure other visible angles, for example between one heavenly body and another and between landmarks ashore. Used horizontally, a sextant can measure the apparent angle between two landmarks such as a lighthouse and a church spire, which can then be used to find the distance "off" or out to sea (provided the distance between the two landmarks is known). Used vertically, a measurement of the angle between the lantern of a lighthouse of known height and the sea level at its base can also be used for distance off.

Due to the sensitivity of the instrument it is easy to knock the mirrors out of adjustment. For this reason a sextant should be checked frequently for errors and adjusted accordingly.

There are four errors that can be adjusted by the navigator and they should be removed in the following order.





</doc>
<doc id="29589" url="https://en.wikipedia.org/wiki?curid=29589" title="Single transferable vote">
Single transferable vote

The single transferable vote (STV) is a voting system designed to achieve proportional representation through ranked voting in multi-seat organizations or constituencies (voting districts). Under STV, an elector (voter) has a single vote that is initially allocated to their most preferred candidate. Votes are totalled and a quota (the number of votes required to win a seat) derived. If their candidate achieves quota, he/she is elected and in some STV systems any surplus vote is transferred to other candidates in proportion to the voters' stated preferences. If more candidates than seats remain, the bottom candidate is eliminated with his/her votes being transferred to other candidates as determined by the voters' stated preferences. These elections and eliminations, and vote transfers if applicable, continue until there are only as many candidates as there are unfilled seats. The specific method of transferring votes varies in different systems (see Counting methods).

The system provides approximately proportional representation while mostly ensuring that the party with the most votes gets the most seats and that minorities have some representation; enables votes to be cast for individual candidates rather than for parties and party machine-controlled party lists, and – compared to first-past-the-post voting – reduces "wasted" votes (votes being wasted on losers and surplus votes being wasted on sure winners) by transferring them to other candidates.

STV is the system of choice of groups such as the Proportional Representation Society of Australia (which calls it quota-preferential proportional representation), the Electoral Reform Society in the United Kingdom and FairVote in the USA (which refers to both STV and instant-runoff voting as ranked-choice voting, although there are other preferential voting methods that use ranked-choice ballots). Its critics contend that some voters find the mechanisms behind STV difficult to understand, but this does not make it more difficult for voters to rank the list of candidates in order of preference on an STV ballot paper (see Voting).

STV has had its widest adoption in the English-speaking world. , in government elections, STV is used for:
In British Columbia , Canada, STV was recommended for provincial elections by the British Columbia Citizens' Assembly on Electoral Reform. In a 2005 provincial referendum, it received 57.69% support and passed in 77 of 79 electoral districts. It was not adopted, however, because it fell short of the 60% threshold requirement the BC Liberal government had set for the referendum to be binding. In a second referendum, on 12 May 2009, STV was defeated 60.91% to 39.09%

STV has also been used in several other jurisdictions, particularly in provincial elections in the cities of Edmonton and Calgary in Alberta. Less well known is STV use at the municipal level in western Canada – Calgary used STV for more than 50 years. For a more complete list, see "History and use of the single transferable vote".

When STV is used for single-winner elections, it is equivalent to the instant-runoff voting (alternative vote) method. STV used for multi-winner elections is sometimes called "proportional representation through the single transferable vote", or PR-STV. "STV" usually refers to the multi-winner version, as it does in this article. In the United States it is sometimes called choice voting, preferential voting or preference voting ("preferential voting" can also refer to a broader category, ranked voting systems).

Hare-Clark is the name given to PR-STV elections in Tasmania and the Australian Capital Territory.

In STV, each voter ranks the list of candidates in order of preference. In the most common ballot design, they place a '1' beside their most preferred candidate, a '2' beside their second most preferred, and so on. The completed ballot paper therefore contains an ordinal list of candidates. In the ballot paper in this image, the preferences of the voter are as follows:


The most straightforward way to count a ranked ballot vote is simply to sequentially identify the candidate with the least support, eliminate that candidate, and transfer those votes to the next-named candidate on each ballot. This process is repeated until there are only as many candidates left as seats available. This method was used for a period of time in several local elections in South Australia. In effect, it is identical to instant-runoff voting, which is commonly used in leadership contests, except that the transfer process is terminated when there are still several candidates remaining, if all the seats have been filled.

In most STV elections, an additional step is taken that ensures that all elected candidates are elected with approximately equal numbers of votes. It can be shown that a candidate requires a minimum number of votes – the quota (or threshold) – to be elected. A number of different quotas can be used; the most common is the Droop quota, given by the floor function formula:

The Droop quota is an extension of requiring a 50% + 1 majority in single-winner elections. For example, at most 3 people can have 25% + 1 in 3-winner elections, 9 can have 10% + 1 in 9-winner elections, and so on.

If fractional votes can be submitted, then the Droop quota may be modified so that the fraction is not rounded down.
Major Frank Britton, of the Election Ballot Services at the Electoral Reform Society, observed that the final plus one of the Droop quota is never needed. So, the quota for one seat is fifty out of a hundred votes, not fifty-one.

An STV election starts with every voter's first choice, according to the following steps:


There are variations, such as how to transfer surplus votes from winning candidates and whether to transfer votes to already-elected candidates. When the number of votes transferred from the losing candidate with the fewest votes is too small to change the ordering of remaining candidates, more than one candidate can be eliminated simultaneously.

One simplistic formula for how to transfer surplus votes is:

however, this can produce fractional votes. See "Counting methods" below for a discussion of how this is handled.

If a candidate is eliminated and their votes are transferred to already victorious candidates, then the new excess votes for the victorious candidate (transferred from the eliminated candidate) will be transferred to the next preference of the victorious candidate, as happened with their initial excess. However, any votes which would transfer from the victorious candidate to one who was already eliminated must be reallocated. See the section on counting methods below for details.

Because votes cast for losing candidates and excess votes cast for winning candidates are transferred to voters' next choice candidates, STV is said to minimize wasted votes.

Suppose a food election is conducted to determine what three foods to serve at a party. There are 5 candidates, 3 of which will be chosen. The candidates are: "Oranges", "Pears", "Chocolate", "Strawberries", and "Sweets". The 20 guests at the party mark their ballots according to the table below. In this example, a second choice is made by only some of the voters.

First, the quota is calculated. Using the Droop quota, with 20 voters and 3 winners to be found, the number of votes required to be elected is:

When ballots are counted the election proceeds as follows:

Result: The winners are Chocolate, Oranges and Strawberries.

STV systems primarily differ in how they transfer votes and in the size of the quota. For this reason some have suggested that STV can be considered a family of voting systems rather than a single system. The Droop quota is the most commonly used quota. This ensures majority rule (except in rare cases) while maintaining the condition that no more candidates can reach a quota than there are seats to be filled. The Hare quota, which was used in the original proposals by Thomas Hare, ensures greater proportionality, at the expense of having to count more votes and not guaranteeing majority rule.

The easiest methods of transferring surpluses involve an element of randomness; partially random systems, such as the Hare system, are used in the Republic of Ireland (except Senate elections) and in Malta, among other places. The Gregory method (also known as Newland-Britain or Senatorial rules) eliminates randomness by allowing for the transfer of fractions of votes. Gregory is in use in Northern Ireland, the Republic of Ireland (Senate elections) and in Australia. Both Gregory and earlier methods have the problem that in some circumstances they do not treat all votes equally. For this reason Meek's method, Warren's method and the Wright system have been invented. While easier methods can usually be counted by hand, except in a very small election Meek and Warren require counting to be conducted by computer. The Wright system is a refinement of the Australian Senate system replacing the process of distribution and segmentation of preferences by a reiterative counting process where the count is reset and restarted on every exclusion. Meek is used in local body elections in New Zealand.

Meek in 1969 was the first to realize that computers make it possible to count votes in way that is conceptually simpler and closer to the original concept of STV. One advantage of Meek's method is that the quota is adjusted at each stage of counting when the number of votes decreases because some become non-transferable.

Meek also considered a variant on his system which allows for equal preferences to be expressed. This has subsequently (since 1998) been used by the John Muir Trust for electing its trustees.

The concept of transferable voting was first proposed by Thomas Wright Hill in 1819. The system remained unused in public elections until 1855, when Carl Andræ proposed a transferable vote system for elections in Denmark, and his system was used in 1856 to elect the Rigsraad and from 1866 it was also adapted for indirect elections to the second chamber, the Landsting, until 1915.

Although he was not the first to propose transferable votes, the English barrister Thomas Hare is generally credited with the conception of STV, and he may have independently developed the idea in 1857. Hare's view was that STV should be a means of "making the exercise of the suffrage a step in the elevation of the individual character, whether it be found in the majority or the minority." In Hare's original system, he further proposed that electors should have the opportunity of discovering which candidate their vote had ultimately counted for, to improve their personal connection with voting. It should be noted that at the time of Hare's original proposal the UK did not use the secret ballot, so not only could the voter determine the ultimate role of their vote in the election, the elected MPs would have been able to determine who had voted for them. As Hare envisaged that the whole House of Commons be elected "at large" this would have replaced geographical constituencies with what Hare called "constituencies of interest" – those people who had actually voted for each MP. In modern elections, held by secret ballot, a voter can discover how their vote was distributed by viewing detailed election results. This is particularly easy to do using Meek's method, where only the final weightings of each candidate need to be published. The elected member is, however, unable to verify who their supporters are.

The noted political essayist John Stuart Mill was a friend of Hare's and an early proponent of STV, praising it at length in his essay "Considerations on Representative Government", in which he writes: "Of all modes in which a national representation can possibly be constituted, this one affords the best security for the intellectual qualifications desirable in the representatives. At present... the only persons who can get elected are those who possess local influence, or make their way by lavish expenditure..." His contemporary, Walter Bagehot, also praised the Hare system for allowing everyone to elect an MP, even ideological minorities, but also argued that the Hare system would create more problems than it solved: "[the Hare system] is inconsistent with the extrinsic independence as well as the inherent moderation of a Parliament – two of the conditions we have seen, are essential to the bare possibility of parliamentary government."

Advocacy of STV spread through the British Empire, leading it to be sometimes known as "British Proportional Representation". In 1896, Andrew Inglis Clark was successful in persuading the Tasmanian House of Assembly to be the first parliament in the world elected by what became known as the "Hare-Clark electoral system", named after himself and Thomas Hare. H. G. Wells was a strong advocate, calling it "Proportional Representation".
The HG Wells formula for scientific voting, repeated, over many years, in his PR writings, to avoid misunderstanding, is Proportional Representation by the Single Transferable Vote in large constituencies.

STV in large constituencies permits an approach to the Hare-Mill-Wells ideal of mirror representation. The UK National Health Service used to elect, First Past The Post, all white male General Practitioners. In 1979, STV proportionally represented women, immigrants and specialists, to the General Medical Council.
In 1948, single transferable vote proportional representation on a state-by-state basis became the method for electing Senators to the Australian Senate. This change has led to the rise of a number of minor parties such as the Democratic Labor Party, Australian Democrats and Australian Greens who have taken advantage of this system to achieve parliamentary representation and the balance of power. From the 1984 election, group ticket voting was introduced in order to reduce a high rate of informal voting but in 2016, group tickets were abolished to avoid undue influence of preference deals amongst parties that were seen as distorting election results and a form of optional preferential voting was introduced.

STV was also adopted in the first half of the 20th century to elect several city councils in the United States. More than twenty cities used STV, including Cleveland, Cincinnati and New York City. As of January 2010, it is used to elect the city council and school committee in Cambridge, Massachusetts and the park board in Minneapolis, Minnesota. STV has also been adopted for student government elections at several American universities, including Carnegie Mellon, Harvard, MIT, Oberlin, Reed, UC Berkeley, UC Davis, Vassar, UCLA, Whitman, and UT Austin. Legislation (HR 3057), was introduced in Congress in June 2017 that would establish STV for US House elections starting in 2022.

The degree of proportionality of STV election results depends directly on the district magnitude (i.e. the number of seats in each district). While Ireland originally had a median district magnitude of five (ranging from three to nine) in 1923, successive governments lowered this. Systematically lowering the number of representatives from a given district directly benefits larger parties at the expense of smaller ones.

Supposing that the Droop quota is used: in a nine-seat district, the quota or threshold is 10% (plus one vote); in a three-seat district, it would be 25% (plus one vote).

A parliamentary committee in 2010 discussed the "increasing trend towards the creation of three-seat constituencies in Ireland" and recommended not less than four-seaters, except where the geographic size of such a constituency would be disproportionately large.

STV provides proportionality by transferring votes to minimize waste, and therefore also minimizes the number of unrepresented or disenfranchised voters.

A frequent concern about STV is its complexity compared with plurality voting methods. Before the advent of computers, this complexity made ballot-counting more difficult than for some other voting methods.

The algorithm is complicated. In large elections with many candidates, a computer may be required. (This is because after several rounds of counting, there may be many different categories of previously transferred votes, each with a different permutation of early preferences and thus each with a different carried-forward weighting, all of which have to be kept track of.)

STV differs from other proportional representation systems in that candidates of one party can be elected on transfers from voters for other parties. Hence, STV may reduce the role of political parties in the electoral process and corresponding partisanship in the resulting government. A district only needs to have four members to be proportional for the major parties, but may under-represent smaller parties, even though they may well be more likely to be elected under STV than under first past the post. Also, while small parties seen as reasonable second preferences by others (such as the Green Party in Ireland) more easily get elected, parties seen as more extreme by others (such as Sinn Féin in Ireland) find it harder to attract second preferences and therefore find it harder to win seats.

As STV is a multi-member system, filling vacancies between elections can be problematic, and a variety of methods have been devised:

If there are not enough candidates to represent one of the priorities the electorate vote for (such as a party), all of them may be elected in the early stages, with votes being transferred to candidates with other views. On the other hand, putting up too many candidates might result in first preference votes being spread too thinly among them, and consequently several potential winners with broad second-preference appeal may be eliminated before others are elected and their second-preference votes distributed. In practice, the majority of voters express preference for candidates from the same party in order, which minimizes the impact of this potential effect of STV.

The outcome of voting under STV is proportional within a single election to the collective preference of voters, assuming voters have ranked their real preferences and vote along strict party lines (assuming parties and no individual independents participate in the election). However, due to other voting mechanisms usually used in conjunction with STV, such as a district or constituency system, an election using STV may not guarantee proportionality across all districts put together.

A number of methods of tactical or strategic voting exist that can be used in STV elections, but much less so than with First Past the Post. (In STV elections, most constituencies will be marginal, at least with regard to the allocation of a final seat.)

STV systems vary, both in ballot design and in whether or not voters are obliged to provide a full list of preferences. In jurisdictions such as Malta, Republic of Ireland and Northern Ireland, voters may rank as many or as few candidates as they wish. Consequently, voters sometimes, for example, rank only the candidates of a single party, or of their most preferred parties. A minority of voters, especially if they do not fully understand the system, may even "bullet vote", only expressing a first preference, or indicate a first preference for multiple candidates, especially when both STV and plurality are being used in concurrent elections. Allowing voters to rank only as many candidates as they wish grants them greater freedom, but can also lead to some voters ranking so few candidates that their vote eventually becomes "exhausted"–that is, at a certain point during the count, it can no longer be transferred and therefore loses an opportunity to influence the result.

The method can be confusing, and may cause some people to vote incorrectly with respect to their actual preferences. The ballots can also be long; having multiple pages also increases the chances of people missing the later opportunities to continue voting.

Some opponents argue that larger, multi-seat districts would require more campaign funds to reach the voters. Proponents argue that STV can lower campaign costs because like-minded candidates can share some expenses. In addition, unlike in at-large plurality elections, candidates do not have to secure the support of at least 50% of voters, allowing candidates to focus campaign spending primarily on supportive voters.

Academic analysis of voting systems such as STV generally centers on the voting system criteria that they pass. No preference voting system satisfies all the criteria in Arrow's impossibility theorem: in particular, STV fails to achieve independence of irrelevant alternatives (like most other vote-based ordering systems) and monotonicity.

The relative performance of political parties in STV (single transferable vote) systems is analysed in a different fashion from that used in other electoral schemes. For example, seeing which candidates are declared elected on first preference votes alone can be shown as follows:

The data can also be analysed to find the proportion of voters who express only a single preference, or those who express a minimum number of preferences, in order to assess party strength. Where parties nominate multiple candidates in an electoral district, analysis can also be done to assess their relative strength.

Other useful information can be found by analysing terminal transfersi.e., when the votes of a candidate are transferred and no other candidate from that party remains in the countespecially with respect to the first instance in which that occurs:

Another effect of STV is that candidates who did well on first preference votes may not be elected, and those who did poorly on first preferences can be elected, because of differences in second and later preferences. This can also be analysed:



</doc>
<doc id="29591" url="https://en.wikipedia.org/wiki?curid=29591" title="Stellarator">
Stellarator

A stellarator is a device used to confine hot plasma with magnetic fields in order to sustain a controlled nuclear fusion reaction. The name refers to the possibility of harnessing the power source of the sun, a stellar object. It is one of the earliest fusion power devices, along with the z-pinch and magnetic mirror.

The stellarator was invented by Lyman Spitzer of Princeton University in 1951, and much of its early development was carried out by his team at what became the Princeton Plasma Physics Laboratory (PPPL). The basic concept is to lay out the magnetic fields so that particles circulating around the long axis of the machine follow twisting paths, which cancels out instabilities seen in purely toroidal machines. This would keep the fuel confined long enough to allow it to be heated to the point where fusion would take place.

The first Model A started operation in 1953 and proved the basic layout worked. Larger models followed, but these demonstrated poor performance, suffering from a problem known as pump-out that caused them to lose plasma at rates far worse than theoretical predictions. By the early 1960s, any hope of quickly producing a commercial machine faded, and attention turned to studying the fundamental theory of high-energy plasmas. By the mid-1960s, Spitzer was convinced that the stellarator was matching the Bohm diffusion rate, which suggested it would never be a practical fusion device.

The release of information on the USSR's tokamak design in 1969 led to the Model C stellarator being converted to the Symmetrical Tokamak, as a much higher-performance concept. Large-scale work on the stellarator concept ended as the tokamak got most of the attention. The tokamak ultimately proved to have similar problems to the stellarators, but for different reasons. Since the 1990s, this has led to renewed interest in the stellarator design. New methods of construction have increased the quality and power of the magnetic fields, improving performance. A number of new devices have been built to test these concepts. Major examples include Wendelstein 7-X in Germany, the Helically Symmetric Experiment (HSX) in the USA, and the Large Helical Device in Japan.

In 1934, Mark Oliphant, Paul Harteck and Ernest Rutherford were the first to achieve fusion on Earth, using a particle accelerator to shoot deuterium nuclei into a metal foil containing deuterium, lithium or other elements. This system allowed them to measure the nuclear cross section of various fusion reactions, and determined that the tritium-deuterium reaction occurred at a lower energy than any other fuel, peaking at about 100,000 electronvolts (100 keV).

100 keV corresponds to a temperature of about a billion kelvins. Due to the Maxwell–Boltzmann statistics, a bulk gas at a much lower temperature will still contain some particles at these much higher energies. Because the fusion reactions release so much energy, even a small number of these reactions can release enough energy to keep the gas at the required temperature. In 1944, Enrico Fermi demonstrated that this would occur at a bulk temperature of about 50 million Celsius, still very hot but within the range of existing experimental systems. The key problem was "confining" such a plasma; no material container could withstand those temperatures. But because plasmas are electrically conductive, they are subject to electric and magnetic fields which provide a number of solutions.

In a magnetic field, the electrons and nuclei of the plasma circle the magnetic lines of force. One way to provide some confinement would be to place a tube of fuel inside the open core of a solenoid. A solenoid creates a magnetic lines running down its center, and fuel would be held away from the walls by orbiting these lines of force. But such an arrangement does not confine the plasma along the length of the tube. The obvious solution is to bend the tube around into a torus (donut) shape, so that any one line forms a circle, and the particles can circle forever.

However, this solution does not actually work. For purely geometric reasons, the magnets ringing the torus are closer together on the inside curve, inside the "donut hole". Fermi noted this would cause the electrons to drift away from the nuclei, eventually causing them to separate and cause large voltages to develop. The resulting electric field would cause the plasma ring inside the torus to expand until it hit the walls of the reactor.

In the post-war era, a number of researchers began considering different ways to confine a plasma. George Paget Thomson of Imperial College London proposed a system now known as z-pinch, which runs a current through the plasma. Due to the Lorentz force, this current creates a magnetic field that pulls the plasma in on itself, keeping it away from the walls of the reactor. This eliminates the need for magnets on the outside, avoiding the problem Fermi noted. Various teams in the UK had built a number of small experimental devices using this technique by the late 1940s.

Another person working on controlled fusion reactors was Ronald Richter, a former German scientist who moved to Argentina after the war. His "thermotron" used a system of electrical arcs and mechanical compression (sound waves) for heating and confinement. He convinced Juan Perón to fund development of an experimental reactor on an isolated island near the Chilean border. Known as the Huemul Project, this was completed in 1951. Richter soon convinced himself fusion had been achieved in spite of other people working on the project disagreeing. The "success" was announced by Perón on 24 March 1951, becoming the topic of newspaper stories around the world.

While preparing for a ski trip to Aspen, Lyman Spitzer received a telephone call from his father, who mentioned an article on Huemul in the "New York Times". Looking over the description in the article, Spitzer concluded it could not possibly work; the system simply could not provide enough energy to heat the fuel to fusion temperatures. But the idea stuck with him, and he began considering systems that would work. While riding the ski lift, he hit upon the stellarator concept.

The basic concept was a way to modify the torus layout so that it addressed Fermi's concerns though the device's geometry. By twisting one end of the torus compared to the other, forming a figure-8 layout instead of a circle, the magnetic lines no longer travelled around the tube at a constant radius, instead they moved closer and further from the torus' center. A particle orbiting these lines would find itself constantly moving in and out across the minor axis of the torus. The drift upward while it travelled through one section of the reactor would be reversed after half an orbit and it would drift downward again. The cancellation was not perfect, but it appeared this would so greatly reduce the net drift rates that the fuel would remain trapped long enough to heat it to the required temperatures.

His 1958 description was simple and direct:
While working at Los Alamos in 1950, John Wheeler suggested setting up a secret research lab at Princeton University that would carry on theoretical work on H-bombs after he returned to the university in 1951. Spitzer was invited to join this program, given his previous research in interstellar plasmas.

But by the time of his trip to Aspen, Spitzer had lost interest in bomb design and he turned his attention full-time to fusion as a power source. Over the next few months, Spitzer produced a series of reports outlining the conceptual basis for the stellarator, as well as potential problems. The series is notable for its depth; it not only included a detailed analysis of the mathematics of the plasma and stability but also outlined a number of additional problems like heating the plasma and dealing with impurities.

With this work in hand, Spitzer began to lobby the Department of Energy (DOE) for funding to develop the system. He outlined a plan involving three stages. The first would see the construction of a Model A, whose purpose was to demonstrate that a plasma could be created and that its confinement time was better than a torus. If the A model was successful, the B model would attempt to heat the plasma to fusion temperatures. This would be followed by a C model, which would attempt to actually create fusion reactions at a large scale. This entire series was expected to take about a decade.

Around the same time, Jim Tuck had been introduced to the pinch concept while working at Clarendon Laboratory at Oxford University. He was offered a job in the US and eventually ended up at Los Alamos, where he acquainted the other researchers with the concept. When he heard Spitzer was promoting the stellarator, he also travelled to Washington to propose building a pinch device. He considered Spitzer's plans "incredibly ambitious." Nevertheless, Spitzer was successful in gaining $50,000 in funding from the DOE, while Tuck received nothing.

The Princeton program was officially created on 1 July 1951. Spitzer, an avid mountain climber, proposed the name "Project Matterhorn" because he felt "the work at hand seemed difficult, like the ascent of a mountain." Two sections were initially set up, S Section working on the stellarator under Spitzer, and B Section working on bomb design under Wheeler. Matterhorn was set up at Princeton's new Forrestal Campus, a plot of land the University purchased from the Rockefeller Institute for Medical Research when Rockefeller relocated to Manhattan. The land was located about from the main Princeton campus and already had sixteen laboratory buildings. Spitzer set up the top-secret S Section in a former rabbit hutch.

It was not long before the other labs began agitating for their own funding. Tuck had managed to arrange some funding for his Perhapsatron through some discretionary budgets at LANL, but other teams at LANL, Berkeley and Oak Ridge (ORNL) also presented their ideas. The DOE eventually organized a new department for all of these projects, becoming "Project Sherwood".

With the funding from the DOE, Spitzer began work by inviting James Van Allen to join the group and set up an experimental program. Allen suggested starting with a small "tabletop" device. This led to the Model A design, which began construction in 1952. It was made from pyrex tubes about in total length, and magnets capable of about 1,000 gauss. The machine began operations in early 1953 and clearly demonstrated improved confinement over the simple torus.

This led to the construction of the Model B, which had the problem that the magnets were not well mounted and tended to move around when they were powered to their maximum capacity of 50,000 gauss. A second design also failed for the same reason, but this machine demonstrated several-hundred-kilovolt X-rays that suggested good confinement. The lessons from these two designs led to the B-1, used ohmic heating (see below) to reach plasma temperatures around 100,000 degrees. This machine demonstrated that impurities in the plasma caused large x-ray emissions that rapidly cooled the plasma. In 1956, B-1 was rebuilt with an ultra-high vacuum system to reduce the impurities but found that even at smaller quantities they were still a serious problem. Another effect noticed in the B-1 was that during the heating process, the particles would remain confined for only a few tenths of a millisecond, while once the field was turned off, any remaining particles were confined for as long as 10 milliseconds. This appeared to be due to "cooperative effects" within the plasma.

Meanwhile, a second machine known as B-2 was being built. This was similar to the B-1 machine but used pulsed power to allow it to reach higher magnetic energy and included a second heating system known as magnetic pumping. This machine was also modified to add an ultra-high vacuum system. Unfortunately, B-2 demonstrated little heating from the magnetic pumping, which was not entirely unexpected because this mechanism required longer confinement times, and this was not being achieved. As it appeared that little could be learned from this system in its current form, in 1958 it was sent to the Atoms for Peace show in Geneva. However, when the heating system was modified, the coupling increased dramatically, demonstrating temperatures within the heating section as high as .

Two additional machines were built to study pulsed operation. B-64 was completed in 1955, essentially a larger version of the B-1 machine but powered by pulses of current that produced up to 15,000 gauss. This machine included a "diverter", which removed impurities from the plasma, greatly reducing the x-ray cooling effect seen on earlier machines. B-64 included straight sections in the curved ends which gave it a squared-off appearance. This appearance led to its name, it was a "figure-8, squared", or 8 squared, or 64. This led to experiments in 1956 where the machine was re-assembled without the twist in the tubes, allowing the particles to travel without rotation.

B-65, completed in 1957, was built using the new "racetrack" layout. This was the result of the observation that adding helical coils to the curved portions of the device produced a field that introduced the rotation purely through the resulting magnetic fields. This had the added advantage that the magnetic field included "shear", which was known to improve stability. B-3, also completed in 1957, was a greatly enlarged B-2 machine with ultra-high vacuum and pulsed confinement up to 50,000 gauss and projected confinement times as long as 0.01 second. The last of the B-series machines was the B-66, completed in 1958, which was essentially a combination of the racetrack layout from B-65 with the larger size and energy of the B-3.

Unfortunately, all of these larger machines demonstrated a problem that came to be known as "pump out". This effect was causing plasma drift rates that were not only higher than classical theory suggested but also much higher than the Bohm rates. B-3's drift rate was a full three times that of the worst-case Bohm predictions, and failed to maintain confinement for more than a few tens of microseconds.

As early as 1954, as research continued on the B-series machines, the design of the Model C device was becoming more defined. It emerged as a large racetrack-layout machine with multiple heating sources and a diverter, essentially an even larger B-66. Construction began in 1958 and was completed in 1961. It could be adjusted to allow a plasma minor axis between and was in length. The toroidal field coils normally operated at 35,000 gauss.

By the time Model C began operations, information collected from previous machines was making it clear that it would not be able to produce large-scale fusion. Ion transport across the magnetic field lines was much higher than classical theory suggested. Greatly increased magnetic fields of the later machines did little to address this, and confinement times simply were not improving. Attention began to turn to a much greater emphasis on the theoretical understanding of the plasma. In 1961, Melvin B. Gottlieb took over the Matterhorn Project from Spitzer, and on 1 February the project was renamed as the Princeton Plasma Physics Laboratory (PPPL).

Continual modification and experimentation on the Model C slowly improved its operation, and the confinement times eventually increased to match that of Bohm predictions. New versions of the heating systems were used that slowly increased the temperatures. Notable among these was the 1964 addition of a small particle accelerator to accelerate fuel ions to high enough energy to cross the magnetic fields, depositing energy within the reactor when they collided with other ions already inside. This method of heating, now known as neutral beam injection, has since become almost universal on magnetic confinement fusion machines.

Model C spent most of its history involved in studies of ion transport. Through continual tuning of the magnetic system and the addition of the new heating methods, in 1969, Model C eventually reached electron temperatures of 400 eV. Through this period, a number of new potential stellarator designs emerged, using a single set of magnetic coils. The Model C used separate confinement and helical coils, but it was seen that these could be combined, and this led to the "torsitron" concept.

In 1968, scientists in the Soviet Union released the results of their tokamak machines, notably their newest example, T-3. The results were so startling that there was widespread scepticism. To address this, the Soviets invited a team of experts from the United Kingdom to test the machines for themselves. Their tests, made using a laser-based system developed for the ZETA reactor in England, verified the Soviet claims of electron temperatures of 1,000 eV. What followed was a "veritable stampede" of tokamak construction worldwide.

At first the US labs ignored the tokamak; Spitzer himself dismissed it out of hand as experimental error. However, as new results came in, especially the UK reports, Princeton found itself in the position of trying to defend the stellarator as a useful experimental machine while other groups from around the US were clamoring for funds to build tokamaks. In July 1969 Gottlieb had a change of heart, offering to convert the Model C to a tokamak layout. In December it was shut down and reopened in May as the Symmetric Tokamak (ST).

The ST immediately matched the performance being seen in the Soviet machines, besting the Model C's results by over ten times. From that point, PPPL was the primary developer of the tokamak approach in the US, introducing a series of machines to test various designs and modifications. The Princeton Large Torus of 1975 quickly hit several performance numbers that were required for a commercial machine, and it was widely believed the critical threshold of breakeven would be reached in the early 1980s. What was needed was larger machines and more powerful systems to heat the plasma to fusion temperatures.

Tokamaks are a type of pinch machine, differing from earlier designs primarily in the amount of current in the plasma: above a certain threshold known as the "safety factor", or "q", the plasma is much more stable. ZETA ran at a "q" around , while experiments on tokamaks demonstrated it needs to be at least 1. Machines following this rule showed dramatically improved performance. However, by the mid-1980s the easy path to fusion disappeared; as the amount of current in the new machines began to increase, a new set of instabilities in the plasma appeared. These could be addressed, but only by greatly increasing the power of the magnetic fields, requiring superconducting magnets and huge confinement volumes. The cost of such a machine was such that the involved parties banded together to begin the ITER project.

As the problems with the tokamak approach grew, there was renewed interest in the stellarator approach. This coincided with the development of advanced computer aided design tools that allowed the construction of complex magnets that were previously known but considered too difficult to design and build.

New materials and methods of construction have increased the quality and power of the magnetic fields, improving performance. A number of new devices have been built to test these concepts. Major examples include Wendelstein 7-X in Germany, the Helically Symmetric Experiment (HSX) in the USA, and the Large Helical Device in Japan. W7X and LHD use superconducting magnetic coils.
The lack of an internal current eliminates some of the instabilities of the tokamak, meaning the stellarator should be more stable at similar operating conditions. On the downside, since no confinement is provided by the current found in a tokamak, the stellarator requires more powerful magnets to reach any given confinement. The stellarator is an inherently steady-state machine, which has several advantages from an engineering standpoint.

Heating a gas increases the energy of the particles within it, so by heating a gas into the hundreds of millions of degrees, the majority of the particles within it would reach the energy required to fuse. According to the Maxwell–Boltzmann distribution, some of the particles will reach the required energies at much lower average temperatures. Because the energy released by the reaction is much greater than what it takes to start it, even a small number of reactions can heat surrounding fuel until it fuses as well. In 1944, Enrico Fermi calculated the D-T reaction would be self-sustaining at about .

Materials heated beyond a few tens of thousand degrees ionize into their electrons and nuclei, producing a gas-like state of matter known as plasma. According to the ideal gas law, like any hot gas, plasma has an internal pressure and thus wants to expand. For a fusion reactor, the challenge is to keep the plasma contained; any known substance would melt at these temperatures. But because a plasma is electrically conductive, it is subject to electric and magnetic fields. In a magnetic field, the electrons and nuclei orbit around the magnetic field lines, confining them to the area defined by the field.

A simple confinement system can be made by placing a tube inside the open core of a solenoid. The tube can be evacuated and then filled with the requisite gas and heated until it becomes a plasma. The plasma naturally wants to expand outwards to the walls of the tube, as well as move along it, towards the ends. The solenoid creates magnetic field lines running down the center of the tube, and the plasma particles orbit these lines, preventing their motion towards the sides. Unfortunately, this arrangement would not confine the plasma along the "length" of the tube, and the plasma would be free to flow out the ends.

The obvious solution to this problem is to bend the tube around into a torus (a ring or donut) shape. Motion towards the sides remains constrained as before, and while the particles remain free to move along the lines, in this case, they will simply circulate around the long axis of the tube. But, as Fermi pointed out, when the solenoid is bent into a ring, the electrical windings would be closer together on the inside than the outside. This would lead to an uneven field across the tube, and the fuel will slowly drift out of the center. Since the electrons and ions would drift in opposite directions, this would lead to a charge separation and electrostatic forces that would eventually overwhelm the magnetic force. Some additional force needs to counteract this drift, providing long-term "confinement".

Spitzer's key concept in the stellarator design is that the drift that Fermi noted could be canceled out through the physical arrangement of the vacuum tube. In a simple torus, particles on the inside edge of the tube, where the field was stronger, would drift up, while those on the outside would drift down (or vice versa). However, if the particle were made to alternate between the inside and outside of the tube, the drifts would cancel out. The cancellation is not perfect, leaving some net drift, but basic calculations suggested drift would be lowered enough to confine plasma long enough to heat it sufficiently.

Spitzer's suggestion for doing this was simple. Instead of a normal torus, the device would essentially be cut in half to produce two half-tori. They would then be joined with two straight sections between the open ends. The key was that they were connected to alternate ends so that the right half of one of the tori was connected to the left of the other. The resulting design resembled a figure-8 when viewed from above. Because the straight tubes could not pass through each other, the design did not lay flat, the tori at either end had to be tilted. This meant the drift cancellation was further reduced, but again, calculations suggested the system would work.

To understand how the system works to counteract drift, consider the path of a single particle in the system starting in one of the straight sections. If that particle is perfectly centered in the tube, it will travel down the center into one of the half-tori, exit into the center of the next tube, and so on. This particle will complete a loop around the entire reactor without leaving the center. Now consider another particle traveling parallel to the first, but initially located near the inside wall of the tube. In this case, it will enter the "outside" edge of the half-torus and begin to drift down. It exits that section and enters the second straight section, still on the inside edge of that tube. However, because the tubes are crossed, when it reaches the second half-torus it enters it on the "inside" edge. As it travels through this section it drifts back up.

This effect would reduce one of the primary causes of drift in the machine, but there were others to consider as well. Although the ions and electrons in the plasma would both circle the magnetic lines, they would do so in opposite directions, and at very high rotational speeds. This leads to the possibility of collisions between particles circling different lines of force as they circulate through the reactor, which due to purely geometric reasons, causes the fuel to slowly drift outward. This process eventually causes the fuel to either collide with the structure or cause a large charge separation between the ions and electrons. Spitzer introduced the concept of a "divertor", a magnet placed around the tube that pulled off the very outer layer of the plasma. This would remove the ions before they drifted too far and hit the walls. It would also remove any heavier elements in the plasma.

Using "classical" calculations the rate of diffusion through collisions was low enough that it would be much lower than the drift due to uneven fields in a normal toroid. But studies in 1949 demonstrated much higher losses and became known as Bohm diffusion. Spitzer spent considerable effort considering this issue, and concluded that the anomalous rate being seen by Bohm was due to instability in the plasma, which he believed could be addressed.

Practical complications make the original figure-8 device less than ideal. This led to alternative designs and additions.

One of the major concerns is that the magnetic fields in the system will only properly confine a particle of a given mass traveling at a given speed. Particles traveling faster or slower will not circulate in the desired fashion. Particles with very low speeds (corresponding to low temperatures) are not be confined and can drift out to the tube walls. Those with too much energy may hit the outside walls of the curved sections. To address these concerns, Spitzer introduced the concept of a "divertor" that would connect to one of the straight sections. This was essentially a mass spectrometer that would remove particles that were moving too fast or too slow for proper confinement.

The physical limitation that the two straight sections cannot intersect means that the rotational transform within the loop is not a perfect 180 degrees, but typically closer to 135 degrees. This led to alternate designs in an effort to get the angle closer to 180. An early attempt was built into the Stellarator B-2, which placed both curved sections flat in relation to the ground, but at different heights. The formerly straight sections had additional curves inserted, two sections of about 45 degrees, so they now formed extended S-shapes. This allowed them to route around each other while being perfectly symmetrical in terms of angles.

A better solution to the need to rotate the particles was introduced in the Stellarator B-64 and B-65. These eliminated the cross-over and flattened the device into an oval, or as they referred to it, a racetrack. The rotation of the particles was introduced by placing a new set of magnetic coils on the half-torus on either end, the "corkscrew windings". The field from these coils mixes with the original confinement fields to produce a mixed field that rotates the lines of force through 180 degrees. This made the mechanical design of the reactor much simpler, but in practice, it was found that the mixed field was very difficult to produce in a perfectly symmetrical fashion.

Unlike the z-pinch designs being explored in the UK and other US labs, the stellarator has no induced electrical current within the plasma - at a macroscopic level, the plasma is neutral and unmoving, in spite of the individual particles within it rapidly circulating. In pinch machines, and the later tokamaks, the current itself is one of the primary methods of heating the plasma. In the stellarator, no such natural heating source is present.

Early stellarator designs used a system similar to those in the pinch devices to provide the initial heating to bring the gas to plasma temperatures. This consisted of a single set of windings from a transformer, with the plasma itself forming the secondary set. When energized with a pulse of current, the particles in the region are rapidly energized and begin to move. This brings additional gas into the region, quickly ionizing the entire mass of gas. This concept was referred to as "ohmic heating" because it relied on the resistance of the gas to create heat, in a fashion not unlike a conventional resistance heater. As the temperature of the gas increases, the conductivity of the plasma improves. This makes the ohmic heating process less and less effective, and this system is limited to temperatures of about 1 million kelvins.

To heat the plasma to higher temperatures, a second heat source was added, the "magnetic pumping" system. This consisted of radio-frequency source fed through a coil spread along the vacuum chamber. The frequency is chosen to be similar to the natural frequency of the particles around the magnetic lines of force, the "cyclotron frequency". This causes the particles in the area to gain energy, which causes them to orbit in a wider radius. Since other particles are orbiting their own lines nearby, at a macroscopic level, this change in energy appears as an increase in pressure. According to the ideal gas law, this results in an increase in temperature. Like the ohmic heating, this process also becomes less efficient as the temperature increases, but is still capable of creating very high temperatures. When the frequency is deliberately set close to that of the ion circulation, this is known as "ion-cycloron resonance heating", although this name is not widely used.

There are several ways to heat the plasma (which must be done before ignition can occur).



Several different configurations of stellarator exist, including:

The goal of magnetic confinement devices is to minimise energy transport across a magnetic field. Toroidal devices are relatively successful because the magnetic properties seen by the particles are averaged as they travel around the torus. The strength of the field seen by a particle, however, generally varies, so that some particles will be trapped by the mirror effect. These particles will not be able to average the magnetic properties so effectively, which will result in increased energy transport. In most stellarators, these changes in field strength are greater than in tokamaks, which is a major reason that transport in stellarators tends to be higher than in tokamaks.

University of Wisconsin electrical engineering Professor David Anderson and research assistant John Canik proved in 2007 that the Helically Symmetric eXperiment (HSX) can overcome this major barrier in plasma research. The HSX is the first stellarator to use a quasisymmetric magnetic field. The team designed and built the HSX with the prediction that quasisymmetry would reduce energy transport. As the team's latest research showed, that is exactly what it does. "This is the first demonstration that quasisymmetry works, and you can actually measure the reduction in transport that you get," says Canik.

The newer Wendelstein 7-X in Germany was designed to be close to omnigeneity (a property of the magnetic field such that the mean radial drift is zero), which is a necessary but not sufficient condition for quasisymmetry; that is, all quasisymmetric magnetic fields are omnigenous, but not all omnigenous magnetic fields are quasisymmetric.





</doc>
<doc id="29592" url="https://en.wikipedia.org/wiki?curid=29592" title="SLA">
SLA

SLA may refer to:





</doc>
<doc id="29593" url="https://en.wikipedia.org/wiki?curid=29593" title="SYSTRAN">
SYSTRAN

SYSTRAN, founded by Dr. Peter Toma in 1968, is one of the oldest machine translation companies. SYSTRAN has done extensive work for the United States Department of Defense and the European Commission. 

SYSTRAN provides the technology for Yahoo! Babel Fish among others. It was used by Google's language tools until 2007. SYSTRAN is used by the Dashboard Translation widget in OS X.

Commercial versions of SYSTRAN can run on Microsoft Windows (including Windows Mobile), Linux, and Solaris. Historically, SYSTRAN systems used Rule-based machine translation (RbMT) technology. With the release of SYSTRAN Server 7 in 2010, SYSTRAN implemented a hybrid rule-based/Statistical machine translation (SMT) technology which was the first of its kind in the marketplace.

, the company had 59 employees of whom 26 are computational experts and 15 computational linguists. The number of employees decreased from 70 in 2006 to 59 in 2008.

With its origin in the Georgetown machine translation effort, SYSTRAN was one of the few machine translation systems to survive the major decrease of funding after the ALPAC Report of the mid-1960s. The company was established in La Jolla in California to work on translation of Russian to English text for the United States Air Force during the Cold War. Large numbers of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio. The quality of the translations, although only approximate, was usually adequate for understanding content.

The company was sold in 1986 to the Gachot family, based in Paris, and is now traded publicly on the French stock exchange. Its company headquarters is in Paris, while its U.S. headquarters is still in La Jolla.

During the dot-com boom, the international language industry started a new era, and SYSTRAN entered into agreements with a number of translation integrators, the most successful of these being WorldLingo.

In 2014, the company was acquired by CSLi (Korea).

Most of SYSTRAN's revenue comes from a few customers. 57.1% comes from the 10 main customers and the three largest customers account for 10.9%, 8.9%, and 8.9% of its revenues, respectively. Revenues had been declining in the early 2000s: 10.2 million euros in 2004, 10.1 million euros in 2005, 9.3 million euros in 2006, 8.8 million euros in 2007, and 7.6 million euros in 2008, before seeing a rebound in 2009 with 8.6 million euros.

The following is a list of the source and target languages with which SYSTRAN works. Many of the pairs are to or from English or French.



</doc>
<doc id="29594" url="https://en.wikipedia.org/wiki?curid=29594" title="Stephen I of Hungary">
Stephen I of Hungary

Stephen I, also known as King Saint Stephen (; ; ; 975 – 15 August 1038 AD), was the last Grand Prince of the Hungarians between 997 and 1000 or 1001, and the first King of Hungary from 1000 or 1001 until his death in 1038. The year of his birth is uncertain, but many details of his life suggest that he was born in or after 975 in Esztergom. At his birth, he was given the pagan name Vajk. The date of his baptism is unknown. He was the only son of Grand Prince Géza and his wife, Sarolt, who was descended from the prominent family of the "gyulas". Although both of his parents were baptized, Stephen was the first member of his family to become a devout Christian. He married Gisela of Bavaria, a scion of the imperial Ottonian dynasty.

After succeeding his father in 997, Stephen had to fight for the throne against his relative, Koppány, who was supported by large numbers of pagan warriors. He defeated Koppány mainly with the assistance of foreign knights, including Vecelin, Hont and Pázmány, but also with help from native lords. He was crowned on 25 December 1000 or 1 January 1001 with a crown sent by Pope Sylvester II. In a series of wars against semi-independent tribes and chieftainsincluding the Black Hungarians and his uncle, Gyula the Youngerhe unified the Carpathian Basin. He protected the independence of his kingdom by forcing the invading troops of Conrad II, Holy Roman Emperor, to withdraw from Hungary in 1030.

Stephen established at least one archbishopric, six bishoprics and three Benedictine monasteries; thus the Church in Hungary developed independently of the archbishops of the Holy Roman Empire. He encouraged the spread of Christianity with severe punishments for ignoring Christian customs. His system of local administration was based on counties organized around fortresses and administered by royal officials. Hungary, which enjoyed a lasting period of peace during his reign, became a preferred route for pilgrims and merchants traveling between Western Europe and the Holy Land or Constantinople.

He survived all of his children. He died on 15 August 1038 and was buried in his new basilica, built in Székesfehérvár and dedicated to the Holy Virgin. His death caused civil wars which lasted for decades. He was canonized by Pope Gregory VII, together with his son, Emeric, and Bishop Gerard of Csanád, in 1083. Stephen is a popular saint in Hungary and the neighboring territories. In Hungary, his feast day (celebrated on 20 August) is also a public holiday commemorating the foundation of the state.

Stephen's birth date is uncertain because it was not recorded in contemporaneous documents. Hungarian and Polish chronicles written centuries later give three different years: 967, 969 and 975. The unanimous testimony of his three late 11th-century or early 12th-century hagiographies and other Hungarian sources, which state that Stephen was "still an adolescent" in 997, substantiate the reliability of the later year (975). Stephen's "Lesser Legend" adds that he was born in Esztergom, which implies that he was born after 972 because his father, Géza, Grand Prince of the Hungarians, chose Esztergom as royal residence around that year. Géza promoted the spread of Christianity among his subjects by force, but never ceased worshipping pagan gods. Both his son's "Greater Legend" and the nearly contemporaneous Thietmar of Merseburg described Géza as a cruel monarch, suggesting that he was a despot who mercilessly consolidated his authority over the rebellious Hungarian lords.

Hungarian chronicles agree that Stephen's mother was Sarolt, daughter of Gyula, a Hungarian chieftain with jurisdiction either in Transylvania or in the wider region of the confluence of the rivers Tisza and Maros. Many historiansincluding Pál Engel and Gyula Kristópropose that her father was identical with "Gylas", who had been baptized in Constantinople around 952 and "remained faithful to Christianity", according to Byzantine chronicler John Skylitzes. However, this identification is not unanimously accepted; historian György Györffy states that it was not Sarolt's father, but his younger brother, who was baptized in the Byzantine capital. In contrast with all Hungarian sources, the "Polish-Hungarian Chronicle" and later Polish sources state that Stephen's mother was Adelhaid, an otherwise unknown sister of Duke Mieszko I of Poland, but the reliability of this report is not accepted by modern historians.

Stephen was born as Vajk, a name derived from the Turkic word "baj", meaning "hero", "master", "prince" or "rich". Stephen's "Greater Legend" narrates that he was baptized by the saintly Bishop Adalbert of Prague, who stayed in Géza's court several times between 983 and 994. However, Saint Adalbert's nearly contemporaneous "Legend", written by Bruno of Querfurt, does not mention this event. Accordingly, the date of Stephen's baptism is unknown: Györffy argues that he was baptized soon after birth, while Kristó proposes that he only received baptism just before his father's death in 997.

Stephen's official hagiography, written by Bishop Hartvic and sanctioned by Pope Innocent III, narrates that he "was fully instructed in the knowledge of the grammatical art" in his childhood. This implies that he studied Latin, though some scepticism is warranted as few kings of this era were able to write. His two other late 11th-century hagiographies do not mention any grammatical studies, stating only that he "was brought up by receiving an education appropriate for a little prince". Kristó says that the latter remark only refers to Stephen's physical training, including his participation in hunts and military actions. According to the "Illuminated Chronicle", one of his tutors was a Count Deodatus from Italy, who later founded a monastery in Tata.

According to Stephen's legends, Grand Prince Géza convoked an assembly of the Hungarian chieftains and warriors when Stephen "ascended to the first stage of adolescence", at the age of 14 or 15. Géza nominated Stephen as his successor and all those present took an oath of loyalty to the young prince. Györffy also writes, without identifying his source, that Géza appointed his son to rule the "Nyitra ducate" around that time. Slovak historians, including Ján Steinhübel and Ján Lukačka, accept Györffy's view and propose that Stephen administered Nyitra (now Nitra, Slovakia) from around 995.

Géza arranged Stephen's marriage, to Gisela, daughter of Henry II, Duke of Bavaria, in or after 995. This marriage established the first family link between a Hungarian ruler and a Western European ruling house, as Gisela was closely related to the Ottonian dynasty of Holy Roman Emperors. According to popular tradition preserved in the Scheyern Abbey in Bavaria, the ceremony took place at the Scheyern castle and was celebrated by Saint Adalbert. Gisela was accompanied to her new home by Bavarian knights, many of whom received land grants from her husband and settled in Hungary, helping to strengthen Stephen's military position. Györffy writes that Stephen and his wife "presumably" settled in Nyitra after their marriage.

Grand Prince Géza died in 997. Stephen convoked an assembly at Esztergom where his supporters declared him grand prince. Initially, he only controlled the northwestern regions of the Carpathian Basin; the rest of the territory was still dominated by tribal chieftains. Stephen's ascension to the throne was in line with the principle of primogeniture, which prescribed that a father was succeeded by his son. On the other hand, it contradicted the traditional idea of seniority, according to which Géza should have been succeeded by the most senior member of the Árpád dynasty, which was Koppány at that time. Koppány, who held the title Duke of Somogy, had for many years administered the regions of Transdanubia south of Lake Balaton.

Koppány proposed to Géza's widow, Sarolt, in accordance with the pagan custom of levirate marriage. He also announced his claim to the throne. Although it is not impossible that Koppány had already been baptized, in 972, most of his supporters were pagans, opponents of the Christianity represented by Stephen and his predominantly German retinue. A charter of 1002 for the Pannonhalma Archabbey writes of a war between "the Germans and the Hungarians" when referring to the armed conflicts between Stephen and Koppány. Even so, Györffy says that "Oszlar" ("Alan"), "Besenyő" ("Pecheneg"), "Kér" and other place names, referring to ethnic groups or Hungarian tribes in Transdanubia around the supposed borders of Koppány's duchy, suggest that significant auxiliary units and groups of Hungarian warriorswho had been settled there by Grand Prince Gézafought in Stephen's army.

Kristó states that the entire conflict between Stephen and Koppány was only a feud between two members of the Árpád dynasty, with no effect on other Hungarian tribal leaders. Koppány and his troops invaded the northern regions of Transdanubia, took many of Stephen's forts and plundered his lands. Stephen, who according to the "Illuminated Chronicle" "was for the first time girded with his sword", placed the brothers Hont and Pázmány at the head of his own guard and nominated Vecelin to lead the royal army. The latter was a German knight who had come to Hungary in the reign of Géza. Hont and Pázmány were, according to Simon of Kéza's "Gesta Hunnorum et Hungarorum" and the "Illuminated Chronicle", "knights of Swabian origin" who settled in Hungary either under Géza or in the first years of Stephen's reign. On the other hand, Lukačka and other Slovak historians say that Hont and Pázmány were "Slovak" noblemen who had joined Stephen during his rule in Nyitra.

Koppány was besieging Veszprém when he was informed of the arrival of Stephen's army. In the ensuing battle, Stephen won a decisive victory over his enemies. Koppány was killed on the battlefield. His body was quartered and its parts were displayed at the gates of the forts of Esztergom, Győr, Gyulafehérvár (Alba Iulia, Romania) and Veszprém in order to threaten all of those who were conspiring against the young monarch.

Stephen occupied Koppány's duchy and granted large estates to his own partisans. He also prescribed that Koppány's former subjects were to pay tithes to the Pannonhalma Archabbey, according to the deed of the foundation of this monastery which has been preserved in a manuscript containing interpolations. The same document declares that "there were no other bishoprics and monasteries in Hungary" at that time. On the other hand, the nearly contemporary Bishop Thietmar of Merseburg stated that Stephen "established bishoprics in his kingdom" before being crowned king. If the latter report is valid, the dioceses of Veszprém and Győr are the most probable candidates, according to historian Gábor Thoroczkay.

By ordering the display of one part of Koppány's quartered corpse in Gyulafehérvár, the seat of his maternal uncle, Gyula the Younger, Stephen asserted his claim to reign all lands dominated by Hungarian lords. He also decided to strengthen his international status by adopting the title of king. However, the exact circumstances of his coronation and its political consequences are subject to scholarly debate.

Thietmar of Merseburg writes that Stephen received the crown "with the favour and urging" of Emperor Otto III (r. 996–1002), implying that Stephen accepted the Emperor's suzerainty before his coronation. On the other hand, all of Stephen's legends emphasize that he received his crown from Pope Sylvester II (r. 999–1003). Kristó and other historians point out that Pope Sylvester and Emperor Otto were close allies, which implies that both reports are valid: Stephen "received the crown and consecration" from the Pope, but not without the Emperor's consent. Around 75 years after the coronation, Pope Gregory VII (r. 1075–1085), who claimed suzerainty over Hungary, declared that Stephen had "offered and devotedly surrendered" Hungary "to Saint Peter" (that is to the Holy See). In a contrasting report, Stephen's "Greater Legend" states that the King offered Hungary to the Virgin Mary. Modern historiansincluding Pál Engel, and Miklós Molnárwrite that Stephen always asserted his sovereignty and never accepted papal or imperial suzerainty. For instance, none of his charters were dated according to the years of the reign of the contemporary emperors, which would have been the case if he had been their vassal. Furthermore, Stephen declared in the preamble to his "First Book of Laws" that he governed his realm "by the will of God".

The exact date of Stephen's coronation is unknown. According to later Hungarian tradition, he was crowned on the first day of the second millennium, which may refer either to 25 December 1000 or to 1 January 1001. Details of Stephen's coronation preserved in his "Greater Legend" suggest that the ceremony, which took place in Esztergom or Székesfehérvár followed the rite of the coronation of the German kings. Accordingly, Stephen was anointed with consecrated oil during the ceremony. Stephen's portrait, preserved on his royal cloak from 1031, shows that his crown, like the Holy Roman Emperor's diadem, was a hoop crown decorated with gemstones.

Besides his crown, Stephen regarded a spear with a flag as an important symbol of his sovereignty. For instance, his first coins bear the inscription LANCEA REGIS ("the king's spear") and depict an arm holding a spear with flag. According to the contemporaneous Adémar de Chabannes, a spear had been given to Stephen's father by Emperor Otto III as a token of Géza's right to "enjoy the most freedom in the possession of his country". Stephen is styled in various ways"Ungarorum rex" ("king of the Hungarians"), "Pannoniorum rex" ("king of the Pannonians") or "Hungarie rex" ("king of Hungary")in his charters.

Although Stephen's power did not rely on his coronation, the ceremony granted him the internationally accepted legitimacy of a Christian monarch who ruled his realm "by the Grace of God". All his legends testify that he established an archbishopric with its see in Esztergom shortly after his coronation. This act ensured that the Church in Hungary became independent of the prelates of the Holy Roman Empire. The earliest reference to an archbishop of Esztergom, named Domokos, has been preserved in the deed of foundation of the Pannonhalma Archabbey from 1002. According to historian Gábor Thoroczkay, Stephen also established the Diocese of Kalocsa in 1001. Stephen invited foreign priests to Hungary to evangelize his kingdom. Associates of the late Adalbert of Prague, including Radla and Astrik, arrived in Hungary in the first years of his reign. The presence of an unnamed "Archbishop of the Hungarians" at the synod of 1007 of Frankfurt and the consecration of an altar in Bamberg in 1012 by Archbishop Astrik show that Stephen's prelates maintained a good relationship with the clergy of the Holy Roman Empire.

The transformation of Hungary into a Christian state was one of Stephen's principal concerns throughout his reign. Although the Hungarians' conversion had already begun in his father's reign, it was only Stephen who systematically forced his subjects to give up their pagan rituals. His legislative activity was closely connected with Christianity. For example, his "First Book of Laws" from the first years of his reign includes several provisions prescribing the observance of feast days and the confession before death. His other laws protected property rights and the interests of widows and orphans, or regulated the status of serfs.

Many Hungarian lords refused to accept Stephen's suzerainty even after his coronation. The new King first turned against his own uncle, Gyula the Younger, whose realm "was most wide and rich", according to the "Illuminated Chronicle". Stephen invaded Transylvania and seized Gyula and his family around 1002 or in 1003. The contemporary "Annals of Hildesheim" adds that Stephen converted his uncle's "country to the Christian faith by force" after its conquest. Accordingly, historians date the establishment of the Diocese of Transylvania to this period. If the identification, proposed by Kristó, Györffy and other Hungarian historians, of Gyula with one Prokuiwho was Stephen's uncle according to Thietmar of Merseburgis valid, Gyula later escaped from captivity and fled to Bolesław I the Brave, Duke of Poland (r. 992–1025).

About a hundred years later, the chronicler Gallus Anonymus also made mention of armed conflicts between Stephen and Boleslav, stating that the latter "defeated the Hungarians in battle and made himself master of all their lands as far as the Danube". Györffy says that the chronicler's report refers to the occupation of the valley of the river Moravaa tributary of the Danubeby the Poles in the 1010s. On the other hand, the "Polish-Hungarian Chronicle" states that the Polish duke occupied large territories north of the Danube and east of the Morava as far as Esztergom in the early 11th century. According to Steinhübel, the latter source proves that a significant part of the lands that now form Slovakia were under Polish rule between 1002 and 1030. In contrast with the Slovak historian, Györffy writes that this late chronicle "in which one absurdity follows another" contradicts all facts known from 11th-century sources.

The "Illuminated Chronicle" narrates that Stephen "led his army against Kean, Duke of the Bulgarians and Slavs whose lands are by their natural position most strongly fortified" following the occupation of Gyula's country. According to a number of historians, including Zoltán Lenkey and Gábor Thoroczkay, Kean was the head of a small state located in the southern parts of Transylvania and Stephen occupied his country around 1003. Other historians, including Györffy, say that the chronicle's report preserved the memory of Stephen's campaign against Bulgaria in the late 1010s.

Likewise, the identification of the "Black Hungarians"who were mentioned by Bruno of Querfurt and Adémar de Chabannes among the opponents of Stephen's proselytizing policyis uncertain. Györffy locates their lands to the east of the river Tisza; while Thoroczkay says they live in the southern parts of Transdanubia. Bruno of Querfurt's report of the Black Hungarians' conversion by force suggests that Stephen conquered their lands at the latest in 1009 when "the first mission of Saint Peter"a papal legate, Cardinal Azoarrived in Hungary. The latter attended the meeting in Győr where the royal charter determining the borders of the newly established Bishopric of Pécs was issued on August 23, 1009.

The Diocese of Eger was also set up around 1009. According to Thoroczkay, "it is very probable" that the bishopric's establishment was connected with the conversion of the Kabarsan ethnic group of Khazar origin and their chieftain. The head of the Kabarswho was either Samuel Aba or his father married Stephen's unnamed younger sister on this occasion. The Aba clan was the most powerful among the native families who joined Stephen and supported him in his efforts to establish a Christian monarchy. The reports by Anonymus, Simon of Kéza and other Hungarian chroniclers of the Bár-Kalán, Csák and other 13th-century noble families descending from Hungarian chieftains suggest that other native families were also involved in the process.

Stephen set up a territory-based administrative system, establishing counties. Each county, headed by a royal official known as a count or "ispán", was an administrative unit organized around a royal fortress. Most fortresses were earthworks in this period, but the castles at Esztergom, Székesfehérvár and Veszprém were built of stone. Forts serving as county seats also became the nuclei of Church organization. The settlements developing around them, where markets were held on each Sunday, were important local economic centers.

Stephen's brother-in-law, Henry II, became King of Germany in 1002 and Holy Roman Emperor in 1013. Their friendly relationship ensured that the western borders of Hungary experienced a period of peace in the first decades of the 11th century. Even when Henry II's discontented brother, Bruno, sought refuge in Hungary in 1004, Stephen preserved the peace with Germany and negotiated a settlement between his two brothers-in-law. Around 1009, he gave his younger sister in marriage to Otto Orseolo, Doge of Venice (r. 1008–1026), a close ally of the Byzantine Emperor, Basil II (r. 976–1025), which suggests that Hungary's relationship with the Byzantine Empire was also peaceful. On the other hand, the alliance between Hungary and the Holy Roman Empire brought her into a war with Poland lasting from around 1014 until 1018. The Poles occupied the Hungarian posts along the river Morava. Györffy and Kristó write that a Pecheneg incursion into Transylvania, the memory of which has been preserved in Stephen's legends, also took place in this period, because the Pechenegs were close allies of the Polish duke's brother-in-law, Grand Prince Sviatopolk I of Kiev (r. 1015–1019).

Poland and the Holy Roman Empire concluded the Peace of Bautzen in January 1018. Later in the same year, 500 Hungarian horsemen accompanied Boleslav of Poland to Kiev, suggesting that Hungary had been included in the peace treaty. The historian Ferenc Makk says that the Peace of Bautzen obliged Boleslav to hand over all the territories he had occupied in the Morava valley to Stephen. According to Leodvin, the first known Bishop of Bihar (r. 1050 – 1060), Stephen allied with the Byzantines and led a military expedition to assist them against "barbarians" in the Balkan Peninsula. The Byzantine and Hungarian troops jointly took "Cesaries" which Györffy identifies as the present-day town of Ohrid. Leodvin's report suggests that Stephen joined the Byzantines in the war ending with their conquest of Bulgaria in 1018. However, the exact date of his expedition is uncertain. Györffy argues that it was only in the last year of the war that Stephen led his troops against the Bulgarians.

Bishop Leodvin wrote that Stephen collected relics of a number of saints in "Cesaries" during his campaign in the Balkans, including Saint George and Saint Nicholas. He donated them to his new triple-naved basilica dedicated to the Holy Virgin in Székesfehérvár, where he also set up a cathedral chapter and his new capital. His decision was influenced by the opening, in 1018 or 1019, of a new pilgrimage route that bypassed his old capital, Esztergom. The new route connected Western Europe and the Holy Land through Hungary. Stephen often met the pilgrims, contributing to the spread of his fame throughout Europe. Abbot Odilo of Cluny, for example, wrote in a letter to Stephen that "those who have returned from the shrine of our Lord" testify to the king's passion "towards the honour of our divine religion". Stephen also established four hostels for pilgrims in Constantinople, Jerusalem, Ravenna and Rome.

In addition to pilgrims, merchants often used the safe route across Hungary when travelling between Constantinople and Western Europe. Stephen's legends refer to 60 wealthy Pechenegs who travelled to Hungary, but were attacked by Hungarian border guards. The king sentenced his soldiers to death in order to demonstrate his determination to preserve internal peace. Regular minting of coinage began in Hungary in the 1020s. Stephen's silver dinars bearing the inscriptions STEPHANUS REX ("King Stephen") and REGIA CIVITAS ("royal city") were popular in contemporary Europe, as demonstrated by counterfeited copies unearthed in Sweden.

Stephen convinced some pilgrims and merchants to settle in Hungary. Gerard, a Benedictine monk who arrived in Hungary from the Republic of Venice between 1020 and 1026, initially planned to continue his journey to the Holy Land, but decided to stay in the country after his meeting with the king. Stephen also established a number of Benedictine monasteriesincluding the abbeys at Pécsvárad, Zalavár and Bakonybélin this period.

The "Long Life of Saint Gerard" mentions Stephen's conflict with Ajtony, a chieftain in the region of the river Maros. Many historians date their clash to the end of the 1020s, although Györffy and other scholars put it at least a decade earlier. The conflict arose when Ajtony, who "had taken his power from the Greeks", according to Saint Gerard's legend, levied tax on the salt transported to Stephen on the river. The king sent a large army led by Csanád against Ajtony, who was killed in battle. His lands were transformed into a Hungarian county and the king set up a new bishopric at Csanád (Cenad, Romania), Ajtony's former capital, which was renamed after the commander of the royal army. According to the "Annales Posonienses", the Venetian Gerard was consecrated as the first bishop of the new diocese in 1030.

Stephen's brother-in-law, Emperor Henry, died on 13 July 1024. He was succeeded by a distant relative, Conrad II (r. 1024–1039), who adopted an offensive foreign policy. Conrad II expelled Doge Otto Orseolothe husband of Stephen's sisterfrom Venice in 1026. He also persuaded the Bavarians to proclaim his own son, Henry, as their duke in 1027, although Stephen's son, Emeric had a strong claim to the Duchy of Bavaria through his mother. Emperor Conrad planned a marriage alliance with the Byzantine Empire and dispatched one of his advisors, Bishop Werner of Strasbourg, to Constantinople. In the autumn of 1027, the bishop seemingly travelled as a pilgrim, but Stephen, who had been informed of his actual purpose, refused to let him enter into his country. Conrad II's biographer Wipo of Burgundy narrated that the Bavarians incited skirmishes along the common borders of Hungary and the Holy Roman Empire in 1029, causing a rapid deterioration in relations between the two countries.

Emperor Conrad personally led his armies to Hungary in June 1030 and plundered the lands west of the River Rába. However, according to the "Annals of Niederalteich", the emperor, suffering from consequences of the scorched earth tactics used by the Hungarian army, returned to Germany "without an army and without achieving anything, because the army was threatened by starvation and was captured by the Hungarians at Vienna". Peace was restored after Conrad had ceded the lands between the rivers Lajta and Fischa to Hungary in the summer of 1031.

Stephen's biographer, Hartvic, narrates that the King, whose children died one by one in infancy, "restrained the grief over their death by the solace on account of the love of his surviving son", Emeric. However, Emeric was wounded in a hunting accident and died in 1031. After the death of his son, the elderly King could never "fully regain his former health", according to the "Illuminated Chronicle". Kristó writes that the picture, which has been preserved in Stephen's legends, of the king keeping the vigils and washing the feet of paupers, is connected with Stephen's last years, following the death of his son.

Emeric's death jeopardized his father's achievements in establishing a Christian state, because Stephen's cousin, Vazulwho had the strongest claim to succeed himwas suspected of an inclination towards paganism. According to the "Annals of Altaich" Stephen disregarded his cousin's claim and nominated his sister's son, the Venetian Peter Orseolo, as his heir. The same source adds that Vazul was captured and blinded, and his three sons, Levente, Andrew and Béla, were expelled from Hungary. Stephen's legends refer to an unsuccessful attempt upon the elderly king's life by members of his court. According to Kristó, the legends refer to a plot in which Vazul participated and his mutilation was a punishment for this act. That Vazul's ears were filled with molten lead was only recorded in later sources, including the "Illuminated Chronicle".

In the view of some historians, provisions in Stephen's "Second Book of Laws" on the "conspiracy against the king and the kingdom" imply that the book was promulgated after Vazul's unsuccessful plot against Stephen. However, this view has not been universally accepted. Györffy states that the law book was issued, not after 1031, but around 1009. Likewise, the authenticity of the decree on tithes is debated: according to Györffy, it was issued during Stephen's reign, but Berend, Laszlovszky and Szakács argue that it "might be a later addition".

Stephen died on 15 August 1038. He was buried in the basilica of Székesfehérvár. His reign was followed by a long period of civil wars, pagan uprisings and foreign invasions. The instability ended in 1077 when Ladislaus, a grandson of Vazul, ascended the throne.

Stephen married Gisela, a daughter of Duke Henry the Wrangler of Bavaria, who was a nephew of Otto I, Holy Roman Emperor. Gisela's mother was Gisela of Burgundy, a member of the Welf dynasty. Born around 985, Gisela was younger than her husband, whom she survived. She left Hungary in 1045 and died as Abbess of the Niedernburg Abbey in Passau in Bavaria around 1060.

Although the "Illuminated Chronicle" states that Stephen "begot many sons", only two of them, Otto and Emeric, are known by name. Otto, who was named after Otto III, seems to have been born before 1002. He died as a child.

Emeric, who received the name of his maternal uncle, Emperor Henry II, was born around 1007. His "Legend" from the early 12th century describes him as a saintly prince who preserved his chastity even during his marriage. According to Györffy, Emeric's wife was a kinswoman of the Byzantine Emperor Basil II. His premature death led to the series of conflicts leading to Vazul's blinding and civil wars.

The following family tree presents Stephen's ancestors and his relatives who are mentioned in the article.

"*A Khazar, Pecheneg or Volga Bulgarian lady."<br>"**Györffy writes that she may have been a member of the Bulgarian Cometopuli dynasty."<br>"***Samuel Aba might have been the son of Stephen's sister instead of her husband."

Stephen has always been considered one of the most important statesmen in the history of Hungary. His main achievement was the establishment of a Christian state that ensured that the Hungarians survived in the Carpathian Basin, in contrast to the Huns, Avars and other peoples who had previously controlled the same territory. As Bryan Cartledge emphasizes, Stephen also gave his kingdom "forty years of relative peace and sound but unspectacular rule".

His successors, including those descended from Vazul, were eager to emphasize their devotion to Stephen's achievements. Although Vazul's son, Andrew I of Hungary, secured the throne due to a pagan uprising, he prohibited pagan rites and declared that his subjects should "live in all things according to the law which King St. Stephen had taught them", according to the 14th-century "Illuminated Chronicle". In medieval Hungary, communities that claimed a privileged status or attempted to preserve their own "liberties" often declared that the origin of their special status was to be attributed to King Saint Stephen. An example is a 1347 letter from the people of Táp telling the king about their grievances against the Pannonhalma Archabbey and stating that the taxes levied upon them by the abbot contradicted "the liberty granted to them in the time of King Saint Stephen".

Stephen's cult emerged after the long period of anarchy characterizing the rule of his immediate successors. However, there is no evidence that Stephen became an object of veneration before his canonization. For instance, the first member of the royal family to be named after him, Stephen II, was born in the early 12th century.

Stephen's canonization was initiated by Vazul's grandson, King Ladislaus I of Hungary, who had consolidated his authority by capturing and imprisoning his cousin, Solomon. According to Bishop Hartvic, the canonization was "decreed by apostolic letter, by order of the Roman see", suggesting that the ceremony was permitted by Pope Gregory VII. The ceremony started at Stephen's tomb, where on 15 August 1083 masses of believers began three days of fasting and praying. Legend tells that Stephen's coffin could not be opened until King Ladislaus held Solomon in captivity at Visegrád. The opening of Stephen's tomb was followed by the occurrence of healing miracles, according to Stephen's legends. Historian Kristó attributes the healings either to mass psychosis or deception. Stephen's legends also say that his "balsam-scented" remains were elevated from the coffin, which was filled with "rose-colored water", on 20 August. On the same day, Stephen's son, Emeric, and the bishop of Csanád, Gerard, were also canonized.

Stephen's first legend, the so-called "Greater Legend", was written between 1077 and 1083. It provided an idealized portrait of the king, one who dedicated himself and his kingdom to the Virgin Mary. However, Stephen's "Lesser Legend"composed around 1100, under King Colomanemphasized Stephen's severity. A third legend, also composed during King Coloman's reign by Bishop Hartvic, was based on the two existing legends. Sanctioned in 1201 by Pope Innocent III, Hartvic's work served as Stephen's official legend. Gábor Klaniczay wrote that Stephen's legends "opened a new chapter in the legends of holy rulers as a genre", suggesting that a monarch can achieve sainthood through actively using his royal powers. Stephen was the first triumphant "miles Christi" ("Christ's soldier") among the canonized monarchs. He was also a "confessor king", one who had not suffered martyrdom, whose cult was sanctioned, in contrast with earlier holy monarchs.

Stephen's cult spread beyond the borders of Hungary. Initially, he was primarily venerated in Scheyern and Bamberg, in Bavaria, but his relics were also taken to Aachen, Cologne, Montecassino and Namur. Upon the liberation of Buda from the Ottoman Turks, Pope Innocent XI expanded King Saint Stephen's cult to the entire Roman Catholic Church in 1686, and declared 2 September his feast day. As the feast of Saint Joachim was moved, in 1969, from 16 August, the day immediately following the day of Stephen's death, Stephen's feast was moved to that date. Stephen is venerated as the patron saint of Hungary, and regarded as the protector of kings, masons, stonecutters, stonemasons and bricklayers, and also of children suffering from severe illnesses. His canonization was recognized by Ecumenical Patriarch Bartholomew I of Constantinople in 2000. In the calendar of the Hungarian Catholic Church, Stephen's feast is observed on 20 August, the day on which his relics were translated. In addition, a separate feast day (30 May) is dedicated to his "Holy Dexter".

Stephen's intact dexter, or right hand (), became the subject of a cult. A cleric named Mercurius stole it, but it was discovered on 30 May 1084 in Bihar County. The theft of sacred relics, or "furta sacra", had by that time become a popular topic of saints' biographies. Bishop Hartvic described the discovery of Stephen's right hand in accordance with this tradition, referring to adventures and visions. An abbey erected in Bihar County (now Sâniob, Romania) was named after and dedicated to the veneration of the Holy Dexter.

The Holy Dexter was kept for centuries in the Szentjobb Abbey, except during the Mongol invasion of 1241 and 1242, when it was transferred to Ragusa (now Dubrovnik, Croatia). The relic was then taken to Székesfehérvár around 1420. Following the Ottoman occupation of the central territories of the Kingdom of Hungary in the mid-16th century, it was guarded in many places, including Bosnia, Ragusa and Vienna. It was returned to Hungary in 1771, when Queen Maria Theresa donated it to the cloister of the Sisters of Loreto in Buda. It was kept in Buda Castle's St. Sigismund Chapel between around 1900 and 1944, in a cave near Salzburg in 1944 and 1945, and again by the Sisters of Loreto in Buda, between 1945 and 1950. Finally, since 1950, the Holy Dexter has been in St. Stephen's Basilica in Budapest. An annual procession celebrating the relic was instituted in 1938, and continued until 1950, when the procession was forbidden by the Communist government. It was resumed in 1988.

According to Stephen's "Greater Legend", the king "himself compiled a book for his son on moral education". This work, now known as "Admonitions" or "De institutione morum", was preserved in manuscripts written in the Late Middle Ages. Although scholars debate whether it can actually be attributed to the king or a cleric, most of them agree that it was composed in the first decades of the 11th century.

The "Admonitions" argues that kingship is inseparably connected with the Catholic faith. Its author emphasized that a monarch is required to make donations to the Church and regularly consult his prelates, but is entitled to punish clergymen who do wrong. One of its basic ideas was that a sovereign has to cooperate with the "pillars of his rule", meaning the prelates, aristocrats, "ispáns" and warriors.

King St Stephen has been a popular theme in Hungarian poetry since the end of the 13th century. The earliest poems were religious hymns which portrayed the holy king as the apostle of the Hungarians. Secular poetry, especially poems written for his feast day, followed a similar pattern, emphasizing Stephen's role as the first king of Hungary. Poets described Stephen as the symbol of national identity and independence and of the ability of the Hungarian nation to survive historical cataclysms during the Communist regime between 1949 and 1989.

A popular hymn, still sung in the churches, was first recorded in the late . It hails King St. Stephen as "radiant star of Hungarians". Ludwig van Beethoven composed his "King Stephen Overture" for the inauguration of the Hungarian theatre in Pest in 1812. According to musician James M. Keller, "[t]he descending unisons that open the "King Stephen Overture" would seem to prefigure the opening of the "Ninth Symphony" [a]nd then a later theme, introduced by flutes and clarinets, seems almost to be a of the famous "Ode "To Joy"" melody of the Ninth Symphony's finale". Hungarian composer Ferenc Erkel named his last complete opera from 1885, "István király" ("King Stephen"), after him. In 1938, Zoltán Kodály wrote a choral piece titled "Ének Szent István Királyhoz" ("Hymn to King Stephen"). In 1983, Levente Szörényi and János Bródy composed a rock opera—"István, a király" ("Stephen, the King")—about the early years of his reign. Seventeen years later, in 2000, Szörényi composed a sequel called "Veled, Uram!" ("You, Sir").





</doc>
<doc id="29598" url="https://en.wikipedia.org/wiki?curid=29598" title="Sprite">
Sprite

Sprite typically refers to:


Sprite or SPRITE may also refer to:










</doc>
<doc id="29602" url="https://en.wikipedia.org/wiki?curid=29602" title="San Giovanni di Posada">
San Giovanni di Posada

San Giovanni di Posada (Latin: Portus Luguidonis or Portus Liquidonis) is a "frazione" and small village in Sardinia, Italy, on the Tyrrhenian coast of the island, in the territory of the "comune" of Posada.

Formerly known as Marina di Posada, it underwent rebuilding in the 1970s as an elegant residential village for holidays.

Its history goes back to the Roman harbour (named "Portus Luguidonis" - presumably located in the little bay in front of the ancient church of St. John), from where the Romans entered inner Sardinia. Through this harbour passed all the goods to or from Rome, but all the cargo was carried by small and light ships directed to Olbia (some 50km north), where bigger ships would have trafficked with Ostia. Traffic was supposedly intense, Sardinia bearing the "sobriquet" "the granary of Rome".

In the immediate surroundings, it is supposed there was a temple in honour of Feronia, an Etruscan deity, goddess of the waters; this would prove the presence of Etruscans in this area at the time of Nuragici people. A similar cult of Feronia is reported on the Italian mainland at least in two places: in Fiano Romano (near Rome), and in Terracina, some 120km south of Rome.

It is one of the main tourist destinations of Sardinia, has a long beach (more than 15km of white sand) and a system of rivers of biological importance. A part of this territory is going to be formally protected in the near future with the creation of a nature park ("Parco Fluviale").



</doc>
<doc id="29603" url="https://en.wikipedia.org/wiki?curid=29603" title="Scott Joplin">
Scott Joplin

Scott Joplin ( or November 24, 1868 – April 1, 1917) was an African-American composer and pianist. Joplin achieved fame for his ragtime compositions and was dubbed the "King of Ragtime". During his brief career, he wrote 44 original ragtime pieces, one ragtime ballet, and two operas. One of his first, and most popular pieces, the "Maple Leaf Rag", became ragtime's first and most influential hit, and has been recognized as the archetypal rag.

Joplin was born into a musical family of railway laborers in Texarkana, Arkansas, and developed his musical knowledge with the help of local teachers. Joplin grew up in Texarkana, where he formed a vocal quartet, and taught mandolin and guitar. During the late 1880s he left his job as a laborer with the railroad, and travelled around the American South as an itinerant musician. He went to Chicago for the World's Fair of 1893, which played a major part in making ragtime a national craze by 1897.

Joplin moved to Sedalia, Missouri, in 1894 and earned a living as a piano teacher; there he taught future ragtime composers Arthur Marshall, Scott Hayden and Brun Campbell. Joplin began publishing music in 1895, and publication of his "Maple Leaf Rag" in 1899 brought him fame. This piece had a profound influence on subsequent writers of ragtime. It also brought the composer a steady income for life, though Joplin did not reach this level of success again and frequently had financial problems. In 1901 Joplin moved to St. Louis, where he continued to compose and publish music, and regularly performed in the St. Louis community. The score to his first opera "A Guest of Honor" was confiscated in 1903 with his belongings because of a non-payment of bills, and is now considered lost. He continued to compose and publish music, and in 1907 moved to New York City to find a producer for a new opera. He attempted to go beyond the limitations of the musical form that made him famous, without much monetary success. His second opera, "Treemonisha", was not received well at its partially staged performance in 1915.

In 1916, Joplin descended into dementia as a result of syphilis. He was admitted to a mental institution in January 1917, and died there three months later at the age of 48. Joplin's death is widely considered to mark the end of ragtime as a mainstream music format, and in the next several years it evolved with other styles into stride, jazz, and eventually big band swing. His music was rediscovered and returned to popularity in the early 1970s with the release of a million-selling album recorded by Joshua Rifkin. This was followed by the Academy Award-winning 1973 film "The Sting" that featured several of his compositions including "The Entertainer". The opera "Treemonisha" was finally produced in full to wide acclaim in 1972. In 1976, Joplin was posthumously awarded a Pulitzer Prize.
According to author Edward A. Berlin, "One tenacious myth tells us that Joplin was born in Texarkana, Texas, on November 24, 1868. The location is easily dispensed with: Texarkana was not established until 1873." But, based on a letter discovered by musicologist John Tennison in 2015 in the December 19, 1856 edition of the "Times-Picayune," it is clear that Texarkana was established as a place-name at least as early as 1856. Consequently, it appears possible that Joplin, born 12 years later, could have been born in Texarkana. Despite evidence to support such a conclusion, some insist that Joplin was born in Linden, Texas, either in late 1867 or early 1868. He was the second of six children (the others being Monroe, Robert, William, Myrtle, and Ossie) born to Giles Joplin, an ex-slave from North Carolina, and Florence Givens, a freeborn African-American woman from Kentucky.

The Joplins subsequently moved to Texarkana, Arkansas, where Giles worked as a laborer for the railroad and Florence was a cleaner. Joplin's father had played the violin for plantation parties in North Carolina, and his mother sang and played the banjo. Joplin was given a rudimentary musical education by his family and from the age of seven, he was allowed to play the piano while his mother cleaned.

At some point in the early 1880s, Giles Joplin left the family for another woman. His wife Florence struggled to support her children through domestic work. Biographer Susan Curtis speculated that the mother's support of Joplin's musical education was critical to the parents' separation. Joplin's father wanted the boy to pursue practical employment that would supplement the family income.

According to a family friend, the young Joplin was serious and ambitious, studying music and playing the piano after school. While a few local teachers aided him, he received most of his music education from Julius Weiss, a German-born American Jewish music professor who had immigrated to Texas in the late 1860s and was employed as music tutor to a prominent local business family. Weiss, as described by "San Diego Jewish World" writer Eric George Tauber, "was no stranger to [receiving] race hatred... As a German Jew, he was often slapped and called a “Christ-killer." Nevertheless, Weiss had studied music at university in Germany and was listed in town records as a "Professor of music." Impressed by Joplin's talent, and realizing his family's dire straits, Weiss taught him free of charge. He tutored the 11-year-old Joplin until the boy was 16, during which time Weiss introduced him to folk and classical music, including opera. Weiss helped Joplin appreciate music as an "art as well as an entertainment," and helped his mother acquire a used piano. According to Weiss' wife, Lottie, Joplin never forgot Weiss. In his later years, after achieving fame as a composer, Joplin sent his former teacher "...gifts of money when he was old and ill," until Weiss died. At the age of 16, Joplin performed in a vocal quartet with three other boys in and around Texarkana, also playing piano. In addition he taught guitar and mandolin.

In the late 1880s, having performed at various local events as a teenager, Joplin chose to give up work as a laborer with the railroad and left Texarkana to become a traveling musician. Little is known about his movements at this time, although he is recorded in Texarkana in July 1891 as a member of the Texarkana Minstrels in a performance that happened to be raising money for a monument to Jefferson Davis, President of the Southern Confederacy. He soon discovered, however, that there were few opportunities for black pianists. Churches and brothels were among the few options for steady work. Joplin played pre-ragtime 'jig-piano' in various red-light districts throughout the mid-South, and some claim he was in Sedalia and St. Louis during this time.

In 1893 Joplin was in Chicago for the World's Fair. While in Chicago, he formed his first band playing cornet and began arranging music for the group to perform. Although the World's Fair minimized the involvement of African-Americans, black performers still came to the saloons, cafés and brothels that lined the fair. The exposition was attended by 27 million Americans and had a profound effect on many areas of American cultural life, including ragtime. Although specific information is sparse, numerous sources have credited the Chicago World Fair with spreading the popularity of ragtime. Joplin found that his music, as well as that of other black performers, was popular with visitors. By 1897 ragtime had become a national craze in American cities, and was described by the "St. Louis Dispatch" as "...a veritable call of the wild, which mightily stirred the pulses of city bred people."

In 1894 Joplin arrived in Sedalia, Missouri. At first, Joplin stayed with the family of Arthur Marshall, at the time a 13-year-old boy but later one of Joplin's students and a rag-time composer in his own right. There is no record of Joplin having a permanent residence in the town until 1904, as Joplin was making a living as a touring musician.

There is little precise evidence known about Joplin's activities at this time, although he performed as a solo musician at dances and at the major black clubs in Sedalia, the Black 400 club and the Maple Leaf Club. He performed in the Queen City Cornet Band, and his own six-piece dance orchestra. A tour with his own singing group, the Texas Medley Quartet, gave him his first opportunity to publish his own compositions and it is known that he went to Syracuse, New York and Texas. Two businessmen from New York published Joplin's first two works, the songs "Please Say You Will", and "A Picture of her Face" in 1895. Joplin's visit to Temple, Texas enabled him to have three pieces published there in 1896, including the "Great Crush Collision March", which commemorated a planned train crash on the Missouri–Kansas–Texas Railroad on September 15 that he may have witnessed. The March was described by one of Joplin's biographers as a "special... early essay in ragtime." While in Sedalia he was teaching piano to students who included future ragtime composers Arthur Marshall, Brun Campbell, and Scott Hayden. In turn, Joplin enrolled at the George R. Smith College, where he apparently studied "...advanced harmony and composition." The College records were destroyed in a fire in 1925, and biographer Edward A. Berlin notes that it was unlikely that a small college for African-Americans would be able to provide such a course.

In 1899, Joplin married Belle, the sister-in-law of collaborator Scott Hayden. Although there were hundreds of rags in print by the time the "Maple Leaf Rag" was published, Joplin was not far behind. His first published rag, "Original Rags", had been completed in 1897, the same year as the first ragtime work in print, the "Mississippi Rag" by William Krell. The "Maple Leaf Rag" was likely to have been known in Sedalia before its publication in 1899; Brun Campbell claimed to have seen the manuscript of the work in around 1898. The exact circumstances that led to the Maple Leaf Rag's publication are unknown, and a number of versions of the event contradict each other. After several unsuccessful approaches to publishers, Joplin signed a contract on August 10, 1899 with John Stillwell Stark, a retailer of musical instruments who later became his most important publisher. The contract stipulated that Joplin would receive a 1% royalty on all sales of the rag, with a minimum sales price of 25 cents. With the inscription "To the Maple Leaf Club" prominently visible along the top of at least some editions, it is likely that the rag was named after the Maple Leaf Club, although there is no direct evidence to prove the link, and there were many other possible sources for the name in and around Sedalia at the time.
There have been many claims about the sales of the "Maple Leaf Rag", for example that Joplin was the first musician to sell 1 million copies of a piece of instrumental music. Joplin's first biographer, Rudi Blesh wrote that during its first six months the piece sold 75,000 copies, and became "...the first great instrumental sheet music hit in America." However, research by Joplin's later biographer Edward A. Berlin demonstrated that this was not the case; the initial print-run of 400 took one year to sell, and under the terms of Joplin's contract with a 1% royalty would have given Joplin an income of $4 (or approximately $ at current prices). Later sales were steady, and would have given Joplin an income that would have covered his expenses. In 1909, estimated sales would have given him an income of $600 annually (approximately $ in current prices).

The "Maple Leaf Rag" did serve as a model for the hundreds of rags to come from future composers, especially in the development of classic ragtime. After the publication of the "Maple Leaf Rag", Joplin was soon being described as "King of rag time writers", not least by himself on the covers of his own work, such as "The Easy Winners" and "Elite Syncopations".

After the Joplins moved to St. Louis in early 1900, they had a baby daughter who died only a few months after birth. Joplin's relationship with his wife was difficult, as she had no interest in music. They eventually separated and then divorced. About this time, Joplin collaborated with Scott Hayden in the composition of four rags. It was in St. Louis that Joplin produced some of his best-known works, including "The Entertainer", "March Majestic", and the short theatrical work "The Ragtime Dance".

In June 1904, Joplin married Freddie Alexander of Little Rock, Arkansas, the young woman to whom he had dedicated "The Chrysanthemum". She died on September 10, 1904, of complications resulting from a cold, ten weeks after their wedding. Joplin's first work copyrighted after Freddie's death, "Bethena", was described by one biographer as "...an enchantingly beautiful piece that is among the greatest of ragtime waltzes."

During this time, Joplin created an opera company of 30 people and produced his first opera "A Guest of Honor" for a national tour. It is not certain how many productions were staged, or even if this was an all-black show or a racially mixed production. During the tour, either in Springfield, Illinois, or Pittsburg, Kansas, someone associated with the company stole the box office receipts. Joplin could not meet the company's payroll or pay for its lodgings at a theatrical boarding house. It is believed that the score for "A Guest of Honor" was lost and perhaps destroyed because of non-payment of the company's boarding house bill.

In 1907, Joplin moved to New York City, which he believed was the best place to find a producer for a new opera. After his move to New York, Joplin met Lottie Stokes, whom he married in 1909. In 1911, unable to find a publisher, Joplin undertook the financial burden of publishing "Treemonisha" himself in piano-vocal format. In 1915, as a last-ditch effort to see it performed, he invited a small audience to hear it at a rehearsal hall in Harlem. Poorly staged and with only Joplin on piano accompaniment, it was "a miserable failure" to a public not ready for "crude" black musical forms—so different from the European grand opera of that time. The audience, including potential backers, was indifferent and walked out. Scott writes that "after a disastrous single performance ... Joplin suffered a breakdown. He was bankrupt, discouraged, and worn out." He concludes that few American artists of his generation faced such obstacles: ""Treemonisha" went unnoticed and unreviewed, largely because Joplin had abandoned commercial music in favor of art music, a field closed to African Americans." In fact, it was not until the 1970s that the opera received a full theatrical staging.

In 1914, Joplin and Lottie self-published his "Magnetic Rag" as the Scott Joplin Music Company, which he had formed the previous December. Biographer Vera Brodsky Lawrence speculates that Joplin was aware of his advancing deterioration due to syphilis and was "...consciously racing against time." In her sleeve notes on the 1992 Deutsche Grammophon release of "Treemonisha" she notes that he "...plunged feverishly into the task of orchestrating his opera, day and night, with his friend Sam Patterson standing by to copy out the parts, page by page, as each page of the full score was completed."

By 1916, Joplin was suffering from tertiary syphilis and a resulting descent into insanity. In January 1917, he was admitted to Manhattan State Hospital, a mental institution. He died there on April 1 of syphilitic dementia at the age of 49 and was buried in a pauper's grave that remained unmarked for 57 years. His grave at Saint Michaels Cemetery in East Elmhurst was finally given a marker in 1974, the year "The Sting", which showcased his music, won for Best Picture at the Oscars.

The combination of classical music, the musical atmosphere present around Texarkana (including work songs, gospel hymns, spirituals and dance music) and Joplin's natural ability have been cited as contributing significantly to the invention of a new style that blended African-American musical styles with European forms and melodies, and first became celebrated in the 1890s: ragtime.

When Joplin was learning the piano, serious musical circles condemned ragtime because of its association with the vulgar and inane songs "...cranked out by the tune-smiths of Tin Pan Alley." As a composer Joplin refined ragtime, elevating it above the low and unrefined form played by the "...wandering honky-tonk pianists... playing mere dance music" of popular imagination. This new art form, the classic rag, combined Afro-American folk music's syncopation and 19th-century European romanticism, with its harmonic schemes and its march-like tempos. In the words of one critic, "Ragtime was basically... an Afro-American version of the polka, or its analog, the Sousa-style march." With this as a foundation, Joplin intended his compositions to be played exactly as he wrote them – without improvisation. Joplin wrote his rags as "classical" music in miniature form in order to raise ragtime above its "cheap bordello" origins and produced work that opera historian Elise Kirk described as, "... more tuneful, contrapuntal, infectious, and harmonically colorful than any others of his era."

Some speculate that Joplin's achievements were influenced by his classically trained German music teacher Julius Weiss, who may have brought a polka rhythmic sensibility from the old country to the 11-year old Joplin. As Curtis put it, "The educated German could open up the door to a world of learning and music of which young Joplin was largely unaware."

Joplin's first and most significant hit, the "Maple Leaf Rag", was described as the archetype of the classic rag, and influenced subsequent rag composers for at least 12 years after its initial publication thanks to its rhythmic patterns, melody lines, and harmony, though with the exception of Joseph Lamb, they generally failed to enlarge upon it.

The opera's setting is a former slave community in an isolated forest near Joplin's childhood town Texarkana in September 1884. The plot centers on an 18-year-old woman Treemonisha who is taught to read by a white woman, and then leads her community against the influence of conjurers who prey on ignorance and superstition. Treemonisha is abducted and is about to be thrown into a wasps' nest when her friend Remus rescues her. The community realizes the value of education and the liability of their ignorance before choosing her as their teacher and leader.

Joplin wrote both the score and the libretto for the opera, which largely follows the form of European opera with many conventional arias, ensembles and choruses. In addition the themes of superstition and mysticism evident in "Treemonisha" are common in the operatic tradition, and certain aspects of the plot echo devices in the work of the German composer Richard Wagner (of which Joplin was aware). A sacred tree Treemonisha sits beneath recalls the tree that Siegmund takes his enchanted sword from in "Die Walküre", and the retelling of the heroine's origins echos aspects of the opera "Siegfried". In addition, African-American folk tales also influence the story—the wasp nest incident is similar to the story of Br'er Rabbit and the briar patch.

"Treemonisha" is not a ragtime opera—because Joplin employed the styles of ragtime and other black music sparingly, using them to convey "racial character," and to celebrate the music of his childhood at the end of the 19th century. The opera has been seen as a valuable record of rural black music from late 19th century re-created by a "skilled and sensitive participant."

Berlin speculates about parallels between the plot and Joplin's own life. He notes that Lottie Joplin (the composer's third wife) saw a connection between the character Treemonisha's wish to lead her people out of ignorance, and a similar desire in the composer. In addition, it has been speculated that Treemonisha represents Freddie, Joplin's second wife, because the date of the opera's setting was likely to have been the month of her birth.

At the time of the opera's publication in 1911, the "American Musician and Art Journal" praised it as, "...an entirely new form of operatic art." Later critics have also praised the opera as occupying a special place in American history, with its heroine, "...a startlingly early voice for modern civil rights causes, notably the importance of education and knowledge to African American advancement." Curtis's conclusion is similar: "In the end, "Treemonisha" offered a celebration of literacy, learning, hard work, and community solidarity as the best formula for advancing the race." Berlin describes it as a "...fine opera, certainly more interesting than most operas then being written in the United States," but later states that Joplin's own libretto showed the composer, "...was not a competent dramatist," with the book not up to the quality of the music.

As Rick Benjamin, the founder and director of the Paragon Ragtime Orchestra, found out, Joplin succeeded in performing "Treemonisha" for paying audiences in Bayonne, New Jersey, in 1913. On 6 December 2011, the centenary of the Joplin piano score's publication, New World Records released an entirely new recording of "Treemonisha". August 1984 saw the German premiere of "Treemonisha" at the Stadttheater Gießen.<ref name="Robbins/Marco">Nancy R. Ping Robbins, Guy Marco: "Scott Joplin: A Guide to Research". Routledge, 2014, p. 299</ref> Another performance in Germany, falsely labelling itself as the German premiere, occurred on 25 April 2015 at the Staatsschauspiel Dresden under direction and choreography of .

Joplin's skills as a pianist were described in glowing terms by a Sedalia newspaper in 1898, and fellow ragtime composers Arthur Marshall and Joe Jordan both said that he played the instrument well. However, the son of publisher John Stark stated that Joplin was a rather mediocre pianist and that he composed on paper, rather than at the piano. Artie Matthews recalled the "delight" the St. Louis players took in outplaying Joplin.

While Joplin never made an audio recording, his playing is preserved on seven piano rolls for use in mechanical player pianos. All seven were made in 1916. Of these, the six released under the Connorized label show evidence of significant editing to correct the performance to strict rhythm and add embellishments, probably by the staff musicians at Connorized. Berlin theorizes that by the time Joplin reached St. Louis, he may have experienced discoordination of the fingers, tremors, and an inability to speak clearly—all symptoms of the syphilis that took his life in 1917. Biographer Blesh described the second roll recording of "Maple Leaf Rag" on the UniRecord label from June 1916 as "...shocking... disorganized and completely distressing to hear." While there is disagreement among piano-roll experts as to how much of this is due to the relatively primitive recording and production techniques of the time, Berlin notes that the "Maple Leaf Rag" roll was likely to be the truest record of Joplin's playing at the time. The roll, however, may not reflect his abilities earlier in life.

Joplin and his fellow ragtime composers rejuvenated American popular music, fostering an appreciation for African-American music among European-Americans by creating exhilarating and liberating dance tunes. "Its syncopation and rhythmic drive gave it a vitality and freshness attractive to young urban audiences indifferent to Victorian proprieties ... Joplin's ragtime expressed the intensity and energy of a modern urban America."

Joshua Rifkin, a leading Joplin recording artist, wrote, "A pervasive sense of lyricism infuses his work, and even at his most high-spirited, he cannot repress a hint of melancholy or adversity ... He had little in common with the fast and flashy school of ragtime that grew up after him." Joplin historian Bill Ryerson adds that, "In the hands of authentic practitioners like Joplin, ragtime was a disciplined form capable of astonishing variety and subtlety ... Joplin did for the rag what Chopin did for the mazurka. His style ranged from tones of torment to stunning serenades that incorporated the bolero and the tango." Biographer Susan Curtis wrote that Joplin's music had helped to "revolutionise American music and culture" by removing Victorian restraint.

Composer and actor Max Morath found it striking that the vast majority of Joplin's work did not enjoy the popularity of the "Maple Leaf Rag", because while the compositions were of increasing lyrical beauty and delicate syncopation they remained obscure and unheralded during his lifetime. Joplin apparently realized that his music was ahead of its time: As music historian Ian Whitcomb mentions that Joplin, "...opined that "Maple Leaf Rag" would make him 'King of Ragtime Composers' but he also knew that he would not be a pop hero in his own lifetime. 'When I'm dead twenty-five years, people are going to recognize me,' he told a friend." Just over thirty years later he was recognized, and later historian Rudi Blesh wrote a large book about ragtime, which he dedicated to the memory of Joplin.

Although he was penniless and disappointed at the end of his life, Joplin set the standard for ragtime compositions and played a key role in the development of ragtime music. And as a pioneer composer and performer, he helped pave the way for young black artists to reach American audiences of both races. After his death, jazz historian Floyd Levin noted: "Those few who realized his greatness bowed their heads in sorrow. This was the passing of the king of all ragtime writers, the man who gave America a genuine native music."

The home Joplin rented In St. Louis 1900-1903 was recognized as a National Historic Landmark in 1976 and was saved from destruction by the local African American community. In 1983, the Missouri Department of Natural Resources made it the first state historic site in Missouri dedicated to the African American heritage. At first it focused entirely on Joplin and ragtime music, ignoring the urban milieu which shaped his musical compositions. A newer heritage project has expanded coverage to include the more complex social history of black urban migration and the transformation of a multi-ethnic neighborhood to the contemporary community. Part of this diverse narrative now includes coverage of uncomfortable topics of racial oppression, poverty, sanitation, prostitution, and sexually transmitted diseases.

After his death in 1917, Joplin's music and ragtime in general waned in popularity as new forms of musical styles, such as jazz and novelty piano, emerged. Even so, jazz bands and recording artists such as Tommy Dorsey in 1936, Jelly Roll Morton in 1939 and J. Russel Robinson in 1947 released recordings of Joplin compositions. "Maple Leaf Rag" was the Joplin piece found most often on 78 rpm records.

In the 1960s, a small-scale reawakening of interest in classical ragtime was underway among some American music scholars such as Trebor Tichenor, William Bolcom, William Albright and Rudi Blesh. Audiophile Records released a two record set, "The Complete Piano Works of Scott Joplin, The Greatest of Ragtime Composers", performed by Knocky Parker, in 1970.

In 1968, Bolcom and Albright interested Joshua Rifkin, a young musicologist, in the body of Joplin's work. Together, they hosted an occasional ragtime-and-early-jazz evening on WBAI radio. In November 1970, Rifkin released a recording called "" on the classical label Nonesuch. It sold 100,000 copies in its first year and eventually became Nonesuch's first million-selling record. The "Billboard" "Best-Selling Classical LPs" chart for September 28, 1974 has the record at number 5, with the follow-up "Volume 2" at number 4, and a combined set of both volumes at number 3. Separately both volumes had been on the chart for 64 weeks. In the top seven spots on that chart, six of the entries were recordings of Joplin's work, three of which were Rifkin's. Record stores found themselves for the first time putting ragtime in the classical music section. The album was nominated in 1971 for two Grammy Award categories: Best Album Notes and Best Instrumental Soloist Performance (without orchestra). Rifkin was also under consideration for a third Grammy for a recording not related to Joplin, but at the ceremony on March 14, 1972, Rifkin did not win in any category. He did a tour in 1974, which included appearances on BBC Television and a sell-out concert at London's Royal Festival Hall. In 1979, Alan Rich wrote in the magazine "New York" that by giving artists like Rifkin the opportunity to put Joplin's music on disk, Nonesuch Records "...created, almost alone, the Scott Joplin revival."

In January 1971, Harold C. Schonberg, music critic at "The New York Times", having just heard the Rifkin album, wrote a featured Sunday edition article entitled "Scholars, Get Busy on Scott Joplin!" Schonberg's call to action has been described as the catalyst for classical music scholars, the sort of people Joplin had battled all his life, to conclude that Joplin was a genius. Vera Brodsky Lawrence of the New York Public Library published a two-volume set of Joplin works in June 1971, entitled "The Collected Works of Scott Joplin", stimulating a wider interest in the performance of Joplin's music.

In mid-February 1973 under the direction of Gunther Schuller, The New England Conservatory Ragtime Ensemble recorded an album of Joplin's rags taken from the period collection "Standard High-Class Rags" called "Joplin: The Red Back Book". The album won a Grammy Award as Best Chamber Music Performance in that year, and went on to become "Billboard" magazine's Top Classical Album of 1974. The group subsequently recorded two more albums for Golden Crest Records: "More Scott Joplin Rags" in 1974 and "The Road From Rags To Jazz" in 1975.

In 1973, film producer George Roy Hill contacted Schuller and Rifkin separately, asking each man to write the score for a film project he was working on: "The Sting". Both men turned down the request because of previous commitments. Instead Hill found Marvin Hamlisch available, and brought him into the project as composer. Hamlisch lightly adapted Joplin's music for "The Sting", for which he won an Academy Award for Best Original Song Score and Adaptation on April 2, 1974. His version of "The Entertainer" reached number 3 on the "Billboard" Hot 100 and the American Top 40 music chart on May 18, 1974, prompting "The New York Times" to write, "The whole nation has begun to take notice." Thanks to the film and its score, Joplin's work became appreciated in both the popular and classical music world, becoming (in the words of music magazine "Record World"), the "classical phenomenon of the decade." Rifkin later said of the film soundtrack that Hamlisch lifted his piano adaptations directly from Rifkin's style and his band adaptations from Schuller's style. Schuller said Hamlisch, "...got the Oscar for music he didn't write (since it is by Joplin) and arrangements he didn't write, and 'editions' he didn't make. A lot of people were upset by that, but that's show biz!"

On October 22, 1971, excerpts from "Treemonisha" were presented in concert form at Lincoln Center with musical performances by Bolcom, Rifkin and Mary Lou Williams supporting a group of singers. Finally, on January 28, 1972, T.J. Anderson's orchestration of "Treemonisha" was staged for two consecutive nights, sponsored by the Afro-American Music Workshop of Morehouse College in Atlanta, with singers accompanied by the Atlanta Symphony Orchestra under the direction of Robert Shaw, and choreography by Katherine Dunham. Schonberg remarked in February 1972 that the "Scott Joplin Renaissance" was in full swing and still growing. In May 1975, "Treemonisha" was staged in a full opera production by the Houston Grand Opera. The company toured briefly, then settled into an eight-week run in New York on Broadway at the Palace Theatre in October and November. This appearance was directed by Gunther Schuller, and soprano Carmen Balthrop alternated with Kathleen Battle as the title character. An "original Broadway cast" recording was produced. Because of the lack of national exposure given to the brief Morehouse College staging of the opera in 1972, many Joplin scholars wrote that the Houston Grand Opera's 1975 show was the first full production.

1974 saw the Birmingham Royal Ballet under director Kenneth MacMillan create "Elite Syncopations", a ballet based on tunes by Joplin and other composers of the era. That year also brought the premiere by the Los Angeles Ballet of "Red Back Book", choreographed by John Clifford to Joplin rags from the collection of the same name, including both solo piano performances and arrangements for full orchestra.








</doc>
<doc id="29605" url="https://en.wikipedia.org/wiki?curid=29605" title="Syncopation">
Syncopation

In music, syncopation involves a variety of rhythms which are in some way unexpected which make part or all of a tune or piece of music off-beat. More simply, syncopation is a general term for "a disturbance or interruption of the regular flow of rhythm": a "placement of rhythmic stresses or accents where they wouldn't normally occur." The correlation of at least two sets of time intervals. Also known as an "Uneven movement from bar to bar".

Syncopation is used in many musical styles, especially dance music--"All dance music makes use of syncopation and it's often a vital element that helps tie the whole track together". In the form of a back beat, syncopation is used in virtually all contemporary popular music.

Syncopation can also occur when a strong harmony is placed on a weak beat, for instance when a 7th-chord is placed on the second beat of measure or a dominant is placed at the fourth beat of a measure. The latter frequently occurs in tonal cadences in 18th and early 19th century music and is the usual conclusion of any section.

A hemiola can also be seen as one straight measure in 3 with one long chord and one short chord and a syncope in the measure thereafter, with one short chord and one long chord. Usually, the last chord in a hemiola is a (bi-)dominant, and as such a strong harmony on a weak beat, hence a syncope.

Technically, "syncopation occurs when a temporary displacement of the regular metrical accent occurs, causing the emphasis to shift from a strong accent to a weak accent." "Syncopation is," however, "very simply, a deliberate disruption of the two- or three-beat stress pattern, most often by stressing an off-beat, or a note that is not on the beat."
In the following example, there are two points of syncopation where the third beats are carried over (sustained) from the second beats rather than missed. In the same way, the first beat of the second bar is carried over from the fourth beat of the first bar. 

Though syncopation may be highly complex, dense or complex looking rhythms often contain no syncopation. The following rhythm, though dense, stresses the regular downbeats, 1 & 4 (in ): 

However, whether it's a placed rest or an accented note, any point in a piece of music that moves your perspective of the downbeat is a point of syncopation because it's shifting where the strong and weak accents are built."

For example, in meters with even numbers of beats (, , etc.), the stress normally falls on the odd-numbered beats. If the even-numbered beats are stressed instead, the rhythm is syncopated. Accordingly, the former implies duple meter (<ins>1</ins>2<ins>1</ins>2) while the latter implies quadruple meter (1<ins>2</ins>3<ins>4</ins>).

The stress can shift by less than a whole beat so it falls on an off beat, as in the following example where the stress in the first bar is shifted back by an eighth note (or quaver) :

<score>\relative c' { d8 a'4 c e gis,8 a1 }</score>

Whereas the notes are expected to fall "on" the beat :

<score>\relative c' { d a' c e gis, a2. }</score>

Playing a note ever so slightly before, or after, a beat is another form of syncopation because this produces an unexpected accent :

<score>\relative c' { \partial 8 d8 a'4 c e gis,8 a(a1) }</score>

It can be helpful to think of a rhythm in eighth notes and count it as "1-and-2-and-3-and-4-and". In general emphasizing the "and" would be considered the off-beat.

Anticipated bass is a bass tone that comes syncopated shortly before the downbeat, which is used in Son montuno Cuban dance music. Timing can vary, but it usually falls on the 2+ as well as the 4 of the time, thus anticipating the third and first beats. This pattern is commonly known as the Afro-Cuban bass tumbao.

Richard Middleton suggests adding the concept of transformation to Narmour's prosodic rules which create rhythmic successions in order to explain or generate syncopations. "The syncopated pattern is heard 'with reference to', 'in light of', as a remapping of, its partner."
He gives examples of various types of syncopation: Latin, backbeat, and before-the-beat. First however, one may listen to the audio example of stress on the "strong" beats, where expected: 

This unsyncopated rhythm is shown in the first measure directly below:

The third measure depicts the syncopated rhythm in the following audio example in which the first and fourth beat are provided as expected, but the accent unexpectedly lands in between the second and third beats, creating a familiar "Latin rhythm" known as tresillo: 

The accent may be shifted from the first to the second beat in duple meter (and the third to fourth in quadruple), creating the backbeat rhythm familiar in rock drumming beatbox stereotypes:

Different crowds will "clap along" at concerts on either 1 & 3 or 2 & 4, as above.

The phrasing of "Satisfaction", a good example of syncopation, is derived here from its theoretic unsyncopated form, a repeated trochee (¯ ˘ ¯ ˘). A backbeat transformation is applied to "I" and "can't", and then a before-the-beat transformation is applied to "can't" and "no".

This demonstrates how each syncopated pattern may be heard as a remapping, "'with reference to'," or, "'in light of'," an unsyncopated pattern.

Syncopation has been an important element of European musical composition since at least the Middle Ages. Many Italian and French compositions of the music of the 14th-century Trecento make use of syncopation, as in of the following madrigal by Giovanni da Firenze. (See also hocket.)]Composers of the musical High Renaissance Venetian School, such as Giovanni Gabrieli (1557–1612), exploited syncopation in both their secular madrigals and instrumental pieces and also in their choral sacred works, such as the motet "Domine, Dominus noster":]Denis Arnold (1979, p. 93) says "the syncopations of this passage are of a kind which is almost a Gabrieli fingerprint, and they are typical of a general liveliness of rhythm common to Venetian music." The composer Igor Stravinsky (1959, p 91), no stranger to syncopation himself, spoke of "those marvellous rhythmic inventions" that feature in Gabrieli's music.

J.S. Bach and Handel used syncopated rhythms as an inherent part of their compositions. One of the best-known examples of syncopation in music from the Baroque era was the "Hornpipe" from Handel’s "Water Music" (1733). ]Christopher Hogwood (2005, p.37) describes the Hornpipe as “possibly the most memorable movement in the collection, combining instrumental brilliance and rhythmic vitality… Woven amongst the running quavers are the insistent off-beat syncopations that symbolise confidence for Handel.” Bach's Brandenburg Concerto No. 4 features striking deviations from the established rhythmic norm in its first and third movements. According to Malcolm Boyd (1993, p. 53), each ritornello section of the first movement, "is clinched with an "Epilog" of syncopated antiphony":] Boyd (1993, p. 85) also hears the coda to the third movement as "remarkable… for the way the rhythm of the initial phrase of the fugue subject is expressed… with the accent thrown on to the second of the two minims (now staccato).":]

Haydn, Mozart, Beethoven, and Schubert used syncopation to create variety especially in their symphonies. The opening movement of Beethoven's "Eroica" Symphony No. 3 exemplifies powerfully the uses of syncopation in a piece in triple time. After setting up a clear pattern of three beats to a bar at the outset, Beethoven disrupts it through syncopation in a number of ways:
(1) By displacing the rhythmic emphasis to a weak part of the beat, as in the first violin part in bars 7-9:]

Taruskin (2010, p. 658) describes here how "the first violins, entering immediately after the C sharp, are made palpably to totter for two bars."

(2) By placing accents on normally weak beats, as in bars 25-26 and 28-35 :]

This "long sequence of syncopated sforzandi" recurs later during the development section of this movement, in a passage that Antony Hopkins (1981, p. 75) describes as "a rhythmic pattern that rides roughshod over the properties of a normal three-in-a bar."
(3) By inserting silences (rests) at points where a listener might expect strong beats, in the words of George Grove (1896, p61), "nine bars of discords given fortissimo on the weak beats of the bar.":]





</doc>
<doc id="29607" url="https://en.wikipedia.org/wiki?curid=29607" title="Strategy">
Strategy

Strategy (from Greek στρατηγία "stratēgia", "art of troop leader; office of general, command, generalship") is a high-level plan to achieve one or more goals under conditions of uncertainty. In the sense of the "art of the general", which included several subsets of skills including "tactics", siegecraft, logistics etc., the term came into use in the 6th century AD in East Roman terminology, and was translated into Western vernacular languages only in the 18th century. From then until the 20th century, the word "strategy" came to denote "a comprehensive way to try to pursue political ends, including the threat or actual use of force, in a dialectic of wills" in a military conflict, in which both adversaries interact.

Strategy is important because the resources available to achieve these goals are usually limited. Strategy generally involves setting goals, determining actions to achieve the goals, and mobilizing resources to execute the actions. A strategy describes how the ends (goals) will be achieved by the means (resources). Strategy can be intended or can emerge as a pattern of activity as the organization adapts to its environment or competes. It involves activities such as strategic planning and strategic thinking.

Henry Mintzberg from McGill University defined strategy as a pattern in a stream of decisions to contrast with a view of strategy as planning,[4] while Henrik von Scheel defines the essence of strategy as the activities to deliver a unique mix of value – choosing to perform activities differently or to perform different activities than rivals. while Max McKeown (2011) argues that "strategy is about shaping the future" and is the human attempt to get to "desirable ends with available means". Dr. Vladimir Kvint defines strategy as "a system of finding, formulating, and developing a doctrine that will ensure long-term success if followed faithfully." Complexity theorists define strategy as the unfolding of the internal and external aspects of the organization that results in actions in a socio-economic context.

Professor Richard P. Rumelt described strategy as a type of problem solving in 2011. He wrote that good strategy has an underlying structure he called a "kernel". The kernel has three parts: 1) A "diagnosis" that defines or explains the nature of the challenge; 2) A "guiding policy" for dealing with the challenge; and 3) Coherent "actions" designed to carry out the guiding policy.
President Kennedy illustrated these three elements of strategy in his Cuban Missile Crisis Address to the Nation of 22 October 1962:

Rumelt wrote in 2011 that three important aspects of strategy include "premeditation, the anticipation of others' behavior, and the purposeful design of coordinated actions." He described strategy as solving a design problem, with trade-offs among various elements that must be arranged, adjusted and coordinated, rather than a plan or choice.

Strategy typically involves two major processes: "formulation" and "implementation". "Formulation" involves analyzing the environment or situation, making a diagnosis, and developing guiding policies. It includes such activities as strategic planning and strategic thinking. "Implementation" refers to the action plans taken to achieve the goals established by the guiding policy.

Bruce Henderson wrote in 1981 that: "Strategy depends upon the ability to foresee future consequences of present initiatives." He wrote that the basic requirements for strategy development include, among other factors: 1) extensive knowledge about the environment, market and competitors;
2) ability to examine this knowledge as an interactive dynamic system; and
3) the imagination and logic to choose between specific alternatives. Henderson wrote that strategy was valuable because of: "finite resources, uncertainty about an adversary's capability and intentions; the irreversible commitment of resources; necessity of coordinating action over time and distance; uncertainty about control of the initiative; and the nature of adversaries' mutual perceptions of each other."

In military theory, strategy is "the utilization during both peace and war, of all of the nation's forces, through large scale, long-range planning and development, to ensure security and victory" ("Random House Dictionary").

The father of Western modern strategic study, Carl von Clausewitz, defined military strategy as "the employment of battles to gain the end of war." B. H. Liddell Hart's definition put less emphasis on battles, defining strategy as "the art of distributing and applying military means to fulfill the ends of policy". Hence, both gave the pre-eminence to political aims over military goals. U.S. Naval War College instructor Andrew Wilson defined strategy as the "process by which political purpose is translated into military action."

Eastern military philosophy dates back much further, with examples such as "The Art of War" by Sun Tzu dated around 500 B.C.

Since 2005, William Eldridge Odom had argued that U.S. interests would be best served by an immediate withdrawal from Iraq, having called the 2003 invasion the worst strategic blunder in the history of U.S. foreign policy.

Modern business strategy emerged as a field of study and practice in the 1960s; prior to that time, the words "strategy" and "competition" rarely appeared in the most prominent management literature.
Alfred Chandler wrote in 1962 that: "Strategy is the determination of the basic long-term goals of an enterprise, and the adoption of courses of action and the allocation of resources necessary for carrying out these goals." Michael Porter defined strategy in 1980 as the "...broad formula for how a business is going to compete, what its goals should be, and what policies will be needed to carry out those goals" and the "...combination of the "ends" (goals) for which the firm is striving and the "means" (policies) by which it is seeking to get there."

Henry Mintzberg described five definitions of strategy in 1998:

In game theory, a "strategy" refers to the rules that a player uses to choose between the available actionable options. Every player in a non-trivial game has a set of possible strategies to use when choosing what moves to make.

A strategy may recursively look ahead and consider what actions can happen in each contingent state of the game—e.g. if the player takes action 1, then that presents the opponent with a certain situation, which might be good or bad, whereas if the player takes action 2 then the opponents will be presented with a different situation, and in each case the choices they make will determine their own future situation.

Strategies in game theory may be random (mixed) or deterministic (pure). Pure strategies can be thought of as a special case of mixed strategies, in which only probabilities 0 or 1 are assigned to actions.

Strategy based games generally require a player to think through a sequence of solutions to determine the best way to defeat the opponent.




</doc>
<doc id="29608" url="https://en.wikipedia.org/wiki?curid=29608" title="Saeed al-Ghamdi">
Saeed al-Ghamdi

Saeed Abdallah Ali Sulayman al-Ghamdi (, ) (November 21, 1979 – September 11, 2001) was one of four hijackers of United Airlines Flight 93 as part of the September 11 attacks.

Born in Saudi Arabia, Ghamdi left his home to fight in Chechnya after dropping out of college, but was reported to have diverted to Afghanistan to train in an al-Qaeda camp. It was reported he was chosen by Osama bin Laden to participate in terrorist attacks in the United States and arrived in the U.S. in June 2001. During his stay in the U.S., he quietly settled in Florida, planning out how the attacks would commence and training on flight simulators.

On September 11, 2001, it was reported he boarded United 93 and assisted in the hijacking of the plane, which was crashed into a field in the control of hijacker-pilot Ziad Jarrah in Shanksville, Pennsylvania, after the passengers attempted to retake control of the plane in an uprising.

Ghamdi was from the al Bahah province of Saudi Arabia, and shared the same tribal affiliation with fellow hijackers Ahmed al-Ghamdi, Hamza al-Ghamdi, and Ahmed al-Haznawi, although he was not related to either Ghamdi. He may have been in contact with the two Ghamdis and Haznawi as early as 1999. This group is noted as being some of the more religiously observant of the hijackers. Ghamdi spent time in al Qasim province, Saudi Arabia where he transferred to college but soon dropped out and ceased contact with his family. While there he probably associated with the radical Saudi cleric named Sulayman al-Alwan as several other future hijackers had.

Saeed later headed to Chechnya to participate in the conflict against the Russians. At this time, Chechen fighters were turning away additional foreigners, many of whom ended up in al-Qaeda camps in Afghanistan to train and await entry to Chechnya. Saeed ended up at the Al Farouq training camp, where he met Ahmed al-Nami, and the brothers Wail and Waleed al-Shehri. The four reportedly pledge themselves to Jihad in the Spring of 2000, in a ceremony presided over by Wail—who had dubbed himself "Abu Mossaeb al-Janubi" after one of Muhammad's companions.

Saeed was known to Tawfiq bin Attash who is thought to have convinced him to become a martyr. Saeed was at that time working as a security guard at Kandahar airport along with Waleed al-Shehri.

Some time late in 2000, Saeed traveled to the United Arab Emirates, where he purchased traveler's cheques presumed to have been paid for by Mustafa al-Hawsawi. Five other hijackers also passed through the UAE and purchased travellers cheques, including Majed Moqed, Wail al-Shehri, Hamza al-Ghamdi, Ahmed al-Haznawi and Ahmed al-Nami.

On November 13, 2000, another Saeed al-Ghamdi tried to obtain a visa to enter the United States, but was declined. Although the 9/11 Commission makes mention of him, there is no evidence he was associated with the hijackers.

In March 2001, Saeed was filmed in a farewell video that was later aired on al-Jazeera. In the video, many future 9/11 hijackers swear to become martyrs, although no details of the plot are revealed. Saeed referred to America as "the enemy", and is seen studying maps and flight manuals.

On June 12, 2001, Saeed al-Ghamdi applied for and received a second two-year US B-1/B-2 (tourist/business) visa in Jeddah, Saudi Arabia. His application was submitted by a local travel agency and processed through Visa Express, a controversial US visa program in Saudi Arabia which was discontinued the following year.

Arriving in the U.S. on June 27, 2001, with Fayez Banihammad, Saeed shared an apartment with Ahmed al-Nami in Delray Beach, Florida. Oddly, he listed the Naval Air Station in Pensacola, Florida, as his permanent address on his driver's license. He was one of 9 hijackers to open a SunTrust bank account with a cash deposit around June 2001.

According to al-Jazeera reporter Yosri Fouda's documentary "Top Secret: The Road to September 11", three weeks prior to the attacks Saeed is believed to have used the name 'Abdul Rahman' to send a message to Ramzi bin al-Shibh (who was posing as a girlfriend) online, in which he wrote 

On September 7, all four of Flight 93 hijackers flew from Fort Lauderdale to Newark International Airport aboard Spirit Airlines.

On the morning of September 11, 2001, Ghamdi boarded United Airlines Flight 93 without incident. Due to the flight's delay, the pilot and crew were notified of the previous hijackings that day, and were told to be on the alert. Within minutes, Flight 93 was hijacked as well.

At least two of the cell phone calls made by passengers indicate that all the hijackers they saw were wearing red bandanas. The calls also indicated that one of the men had tied a box around his torso, and claimed there was a bomb inside; it is not known which hijacker this was.

According to the , it appeared Saeed may have been at the controls of the flight when it crashed, although the 9/11 commission asserts that Ziad Jarrah was the pilot.

Passengers on the plane heard through phone calls the fates of the other hijacked planes. A failed passenger uprising resulted in the plane crashing into a field in Shanksville, Pennsylvania, killing everyone aboard.

On September 23, 2001, before the FBI had released the pictures of the hijackers, the BBC and "The Daily Telegraph" reported that a Saudi Airlines pilot named Saeed al-Ghamdi was furious that a name on the hijacker's list released by the FBI matched his own. CNN also showed a picture of the "living" Ghamdi as the hijacker. The man claimed CNN likely got his picture from a Flight Safety flying school in Florida he attended. "Der Spiegel" later investigated the claims of "living" hijackers by the BBC and discovered them to be cases of mistaken identity.

According to immigration records in the Philippines, someone named Saeed al-Ghamdi visited that country on at least 15 occasions in 2001, entering as a tourist. The last visit ended on August 6. This may have been a different person with the same name, as no other information is available. 

In June 2005 the Saudi government released a list (see al-Qaeda in the Arabian Peninsula) of 36 wanted (and alive) terrorists, one of whom was Salih Sa'id Al Batih al-Ghamdi. 9/11 conspiracy theorists quickly confused him with the hijacker Saeed al-Ghamdi.

He has been portrayed by Iraqi actor Lewis Alsamari in "United 93" and Shawn Ahmed in "Flight 93".




</doc>
<doc id="29611" url="https://en.wikipedia.org/wiki?curid=29611" title="Scripture (disambiguation)">
Scripture (disambiguation)

Scripture is that portion of literature deemed authoritative for establishing instructions within any of a number of specific religious traditions, especially the Abrahamic religions

Scripture or scripture may also refer to:



</doc>
<doc id="29612" url="https://en.wikipedia.org/wiki?curid=29612" title="Syncretism">
Syncretism

Syncretism () is the combining of different beliefs, while blending practices of various schools of thought. Syncretism involves the merging or assimilation of several originally discrete traditions, especially in the theology and mythology of religion, thus asserting an underlying unity and allowing for an inclusive approach to other faiths. Syncretism also occurs commonly in expressions of arts and culture (known as eclecticism) as well as politics (syncretic politics).

The English word is first attested in the early 17th century, from Modern Latin "syncretismus", drawing on Greek συγκρητισμός ("synkretismos"), supposedly meaning "Cretan federation", but this is a spurious etymology from the naive idea in Plutarch's 1st-century AD essay on "Fraternal Love (Peri Philadelphias)" in his collection "Moralia" (2.490b). He cites the example of the Cretans, who compromised and reconciled their differences and came together in alliance when faced with external dangers. "And that is their so-called "Syncretism" [Union of Cretans]". More likely as an etymology is sun- ("with") plus kerannumi ("mix") and its related noun, "krasis," "mixture."

Erasmus probably coined the modern usage of the Latin word in his "Adagia" ("Adages"), published in the winter of 1517–1518, to designate the coherence of dissenters in spite of their differences in theological opinions. In a letter to Melanchthon of April 22, 1519, Erasmus specifically adduced the Cretans of Plutarch as an example of his adage "Concord is a mighty rampart".

Overt syncretism in folk belief may show cultural acceptance of an alien or previous tradition, but the "other" cult may survive or infiltrate without authorized "syncresis" nevertheless. For example, some Conversos developed a sort of cult for martyr-victims of the Spanish Inquisition, thus incorporating elements of Catholicism while resisting it.

Some religious movements have embraced overt syncretism, such as the case of melding Shintō beliefs into Buddhism or the amalgamation of Germanic and Celtic pagan views into Christianity during its spread into Gaul, the British Isles, Germany, and Scandinavia. Indian influences are seen in the practice of Shi'i Islam in Trinidad. Others have strongly rejected it as devaluing and compromising precious and genuine distinctions; examples of this include post-Exile Second Temple Judaism, Islam, and most of Protestant Christianity.

Syncretism tends to facilitate coexistence and unity between otherwise different cultures and worldviews (intercultural competence), a factor that has recommended it to rulers of multi-ethnic realms. Conversely, the rejection of syncretism, usually in the name of "piety" and "orthodoxy", may help to generate, bolster or authenticate a sense of uncompromised cultural unity in a well-defined minority or majority.

Religious syncretism exhibits blending of two or more religious belief systems into a new system, or the incorporation into a religious tradition of beliefs from unrelated traditions. This can occur for many reasons, and the latter scenario happens quite commonly in areas where multiple religious traditions exist in proximity and function actively in a culture, or when a culture is conquered, and the conquerors bring their religious beliefs with them, but do not succeed in entirely eradicating the old beliefs or (especially) practices.

Religions may have syncretic elements to their beliefs or history, but adherents of so-labeled systems often frown on applying the label, especially adherents who belong to "revealed" religious systems, such as the Abrahamic religions, or any system that exhibits an exclusivist approach. Such adherents sometimes see syncretism as a betrayal of their pure truth. By this reasoning, adding an incompatible belief corrupts the original religion, rendering it no longer true. Indeed, critics of a specific syncretistic trend may sometimes use the word "syncretism" as a disparaging epithet, as a charge implying that those who seek to incorporate a new view, belief, or practice into a religious system actually distort the original faith. Non-exclusivist systems of belief, on the other hand, may feel quite free to incorporate other traditions into their own. Keith Ferdinando notes that the term "syncretism" is an elusive one, and can apply to refer to substitution or modification of the central elements of a religion by beliefs or practices introduced from somewhere else. The consequence under such a definition, according to Ferdinando, can lead to a fatal "compromise" of the original religion's "integrity".

In modern secular society, religious innovators sometimes construct new religions syncretically as a mechanism to reduce inter-religious tension and enmity, often with the effect of offending the original religions in question. Such religions, however, do maintain some appeal to a less exclusivist audience. Note the Living Church in Soviet Russia and the German Evangelical Church in Nazi Germany.

According to some authors, "Syncretism is often used to describe the product of the large-scale imposition of one alien culture, religion, or body of practices over another that is already present." Others such as Jerry H. Bentley, however, have argued that syncretism has also helped to create cultural compromise. It provides an opportunity to bring beliefs, values, and customs from one cultural tradition into contact with, and to engage different cultural traditions. Such a migration of ideas is generally successful only when there is a resonance between both traditions. While, as Bentley has argued, there are numerous cases where expansive traditions have won popular support in foreign lands, this is not always so.

The modern, rational non-pejorative connotations of syncretism date from Denis Diderot's "Encyclopédie" articles: "Eclecticisme" and "Syncrétistes, Hénotiques, ou Conciliateurs." Diderot portrayed syncretism as the concordance of eclectic sources.




</doc>
<doc id="29614" url="https://en.wikipedia.org/wiki?curid=29614" title="S7G reactor">
S7G reactor

The S7G reactor was a prototype naval reactor designed for the United States Navy to provide electricity generation and propulsion on warships. The S7G designation stands for:


This prototype design was a land-based nuclear reactor that did not use control rods. It was tested in the late 1970s and early 1980s at the Modifications and Additions to a Reactor Facility (MARF) plant located at the Knolls Atomic Power Laboratory's Kesselring Site in Ballston Spa, New York. It consisted of an experimental reactor core installed in a modified S5W reactor plant.

Instead of the movable hafnium-based control rods used in all of the other United States Naval reactors, reactivity in the S7G core was controlled by stationary gadolinium-clad tubes partially filled with water. Water could be pumped from the portion of the tube inside the core up to a reservoir above the core, or allowed to flow back down into the tube. A higher water level in the tube slowed more neutrons in the core, causing more neutron capture by the gadolinium tube cladding rather than by the uranium fuel, thus lowering the power level.

The system was configured with the pump running continually to keep the water level low; on loss of electrical power, all of the water would flow back into the tube, shutting down the reactor. As with all small pressurized water reactors, the design also had the advantage of negative feedback: an increase in reactor power caused the water to expand, leading to reduced thermalization of neutrons and lowering absorption by the fuel, therefore lowering the power. Thus, changes in the average coolant temperature, notably from the steam demand of engine throttles, naturally maintains reactor power without intervention from a reactor operator.

The S7G reactor was never used on a ship. In the late 1980s the S7G core was replaced with the experimental DMC (Developmental Materials Core)


</doc>
<doc id="29617" url="https://en.wikipedia.org/wiki?curid=29617" title="Subject–verb–object">
Subject–verb–object

In linguistic typology, subject–verb–object (SVO) is a sentence structure where the subject comes first, the verb second, and the object third. Languages may be classified according to the dominant sequence of these elements in unmarked sentences (i.e., sentences in which an unusual word order is not used for emphasis). The label is often used for ergative languages that do not have subjects, but have an agent–verb–object order.

SVO is used in the active voice. SVO is the second-most common order by number of known languages, after SOV. Together, SVO and SOV account for more than 75% of the world's languages. It is also the most common order developed in Creole languages, suggesting that it may be somehow more initially 'obvious' to human psychology.

Languages regarded as SVO include: Albanian, Arabic dialects, Bosnian, Chinese (Cantonese and Mandarin), English, Estonian, Finnish (but see below), French, Ganda, Greek, Hausa, Icelandic (with the V2 restriction), Igbo, Italian, Javanese, Kashubian, Khmer, Latvian, Macedonian, Malay (Malaysian and Indonesian), Modern Hebrew, Polish, Portuguese, Quiche, Reo Rapa, Romanian, Rotuman, Russian (but see below), Serbian, Croatian, Slovenian, Spanish, Swahili, Thai and Lao, Ukrainian (but see below), Vietnamese, Yoruba and Zulu.

Ancient Greek has free syntactic order, though Classical Greeks tended to favor SOV. Many famous phrases are SVO, however.

Subject–verb–object languages almost always place relative clauses after the nouns they modify and adverbial subordinators before the clause modified, with varieties of Chinese being notable exceptions.

Although some subject–verb–object languages in West Africa, the best known being Ewe, use postpositions in noun phrases, the vast majority of them, such as English, have prepositions. Most subject–verb–object languages place genitives after the noun, but a significant minority, including the postpositional SVO languages of West Africa, the Hmong–Mien languages, some Sino-Tibetan languages, and European languages like Swedish, Danish, Lithuanian and Latvian have "prenominal" genitives (as would be expected in an SOV language).

Non-European languages, usually subject–verb–object languages, have a strong tendency to place adjectives, demonstratives and numerals after nouns that they modify, but Chinese, Vietnamese, Malaysian and Indonesian place numerals before nouns, as in English. Some linguists have come to view the numeral as the head in the
E relationship to fit the rigid right-branching of these languages.

There is a strong tendency, as in English, to have auxiliaries precede main verbs: "I am thinking. He should reconsider."

An example of SVO order in English is:
In analytic languages such as English, subject-verb-object order is relatively inflexible because it identifies which part of the sentence is the subject and which one is the object. ("The dog bit Andy" and "Andy bit the dog" mean two completely different things, while, in case of "Bit Andy the dog", it may be difficult to determine whether it's a complete sentence or a fragment, with "Andy the dog" the object and an omitted/implied subject.) The situation is more complex in languages that have no word order imposed by their grammar; example: Russian, Finnish, Ukrainian, and Hungarian have both the VO and OV constructs in their common word order uses.

In some languages, some word orders are considered more "natural" than others. In some, the order is the matter of emphasis. For example, Russian allows the use of subject-verb-object in any order and "shuffles" parts to bring up a slightly different contextual meaning each time. E.g. "любит она его" (loves she him) may be used to point out "she acts this way because she LOVES him", or "его она любит" (him she loves) is used in the context "if you pay attention, you'll see that HE is the one she truly loves", or "его любит она" (him loves she) may appear along the lines "I agree that cat is a disaster, but since my wife adores it and I adore her...". Regardless of order, it is clear that "его" is the object because it is in the accusative case. In Polish, SVO order is basic in an affirmative sentence, and a different order is used to either emphasize some part of it or to adapt it to a broader context logic. For example, ""Roweru" ci nie kupię" (I won't buy you "a bicycle"), ""Od piątej" czekam" (I've been waiting "since five").

In Turkish, it is normal to use SOV, but SVO may be used sometimes to emphasize the verb. For example, "John terketti Mary'yi" (Lit. "John/left/Mary": John left Mary) is the answer to the question "What did John do with Mary?" instead of the regular [SOV] sentence "John Mary'yi terketti" (Lit. "John/Mary/left").

In German, Dutch, and Kashmiri, SOV with V2 word order in main clauses coexists with SOV in subordinate clauses, as given in Example 1 below; and a change in syntax, such as by bringing an adpositional phrase to the front of the sentence for emphasis, may also dictate the use of VSO, as in Example 2. In Kashmiri, the word order in embedded clauses is conditioned by the category of the subordinating conjunction, as in Example 3. 

English developed from such a reordering language and still bears traces of this word order, for example in locative inversion ("In the garden sat a cat.") and some clauses beginning with negative expressions: "only" ("Only then do we find X."), "not only" ("Not only did he storm away but also slammed the door."), "under no circumstances" ("under no circumstances are the students allowed to use a mobile phone"), "never" ("Never have I done that."), "on no account" and the like. In such cases, "do"-support is sometimes required, depending on the construction.



</doc>
<doc id="29618" url="https://en.wikipedia.org/wiki?curid=29618" title="Skopje">
Skopje

Skopje (, ; ) is the capital and largest city of the Republic of Macedonia. It is the country's political, cultural, economic, and academic center. It was known in the Roman period under the name "Scupi".

The territory of Skopje has been inhabited since at least 4000 BC; remains of Neolithic settlements have been found within the old Kale Fortress that overlooks the modern city centre. Scupi became the capital of Dardania in the second century BC. On the eve of the 1st century AD, the settlement was seized by the Romans and became a military camp. When the Roman Empire was divided into eastern and western halves in 395 AD, Scupi came under Byzantine rule from Constantinople. During much of the early medieval period, the town was contested between the Byzantines and the Bulgarian Empire, whose capital it was between 972 and 992.

From 1282, the town was part of the Serbian Empire and acted as its capital city from 1346 to 1371. In 1392, the city was conquered by the Ottoman Turks who called the town "Üsküp". The town stayed under Turkish control for over 500 years, serving as the capital of pashasanjak of Üsküb and later the Vilayet of Kosovo. At that time the city was famous for its oriental architecture . In 1912, it was annexed by the Kingdom of Serbia during the Balkan Wars and after the First World War the city became part of the newly formed Kingdom of Serbs, Croats and Slovenes (Kingdom of Yugoslavia). In the Second World War the city was conquered by the Bulgarian Army, which was part of the Axis powers. In 1944, it became the capital city of Democratic Macedonia (later Socialist Republic of Macedonia), which was a federal state, part of Democratic Federal Yugoslavia (later Socialist Federal Republic of Yugoslavia). The city developed rapidly after World War II, but this trend was interrupted in 1963 when it was hit by a disastrous earthquake. In 1991, it became the capital city of an independent Macedonia.

Skopje is located on the upper course of the Vardar River, and is located on a major north-south Balkan route between Belgrade and Athens. It is a center for metal-processing, chemical, timber, textile, leather, and printing industries. Industrial development of the city has been accompanied by development of the trade, logistics, and banking sectors, as well as an emphasis on the fields of transportation, culture and sport. According to the last official count from 2002, Skopje has a population of 506,926 inhabitants; according to official estimates, the city has a population of 544,086 inhabitants, as of June 30, 2015.

Skopje is located in the north of the Republic of Macedonia, in the center of the Balkan peninsula, and halfway between Belgrade and Athens. The city was built in the Skopje valley, oriented on a west-east axis, along the course of the Vardar river, which flows into the Aegean Sea in Greece. The valley is approximately wide and it is limited by several mountain ranges to the North and South. These ranges limit the urban expansion of Skopje, which spreads along the Vardar and the Serava, a small river which comes from the North. In its administrative boundaries, the City of Skopje stretches for more than , but it is only wide.

Skopje is approximately 245 m above sea level and covers 571.46 km. The urbanised area only covers 337 km, with a density of 65 inhabitants per hectare. Skopje, in its administrative limits, encompasses many villages and other settlements, including Dračevo, Gorno Nerezi and Bardovci. According to the 2002 census, the City of Skopje comprised 506,926 inhabitants.

The City of Skopje reaches the Kosovo border to the North-East. Clockwise, it is also bordered by the Macedonian municipalities of Čučer-Sandevo, Lipkovo, Aračinovo, Ilinden, Studeničani, Sopište, Želino and Jegunovce.

The Vardar river, which flows through Skopje, is at approximately from its source near Gostivar. In Skopje, its average discharge is 51 m/s, with a wide amplitude depending on seasons, between 99.6 m/s in May and 18.7 m/s in July. The water temperature is comprised between 4.6 °C in January and 18.1 °C in July.
Several rivers meet the Vardar within the city boundaries. The largest is the Treska, which is long. It crosses the Matka Canyon before reaching the Vardar on the western extremity of the City of Skopje. The Lepenec, coming from Kosovo, flows into the Vardar on the northwestern end of the urban area. The Serava, also coming from the North, had flowed through the Old Bazaar until the 1960s, when it was diverted towards the West because its waters were very polluted. Originally, it met the Vardar close to the seat of the Macedonian Academy of Sciences and Arts. Nowadays, it flows into the Vardar near the ruins of Scupi. Finally, the Markova Reka, the source of which is on Mount Vodno, meets the Vardar at the eastern extremity of the city. These three rivers are less than long.
The city of Skopje comprises two artificial lakes, located on the Treska. The lake Matka is the result of the construction of a dam in the Matka Canyon in the 1930s, and the Treska lake was dug for leisure purpose in 1978. Three small natural lakes can be found near Smiljkovci, on the northeastern edge of the urban area.

The river Vardar historically caused many floods, such as in 1962, when its outflow reached 1110 m/s. Several works have been carried since Byzantine times to limit the risks, and since the construction of the Kozjak dam on the Treska in 1994, the flood risk is close to zero.

The subsoil contains a large water table which is alimented by the Vardar river and functions as an underground river. Under the table lies an aquifer contained in marl. The water table is 4 to 12 m under the ground and 4 to 144 m deep. Several wells collect its waters but most of the drinking water used in Skopje comes from a karstic spring in Rašče, located west of the city.

The Skopje valley is bordered on the West by the Šar Mountains, on the South by the Jakupica range, on the East by hills belonging to the Osogovo range, and on the North by the Skopska Crna Gora. Mount Vodno, the highest point inside the city limits, is 1066 m high and is part of the Jakupica range.

Although Skopje is built on the foot of Mount Vodno, the urban area is mostly flat. It comprises several minor hills, generally covered with woods and parks, such as Gazi Baba hill (325 m), Zajčev Rid (327 m), the foothills of Mount Vodno (the smallest are between 350 and 400 m high) and the promontory on which Skopje Fortress is built.
The Skopje valley is located near a seismic fault between the African and Eurasian tectonic plates and experiences regular seismic activity. This activity in enhanced by the porous structure of the subsoil. Large earthquakes occurred in Skopje in 518, 1505 and 1963.

The Skopje valley belongs to the Vardar geotectonic region, the subsoil of which is formed of Neogene and Quaternary deposits. The substratum is made of Pliocene deposits including sandstone, marl and various conglomerates. It is covered by a first layer of Quaternary sands and silt, which is between 70 and 90 m deep. The layer is topped by a much smaller layer of clay, sand, silt and gravel, carried by the Vardar river. It is between 1.5 and 5.2 m deep.

In some areas, the subsoil is karstic. It led to the formation of canyons, such as the Matka Canyon, which is surrounded by ten caves. They are between 20 and 176 m deep.

The climate is usually classified as sub-Mediterranean, (Köppen climate classification: "BSk") with a mean annual temperature of . Precipitation is relatively low due to the pronounced rain shadow of the Prokletije mountains to the northwest, being only a quarter of what is received on the Adriatic Sea coast at the same latitude. The summers are long, hot and relatively dry with low humidity. Skopje's average July high is . On average Skopje sees 88 days above each year, and 10.2 days above every year. Winters are short, relatively cold and wet. Snowfalls are common in the winter period, but heavy snow accumulation is rare and the snowcover lasts only for a few hours or a few days if heavy. In summer, temperatures are usually above and sometimes above . In spring and autumn, the temperatures range from . In winter, the day temperatures are roughly , but at nights they often fall below and sometimes below . Typically, temperatures throughout one year range from −13 °C to 39 °C. Occurrences of precipitation are evenly distributed throughout the year, being heaviest from October to December, and from April to June.

The city of Skopje encompasses various natural environments and its fauna and flora are rich. However, it is threatened by the intensification of agriculture and the urban extension. The largest protected area within the city limits is Mount Vodno, which is a popular leisure destination. A cable car connects its peak to the downtown, and many pedestrian paths run through its woods. Other large natural spots include the Matka Canyon.

The city itself comprises several parks and gardens amounting to 4,361 hectares. Among these are the City Park (Gradski Park), built by the Ottoman Turks at the beginning of the 20th century; Žena Borec Park, located in front of the Parliament; the University arboretum; and Gazi Baba forest. Many streets and boulevards are planted with trees.

Skopje experiences many environmental issues which are often overshadowed by the economic poverty of the country. However, alignment of Macedonian law on European law has brought progress in some fields, such as water and waste treatment, and industrial emissions.

Steel processing, which a crucial activity for the local economy, is responsible for soil pollution with heavy metals such as lead, zinc and cadmium, and air pollution with nitrogen oxide and carbon monoxide. Vehicle traffic and district heating plants are also responsible for air pollution. The highest pollution levels usually occur in autumn and winter.

Water treatment plants are being built, but much polluted water is still discharged untreated into the Vardar. Waste is disposed of in the open-air municipal landfill site, located north of the city. Every day, it receives 1,500 m of domestic waste and 400 m of industrial waste. Health levels are better in Skopje than in the rest of the Republic of Macedonia, and no link has been found between the low environmental quality and the health of the residents.

The urban morphology of Skopje was deeply impacted by the 26th of July 1963 earthquake which destroyed 80% of the city and by the reconstruction that followed. For instance, neighbourhoods were rebuilt in such a way that the demographic density remains low to limit the impact of potential future earthquakes.

Reconstruction following the 1963 earthquake was mainly conducted by the Polish architect Adolf Ciborowski, who had already planned the reconstruction of Warsaw after World War II. Ciborowski divided the city in blocks dedicated to specific activities. The banks of the Vardar river became natural areas and parks, areas located between the main boulevards were built with highrise housing and shopping malls, and the suburbs were left to individual housing and industry. Reconstruction had to be quick in order to relocate families and to relaunch the local economy. To stimulate economic development, the number of thoroughfares was increased and future urban extension was anticipated.
The south bank of the Vardar river generally comprises highrise tower blocks, including the vast Karpoš neighbourhood which was built in the 1970s west of the centre. Towards the East, the new municipality of Aerodrom was planned in the 1980s to house 80,000 inhabitants on the site of the old airport. Between Karpoš and Aerodrom lies the city centre, rebuilt according to plans by Japanese architect Kenzo Tange. The centre is surrounded by a row of long buildings suggesting a wall ("Gradski Zid").

On the north bank, where the most ancient parts of the city lie, the Old Bazaar was restored and its surroundings were rebuilt with low-rise buildings, so as not to spoil views of the Skopje Fortress. Several institutions, including the university and the Macedonian academy, were also relocated on the north bank in order to reduce borders between the ethnic communities. Indeed, the north bank is mostly inhabited by Muslim Albanians, Turks and Roma, whereas Christian ethnic Macedonians predominantly reside on the south bank.

The earthquake left the city with few historical monuments, apart from the Ottoman Old Bazaar, and the reconstruction, conducted between the 1960s and 1980s, turned Skopje into a modernist but grey city. At the end of the 2000s, the city center experienced profound changes. A highly controversial urban project, "Skopje 2014", was adopted by the municipal authorities in order to give the city a more monumental and historical aspect, and thus to transform it into a proper national capital. Several neoclassical buildings destroyed in the 1963 earthquake were rebuilt, including the national theatre, and streets and squares were refurbished. Many other elements were also built, including fountains, statues, hotels, government buildings and bridges. The project has been criticised because of its cost and its historicist aesthetics. The large Albanian minority felt it was not represented in the new monuments, and launched side projects, including a new square over the boulevard that separate the city centre from the Old Bazaar.

Some areas of Skopje suffer from a certain anarchy because many houses and buildings were built without consent from the local authorities.

Outside of the urban area, the City of Skopje encompasses many small settlements. Some of them are becoming outer suburbs, such as Singeliḱ, located on the road to Belgrade, which has more than 23,000 inhabitants, and Dračevo, which has almost 20,000 inhabitants. Other large settlements are located north of the city, such as Radišani, with 9,000 inhabitants, whereas smaller villages can be found on Mount Vodno or in Saraj municipality, which is the most rural of the ten municipalities that form the City of Skopje.

Some localities located outside the city limits are also becoming outer suburbs, particularly in Ilinden and Petrovec municipality. They benefit from the presence of major roads, railways and the airport, located in Petrovec.

Skopje is an ethnically diverse city, and its urban sociology primarily depends on ethnic and religious belonging. Macedonians form 66% of the city population, while Albanians and Roma account respectively for 20% and 6%. Each ethnic group generally restrict itself to certain areas of the city. Macedonians live south of the Vardar, in areas massively rebuilt after 1963, and Muslims live on the northern side, in the oldest neighbourhoods of the city. These neighbourhoods are considered more traditional, whereas the south side evokes to Macedonians modernity and rupture from rural life.

The northern areas are the poorest. This is especially true for Topaana, in Čair municipality, and for Šuto Orizari municipality, which are the two main Roma neighbourhoods. They are made of many illegal constructions not connected to electricity and water supply, which are passed from a generation to the other. Topaana, located close to the Old Bazaar, is a very old area: it was first mentioned as a Roma neighbourhood in the beginning of the 14th century. It has between 3,000 and 5,000 inhabitants. Šuto Orizari, located on the northern edge of the city, is a municipality of its own, with Romani as its local official language. It was developed after the 1963 earthquake to accommodate Roma who had lost their house.

The population density varies greatly from an area to the other. So does the size of the living area per person. The city average was at per person , but at in Centar on the south bank, and only in Čair on the north bank. In Šuto Orizari, the average was at .

The current name of the city comes from Scupi, which was the name of the Dardanian settlement (and later of the Roman colony) located nearby, which derives from , "Skoupoi". The meaning of that name is unknown, but probably derives from the Greek - "episkopos" , i.e. "episcopus" (lit. "watcher, observer"; cf. the modern English adjective episcopal), referring to its position on a high place, from which the whole place could be observed.

After Antiquity, Scupi was occupied by various people and consequently its name was translated several times in several languages. Thus Scupi became "Skopie" () for Bulgarians, and later "Üsküb" () for the Turks. This name was adapted in Western languages in "Uskub" or "Uskup", and these two appellations were used in the Western world until 1912. Some Western sources also cite "Scopia" and "Skopia".

When Vardar Macedonia was annexed by the Kingdom of Serbia in 1912, the city officially became "Skoplje" and this name was adopted by many languages. The city eventually became "Skopje" () after the Second World War, when standard Macedonian became the official language of the Socialist Republic of Macedonia. The local Albanians call the city "Shkup" and "Shkupi", the latter being the definite form.

The rocky promontory on which stands the Fortress was the first site settled by man in Skopje. The earliest vestiges of human occupation found on this site date from the Chalcolithic (4th millennium BC).

Although the Chalcolithic settlement must have been of some significance, it declined during the Bronze Age. Archeological research suggest that the settlement always belonged to a same culture, which progressively evolved thanks to contacts with Balkan and Danube cultures, and later with the Aegean. The locality eventually disappeared during the Iron Age when Scupi emerged. It was located on Zajčev Rid hill, some west of the fortress promontory. Located at the centre of the Balkan peninsula and on the road between Danube and Aegean Sea, it was a prosperous locality, although its history is not well known.

The earliest people in Skopje Valley were probably the Triballi. Later the area was populated by the Paionians. Scupi was originally a Paionian settlement, but it became afterwards Dardanian town. Dardanians, who lived in present-day Kosovo, invaded the region around Skopje during the 3rd century BC. "Scupi", the ancient name for Skopje, became the capital of Dardania, which extended from Naissus to Bylazora in the second century BC. The Dardanians had remained independent after the Roman conquest of Macedon, and it seems most likely that Dardania lost independence in 28 BC.

Roman expansion east brought Scupi under Roman rule as a colony of legionnaires, mainly veterans of the Legio VII Claudia in the time of Domitian (81–96 AD). However, several legions from the Roman province of Macedonia of Crassus' army may already have been stationed in there around 29–28 BC, before the official imperial command was instituted. The first mention of the city was made at that period by Livy, who died in 17 AD. Scupi first served as a military base to maintain peace in the region and was officially named "Colonia Flavia Scupinorum", "Flavia" being the name of the emperor's dynasty. Shortly afterwards it became part of the province of Moesia during Augustus's rule. After the division of the province by Domitian in 86 AD, Scupi was elevated to colonial status, and became a seat of government within the new province of Moesia Superior. The district called Dardania (within Moesia Superior) was formed into a special province by Diocletian, with the capital at Naissus. In Roman times the eastern part of Dardania, from Scupi to Naissus, remained inhabited mostly by a local population, mainly from Thracian origin.

The city population was very diverse. Engravings on tombstones suggest that only a minority of the population came from Italy, while many veterans were from Dalmatia, South Gaul and Syria. Because of the ethnic diversity of the population, Latin maintained itself as the main language in the city at the expense of Greek, which was spoken in most of the Moesian and Macedonian cities. During the following centuries, Scupi experienced prosperity. The period from the end of the 3rd century to the end of the 4th century was particularly flourishing. A first church was founded under the reign of Constantine the Great and Scupi became the seat of a diocese. In 395, following the division of the Roman Empire in two, Scupi became part of the Eastern Roman Empire.

In its heyday, Scupi covered 40 hectares and was closed by a wide wall. It had many monuments, including four necropoles, a theatre, thermae, and a large Christian basilica.

In 518, Scupi was destroyed by a violent earthquake, possibly the most devastating one Macedonia has ever experienced. At that time, the region was threatened by the Barbarian invasions, and the city inhabitants had already fled in forests and mountains before the disaster occurred. Scupi was eventually rebuilt by Justinian I. During his reign, many Byzantine towns were relocated on hills and other easily defendable places to face invasions. Scupi was thus transferred on another site: the promontory on which stands the fortress. However, Scupi was sacked by Slavs at the end of the 6th century and the city seems to have fallen under Slavic rule in 695. The Slavic tribe which settled in Scupi were probably the Berziti who had invaded the entire Vardar valley. The city is not mentioned during the three following centuries but along with the rest of Upper Vardar it became part of the expanding First Bulgarian Empire in the 830s.
Starting from the end of the 10th century Skopje experienced a period of wars and political troubles. It served as Bulgarian capital from 972 to 992, and Samuil ruled it from 976 until 1004 when its governor Roman surrendered it to Byzantine Emperor Basil the Bulgar Slayer in 1004 in exchange for the titles of patrician and strategos. Later, Skopje was briefly seized twice by Slavic insurgents who wanted to restore a Bulgarian state. At first in 1040 under Peter Delyan's command, and in 1072 under the orders of Georgi Voyteh. In 1081, Skopje was captured by Norman troops led by Robert Guiscard and the city remained in their hands until 1088. Skopje was subsequently conquered by the Serbian Grand Prince Vukan in 1093, and again by the Normans four years later. However, because of epidemics and food shortage, Normans quickly surrendered to the Byzantines.

During the 12th and 13th centuries, Bulgarians and Serbs took advantage of Byzantine decline to create large kingdoms stretching from Danube to the Aegean Sea. Kaloyan brought Skopje back into reestablished Bulgaria in 1203 until his nephew Strez declared autonomy along the Upper Vardar with Serbian help only five years later. In 1209 Strez switched allegiances and recognized Boril of Bulgaria with whom he led a successful joint campaign against Serbia's first internationally recognized king Stefan Nemanjić. From 1214 to 1230 Skopje was a part of Byzantine successor state Epirus before recaptured by Ivan Asen II and held by Bulgaria until 1246 when the Upper Vardar valley was incorporated once more into a Byzantine state – the Empire of Nicaea. Byzantine conquest was briefly reversed in 1255 by the regents of the young Michael Asen I of Bulgaria. Meanwhile, in the parallel civil war for the Crown in Tarnovo Skopje bolyar and grandson to Stefan Nemanja Constantine Tikh gained the upper hand and ruled until Europe's only successful peasant revolt the Uprising of Ivaylo deposed him. In 1282 Skopje was captured by Serbian king Milutin. Under the political stability of the Nemanjić rule, Skopje slowly spread outside the walls of the fortress towards Gazi Baba hill. Churches, monasteries and markets were built and tradesmen from Venice and Dubrovnik opened shops. The town greatly benefited from its location on the roads between Europe, Middle-East and Africa. In the 14th century, Skopje became such an important city that king Dušan made it the capital of the Serbian kingdom. In 1346, he was crowned "Emperor of the Serbs and Greeks" in Skopje. After his death the Serbian Empire collapsed into many small principalities which were unable to defend themselves against the Turks. Skopje was first inherited by the Lordship of Prilep and finally taken by Vuk Branković in the wake of the Battle of Maritsa (1371) before becoming part of the Ottoman Empire in 1392.

Skopje economic life greatly benefited from its position in the middle of Turkish Europe. Until the 17th century, Skopje experienced a long golden age. Around 1650, the number of inhabitants in Skopje was between 30,000 and 60,000 and the city contained more than 10,000 houses. It was then one of the only big cities on the territory of future Yugoslavia, together with Belgrade and Sarajevo. At that time, Dubrovnik, which was a busy harbour, had not even 7,000 inhabitants. Following the Ottoman conquest, the city population changed. Christians were forcibly converted to Islam or were replaced by Turks and Jews. At that time, Christians of Skopje were mostly non converted Slavs and Albanians, but also Ragusan and Armenian tradesmen. Ottoman Turks drastically changed the appearance of the city. They organised the Bazaar with its caravanserais, mosques and baths.

The city severely suffered from the Great Turkish War at the end of the 17th century and consequently experienced recession until the 19th century. In 1689, Austrians seized Skopje which was already weakened by a cholera epidemic. The same day, general Silvio Piccolomini set fire to the city to end the epidemic. It is however possible that he wanted to avenge damages that Turks caused in Vienna in 1683. Skopje burned during two days. The Austrian presence in Macedonia motivated Slav uprisings. Nevertheless, Austrians left the country within the year and Hajduks, leaders of the uprisings, had to follow them in their retreat north of the Balkans. Some were arrested by the Turks, such as Petar Karposh, who was impaled on Skopje Stone Bridge.

After the war, Skopje was in ruins. Most of the official buildings were restored or rebuilt, but the city experienced new plague and cholera epidemics and many inhabitants emigrated. The Ottoman Turkish Empire as a whole entered in recession and political decline. Many rebellions and pillages occurred in Macedonia during the 18th century, either led by Turkish outlaws, Janissaries or Hajduks. An estimation conducted by French officers around 1836 revealed that at that time Skopje only had around 10,000 inhabitants. It was largely overwhelmed by two towns of the present-day Republic of Macedonia: Bitola (40,000) and Štip (15–20,000).
Skopje began to recover from decades of decline after 1850. At that time, the city experienced a slow but steady demographic growth, mainly due to the rural exodus of Slav Macedonians. It was also fuelled by the exodus of Muslims from Serbia and Bulgaria, which were gaining autonomy and independence from the Empire at that time. During the Tanzimat reforms, nationalism arose in the Empire and in 1870 a new Bulgarian Church was established and its separate diocese was created, based on ethnic identity, rather than religious principles. The Slavic population of the bishopric of Skopje voted in 1874 overwhelmingly, by 91% in favour of joining the Exarchate and became part of the Bulgarian Millet. Economic growth was permitted by the construction of the Skopje-Salonica railway in 1873. The train station was built south of the Vardar and this contributed to the relocation of economic activities on this side of the river, which had never been urbanised before. Because of the rural exodus, the share of Christians in the city population arose. Some of the newcomers became part of the local elite and helped to spread nationalist ideas Skopje was one of the five main centres of the Internal Macedonian Revolutionary Organization when it organised the 1903 Ilinden uprising. Its revolutionary network in Skopje region was not well-developed and the lack of weapons was a serious problem. At the outbreak of the uprising the rebel forces derailed a military train. On 3 and 5 August respectively, they attacked a Turkish unit guarding the bridge on the Vardar river and gave a battle in the "St. Jovan" monastery. In the next few days the band was pursued by numerous Bashibozuks and moved to Bulgaria.

In 1877, Skopje was chosen as the capital city of the new Kosovo Vilayet, which encompassed present-day Kosovo, northwestern Macedonia and the Sanjak of Novi Pazar. In 1905, the city had 32,000 inhabitants, making it the largest of the vilayet, although closely followed by Prizren with its 30,000 inhabitants. Of the Skopje Muslim population of the late Ottoman period German linguist Gustav Weigand noted that though most were Albanians regarded as "Turks" or Ottomans (Osmanli), they spoke Turkish in public and Albanian at home. At the beginning of the 20th century, local economy was focused on dyeing, weaving, tanning, ironworks and wine and flour processing.

Following the Young Turk Revolution in 1908, the Ottoman Turkish Empire experienced democracy and several political parties were created. However, some of the policies implemented by the Young Turks, such as a tax rise and the interdiction of ethnic-based political parties, discontented minorities. Albanians opposed the nationalist character of the movement and led local uprisings in 1910 and 1912. During the latter they managed to seize most of Kosovo and took Skopje on 11 August. On 18 August, the insurgents signed the Üsküb agreement which provided for the creation of an autonomous Albanian province and they were amnestied the day later.

Following an alliance contracted in 1912, Bulgaria, Greece and Serbia declared war on the Ottoman Empire. Their goal was to definitely expel Turks from Europe. The First Balkan War started on 8 October 1912 and lasted six weeks. Serbians reached Skopje on 26 October. The Turkish forces had left the city the day before. The Serbian annexation led to the exodus of many Turks: 725 Turkish families left the city on 27 January 1913. The same year, the city population was evaluated at 37,000 by the Serbian authorities.

In 1915, during the First World War, Serbian Macedonia was invaded by Bulgaria, which captured Skopje on 22 October 1915 . Serbia, allied to the Triple Entente, was helped by France, Britain, Greece, and Italy, which formed the Macedonian Front. Following a great Allied offensive in 1918, the Armée française d'Orient reached Skopje 29 September and took the city by surprise. After the end of the World War, Macedonia became part of the new Kingdom of Serbs, Croats, and Slovenes, which became "Kingdom of Yugoslavia" in 1929. A mostly foreign ethnic Serb ruling class gained control, imposing a repression unknown under the previous Turkish rulers. The policies of de-Bulgarisation and assimilation were pursued. At that time part of the young locals, repressed by the Serbs, tried to find a separate way of ethnic Macedonian development. In 1931, in a move to formally decentralize the country, Skopje was named the capital of the Vardar Banovina of the Kingdom of Yugoslavia. Until the Second World War, Skopje experienced strong economic growth, and its population increased. The city had 41,066 inhabitants in 1921, 64,807 in 1931, and 80,000 in 1941. Although located in an underdeveloped region, it attracted wealthy Serbs who opened businesses and contributed to the modernisation of the city. In 1941, Skopje had 45 factories, half of the industry in the whole of Macedonia.

In 1941, during the Second World War, Yugoslavia was invaded by Nazi Germany. Germans seized Skopje 8 April and left it to their Bulgarian allies on 22 April 1941. To ensure bulgarisation of the society, authorities closed Serbian schools and churches and opened new schools and a higher education institute, the King Boris University. The 4,000 Jews of Skopje were all deported in 1943 to Treblinka where almost all of them died. Local Partisan detachments started a widespread guerrilla after the proclamation of the "Popular Republic of Macedonia" by the ASNOM on 2 August 1944.

Skopje was liberated on 13 November 1944 by Yugoslav Partisan units of the Macedonian National Liberation Army, together with units of the newly allied Bulgarian People's Army (Bulgaria having switched sides in the war in September).

After World War II, Skopje greatly benefited from Socialist Yugoslav policies which encouraged industry and the development of Macedonian cultural institutions. Consequently, Skopje became home to a national library, a national philharmonic orchestra, a university and the Macedonian Academy. However, its post-war development was altered by the 1963 earthquake which occurred 26 July. Although relatively weak in magnitude, it caused enormous damage in the city and can be compared to the 1960 Agadir earthquake. The disaster killed 1,070 people, injuring 3,300 others. 16,000 people were buried alive in ruins and 70% of the population lost their home. Many educational facilities, factories and historical buildings were destroyed.

After the earthquake, reconstruction was quick. It had a deep psychological impact on the population because neighbourhoods were split and people were relocated to new houses and buildings they were not familiar with. Reconstruction was finished by 1980, even if many elements were never built because funds were exhausted. Skopje cityscape was drastically changed and the city became a true example of modernist architecture. Demographic growth was very important after 1963, and Skopje had 408,100 inhabitants in 1981. However, during the 1980s and the 1990s, the Republic of Macedonia experienced inflation and recession and the local economy heavily suffered. The situation became better during the 2000s thanks to new investments. Many landmarks were restored and the "Skopje 2014" project renewed the appearance of the city centre.

The Flag of Skopje is a red banner in proportions 1:2 with a gold-coloured coat of arms of the city positioned in the upper-left corner. It is either vertical or horizontal, but the vertical version was the first to be used.

The coat of arms of the city was adopted in the 1950s. It depicts the Stone Bridge with the Vardar river, the Kale Fortress and the snow-capped peaks of the Šar mountains.

Being the capital and largest city of the Republic of Macedonia, Skopje enjoys a particular status granted by law. The last revision of its status was made in 2004. Since then, the City of Skopje has been divided into 10 municipalities which all have a council and a mayor, like all the municipalities of the Republic of Macedonia. Municipalities only deal with matters specific of their territory, and the City of Skopje deals with matters that concern all of them, or that cannot be divided between two or more municipalities.

The City of Skopje is part of Skopje Statistical Region, which has no political or administrative power.

The City Council consists of 45 members who serve a four-year term. It primarily deals with budget, global orientations and relations between the City and the government. Several commissions exist to treat more specific topics, such as urbanism, finances, environment of local development. The President of the Council is elected by the Council Members. Since 2017 the president has been Ljubica Jancheva, member of SDSM.

Following the 2017 local elections, the City Council is constituted as follows:

The Mayor of Skopje is elected every four years.
The mayor represents the City of Skopje and he can submit ideas to the Council. He manages the administrative bodies and their officials.

Skopje was first divided into administrative units in 1945, but the first municipalities were created in 1976. They were five: Centar, Čair, Karpoš, Gazi Baba and Kisela Voda. After the independence of the Republic of Macedonia, power was centralised and municipalities lost much of their competences. A 1996 law restored them and created two new municipalities: Gjorče Petrov and Šuto Orizari. After the insurgency between Albanian rebels and Macedonian forces in 2001, a new law was enacted in 2004 to incorporate Saraj municipality into the City of Skopje. Saraj is mostly populated by Albanians and, since then, Albanians represent more than 20% of the city population. Thus Albanian became the second official language of the city administration, something which was one of the claims of the Albanian rebels. The same year, Aerodrom Municipality separated itself from Kisela Voda, and Butel municipality from Čair.

Municipalities are administered by a council of 23 members elected every four years. They also have a mayor and several departments (education, culture, finances...). The mayor primarily deals with these departments.

Skopje is a medium city at European level. Being the capital and largest city in the Republic of Macedonia, Skopje concentrates a large share of the national economy. The Skopje Statistical Region, which encompasses the City of Skopje and some neighbouring municipalities, produces 45,5% of the Macedonian GDP. In 2009, the regional GDP per capita amounted to USD 6,565, or 155% of the Macedonian GDP per capita. This figure is however smaller than the one of Sofia (USD 10,106), Sarajevo (USD 10,048) or Belgrade (USD 7,983), but higher than the one of Tirana (USD 4,126).

Because there are no other large cities in the Republic of Macedonia, and because of political and economical centralisation, a large number of Macedonians living outside of Skopje work in the capital city. The dynamism of the city also encourages rural exodus, not only from Macedonia, but also from Kosovo, Albania and Southern Serbia.

In 2009, Skopje had 26,056 firms but only 145 of them had a large size. The large majority of them are either small (12,017) or very small (13,625). A large share of the firms deal with trade of goods (9,758), 3,839 are specialised in business and real estate, and 2,849 are manufacturers. Although few in number, large firms account for 51% of the local production outside finance.
The city industry is dominated by food processing, textile, printing and metal processing. In 2012, it accounted for 30% of the city GDP. Most of the industrial areas are located in Gazi Baba municipality, on the major routes and rail lines to Belgrade and Thessaloniki. Notably, the ArcelorMittal and Makstil steel plants are located there, and also the Skopje Brewery. Other zones are located between Aerodrom and Kisela Voda, along the railway to Greece. These zones comprise Alkaloid Skopje (pharmaceuticals), Rade Končar (electrical supplies), Imperial Tobacco, and Ohis (fertilisers). Two special economic zones also exist, around the airport and the Okta refinery. They have attracted several foreign companies, such as Johnson Controls, Johnson Matthey and Van Hool.

As the financial capital of the Republic of Macedonia, Skopje is the seat of the Macedonian Stock Exchange, of the National Bank and of most of the Macedonian banking, insurance and telecommunication companies, such as Makedonski Telekom, Komercijalna banka Skopje and Stopanska Banka. The services sector produces 60% of the city GDP.

Besides many small traditional shops, Skopje has two large markets, the "Zelen Pazar" (green market) and the "Bit Pazar" (flea market). They are both considered as local institutions. However, since the 1970s, retailing has largely been modernised and Skopje now has many supermarkets and shopping malls. The largest, Skopje City Mall, opened in 2012. It comprises a Carrefour hypermarket, 130 shops and a cinema, and employs 2,000 people.

51% of Skopje active population is employed in small firms. 52% of the population work in the services sector, 34% in industry, and the remaining is mainly employed in administration.

The unemployment rate for the Skopje Statistical Region was at 27% in 2009, three points under the national rate (30%). The neighbouring Polog Region had a similar rate, but the less affected region was the South-West, with 22%. Unemployment in Skopje mainly concern men, who represent 56% of job-seekers, people between 25 and 44 years old (45% of job-seekers), and non-qualified people (43%). Unemployment also concerns Roma people, who represent 4.63% of the city population. Unemployment concerns 70% of the active population in the community.

The average net monthly wage in Skopje was at €400 in October 2010, which represented 120% of the national figure. The average wage in Skopje was then lower than in Sarajevo (€522) Sofia (€436) and in Belgrade (€440).

The City of Skopje had 506,926 inhabitants within its administrative limits in 2002. Skopje's employment area covers a large part of the Republic of Macedonia, including Veles, Kumanovo and Tetovo, and totaling more than one million inhabitants.

Skopje concentrates a third of Macedonia's population and other Macedonian towns are much smaller. The second most populous municipality, Kumanovo, had 107,632 inhabitants in 2011, and an urban unit of 76,272 inhabitants in 2002.

Before the Austro-Turkish war and the 1698 Great Fire, Skopje was one of the biggest cities in the Balkans, with a population estimated between 30,000 and 60,000 inhabitants. After the fire, it experienced a long period of decline and only had 10,000 inhabitants in 1836. However, the population started to rise again after 1850 and reached 32,000 inhabitants in 1905. In the 20th century, Skopje was one of the fastest growing cities in Yugoslavia and it has 448,200 inhabitants in 1971. Since then, the demographic growth has continued at a steady pace.

Skopje, as the Republic of Macedonia as a whole, is characterised by a large ethnic diversity. The city is located in a region where Ethnic Albanians and Macedonians meet, and it welcomed Romani, Turks, Jews and Serbs throughout its history. Skopje was mainly a Muslim city until the 19th century, when large numbers of Christians started to settle there. According to the 2002 census, Macedonians were the largest ethnic group in Skopje, with 338,358 inhabitants, or 66.75% of the population. Then came Albanians with 103,891 inhabitants (20.49%), Roma people with 23,475 (4.63%), Serbs (14,298 inhabitants), Turks (8,595), Bosniaks (7,585) and Vlachs (2,557). 8,167 people did not belong to any of these groups.

Ethnic Macedonians form an overwhelming majority of the population in the municipalities of Aerodrom, Centar, Gjorče Petrov, Karpoš and Kisela Voda, which are all located south of the Vardar. They also form a majority in Butel and Gazi Baba which are north of the river. Albanians form a majority in Čair which roughly corresponds to the Old Bazaar, and in Saraj. They form a large minority in Butel and Gazi Baba. Šuto Orizari, located on the northern edge of the city, is predominantly Roma.

When an ethnic minority forms at least 20% of the population in a municipality, its language can become official on the local level. Thus, in Čair and Saraj schools and administration use Albanian, and Romani in Šuto Orizari. The latter is the only municipality in the world where Romani is an official language.

Relations between the two largest groups, Macedonians and Albanians, are sometimes difficult, as in the rest of the country. Each group tolerate the other but they tend to avoid each other and live in what can appear as two parallel worlds. The Roma minority is on its side very deprived. Its exact size is not known because many Macedonian Roma declare themselves as belonging to other ethnic groups or simply avoid censuses. However, even if official figures are underestimated, Skopje is the city in the world with the largest Roma population.

Religious affiliation is diverse: Macedonians, Serbs, and Vlachs are mainly Orthodox, with the majority affiliated to the Macedonian Orthodox Church; Turks are almost entirely Muslim; those of Albanian ethnicity are largely Muslim, although Skopje also has a sizeable Roman Catholic Albanian minority, into which Mother Teresa was born; the Roma (Gypsies) represent a mixture (in almost equal numbers) of Muslim and Orthodox religious heritage.

According to the 2002 census, 68.5% of the population of Skopje belonged to the Eastern Orthodox Church, while 28.6% of it belonged to Islam. The city also had Catholic (0.5%) and Protestant (0.04%) minorities. The Catholics are served by the Latin bishopric of Skopje, in which is also vested the Byzantine Catholic Apostolic Exarchate of Macedonia.

Until World War II, Skopje had a significant Jewish minority which mainly descended from Spanish Sephardis who had escaped the Inquisition. The community comprised 2,424 members in 1939 (representing about 3% of the city population), but most of them were deported and killed by Nazis. After the war, most of the survivors settled in Israel. Today the city has around 200 Jewish inhabitants (about 0.04% of the population).

Because of its Ottoman past, Skopje has more mosques than churches. Religious communities often complain about the lack of infrastructure and new places of worship are often built. Skopje is the seat of many Macedonian religious organisations, such as the Macedonian Orthodox Church and the Islamic Religious Union of Macedonia. It has an Orthodox cathedral and seminary, several madrasahs, a Roman Catholic cathedral and a synagogue.

Skopje has several public and private hospitals and specialised medical institutions, such as the Filip II Hospital, a psychiatric hospital, two obstetric hospitals, a gerontology hospital and institutes for respiratory and ocular diseases. In 2012, Skopje had a ratio of one physician per 251.6 inhabitants, a figure higher than the national ratio (one per 370.9). The ratio of medical specialists was also higher than in the rest of the country. However, the ratio of hospital beds, pharmacists and dentists was lower in Skopje. The population in Skopje enjoys better health standards than other Macedonians. In 2010, the mortality rate was at 8.6‰ in Skopje and 9.3‰ on the national level. The infant mortality rate was at 6.8‰ in Skopje and 7.6‰ in Macedonia.

Skopje's citizenry is generally more educated than the rest of the country. For one, 16% of Skopjans graduated university in contrast to 10% for the rest of the country. The number of people with a complete lack of education or ones who received a partial education is lower in Skopje at 9% compared to the provincial average of 17%. 80% of Macedonian citizens who hold a PhD take up residence in Skopje.

Skopje has 21 secondary schools; 5 of which serve as general high-school gymnasiums and 16 vocational schools. The city is also host to several higher education institutions, the most notable of which is Ss. Cyril and Methodius University, founded in 1949. The university has 23 departments, 10 research institutes and is attended by an average of 50,000 students. After the declaration of independence for the Republic of Macedonia in 1991, several private universities were brought to existence. The largest private universities in Skopje are currently European University with 7 departments and FON University with 9 departments respectively.

Skopje is the largest media center in Macedonia. Of the 818 newspapers surveyed in 2000 by the Ministry of Information, over 600 had their headquarters in Skopje. The daily Dnevnik, founded in 1996, with 60 000 runs per day is the most printed in the country. Also based in Skopje, Večer is pulled 50,000 copies and the state owns one third of its capital, as well as Nova Makedonija, reprinted 20,000 copies. Other major newspapers in Skopje, totally private, are Utrinski Vesnik (30,000 copies), Vest (25,000 copies) and Vreme (15,000 copies). Magazines Fokus (12,000 copies), Start (10,000 copies), and Denes (7,500 copies) also have their headquarters in Skopje.

The city is home of the studios of Macedonian Radio-Television (MRT), the country's public radio and television. Founded in 1966, it operates with three national broadcast channels, twenty-four hours at day. The most popular private television stations are Sitel. Kanal 5, Telma, Alfa TV and AlsatM are another major private television companies. MRT also operates radio stations with national coverage, the private station Skopje's Kanal 77 is the only one to have such a span. Radio Antenna 5 and Metropolis are two other major private stations that have their headquarters in Skopje.

Also, the city boasts big news agencies in the country, both public, as the Macedonian Information Agency, and private, such as the Makfax.

As the capital and largest city of Macedonia, Skopje has many major sporting facilities. The city has three large swimming pools, two of which feature Olympic pools. These pools are particularly relevant to coaching water polo teams. Skopje also boasts many football stadiums, like Ilinden in Čair and Železarnica, which can accommodate between 4,000 and 4,500 spectators. The basketball court Kale can accommodate 5 000 people and the court of Jane Sandanski, 4000 people.

The largest stadium remains the Philip II Arena. The stadium, built in 1947 and named until 2008, City Stadium Skopje experienced a total renovation, begun in 2009 to meet the standards of FIFA. Fully renovated the stadium contains 32,580 seats, and a health spa and fitness. The Boris Trajkovski Sports Center is the largest sports complex in the country. It was opened in 2008 and named after president Boris Trajkovski, who died in 2004. It includes room dedicated to handball, basketball and volleyball, a bowling alley, a fitness area and an ice hockey court. Its main hall, which regularly hosts concerts, holds around 10,000 people.

FK Vardar and FK Rabotnički are the two most popular football teams, playing in the first national league. Their workouts are held at Philip II Arena, like those of the national team. The city is also home to many smaller football clubs, such as: FK Makedonija Gjorče Petrov, FK Gorno Lisiče, FK Lokomotiva Skopje, FK Metalurg Skopje, FK Madžari Solidarnost and FK Skopje, who play in first, second or third national league. Another popular sport in Macedonia is basketball, represented in particular by the teams Rabotnički and MZT Skopje. Handball is illustrated by RK Vardar PRO and RK Metalurg Skopje, also the women's team ŽRK Metalurg and ŽRK Vardar. The city co-hosted the 2008 European Women's Handball Championship together with Ohrid. and will host the 2017 UEFA Super Cup, the match between the two giants of the European football Real Madrid and Manchester United

Skopje is located near three other capital cities, Prishtina ( away), Tirana (291 km) and Sofia (245 km). Thessaloniki is south and Belgrade is north. Skopje is also at the crossroad of two Pan-European corridors: Corridor X, which runs between Austria and Greece, and Corridor VIII, which runs from the Adriatic in Albania to the Black sea in Bulgaria. Corridor X links Skopje to Thessaloniki, Belgrade and Western Europe, while Corridor VIII links it with Tirana and Sofia.

Corridor X locally corresponds to the M-1 motorway (E75), which is the longest Macedonian highway. It also corresponds to the Tabanovce-Gevgelija railway. Corridor VIII, less developed, corresponds to the M-4 motorway and the Kičevo-Beljakovce railway. Skopje is not quite on the Corridor X and the M-1 does not pass on the city territory. Thus the junction between the M-1 and M-4 is located some east, close to the airport. Although Skopje is geographically close to other major cities, movement of people and goods is not optimised, especially with Albania. This is mainly due to poor infrastructure. As a result, 61.8% of Skopjans have never been to Tirana, while only 6.7% have never been to Thessaloniki and 0% to Sofia. Furthermore, 26% of Thessalonians, 33% of Sofians and 37% of Tiranans have never been to Skopje.

The main railway station in Skopje is serviced by the Belgrade-Thessaloniki and Skopje-Prishtina international lines. After the completion of the Corridor VIII railway scheduled for 2022, the city will also be linked to Tirana and Sofia. Daily trains also link Skopje with other Macedonian towns, such as Kumanovo, Kičevo, Štip, Bitola or Veles.

Skopje has several minor railway stations but the city does not have its own railway network and they are only serviced by intercity or international lines. On the railway linking the main station to Belgrade and Thessaloniki are Dračevo and Dolno Lisiče stations, and on the railway to Kičevo are Skopje-North, Gjorče Petrov and Saraj stations. Several other stations are freight-only.

Skopje coach station opened in 2005 and is built right under the main railway station. It can host 450 coaches in a day. Coach connections to and from Skopje are much more efficient and diverse than train connections. Indeed, it is regularly linked to many Macedonian localities and foreign cities including Istanbul, Sofia, Prague, Hamburg and Stockholm.

Skopje has a bus network managed by the city and operated by three companies. The oldest and largest is JSP Skopje, a public company founded in 1948. JSP lost its monopoly on public transport in 1990 and two new companies, Sloboda Prevoz and Mak Ekspres, obtained several lines. However, most of the network is still in the hands of JSP which operates 67 lines out of 80. Only 24 lines are urban, the others serving localities around the city. Many of the JSP vehicles are red double-decker buses built by Chinese bus manufacturer Yutong and designed to resemble the classic British AEC Routemaster.

A tram network has long been planned in Skopje and the idea was first proposed in the 1980s. The project became real in 2006 when the mayor Trifun Kostovski asked for feasibility studies. His successor Koce Trajanovski launched a call for tenders in 2010 and the first line is scheduled for 2019.

A new network for small buses started to operate in June 2014, not to replace but to decrease the number of big buses in the city centre.

Skopje has an international airport, International Airport Skopje. It is located in Petrovec, some east of the city. Since 2008, it has been managed by the Turkish TAV Airports Holding and it can accommodate up to four million passengers per year. The annual traffic has constantly risen since 2008, reaching one million passengers in 2014.

Skopje's airport has connections to several European cities, including Vienna, Zürich, Brussels, Istanbul, London and Rome. It also maintains a direct connection with Dubai and Doha, Qatar.

Being the capital of the Republic of Macedonia, Skopje is home to the largest cultural institutions of the country, such as the National and University Library "St. Kliment of Ohrid", the Macedonian Academy of Sciences and Arts, the National Theatre, the National Philarmonic Orchestra and the Macedonian Opera and Ballet. Among the local institutions are the Brothers Miladinov Library which has more than a million documents, the Cultural Information Centre which manages festivals, exhibitions and concerts, and the House of Culture Kočo Racin which is dedicated to contemporary art and young talents.

Skopje has also several foreign cultural centres, such as a Goethe-Institut, a British Council, an Alliance française, an American Corner.

The city has several theatres and concert halls. The Univerzalna Sala, seating 1,570, was built in 1966 and is used for concerts, fashion shows and congresses. The Metropolis Arena, designed for large concerts, has 3,546 seats. Other large halls include the Macedonian Opera and Ballet (800 seats), the National Theatre (724), and the Drama Theatre (333). Other smaller venues exist, such as the Albanian Theatre and the Youth Theatre. A Turkish Theatre and a Philharmonic hall are under construction.

The largest museum in Skopje is the Museum of Macedonia which details the history of the country. Its icons and lapidary collections are particularly rich. The Macedonian Archeological Museum, opened in 2014, keeps some of the best archeological finds in Macedonia, dating from Prehistory to the Ottoman period. The National Gallery of Macedonia exhibits paintings dating from the 14th to the 20th century in two former Turkish baths of the Old Bazaar. The Contemporary Art Museum of Macedonia was built after the 1963 earthquake thanks to international assistance. Its collections include Macedonian and foreign art, with works by Fernand Léger, André Masson, Pablo Picasso, Hans Hartung, Victor Vasarely, Alexander Calder, Pierre Soulages, Alberto Burri and Christo.

The Skopje City Museum is located inside the remains of the old railway station, destroyed by the 1963 earthquake. It is dedicated to local history and it has four departments: archeology, ethnology, history, and art history. The Memorial House of Mother Teresa was built in 2009 on the original site of the church in which the saint had been baptised. The Museum of the Macedonian Struggle is dedicated to the modern national history and the struggle of Macedonians for their independence. Nearby is the Holocaust Memorial Center for the Jews of Macedonia. The Macedonian Museum of Natural History showcases some 4,000 items while the 12-ha Skopje Zoo is home to 300 animals.

Although Skopje has been destroyed many times through its history, it still has many historical landmarks which reflect the successive occupations of the city. Skopje has one of the biggest Ottoman urban complexes in Europe, with many Ottoman monuments still serving their original purpose. It was also a ground for modernist experiments in the 20th century, following the 1963 earthquake. In the beginning of the 21st century, it is again the subject of massive building campaigns, thanks to the "Skopje 2014" project. Skopje is thus an environment where old, new, progressist, reactionary, eastern and western perspectives coexist.
Skopje has some remains of Prehistorical architecture which can be seen on the Tumba Madžari Neolithic site. On the other side of the city lie the remains of the ancient Scupi, with ruins of a theatre, thermae and a basilica. The Skopje Aqueduct, located between Scupi and the city centre, is rather mysterious because its date of construction is unknown. It seems to have been built by the Byzantines or the Turks, but it was already out of use in the 16th century. It consists of 50 arches, worked in cloisonné masonry.
Skopje Fortress was rebuilt several times before it was destroyed by the 1963 earthquake. Since then, it has been restored to its medieval appearance. It is the only medieval monument in Skopje, but several churches located around the city illustrate the Vardar architectural school which flourished around 1300. Among these churches are the ones around Matka Canyon (St Nicholas, St Andrew and Matka churches). The church of St. Panteleimon in Gorno Nerezi dates from the 12th century. Its expressive frescoes anticipate the Italian primitives.
Examples of Ottoman Turkish architecture are located in the Old Bazaar. Mosques in Skopje are usually simple in design, with a square base and a single dome and minaret. There entrance is usually emphasised by a portico, as on Mustafa Pasha Mosque, dating from the 15th century. Some mosques show some originality in their appearance: Sultan Murad and Yahya Pasha mosques have lost their dome and have a pyramidal roof, while Isa Bey mosque has a rectangular base, two domes and two side wings. The Aladža Mosque was originally covered with blue faience, but it disappeared in the 1689 Great Fire. However, some tiles are still visible on the adjoining türbe. Other Turkish public monuments include the 16th-century clock tower, a bedesten, three caravanserais, two Turkish baths and the Stone Bridge, first mentioned in 1469.

The oldest churches in the city centre, the Ascension and St Dimitri churches, were built in the 18th century, after the 1689 Great Fire. They were both renovated in the 19th century. The Church of the Ascension is particularly small it is half-buried in order not to overlook neighbouring mosques. In the 19th century, several new churches were built, including the Church of the Nativity of the Virgin Mary, which is a large three-nave building designed by Andrey Damyanov.
After 1912, when Skopje was annexed by Serbia, the city was drastically westernised. Wealthy Serbs built mansions and town houses such as the 1926 Ristiḱ Palace. Architecture of that time is very similar to the one of Central Europe, but some buildings are more creative, such as the Neo-Moorish Arab House and the Neo-Byzantine train station, both built in 1938. Modernism appeared as early as 1933 with the former Ethnographic Museum (today the City Gallery), designed by Milan Zloković. However, modernist architecture only fully developed in Skopje after the 1963 earthquake. The reconstruction of city centre was partially planned by Japanese Kenzo Tange who designed the new train station. Macedonian architects also took part to the reconstruction: Georgi Konstantinovski designed the City Archives building in 1968 and the Hall of residence Goce Delčev in 1975, while Janko Konstantinov designed the Telecommunication Centre and the main post office (1974–1989). Slavko Brezovski designed the Church of St. Clement of Ohrid. These two buildings are noted for their originality although they are directly inspired by brutalism.
The reconstruction turned Skopje into a proper modernist city, with large blocks of flats, austere concrete buildings and scattered green spaces. The city centre was considered as a grey and unattractive place when local authorities unveiled the "Skopje 2014" project in 2010. It made plans to erect a large number of statues, fountains, bridges, and museums at a cost of about €500 million.

The project has generated controversy: critics have described the new landmark buildings as signs of reactionary historicist aesthetics. Also, the government has been criticised for its cost and for the original lack of representation of national minorities in the coverage of its set of statues and memorials. However, representations of minorities have since been included among the monuments. The scheme is accused of turning Skopje to a theme park, which is viewed as nationalistic kitsch, and has made Skopje an example to see how national identities are constructed and how this construction is mirrored in the urban space.

The Skopje Jazz Festival has been held annually in October since 1981. It is part of the European Jazz Network and the European Forum of World Wide Festivals. The artists' profiles include fusion, acid jazz, Latin jazz, smooth jazz, and avant-garde jazz. Ray Charles, Tito Puente, Gotan Project, Al Di Meola, Youssou N'Dour, among others, have performed at the festival. Another music festival in Skopje is the Blues and Soul Festival. It is a relatively new event in the Macedonian cultural scene that occurs every summer in early July. Past guests include Larry Coryell, Mick Taylor & the All-Stars Blues Band, Candy Dulfer & Funky Stuff, João Bosco, The Temptations, Tolo Marton Trio, Blues Wire, and Phil Guy.

The Skopje Cultural Summer Festival is a renowned cultural event that takes place in Skopje each year during the summer. The festival is a member of the International Festivals and Events Association (IFEA) and it includes musical concerts, operas, ballets, plays, art and photograph exhibitions, movies, and multimedia projects that gather 2,000 participants from around the world each year including the St Petersburg Theatre, the Chamber Orchestra of the Bolshoi Theatre, Irina Arkhipova, Viktor Tretiakov, The Theatre of Shadows, Michel Dalberto, and David Burgess.

May Opera Evenings is a festival that has occurred annually in Skopje since 1972 and is dedicated to promoting opera among the general public. Over the years, it has evolved into a stage on which artists from some 50 countries have performed. There is one other major international theater festival that takes place each year at the end of month September, the Young Open Theater Festival (MOT), which was organized for the first time in May 1976 by the Youth Cultural Center – Skopje. More than 700 theatrical performances have been presented at this festival so far, most of them being alternative, experimental theatre groups engaging young writers and actors. The MOT International theater festival is also a member of the International Network for Contemporary Performing Arts or IETM. Within the framework of the MOT Festival, the Macedonian National Center of the International Theater Institute (ITI) was established, and at the 25th ITI World Congress in Munich in 1993, it became a regular member of this theater association. The festival has an international character, always representing theaters from all over the world that present and enhance exchange and circulation of young-fresh-experimental-avant guard theatrical energy and experience between its participants on one side and the audience on the other.

The Skopje Film Festival is an annual event held in the city every March. Over 50 films are shown at this five-day festival, mostly from Macedonia and Europe, but also including some non-commercial film productions from all over the world.

Skopje has a diverse nightlife. There is a large emphasis on casinos, many of which are associated with hotels, such as that of the Holiday Inn. Other casinos include Helios Metropol, Olympic, Bon Venon, and Sherry. Among young people the most popular destinations are bars, discos, and nightclubs which can be found in the center and the City Park. Among the most popular nightclubs are Midnight, Hard Rock, Maracana, B2, Havana and Colosseum where world-famous disc jockeys and idiosyncratic local performances are frequent. In 2010, the Colosseum club was named fifth on a list of the best clubs in Southeastern Europe. Armin van Buuren, Above and Beyond, The Shapeshifters are just some of the many musicians that have visited the club. Nighttime concerts in local, regional and global music are often held at the Philip II National Arena and Boris Trajkovski Sports Center. For middle-aged people, places for having fun are also the "kafeanas" where traditional Macedonian food is served and traditional Macedonian Music ("Starogradska muzika") is played, but music from all the Balkans, particularly Serbian folk music is also popular. Apart from the traditional Macedonian restaurants, there are restaurants featuring international cuisines. Some of the most popular cafés in Skopje are Café Ei8ht, Café Trend, Drama Café, Lex Café and Blue Café. The Old Bazaar was a popular nightlife destination in the past. The national government has created a project to revive nightlife in the Old Bazaar. The closing time in shops, cafés and restaurants was extended due to the high attendances recorded. In the bazaar's restaurants, along with the traditional Macedonian wine and food, dishes of the Ottoman cuisine are also served.

Notable people from Skopje include:


Skopje is twinned with:






</doc>
<doc id="29622" url="https://en.wikipedia.org/wiki?curid=29622" title="Speed metal">
Speed metal

Speed metal is an extreme subgenre of heavy metal music that originated in the late 1970s from new wave of British heavy metal (NWOBHM) roots. It is described by AllMusic as "extremely fast, abrasive, and technically demanding" music.

"It is usually considered less abrasive and more melodic than thrash metal, showing less influence from hardcore punk. However, speed metal is usually faster and more aggressive than traditional heavy metal, also showing more inclination to virtuoso soloing and featuring short instrumental passages between couplets. Speed metal songs frequently make use of highly expressive vocals, but are usually less likely to employ 'harsh' vocals than thrash metal songs."

One of the key influences on the development of speed metal was the new wave of British heavy metal, or NWOBHM. This was a heavy metal movement that started in the late 1970s, in Britain, and achieved international attention by the early 1980s. NWOBHM bands toned down the blues influences of earlier acts, incorporated elements of punk, increased the tempo, and adopted a "tougher" sound, taking a harder approach to its music.

It was an era directed almost exclusively at heavy metal fans and is considered to be a major foundation stone for the extreme metal genres.

The NWOBHM came to dominate the heavy metal scene of the early-mid-1980s. It was musically characterized by fast upbeat tempo songs, power chords, fast guitar solos and melodic, soaring vocals. Groups such as Iron Maiden, Judas Priest, Venom, Saxon and Motörhead as well as many lesser-known ones, became part of the canon that influenced American bands that formed in the early eighties.

Motörhead is often credited as the first band to play speed metal. Some of speed metal's earlier influences include Black Sabbath's "Children of the Grave", Budgie's "Breadfan" and Queen's "Stone Cold Crazy" (the latter two were eventually covered by the thrash metal band Metallica), as well as certain Deep Purple songs such as "Speed King", "Fireball" and "Highway Star". The latter was called "early speed metal" by Robb Reiner of speed metal band Anvil.

The origin song for the genre was aptly named "Speed King" by Deep Purple. Recording on the song started in 1969 making it nearly a full decade ahead of the musical style being recognized. The song is not only very fast and technical but was also extremely loud creating noticeable distortion in the recording process. The title song for the bands next album, "Fireball", is a further refinement of the band's influence with drummer Ian Paice's use of the double bass. The way the double bass is played in "Fireball" - up tempo "four on the floor" - becomes a mainstay in many Heavy, Speed and Thrash Metal songs in the years to come. This is the only Deep Purple song that employs the double bass and video from the band shows them actually bring out the second bass as needed to play the song. While speedy, technical playing did not dominate Deep Purple's music, they clearly were the inventors of rock that was fast, technical and loud. Those characteristics would become the hallmarks of Speed Metal. Given the name of the origin song - Speed King - they also probably played a role in the genre's naming. At the very least they acknowledged what they were doing which was a radical departure from all prior rock music.

Black Sabbath are a British heavy metal band from Birmingham, England, and are often cited as one of the grandfathers of the genre. Though usually known for playing a fairly slow, sludgy tempo, "After Forever" is a very up-tempo song with a much faster pace than other songs in their catalogue. Still in certain other songs such as "Electric Funeral", "Into the Void" and "Under the Sun (Every Day Comes and Goes)" there is a section in the middle of the song that shifts away from the core music and plays a much faster pace than in the rest of the song, then returns to the original melody. There are those who believe that their song "Symptom of the Universe" from their 1975 release "Sabotage" album is the first true example of a speed metal song.

Judas Priest are a British heavy metal band, also formed in Birmingham, England. They often played faster than most rock groups of the time and brought a more "metallic" sound to the guitars. Some songs, such as 1978's "Exciter", were groundbreaking for their sheer ferocity and speed; few, if any, bands exempting Motörhead, played with the same tempo . 

Exciter (who took their name from the aforementioned Judas Priest song) is a Canadian speed metal band from Ottawa, Ontario, which was formed in 1978. They are widely considered to be one of the first speed metal bands and a seminal influence of the thrash metal genre. Anvil are another Canadian speed metal band, from Toronto, Ontario, who also formed in 1978. To date, the band has released sixteen studio albums, and has been cited as having influenced many notable thrash metal groups, including Metallica, Anthrax, Slayer and Megadeth. Annihilator is a Canadian speed/thrash metal band founded in 1984 by vocalist, guitarist and bassist Jeff Waters. They are the highest selling heavy metal group in Canadian history, having sold 2 million records worldwide.

Accept is a German heavy metal band which played an important role in the development of speed and thrash metal, being part of the German heavy metal scene, which emerged in the early to mid-1980s. Of particular importance was their 1982 track "Fast as a Shark".

Speed metal eventually evolved into thrash metal. Although many tend to equate the two subgenres, others argue that there is a distinct difference between them. In his book "", Ian Christe states that "...thrash metal relies more on long, wrenching rhythmic breaks, while speed metal... is a cleaner and more musically intricate subcategory, still loyal to the dueling melodies of classic metal." However, on the very next page, Christe calls speed metal a "subset of thrash metal" and argues that "There was little intrinsic difference between speed metal and thrash metal. With the sudden boom of fast, raging bands, however, it sometimes helped to distinguish between the throbbing, rhythm-heavy thrash metal and something a bit cleaner and more melodic--dubbed speed metal."

Speed metal's sound varied between various regional scenes. European bands leaned towards the sound of bands like Venom and Motörhead. Japanese bands had a more melodic sound that resembled power metal. North American bands had a faster, more aggressive sound that would later influence the thrash metal movement.



</doc>
<doc id="29623" url="https://en.wikipedia.org/wiki?curid=29623" title="Segway (disambiguation)">
Segway (disambiguation)

Segway may refer to:




</doc>
<doc id="29630" url="https://en.wikipedia.org/wiki?curid=29630" title="Stan Rogers">
Stan Rogers

Stanley Allison "Stan" Rogers (November 29, 1949 – June 2, 1983) was a Canadian folk musician and songwriter.

Rogers was noted for his rich, baritone voice and his traditional-sounding songs which were frequently inspired by Canadian history and the daily lives of working people, especially those from the fishing villages of the Maritime provinces and, later, the farms of the Canadian prairies and Great Lakes. Rogers died in a fire aboard Air Canada Flight 797 on the ground at the Greater Cincinnati Airport at the age of 33.

Rogers was born in Hamilton, Ontario the eldest son of Nathan Allison Rogers and Valerie (née Bushell) Rogers, two Maritimers who had relocated to Ontario in search of work shortly after their marriage in July 1948. Although Rogers was raised in Binbrook, Ontario, he often spent summers visiting family in Guysborough County, Nova Scotia.

It was there that he became familiar with the way of life in the Maritimes, an influence which was to have a profound impact on his subsequent musical development. He was interested in music from an early age, reportedly beginning to sing shortly after learning to speak. He received his first guitar, a miniature hand-built by his uncle Lee Bushell, when he was five years of age. He was exposed to a variety of music influences, but among the most lasting were the country and western tunes his uncles would sing during family get-togethers. Throughout his childhood, he would practice his singing and playing along with his brother Garnet, six years his junior.

While Rogers was attending Saltfleet High School, Stoney Creek, Ontario, he started to meet other young people interested in folk music, although at this time he was dabbling in rock and roll, singing and playing bass guitar in garage bands such as "Stanley and the Living Stones" and "The Hobbits". After high school, Rogers briefly attended both McMaster University and Trent University, where he performed in small venues with other student musicians, including Ian Tamblyn, Chris Ward and fellow Hobbit Nigel Russell.

Rogers signed with RCA Records in 1970 and recorded two singles: "Here's to You Santa Claus" in 1970, and "The Fat Girl Rag" in 1971. In 1973, Rogers recorded three singles for Polygram: "Three Pennies", "Guysborough Train", and "Past Fifty."
In 1976, Rogers recorded his debut album, "Fogarty's Cove", released in 1977 on Barnswallow Records. The album's subject matter dealt almost entirely with life in maritime Canada, and was an immediate success. Rogers then formed Fogarty's Cove Music, and bought Barnswallow during the production of "Turnaround", allowing him to release his own albums. Posthumously, additional albums were released.

Rogers' songs often had a Celtic feel which was due, in part, to his frequent use of DADGAD guitar tuning. He regularly used his William 'Grit' Laskin built 12-string guitar in his performances. His best-known pieces include "Northwest Passage", "Barrett's Privateers", "The Mary Ellen Carter", "Make and Break Harbour", "The Idiot", "Fogarty's Cove", and "White Squall".

Rogers died alongside 22 other passengers most likely of smoke inhalation on June 2, 1983, while traveling on Air Canada Flight 797 (a McDonnell Douglas DC-9) after performing at the Kerrville Folk Festival. The airliner was flying from Dallas, Texas, to Toronto and Montreal when a fire of unknown ignition source within the vanity or toilet shroud of the aft washroom forced it to make an emergency landing at the Greater Cincinnati Airport in northern Kentucky.

There were initially no visible flames, and after attempts to extinguish the fire were unsuccessful, smoke filled the cabin. Upon landing, the plane's doors were opened, allowing the five crew and 18 of the passengers to escape, but approximately 60 to 90 seconds into the evacuation the oxygen rushing in from outside caused a flash fire. Rogers was one of the passengers still on the plane at the time of the fire.

His ashes were scattered in the Atlantic Ocean off the coast of Nova Scotia.

Rogers' legacy includes his recordings, songbook, and plays for which he was commissioned to write music. His songs are still frequently covered by other musicians, and are perennial favourites at Canadian campfires and song circles. Members of Rogers' band, including his brother Garnet Rogers, continue to be active performers and form a significant part of the fabric of contemporary Canadian folk music. Following his death, he was nominated for the 1984 Juno Awards in the category for Best Male Vocalist. In 1994, his posthumous live album "Home in Halifax" was likewise nominated for Best Roots and Traditional Album.

His widow, Ariel, continues to oversee his estate and legacy. His music and lyrics have been featured in numerous written publications and films. For instance, his lyrics have appeared in school poetry books, taking their place alongside acknowledged classics. His song "Northwest Passage" was featured in the last episode of the TV show "Due South", his songs "Barrett's Privateers" and "Watching the Apples Grow" having been previously featured. "Barrett's Privateers" has also been used extensively in promotion ads for Alexander Keith's ale. In the 2005 CTV made-for-TV movie on the life of Terry Fox, Rogers' "Turnaround" is the music over the closing shot. As the movie ends, Fox is depicted, alone, striding up a hill, while the lyric "And yours was the open road. The bitter song / The heavy load that I'll never share, tho' the offer's still there / Every time you turn around," forges a link between these Canadian icons. Many of his songs on the albums "Northwest Passage" and "From Fresh Water" refer to events in Canadian history.

Adrienne Clarkson, who, prior to serving as the Governor General of Canada from 1999 to 2005, had worked for the Canadian Broadcasting Corporation, highlighted Rogers' career in a 1989 television documentary called "One Warm Line" on CBC Television; she also quoted Rogers in her investitural address.

When CBC's Peter Gzowski asked Canadians to pick an alternate national anthem, "Northwest Passage" was the overwhelming choice.

The Stan Rogers Folk Festival is held every year in Canso, Nova Scotia. In 1995, several artists performed two nights of concerts at Halifax's Rebecca Cohn Auditorium, which were released on album that year as "Remembering Stan Rogers".

Rogers is also a lasting fixture of the Canadian folk festival Summerfolk, held annually in Owen Sound, Ontario, where the main stage and amphitheater are dedicated as the "Stan Rogers Memorial Canopy". The festival is firmly fixed in tradition, with Rogers' song "The Mary Ellen Carter" being sung by all involved, including the audience and a medley of acts at the festival.

At The Canmore Folk Festival, Alberta's longest running folk music festival, performers take to the Stan Rogers Memorial Stage, which is the festival's main stage.

Stan's son, Nathan Rogers, is also an established Canadian folk artist with a voice and lyrical acumen similar to his father's. He has released two critically acclaimed solo discs and tours internationally as a solo act and in the trio "Dry Bones".

In 2007, Rogers was recognized posthumously with a National Achievement Award at the annual SOCAN Awards held in Toronto.

In 2013, Groundwood Books turned Rogers' song Northwest Passage into a children's book illustrated by award-winning artist Matt James.






</doc>
<doc id="29631" url="https://en.wikipedia.org/wiki?curid=29631" title="Sacramento, California">
Sacramento, California

Sacramento ( ; ) is the capital city of the U.S. state of California and the seat of Sacramento County. It is at the confluence of the Sacramento River and the American River in the northern portion of California's expansive Central Valley, known as the Sacramento Valley. Its estimated 2018 population of 501,334 makes it the sixth-largest city in California, the fastest-growing big city in the state, and the 35th largest city in the United States. Sacramento is the cultural and economic core of the Sacramento metropolitan area, which includes seven counties with a 2010 population of 2,414,783. Its metropolitan area is the fifth largest in California after the Los Angeles metropolitan area, the San Francisco Bay Area, the Inland Empire, and the San Diego metropolitan area, and is the 27th largest in the United States. In 2002, the Civil Rights Project at Harvard University conducted for "Time" magazine named Sacramento "America's Most Diverse City".

Sacramento became a city through the efforts of the Swiss immigrant John Sutter, Sr., his son John Augustus Sutter, Jr., and James W. Marshall. Sacramento grew quickly thanks to the protection of Sutter's Fort, which was established by Sutter. During the California Gold Rush, Sacramento was a major distribution point, a commercial and agricultural center, and a terminus for wagon trains, stagecoaches, riverboats, the telegraph, the Pony Express, and the First Transcontinental Railroad.

The city was named after the Sacramento River, which forms its western border. The river was named by Spanish cavalry officer Gabriel Moraga for the "Santísimo Sacramento" (Blessed Sacrament), referring to the Catholic Eucharist.

Today, the city is known for its diversity, tree canopy (largest in the U.S.), historic Old Sacramento, evolving contemporary culture as the most "hipster city" in California, sunny climate, state administration, and farm-to-fork dining. California State University, Sacramento, is the largest university in the city and a designated "Tree City USA" campus. The University of the Pacific is a private university with one of its three campuses, the McGeorge School of Law, in Sacramento. In addition, the University of California, Davis, west of Sacramento, operates UC Davis Medical Center, a world-renowned research hospital, in the city of Sacramento.

Nisenan (Southern Maidu) and Plains Miwok Native Americans had lived in the area for perhaps thousands of years. Unlike the settlers who would eventually make Sacramento their home, these Native Americans left little evidence of their existence. Traditionally, their diet was dominated by acorns taken from the plentiful oak trees in the region, and by fruits, bulbs, seeds, and roots gathered throughout the year.

In 1808, the Spanish explorer Gabriel Moraga discovered and named the Sacramento Valley and the Sacramento River. A Spanish writer with the Moraga expedition wrote: "Canopies of oaks and cottonwoods, many festooned with grapevines, overhung both sides of the blue current. Birds chattered in the trees and big fish darted through the pellucid depths. The air was like champagne, and "(the Spaniards)" drank deep of it, drank in the beauty around them. "¡Es como el sagrado sacramento! (It's like the Blessed Sacrament.)" The valley and the river were then christened after the "Most Holy Sacrament of the Body and Blood of Christ", referring to the Catholic sacrament of the Eucharist.

 John Sutter Sr. first arrived in the area on August 13, 1839, at the divergence of the American and Sacramento Rivers with a Mexican land grant of 50,000 acres. The next year, he and his party established Sutter's Fort, a massive adobe structure with walls eighteen feet high and three feet thick.

Representing Mexico, Sutter Sr. called his colony New Helvetia, a Swiss inspired name, and was the political authority and dispenser of justice in the new settlement. Soon, the colony began to grow as more and more pioneers headed west. Within just a few short years, Sutter Sr. had become a grand success, owning a ten-acre orchard and a herd of thirteen thousand cattle. Fort Sutter became a regular stop for the increasing number of immigrants coming through the valley. In 1847 Sutter Sr. received 2,000 fruit trees, which started the agriculture industry in the Sacramento Valley. Later that same year, Sutter Sr. hired James Marshall to build a sawmill so that he could continue to expand his empire, however, unbeknownst to many, Sutter Sr.'s "empire" had been built on some very thin margins of credit.

In 1848, when gold was discovered by James W. Marshall at Sutter's Mill in Coloma (located some northeast of the fort), a large number of gold-seekers came to the area, increasing the population. In August 1848 Sutter Sr.'s son, John Sutter Jr. arrived in the area to assist his father in relieving his indebtedness. Now compounding the problem of his father's indebtedness, was the additional strain placed on the Sutters by the ongoing arrival of thousands of new gold miners and prospectors in the area, many quite content to squat on unwatched portions of the vast Sutter lands, or to abscond with various unattended Sutter properties or belongings if they could. In Sutter's case, rather than being a 'boon' for Sutter, his employee's discovery of gold in the area turned out to be more of a personal 'bane' for him.

By December 1848, John Sutter Jr., in association with Sam Brannan, began laying out the City of Sacramento, 2 miles south of his father's settlement of New Helvetia. This venture was undertaken against the wishes of Sutter Sr., however the father, being deeply in debt, was in no position to stop the venture. For commercial reasons the new city was named "Sacramento City," after the Sacramento River. Sutter Jr. and Brannon hired topographical engineer William H. Warner to draft the official layout of the city, which included 26 lettered and 31 numbered streets (today's grid from C St. to Broadway and from Front St. to Alhambra Blvd.). Unfortunately, a certain bitterness grew between the elder Sutter and his son as Sacramento became an overnight commercial success (Sutter's Fort, Mill and the town of Sutterville, all founded by John Sutter, Sr., would eventually fail).

The citizens of Sacramento adopted a city charter in 1849, which was recognized by the state legislature in 1850. Sacramento is the oldest incorporated city in California, incorporated on February 27, 1850. During the early 1850s, the Sacramento valley was devastated by floods, fires and cholera epidemics. Despite this, because of its position just downstream from the Mother Lode in the Sierra Nevada, the new city grew, quickly reaching a population of 10,000.

Throughout the early 1840s and 1850s, China was at war with Great Britain and France in the First and Second Opium Wars. The wars, along with endemic poverty in China, helped drive many Chinese immigrants to America. Many first came to San Francisco, which was then the largest city in California, and known as "Dai Fow" (The Big City), and some came eventually to Sacramento (then the second-largest city in California), also known as "Yee Fow" (Second City). Many of these immigrants came in hope of a better life as well as the possibility of finding gold in the foothills east of Sacramento.

Sacramento's Chinatown was located on "I" Street from Second to Sixth Streets. At the time, this area of "I" Street was considered a health hazard because - lying within a levee zone - it was lower than other parts of the city, which were situated on higher land. Throughout Sacramento's Chinatown history, there were fires, acts of discrimination, and prejudicial legislation such as the Chinese Exclusion Act that was not repealed until 1943. The mysterious fires were thought to be set off by those who did not take a liking to the Chinese working class. Ordinances on what was viable building material were set into place to try to get the Chinese to move out. Newspapers such as The Sacramento Union wrote stories at the time that portrayed the Chinese in an unfavorable light to inspire ethnic discrimination and drive the Chinese away. As the years passed, a railroad was created over parts of the Chinatown, and further politics and laws would make it even harder for Chinese workers to sustain a living in Sacramento. While the east side of the country fought for higher wages and fewer working hours, many cities in the western United States wanted the Chinese out because of the belief that they were stealing jobs from the white working class.

The Chinese remained resilient despite these efforts. They built their buildings out of bricks just as the building guidelines were established. They helped build part of the railroads that span the city as well as made a great contribution to the transcontinental railroad that spans the United States. They also helped build the levees within Sacramento and its surrounding cities. As a result, the Chinese are a well-recognized part of Sacramento's history and heritage.

While most of Sacramento's Chinatown has now been razed, a small Chinatown mall remains as well as a museum dedicated to the history of Sacramento's Chinatown and the contributions Chinese Americans have made to the city. Amtrak sits along what was part of Sacramento's Chinatown "I" Street.

The California State Legislature, with the support of Governor John Bigler, moved to Sacramento in 1854. The capital of California under Spanish (and, subsequently, Mexican) rule had been Monterey, where in 1849 the first Constitutional Convention and state elections were held. The convention decided that San Jose would be the new state's capital. After 1850, when California's statehood was ratified, the legislature met in San Jose until 1851, Vallejo in 1852, and Benicia in 1853, before moving to Sacramento. In the 1879 Constitutional Convention, Sacramento was named to be the permanent state capital.

Begun in 1860 to be reminiscent of the United States Capitol in Washington, D.C., the Classical Revival style California State Capitol was completed in 1874. In 1861, the legislative session was moved to the Merchants Exchange Building in San Francisco for one session because of massive flooding in Sacramento. The legislative chambers were first occupied in 1869 while construction continued. From 1862 to 1868, part of the Leland Stanford Mansion was used for the governor's offices during Stanford's tenure as the Governor; and the legislature met in the Sacramento County Courthouse.

With its new status and strategic location, Sacramento quickly prospered and became the western end of the Pony Express. Later it became a terminus of the First Transcontinental Railroad, which began construction in Sacramento in 1863 and was financed by "The Big Four"—Mark Hopkins, Charles Crocker, Collis P. Huntington, and Leland Stanford.

In 1850 and again in 1861, Sacramento citizens were faced with a completely flooded town. After the devastating 1850 flood, Sacramento experienced a cholera epidemic and a flu epidemic, which crippled the town for several years. In 1861, Governor Leland Stanford, who was inaugurated in early January 1861, had to attend his inauguration in a rowboat, which was not too far from his house in town on N street. The flood waters were so bad, the legend says, that when he returned to his house, he had to enter into it through the second floor window. From 1862 until the mid-1870s Sacramento raised the level of its downtown by building reinforced brick walls on its downtown streets, and filling the resulting street walls with dirt. Thus the previous first floors of buildings became the basements, with open space between the street and the building, previously the sidewalk, now at the basement level. Most property owners used screw jacks to raise their buildings to the new grade. The sidewalks were covered, initially by wooden sidewalks, then brick barrel vaults, and eventually replaced by concrete sidewalks. Over the years, many of these underground spaces have been filled or destroyed by subsequent development. However, it is still possible to view portions of the "Sacramento Underground".

The same rivers that earlier brought death and destruction began to provide increasing levels of transportation and commerce. Both the American and especially Sacramento rivers would be key elements in the economic success of the city. In fact, Sacramento effectively controlled commerce on these rivers, and public works projects were funded though taxes levied on goods unloaded from boats and loaded onto rail cars in the historic Sacramento Rail Yards. Now both rivers are used extensively for recreation. The American River is a 5-mph (8-km/h) waterway for all power boats (including jet-ski and similar craft) (Source Sacramento County Parks & Recreation) and has become an international attraction for rafters and kayaking.

The Sacramento River sees many boaters, who can make day trips to nearby sloughs or continue along the Delta to the Bay Area and San Francisco. The "Delta King", a paddlewheel steamboat which for eighteen months lay on the bottom of the San Francisco Bay, was refurbished and now boasts a hotel, a restaurant, and two different theaters for nightlife along the Old Sacramento riverfront.

The city's current charter was adopted by voters in 1920. As a charter city, Sacramento is exempt from many laws and regulations passed by the state legislature. The city has expanded continuously over the years. The 1964 merger of the City of North Sacramento with Sacramento substantially increased its population, and large annexations of the Natomas area eventually led to significant population growth throughout the 1970s, 1980s, and 1990s.

Sacramento County (along with a portion of adjacent Placer County) is served by a customer-owned electric utility, the Sacramento Municipal Utility District (SMUD). Sacramento voters approved the creation of SMUD in 1923. In April 1946, after 12 years of litigation, a judge ordered Pacific Gas & Electric to transfer title of Sacramento's electric distribution system to SMUD. Today SMUD is the sixth-largest public electric utility in the U.S., and is a leader for innovative programs and services, including the development of clean fuel resources, such as solar power. The year following the creation of SMUD, 1924, brought several events in Sacramento: Standard Oil executive Verne McGeorge established McGeorge School of Law, American department store Weinstock & Lubin opened a new store at 12th and K street, the US$2 million Senator Hotel was open, Sacramento's drinking water became filtered and treated drinking water, and Sacramento boxer Georgie Lee fought Francisco Guilledo, a Filipino professional boxer known as Pancho Villa, at L Street Auditorium on March 21.

Early in World War II, the Sacramento Assembly Center (also known as the Walerga Assembly Center) was established to house Japanese Americans forcibly "evacuated" from the West Coast under Executive Order 9066. The camp was one of fifteen temporary detention facilities where over 110,000 Japanese Americans, two-thirds of them U.S. citizens, were held while construction on the more permanent War Relocation Authority camps was completed. The assembly center was built on the site of a former migrant labor camp, and inmates began arriving from Sacramento and San Joaquin Counties on May 6, 1942. It closed after only 52 days, on June 26, and the population of 4,739 was transferred to the Tule Lake concentration camp. The site was then turned over to the Army Signal Corps and dedicated as Camp Kohler. After the war and the end of the incarceration program, returning Japanese Americans were often unable to find housing and so 234 families temporarily lived at the former assembly center. Camp Kohler was destroyed by a fire in December 1947, and the assembly center site is now part of the Foothill Farms-North Highlands subdivision.

The Sacramento-Yolo Port District was created in 1947, and ground was broken on the Port of Sacramento in 1949. On June 29, 1963, with 5,000 spectators waiting to welcome her, the Motor Vessel "Taipei Victory" arrived. The port was open for business. The Nationalist Chinese flagship, freshly painted for the historic event, was loaded with 5,000 tons of bagged rice for Mitsui Trading Co. bound for Okinawa and 1,000 tons of logs for Japan. She was the first ocean-going vessel in Sacramento since the steamship "Harpoon" in 1934. The Port of Sacramento has been plagued with operating losses in recent years and faces bankruptcy. This severe loss in business is due to the heavy competition from the Port of Stockton, which has a larger facility and a deeper channel. As of 2006, the city of West Sacramento took responsibility for the Port of Sacramento. During the Vietnam War era, the Port of Sacramento was the major terminus in the supply route for all military parts, hardware and other cargo going to Southeast Asia.
In 1967, Ronald Reagan became the last Governor of California to live permanently in the city. A new executive mansion, constructed by private funds in a Sacramento suburb for Reagan, remained vacant for nearly forty years and was recently sold by the state.

The 1980s and 1990s saw the closure of several local military bases: McClellan Air Force Base, Mather Air Force Base, and Sacramento Army Depot. In 1980, there was another flood. The flood's damage affected the "boat section" of Interstate 5. The culmination of a series of storms as well as a faulty valve are believed to have caused this damage.
In the early 1990s, Mayor Joe Serna attempted to lure the Los Angeles Raiders football team to Sacramento, selling $50 million in bonds as earnest money. When the deal fell through, the bond proceeds were used to construct several large projects, including expanding the Sacramento Convention Center Complex and refurbishing of the Memorial Auditorium. Serna renamed a city park for migrant worker rights activist Cesar Chavez. Through his effort, Sacramento became the first major city in the country to have a paid municipal holiday honoring Chavez.

In spite of military base closures and the decline of agricultural food processing, Sacramento has continued to experience population growth in recent years. Primary sources of population growth are an influx of residents from the nearby San Francisco Bay Area, as well as immigration from Asia and Latin America. From 1990 to 2000, the city's population grew by 14.7%. The United States Census Bureau estimates that from 2000 to 2007, the county's population increased by nearly 164,000 residents.

In the late 1990s and early 2000s (decade), Mayor Heather Fargo made several abortive attempts to provide taxpayer financing of a new sports arena for the Maloof brothers, owners of the Sacramento Kings NBA Basketball franchise. In November 2006, Sacramento voters soundly defeated a proposed sales tax hike to finance the plan. The defeat was due in part to competing plans for the new arena and its location. After acquiring the majority stake in the Sacramento Kings, the team's new owner, Vivek Ranadivé with the help of the city, agreed to build a new Arena in the downtown area. With a final estimated cost of $558.2 million, Sacramento's Golden 1 Center opened on September 30, 2016.

Despite a devolution of state bureaucracy, the state government remains by far Sacramento's largest employer. The City of Sacramento expends considerable effort to keep state agencies from moving outside the city limits. In addition, many federal agencies have offices in Sacramento. (The California Supreme Court normally sits in nearby San Francisco.)

According to the United States Census Bureau, the city covers an area of , 97.81% of it land, and 2.19% of it water.

Depth to groundwater is typically about . Much of the land to the west of the city (in Yolo County) is permanently reserved for a vast flood control basin (the Yolo Bypass), due to the city's historical vulnerability to floods. As a result, the greater metropolitan area sprawls only four miles (6 km) west of downtown (as West Sacramento, California) but northeast and east, into the Sierra Nevada foothills, and to the south into valley farmland.

The city is located at the confluence of the Sacramento River and the American River, and has a deep-water port connected to the San Francisco Bay by a channel through the Sacramento–San Joaquin River Delta. It is the shipping and rail center for the Sacramento Valley. Food processing is among the major industries in the area.

The city groups most of its neighborhoods into four areas:

Alkali Flat, Boulevard Park, Campus Commons, Sacramento State, Dos Rios Triangle, Downtown, East Sacramento, Fab Forties, Mansion Flats, Marshall School, Midtown, New Era Park, McKinley Village, Newton Booth, Old Sacramento, Poverty Ridge, Richards, Richmond Grove, River Park, Elmhurst, Sierra Oaks, Southside Park.

Airport, Carleton Tract, Freeport Manor, Golf Course Terrace, Greenhaven, Curtis Park, Hollywood Park, Land Park, Little Pocket, Mangan Park, Meadowview, Parkway, Pocket, Sacramento City College, South Land Park, Valley Hi / North Laguna, Z'Berg Park.

Alhambra Triangle, Avondale, Brentwood, Carleton Tract, Colonial Heights, Colonial Village, Colonial Village North, Curtis Park, Elmhurst, Fairgrounds, Florin, Industrial Park, Fruitridge Manor, Glen Elder, Glenbrook, Granite Regional Park, Lawrence Park, Med Center, North City Farms, Oak Park, Packard Bell, South City Farms, Southeast Village, Tahoe Park, Tahoe Park East, Tahoe Park South, Tallac Village, Vintage Park, Churchill Downs, and Woodbine.

Ben Ali, Del Paso Heights, Gardenland, Hagginwood, McClellan Heights West, Natomas (north, south, west), North Sacramento, Northgate, Robla, Swanston Estates, Terrace Manor, Valley View Acres, and Woodlake.

Additional prominent regions and neighborhoods in the city include American River Parkway, Arden-Arcade, Arden Fair, Cal Expo, Capital Avenue, Coffing, College Glen, College Greens, Colonial Manor, Cordova, Creekside, East Fruitridge, Elder Creek, Elkhorn, Elvas, Erikson Industrial Park, Excelsior Sunrise, Foothill Farms, Franklin, Frates Ranch, Gateway Center, Gateway West, Glenwood Meadows, Hansen Park, Heritage Park, Johnson Business Park, Johnson Heights, Mayhew, Metro Center, Mills, Natomas Corporate Center, Natomas Creek, Natomas Crossing, Natomas Park, Newton Booth, Noralto, Northpointe, Norwood, Oak Knoll, Old North Sacramento, Parker Homes, Point West, Raley Industrial Park, Regency Park, Richardson Village, Richmond Grove, Rosemont, Sierra Oaks, Sports Complex, Strawberry Manor, Sundance Lake, Swanston Palms, Town and Country Village, Upper Land Park, Village 5, Village 7, Village 12, Village 14, Village Green, Walerga, Walsh Station, West Del Paso Heights, Westlake, Willowcreek, Wills Acres, Winn Park, Woodside and Youngs Heights.

Sacramento has a hot-summer Mediterranean climate (Köppen "Csa"), characterized by damp to wet, mild winters and hot, dry summers. The wet season is generally October through April, though there may be a day or two of light rainfall in June or September. The normal annual mean temperature is , with the monthly daily average temperature ranging from in December to in July. Summer heat is often moderated by a sea breeze known as the "delta breeze" which comes through the Sacramento–San Joaquin River Delta from the San Francisco Bay, and temperatures cool down sharply at night.

The foggiest months are December and January. Tule fog can be extremely dense, lowering visibility to less than and making driving conditions extremely hazardous. Chilling tule fog events have been known to last for several consecutive days or weeks. During Tule fog events, temperatures do not exceed 50 degrees.

Snowfall is rare in Sacramento, which is only above sea level. In the downtown area, there have been only 3 significant snow accumulations since 1900, the last one being in 1976. During especially cold winter and spring storms, intense showers do occasionally produce a significant amount of hail, which can create hazardous driving conditions. Snowfall that does fall in the city often melts upon ground contact, with traceable amounts occurring in some years. Significant annual snow accumulations occur in the foothills located east of the city, which had brief and traceable amounts of snowfall in January 2002, December 2009 and February 2011. The greatest snowfall ever recorded in Sacramento was on January 5, 1888.

On average, there are 73 days where the high exceeds , and 14 days where the high exceeds ; On the other extreme, there are 15 days where the temperature does not exceed , and 15 freezing nights per year. Official temperature extremes range from on December 22, 1990 to on June 15, 1961; a station around east-southeast of the city dipped to on December 11, 1932.

The average annual precipitation is . On average, precipitation falls on 60 days each year in Sacramento, and nearly all of this falls during the winter months. Average January rainfall is , and measurable precipitation is rare during the summer months. In February 1992, Sacramento had 16 consecutive days of rain, resulting in an accumulation of for the period. On rare occasions, monsoonal moisture surges from the Desert Southwest can bring upper-level moisture to the Sacramento region, leading to increased summer cloudiness, humidity, and even light showers and thunderstorms. Monsoon clouds do occur, usually during late July through early September. Sacramento is the second most flood susceptible city in the United States after New Orleans.

Sacramento has been noted as being the sunniest location on the planet for three months of the year, from July through September. It holds the distinction as the sunniest month, in terms of percent possible sunshine, of anywhere in the world; July in Sacramento averages 14 hours and 12 minutes of sunshine per day, amounting to approximately 98% of possible sunshine.

In 2002, the Civil Rights Project at Harvard University conducted for "Time" magazine named Sacramento "America's Most Diverse City". The U.S. Census Bureau also groups Sacramento with other U.S. cities having a "high diversity" rating of the diversity index. Moreover, Sacramento is one of the most well-integrated U.S. cities, having a relatively high level of ethnic and racial heterogeneity within its neighborhoods.

The 2010 United States Census reported that Sacramento had a population of 466,488. The population density was 4,660.0 people per square mile (1,799.2/km).

The racial makeup of Sacramento was:

Hispanic or Latino of any race were 125,276 persons (26.9%); 22.6% of Sacramento's population is of Mexican heritage, 0.7% Puerto Rican, 0.5% Salvadoran, 0.2% Guatemalan, and 0.2% Nicaraguan. Non-Hispanic Whites were 34.5% of the population in 2010, down from 71.4% in 1970.

The Census reported that 458,174 people (98.2% of the population) lived in households, 4,268 (0.9%) lived in non-institutionalized group quarters, and 4,046 (0.9%) were institutionalized. Also, with the recent housing crash there have been no changes to these numbers.

There were 174,624 households, out of which 57,870 (33.1%) had children under the age of 18 living in them, 65,556 (37.5%) were opposite-sex married couples living together, 27,640 (15.8%) had a female householder with no husband present, 10,534 (6.0%) had a male householder with no wife present. There were 13,234 (7.6%) unmarried opposite-sex partnerships, and 2,498 (1.4%) same-sex married couples or partnerships. 53,342 households (30.5%) were made up of individuals and 14,926 (8.5%) had someone living alone who was 65 years of age or older. The average household size was 2.62. There were 103,730 families (59.4% of all households); the average family size was 3.37.

Sacramento has one of the highest LGBT populations per capita, ranking seventh among major American cities, and third in California behind San Francisco and slightly behind Oakland, with roughly 10% of the city's total population identifying themselves as gay, lesbian, or bisexual.

The age distribution of the city was follows: 116,121 people (24.9%) were under the age of 18, 52,438 people (11.2%) aged 18 to 24, 139,093 people (29.8%) aged 25 to 44, 109,416 people (23.5%) aged 45 to 64, and 49,420 people (10.6%) who were 65 years of age or older. The median age was 33.0 years. For every 100 females, there were 94.9 males. For every 100 females age 18 and over, there were 92.2 males.

There were 190,911 housing units at an average density of 1,907.1 per square mile (736.3/km), of which 86,271 (49.4%) were owner-occupied, and 88,353 (50.6%) were occupied by renters. The homeowner vacancy rate was 2.8%; the rental vacancy rate was 8.3%. 231,593 people (49.6% of the population) lived in owner-occupied housing units and 226,581 people (48.6%) lived in rental housing units.

As of the census of 2000, there are 407,018 people, 154,581 households, and 91,202 families residing in the city. The population density is 4,189.2 people per square mile (1,617.4/km). There are 163,957 housing units at an average density of 1,687.5 per square mile (651.5/km). The racial makeup of the city is 41.1% White, 19.5% African American, 1.3% Native American, 12.6% Asian, 0.9% Native Hawaiian and Pacific Islander, 11.0% from other races, and 6.4% from two or more races. 21.6% of the population are Hispanic or Latino of any race.

There are 154,581 households out of which 30.2% have children under the age of 18 living with them, 38.4% are married couples living together, 15.4% have a female householder with no husband present, and 41.0% are non-families. 32.0% of all households are made up of individuals and 9.2% have someone living alone who is 65 years of age or older. The average household size is 2.57 and the average family size is 3.35.

In the city, the age distribution of the population shows 27.3% under the age of 18, 10.4% from 18 to 24, 30.7% from 25 to 44, 20.2% from 45 to 64, and 11.4% who are 65 years of age or older. The median age is 33 years. For every 100 females, there are 94.5 males. For every 100 females age 18 and over, there are 91.0 males.

The median income for a household in the city is $37,049, and the median income for a family is $42,051. Males have a median income of $35,946 versus $31,318 for females. The per capita income for the city is $18,721. 20.0% of the population and 15.3% of families are below the poverty line. Out of the total population, 29.5% of those under the age of 18 and 9.0% of those 65 and older are living below the poverty line.

Sutter Health, Blue Diamond Growers, Aerojet, Teichert, and The McClatchy Company are among the companies based in Sacramento.

As of 2012, the top employers in the County of Sacramento were:

The oldest part of the town besides Sutter's Fort is Old Sacramento, which consists of cobbled streets and many historic buildings, several from the 1850s and 1860s. Buildings have been preserved, restored or reconstructed, and the district is now a substantial tourist attraction, with rides on steam-hauled historic trains and horse-drawn carriages.

The historic buildings include the Lady Adams Building, built by the passengers and ship's carpenters of the ship "Lady Adams". Having survived the Great Conflagration of November 1852, it is the oldest surviving building in Sacramento other than Sutter's Fort. 

Another surviving landmark is the B.F. Hastings building, built in 1853. Early home of the California Supreme Court and the location of the office of Theodore Judah, it also was the western terminus of the Pony Express.

The "Big Four Building", built in 1852, was home to the offices of Collis Huntington, Mark Hopkins, Leland Stanford, and Charles Crocker. The Central Pacific Railroad and Southern Pacific Railroad were founded there. The original building was destroyed in 1963 for the construction of Interstate 5, but was re-created using original elements in 1965. It is now a National Historic Landmark. Also of historic interest is the Eagle Theatre (Sacramento, California), a reconstruction of California's first permanent theatre in its original location.

There are several major theatre venues for Sacramento. The Sacramento Convention Center Complex governs both the Community Center Theatre and Memorial Auditorium. The Wells Fargo Pavilion is the most recent addition in 2003. It is built atop the old Music Circus tent foundations. Next to that is the McClatchy Main stage, originally built as a television studio, which was renovated at the same time the pavilion was built. It is the smaller of the venues and provides seating for only 300. The Sacramento Ballet, Sacramento Philharmonic Orchestra and the Sacramento Opera perform at the Community Center Theater.

Professional theatre is represented in Sacramento by a number of companies. California Musical Theatre and its Summer stock theatre, Music Circus, lure many directors, performers, and artists from New York and Los Angeles to work alongside a large local staff for their productions at the Wells Fargo Pavilion. During the fall, winter and spring seasons Broadway Sacramento brings bus and truck tours to the Community Center Theater. At the B Street Theatre, smaller and more intimate professional productions are performed as well as a children's theatre that will soon be opening a larger theatre complex in the heart of midtown in 2014. Rounding out the professional companies is Capital Stage, which performed aboard the Delta King until the end of the 2010–2011 season and soon took up residence at its own venue along the J-Street corridor.

The Sacramento area has one of the largest collection of community theatres in California. Some of these include the Thistle Dew Dessert Theatre and Playwrights Workshop, Davis Musical Theatre Co., El Dorado Musical Theatre, Runaway Stage Productions, River City Theatre Company, Flying Monkey Productions, The Actor's Theatre, KOLT Run Productions, Kookaburra Productions, Big Idea Theatre, Celebration Arts, Lambda Player, Light Opera Theatre of Sacramento, Synergy Stage and the historic Eagle Theatre. The Sacramento Shakespeare Festival provides entertainment under the stars every summer in William Land Park. Many of these theatres compete annually for the Elly Awards overseen by The Sacramento Area Regional Theatre Alliance or SARTA.

The Sacramento Metropolitan Arts Commission is an organization which was established as the Sacramento arts council in 1977 to provide several arts programs for the city. These include Art in Public Places, Arts Education, Grants and Cultural Programs, Poet Laureate Program, Arts Stabilization Programs and Other Resources and opportunities.

Sacramento Second Saturday Art Walk is a program of local art galleries that stay open into the late evenings every second Saturday of each month, providing a unique experience for the local population as well as tourists to view original art and meet the artists themselves.

Sacramento has several major museums. The Crocker Art Museum is the oldest public art museum west of the Mississippi River. On July 26, 2007, the museum broke ground for an expansion that more than tripled the museum's floor space. The modern architecture is very different from the museum's original Victorian style building. Construction was completed in 2010.
Also of interest is the Governor's Mansion State Historic Park, a large Victorian Mansion which was home to 13 of California's Governors, as well as the official residence for current governor Jerry Brown following renovations in 2015. The Leland Stanford Mansion State Historic Park, which was completely restored in 2006, serves as the State's official address for diplomatic and business receptions. Guided public tours are available. The California Museum for History, Women, and the Arts, home of the California Hall of Fame, is a cultural destination dedicated to telling the rich history of California and its unique influence on the world of ideas, innovation, art and culture. The museum educates tens of thousands of school children through inspiring programs, sharing with world visitors California's rich art, history and cultural legacy through dynamic exhibits, and serving as a public forum and international meeting place. The California State Railroad Museum in Old Sacramento has historical exhibits and live steam locomotives that patrons may ride. The California Automobile Museum, located just south of Old Sacramento, is filled with automotive history and vehicles from 1880 to 2006 and is the oldest non-profit automotive museum in the West. The mission of it is to preserve, promote, and teach automotive culture and its influence on our lives—past, present and future. In addition, the Sacramento History Museum, in the heart of Old Sacramento, focuses on the history of Sacramento from the region's pre-Gold Rush history through the present day.

There is a Museum Day held in Sacramento every year, when 26 museums in the greater Sacramento area offer free admission. The 2009 Sacramento Museum Day brought out more than 80,000 people, the largest number the event has gathered. Sacramento Museum Day is held every year on the first Saturday of February.

Tower Records was started and based in Sacramento until its closing.
Rappers C-Bo, Marvaless, and Lunasicc are among those native to the area. Classical music is widely available. The Sacramento Philharmonic Orchestra, the Sacramento Baroque Soloists, the Sacramento Choral Society & Orchestra, the Sacramento Youth Symphony, the Sacramento Master Singers, the Sacramento Children's Chorus, and the Camellia Symphony each present a full season of concerts.

Each year, the city hosts the Sammies, the Sacramento Music Awards. Sacramento also has a reputation as a center for Dixieland jazz, because of the Sacramento Jazz Jubilee which is held every Memorial Day weekend. Events and performances are held in multiple locations throughout the city. Each year thousands of jazz fans from all over the world visit for this one weekend.

A growing number of rock, hardcore and metal bands hail from the Sacramento area, including Tesla, Deftones, Papa Roach, Will Haven, Trash Talk, Dance Gavin Dance, A Lot Like Birds, Far, CAKE, !!!, Oleander and Steel Breeze; plus some other famous musicians like record producer and recording artist Charlie Peacock, Bob Stubbs of Social Distortion and Craig Chaquico of Jefferson Starship. Along with these bands, the Aftershock Festival has been held at Discovery Park since 2012.

Scottish pop band Middle of the Road sang kindly of Sacramento in their 1972 European hit song "Sacramento". Experimental groups such as Hella, Death Grips, and Tera Melos also come out of Sacramento.

Sacramento is home to the Sacramento French Film Festival, a cultural event held every year in July that features U.S. premieres of French films and classic masterpieces of French cinema and the Sacramento Japanese Film Festival, also held in July. In addition, Sacramento is home to the Trash Film Orgy, a summer film festival celebrating the absurd, B-movies, horror, monster, exploitation. Founded in 2007, the Sacramento Horror Film Festival showcases feature-length and short films as well as live musical and theatrical performances in the horror and macabre genres.

Of note, Sacramento has been home to various actors, including Eddie Murphy, who resided in the Riverlake community of Pocket-Greenhaven with his then wife Nicole Mitchell Murphy, a fashion model and Sacramento native. It is also the home of director Greta Gerwig, whose solo directorial debut Lady Bird is set in Sacramento.

In 2012, Sacramento started the marketing campaign as "America's Farm-to-Fork Capital" due to Sacramento's many restaurants that source their food locally from the numerous surrounding farms. The city has an annual Farm-to-Fork festival that showcases various grocers and growers in the industry. In 2012, The Kitchen was nominated for Outstanding Restaurant by the James Beard Foundation. It continues to excel, earning the AAA's Five Diamond dining award since 2011. Sacramento is home to well-known cookbook authors, Biba Caggiano of Biba's Restaurant and Mai Pham of Lemongrass and Star Ginger.

Sacramento is also known for its beverage culture, with keystone events that include Cal Expo's Grape and Gourmet, Sacramento Beer Week, and Sacramento Cocktail Week. Its growing beer scene is evident, with over 60 microbreweries in the region as of 2017. Some local brews include Track 7 Brewing Company, Big Stump Brew Co, Oak Park Brewing Co., and Sactown Union Brewery. Numerous beer festivals around the region highlight both local and visitor beers. In addition to festivals in Elk Grove, Davis, Roseville, Placerville, and Woodland, Sacramento hosts the annual California Beer Craft Summit, an exposition dedicated to the art of brewing. The summit also hosts the largest beer festival on the West Coast, featuring over 160 breweries in downtown Sacramento.

Sacramento's contemporary culture is reflected in its coffee. An "underrated coffee city", Sacramento has above-average marks for local coffee. The city has numerous community roasters and coffee shops. Examples include Temple Coffee, Insight Coffee Roasters, Old Soul Co., Chocolate Fish Roasters, Naked Lounge, Pachamama Roasting Co., and Identity Coffees. In addition to local brands, the region offers other chains like Starbucks, Peet's Coffee & Tea, and Philz Coffee.

Sacramento has one of the highest LGBT populations per capita, ranking seventh among major American cities, and third in California behind San Francisco and slightly behind Oakland, with roughly 10% of the city's total population identifying themselves as gay, lesbian, or bisexual. Lavender Heights, Sacramento, California is the hub for LGBTQ activities in the city and is a centrally located district in Midtown Sacramento centered within and around K & 20th streets. The area owes its name to the high number of gay-owned homes and businesses residing there. The area is also home to many of the city's LGBTQ inclusive music and arts festivals, including the Second Saturday Block Party from May to September.

Sacramento is home to one major league sports team — the Sacramento Kings of the National Basketball Association. The Kings came to Sacramento from Kansas City in 1985. On January 21, 2013, a controlling interest of the Sacramento Kings was sold to Chris Hansen, who intended to move the franchise to Seattle for the 2013–2014 NBA season and rename the team the Seattle SuperSonics. Sacramento Mayor Kevin Johnson fought the move, forming an ownership group led by Vivek Ranadive to keep the Kings in Sacramento. On May 16, 2013, the NBA Board of Governors voted 22–8 to keep the Kings in Sacramento.

Sacramento has two other professional teams. Sacramento Republic FC began play in April 2014 at Hughes Stadium before a sellout crowd of 20,231, setting a USL Pro regular-season single game attendance record. The Republic FC won the USL championship in their first season. In 2000, AAA minor league baseball returned to Sacramento with the Sacramento River Cats, an affiliate of the San Francisco Giants and formerly an affiliate of the Oakland Athletics. The River Cats play in Raley Field, in West Sacramento.

Sacramento is the former home of two professional basketball teams. The Sacramento Heatwave of the American Basketball Association previously played in the Sacramento area until 2013. Sacramento was also formerly home to the now defunct Sacramento Monarchs of the WNBA. The Monarchs were one of the eight founding members of the WNBA in 1997 and won the WNBA Championship in 2005, but folded in November 2009.

Sacramento has frequently hosted the NCAA Men's Outdoor Track and Field Championship as well as the 1st and 2nd rounds of the NCAA Men's Division I Basketball Championship. The California International Marathon (est. 1983) attracts a field of international elite runners who vie for a share of the $50,000 prize purse. The fast course is popular for runners seeking to achieve a Boston Marathon qualifying time and fitness runners.

Sacramento boasts an extensive park system consisting of over of parkland and recreation centers. The city features a collection of smaller parks in the Downtown districts, including Crocker Park, Pioneer Landing and Southside Park. Popular parks outside the central core include American River Parkway which spans 23 miles along the American River, and William Land Park.

In its 2013 ParkScore ranking, The Trust for Public Land reported that Sacramento was tied with San Francisco and Boston for having the 3rd best park system among the 50 most populous U.S. cities. ParkScore ranks city park systems by a formula that analyzes the city's median park size, park acres as percent of city area, the percent of residents within a half-mile of a park, spending of park services per resident, and the number of playgrounds per 10,000 residents.

Sacramento is a hotbed for high school rugby. Jesuit High is the recent defending national champion (winning five times in total). Their arch-rival school Christian Brothers came in second nationwide. Burbank, Del Campo and Vacaville have also placed well in the national competition over the years. The Sacramento Valley High School Rugby Conference hosts the largest and arguably deepest preseason youth and high school rugby tournament in America.

Sacramento hosts some recreational facilities and events. The Jedediah Smith Memorial Trail that runs between Old Sacramento and Folsom Lake grants access to the American River Parkway, a natural area that includes more than of undeveloped land. It attracts cyclists and equestrians from across the state. The California State Fair is held in Sacramento each year at the end of the summer, ending on Labor Day. In 2010, the State Fair moved to July. More than one million people attended this fair in 2001.

Among other recreational options in Sacramento is Discovery Park, a park studded with stands of mature trees and grasslands. This park is situated where the American River flows into the Sacramento River.

In amateur sports, Sacramento claims many prominent Olympians such as Mark Spitz, Debbie Meyer (6 time gold medalist in for US swimming), Mike Burton, Summer Sanders (Gold medalist in swimming, and trained in childhood by Debbie Meyer at Rio Del Oro Racquet Club), Jeff Float (all swimming), and Billy Mills (track). Coach Sherm Chavoor founded his world-famous Arden Hills Swim Club just east of the city and trained Burton, Spitz and others.

The government of Sacramento operates as a charter city (as opposed to a general law city) under the Charter of the City of Sacramento. The elected government is composed of the Sacramento City Council with 8 city council districts and the Mayor of Sacramento, which operate under a mayor-council government. In addition, there are numerous departments and appointed officers such as the City Manager, Sacramento Police Department (SPD), the Sacramento Fire Department (SFD), City Clerk, City Attorney, and City Treasurer. As of 2016, the mayor is Darrell Steinberg and the council members are Angelique Ashby, Allen Warren, Jeff Harris, Steve Hansen, Jay Schenirer, Rich Jennings, and Larry Carr.

The City of Sacramento is part of Sacramento County, for which the government of Sacramento County is defined and authorized under the California Constitution, California law, and the Charter of the County of Sacramento. Much of the government of California is in practice the responsibility of county governments, such as the Government of Sacramento County. The county government provides countywide services such as elections and voter registration, law enforcement, jails, vital records, property records, tax collection, public health, and social services. The government of Sacramento County is composed of the elected five-member Board of Supervisors, several other elected offices, including the Sheriff, District Attorney, and Assessor, and numerous county departments and entities under the supervision of the County Executive Officer. Sacramento is located within all of the supervisorial districts, currently represented by Phil Serna, Jimmie R. Yee, Susan Peters, Roberta MacGlashan, and Don Nottoli. The other officials elected in part by Sacramento residents currently include Sheriff Scott Jones, District Attorney Anne Marie Schubert, and Assessor Kathleen Kelleher. In addition, several other entities of the government of California have jurisdiction conterminous with Sacramento County, such as the Sacramento County Superior Court.

In the California State Senate, Sacramento is the heart of the 6th district, represented by Democrat Richard Pan. In the California State Assembly, it is split between , and .

In the United States House of Representatives, Sacramento forms the majority of the .

The Sacramento area hosts a wide variety of higher educational opportunities. There are two major public universities, many private institutions, community colleges, vocational schools, and McGeorge School of Law.

Sacramento is home to Sacramento State (California State University, Sacramento), founded as Sacramento State College in 1947. In 2004, enrollment was 22,555 undergraduates and 5,417 graduate students in the university's eight colleges. The university's mascot is the hornet, and the school colors are green and gold. The campus is located along the American River Parkway a few miles east of downtown.

The University of California has a campus, UC Davis, in nearby Davis and has a graduate center in downtown Sacramento. The UC Davis Graduate School of Management (GSM) is near the UC Davis Medical Center off of Stockton Boulevard near Highway 50. Many students, about 400 out of 517, at the UC Davis GSM are working professionals and are completing their MBA part-time. The part-time program is ranked in the top-20 and is well known for its small class size, world class faculty, and involvement in the business community. UC also maintains the University of California Sacramento Center (UCCS) for undergraduate and graduate studies. Similar to the UC's Washington, D.C., program, "Scholar Interns" engage in both academic studies and as well as internships, often with the state government. The UC Davis School of Medicine is located at the UC Davis Medical Center between the neighborhoods of Elmhurst, Tahoe Park, and Oak Park.

The Los Rios Community College District consists of several two-year colleges in the Sacramento area—American River College, Cosumnes River College, Sacramento City College, Folsom Lake College, plus a large number of outreach centers for those colleges. Sierra College is on the outskirts of Sacramento in Rocklin.

University of the Pacific has its Sacramento Campus in the Oak Park neighborhood of Sacramento. The campus houses McGeorge School of Law, a top 100 law school according to "U.S. News & World Report"'s annual rankings of U.S. law schools (2006, 2007 & 2008). In 2015, the campus was expanded to become a comprehensive graduate and professional campus, including programs in analytics, business, education, health sciences, and public policy.

The National University Sacramento regional campus offers bachelor's and master's degrees in business, education, health-care and teaching credential programs.

The University of San Francisco has one of its four regional campuses in Sacramento. At the undergraduate level they offer degrees in Applied Economics, Information Systems, Organizational Behavior and Leadership, and Public Administration. At the graduate level, Master's programs are offered in: Information Security and Assurance, Information Systems, Organization Development, Project Management, Public Administration, Nonprofit Administration, and Counseling.

The private University of Southern California has an extension in downtown Sacramento, called the State Capital Center. The campus, taught by main campus professors, Sacramento-based professors, and practitioners in the State Capitol and state agencies, offers Master of Public Administration, Masters of Public Policy, and Master of Public Health degrees.

Epic Bible College and the Professional School of Psychology are also based in Sacramento.

Western Seminary has one of its four campuses in Sacramento, which opened on the campus of Arcade Church in 1991. Western is an evangelical, Christian graduate school that provides theological training for students who hope to serve in a variety of ministry roles including pastors, marriage and family therapists, educators, missionaries and lay leadership. The Sacramento campus offers four master's degrees, and a variety of other graduate-level programs.

Sacramento has a number of private vocational schools as well.

A satellite campus of Alliant International University offers graduate and undergraduate programs of study.

The Art Institute of California – Sacramento was established in 2007, and is a branch of The Art Institute of California – Los Angeles. The school is focused on educating students in the field of commercial arts. The school offers both a Bachelor of Science and an Associate of Science degree, as well as diplomas in some areas of study. Some majors the school offers are Digital Film-making & Video Production, Culinary Management, Graphic Design, and Game Art & Design.

On J Street, there is the Lincoln Law School of Sacramento, a private, evening-only law school program with a strong legal presence in the region.

The Universal Technical Institute (UTI) is in Sacramento; it offers automotive programs in auto mechanical, auto body, and diesel.

The Sacramento Public Library system has 28 branches located in the greater area. The Sacramento area is served by various public school districts, including the Sacramento City Unified School District, Natomas Unified School District, San Juan Unified School District, Twin Rivers Unified School District, and Elk Grove Unified School District. As of 2009, the area's schools employed 9,600 elementary school teachers (not including special education teachers), and 7,410 middle school teachers (not including special education or vocational teachers).

Almost all areas south of the American River are served by the Sacramento City Unified School District. The only exceptions are the Valley Hi/North Laguna and Florin areas that are served by the Elk Grove Unified School District.

Areas north of the American River are served by the remaining school districts. This area was not originally part of the City of Sacramento and as such is not served by Sacramento City Unified School District. North Sacramento outside of Natomas and Robla (for K-8) is served by the Twin Rivers Unified School District. The Robla area is served by the Robla School District for K-8 and by Twin Rivers for 9–12. The Natomas region is served by the Natomas Unified School District. The Campus Commons area and the small portions of the Sierra Oaks neighborhood that fall into the city of Sacramento are served by the San Juan Unified School District.

While Roman Catholic institutions still dominate the independent school scene in the Sacramento area, in 1964, Sacramento Country Day School opened and offered Sacramento citizens an independent school that is affiliated with the California Association of Independent Schools. SCDS has grown to its present-day status as a learning community for students from pre-kindergarten through twelfth grade. Additionally, the suburb of Fair Oaks hosts the expansive riverside campus of the Sacramento Waldorf School, a Steiner school adjacent to the Rudolf Steiner College, and the largest Waldorf school in North America. Sacramento Waldorf School educates students from pre-K through 12th grade on a secluded, pastoral site that incorporates a large, functioning biodynamic farm.

Shalom School is the only Jewish day school in Sacramento; however, Brookefield School on property owned by Congregation B'nai Israel provides extracurricular Jewish education.

Capital Christian School is a pre-school–12th grade private, Christian school. There is a small Bible college on campus offering associate degrees in Bible studies or theology. Sacramento Adventist Academy is another Christian school in Greater Sacramento. This is a pre-school–12 institution, as well.

There is one Islamic school in Sacramento, Masjid Annur, founded in 1988.




The Sacramento region is served by several highways and freeways. Interstate 80 (I-80) is the major east-west route, connecting Sacramento with San Francisco in the west, and Reno in the east. Business 80 (the Capital City Freeway) splits from I-80 in West Sacramento, runs through Sacramento, and then rejoins its parent in the northwest portion of the city. U.S. Highway 50 also begins its eastern journey in West Sacramento, co-signed with Business 80, but then splits off and heads toward South Lake Tahoe as the El Dorado Freeway. A sign at the eastern terminus of US 50 in Ocean City, Maryland gives the distance to Sacramento as .

Interstate 5 (I-5) runs though Sacramento, heads north up to Redding, and then heads south near the western edge of the California Central Valley towards Los Angeles. California State Highway 99 runs through Sacramento, heading closer to the eastern edge of the Central Valley, connecting to Marysville and Yuba City in the north, and Fresno and Bakersfield in the south. California State Highway 160 approaches the city after running along the Sacramento River from Contra Costa County in the south, and then becomes a major city street in Downtown Sacramento before turning into the North Sacramento Freeway, going over the American River to Business 80.

Some Sacramento neighborhoods, such as Downtown Sacramento and Midtown Sacramento are very bicycle friendly as are many other communities in the region. As a result of litigation, Sacramento has undertaken to make all city facilities and sidewalks wheelchair accessible. In an effort to preserve its urban neighborhoods, Sacramento has constructed traffic-calming measures in many areas.

Amtrak provides passenger rail service to the city of Sacramento. The Sacramento Valley Rail Station is on the corner of 5th and I streets near the historic Old Town Sacramento and underwent extensive renovations in 2007. The station serves as a Sacramento Regional Transit District Light Rail terminus.

Amtrak California operates the Capitol Corridor, a multiple-frequency service providing service from the capital city to its northeastern suburbs and the San Francisco Bay Area.

Sacramento is the northern terminus of the Amtrak California "San Joaquins" route which provide direct multiple-frequency passenger rail service to California's Central Valley as far as Bakersfield; Thruway Motorcoach connections are available from the trains at Bakersfield to Southern California and Southern Nevada. An additional service under this banner is expected to be routed through Midtown in 2020.

Sacramento is a stop along Amtrak's "Coast Starlight" route which provides scenic service to Seattle via Klamath Falls and Portland to the north and to Los Angeles via San Luis Obispo and Santa Barbara to the south.

Amtrak's "California Zephyr" serves Sacramento daily and provides service to the east serving Reno, Salt Lake, Denver, Omaha, Chicago and intermediate cities.

The Sacramento Valley Rail Station provides numerous Thruway Motorcoach routes. One route serves the cities of Marysville, Oroville, Chico, Corning, Red Bluff and Redding with additional service to Yreka and even Medford, Oregon. A second serves the cities of Roseville, Rocklin, Auburn, Colfax, Truckee, Reno and Sparks. The third and final thruway motorcoach route serves Placerville, Lake Tahoe, Stateline Casinos, and Carson City, Nevada. Each of these routes provides multiple frequencies each day.

Sacramento has the second busiest Amtrak station in California and the seventh busiest in the country.

Altamont Corridor Express commuter rail service is expected to be routed through Sacramento in 2020. This service will utilize the Union Pacific's Sacramento Subdivison, the route of the original "California Zephyr", where additional passenger capacity is available.

Sacramento is expected to serve as the northern terminus of the California High-Speed Rail system.

A 2011 study by Walk Score ranked Sacramento 24th most walkable of fifty largest U.S. cities.

Sacramento International Airport

Sacramento International Airport is a public airport 10 miles (16 km) northwest of downtown Sacramento, in Sacramento County, California. It is run by Sacramento County. Southwest Airlines currently accounts for half the airline passengers. Other airlines include Delta, United, American Airlines and Alaska. Sacramento International Airport handles flights to and from various US destinations (including Hawaii) as well as Mexico, Canada and connecting flights to Europe, Asia, and South America, and served more than 10 million passengers in 2016.

The airport is best known for its red rabbit installation by Lawrence Argent entitled "Leap".

The city and its suburbs are served by Sacramento Regional Transit District, which ranks as the eleventh busiest in the United States. Sac RT is a bus and light-rail system, with 274 buses and 76 light-rail vehicles providing service for 58,200 daily passengers. The three Light-rail lines (Blue, Gold, & Green) is a 42.9 mi (69.0 km) system with 54 stations. The Gold Line was extended east as far as the city of Folsom, and more recently the Blue Line was extended south from Meadowview Rd to Cosumnes River College. Sacramento's light rail system goes to the Sacramento Valley Rail Station, Cosumnes River College (Sacramento RT) in south Sacramento, and north to Watt/I-80 where I-80 and Business 80 meet. The Light-rail Blue & Gold Lines have 15 minute weekday headways and 30 minute weekday evening and weekend/holiday headways; the Green Line has 30 minute weekday headways and no weekend service. There are expansion plans to extend the Green Line to Sacramento International Airport and the Blue Line to the City of Roseville, California through the City of Citrus Heights, California. Yolobus provides bus service to West Sacramento and Yolo County.

Greyhound Lines provides intercity bus service to Portland, Reno, Los Angeles, and San Francisco from its new station along Richards Boulevard. Intercity bus service to San Francisco and Sparks, Nevada is offered by Megabus.

Bicycling is an increasingly popular transportation mode in Sacramento, which enjoys a mild climate and flat terrain. Bicycling is especially common in the older neighborhoods of Sacramento's center, such as Alkali Flat, Midtown, McKinley Park, Land Park, and East Sacramento. Many employees who work downtown commute by bicycle from suburban communities on a dedicated bicycle path on the American River Parkway. Sacramento was designated as a Silver Level Bicycle Friendly Community by the League of American Bicyclists in September 2006. The advocacy organization Sacramento Area Bicycle Advocates co-sponsors the Sacramento Area Council of Governments' May is Bike Month campaign.

There is commuter bus service from Yolo County on Yolobus, from Solano County on FAST, on two bus lines from Yuba County's Yuba Sutter Transit, from Amador Transit's Sacramento Line, on Placer County Transit's Auburn to Light Rail Line, and from San Joaquin County on several SMART bus lines.


As of 2015, the City of Sacramento has 12 sister cities. They are:




</doc>
<doc id="29635" url="https://en.wikipedia.org/wiki?curid=29635" title="Sierpinski carpet">
Sierpinski carpet

The Sierpinski carpet is a plane fractal first described by Wacław Sierpiński in 1916. The carpet is one generalization of the Cantor set to two dimensions; another is the Cantor dust.

The technique of subdividing a shape into smaller copies of itself, removing one or more copies, and continuing recursively can be extended to other shapes. For instance, subdividing an equilateral triangle into four equilateral triangles, removing the middle triangle, and recursing leads to the Sierpinski triangle. In three dimensions, a similar construction based on cubes is known as the Menger sponge.

The construction of the Sierpinski carpet begins with a square. The square is cut into 9 congruent subsquares in a 3-by-3 grid, and the central subsquare is removed. The same procedure is then applied recursively to the remaining 8 subsquares, "ad infinitum". It can be realised as the set of points in the unit square whose coordinates written in base three do not both have a digit '1' in the same position.

The process of recursively removing squares is an example of a finite subdivision rule.

The Sierpinski carpet can also be created by iterating every pixel in a square and using the following algorithm to decide if the pixel is filled. The following implementation is valid C, C++, and most languages derived from C.
/*
int isSierpinskiCarpetPixelFilled(int x, int y)

The area of the carpet is zero (in standard Lebesgue measure).

The interior of the carpet is empty.

The Hausdorff dimension of the carpet is .

Sierpiński demonstrated that his carpet is a universal plane curve. That is: the Sierpinski carpet is a compact subset of the plane with Lebesgue covering dimension 1, and every subset of the plane with these properties is homeomorphic to some subset of the Sierpinski carpet.

This 'universality' of the Sierpinski carpet is not a true universal property in the sense of category theory: it does not uniquely characterize this space up to homeomorphism. For example, the disjoint union of a Sierpinski carpet and a circle is also a universal plane curve. However, in 1958 Gordon Whyburn uniquely characterized the Sierpinski carpet as follows: any curve that is locally connected and has no 'local cut-points' is homeomorphic to the Sierpinski carpet. Here a local cut-point is a point for which some connected neighborhood of has the property that is not connected. So, for example, any point of the circle is a local cut point.

In the same paper Whyburn gave another characterization of the Sierpinski carpet. Recall that a continuum is a nonempty connected compact metric space. Suppose is a continuum embedded in the plane. Suppose its complement in the plane has countably many connected components and suppose:


Then is homeomorphic to the Sierpinski carpet.

The topic of Brownian motion on the Sierpinski carpet has attracted interest in recent years. Martin Barlow and Richard Bass have shown that a random walk on the Sierpinski carpet diffuses at a slower rate than an unrestricted random walk in the plane. The latter reaches a mean distance proportional to after steps, but the random walk on the discrete Sierpinski carpet reaches only a mean distance proportional to for some . They also showed that this random walk satisfies stronger large deviation inequalities (so called "sub-Gaussian inequalities") and that it satisfies the elliptic Harnack inequality without satisfying the parabolic one. The existence of such an example was an open problem for many years.

A variation of the Sierpinski carpet, called the Wallis sieve, starts in the same way, by subdividing the unit square into nine smaller squares and removing the middle of them. At the next level of subdivision, it subdivides each of the squares into 25 smaller squares and removes the middle one, and it continues at the th step by subdividing each square into smaller squares and removing the middle one.

By the Wallis product, the area of the resulting set is , unlike the standard Sierpinski carpet which has zero limiting area.

However, by the results of Whyburn mentioned above, we can see that the Wallis sieve is homeomorphic to the Sierpinski carpet. In particular, its interior is still empty.

Mobile phone and WiFi fractal antennas have been produced in the form of few iterations of the Sierpinski carpet. Due to their self-similarity and scale invariance, they easily accommodate multiple frequencies. They are also easy to fabricate and smaller than conventional antennas of similar performance, thus being optimal for pocket-sized mobile phones.




</doc>
<doc id="29637" url="https://en.wikipedia.org/wiki?curid=29637" title="Subspace">
Subspace

Subspace may refer to:





</doc>
<doc id="29638" url="https://en.wikipedia.org/wiki?curid=29638" title="Sierpinski triangle">
Sierpinski triangle

The Sierpinski triangle (also with the original orthography "Sierpiński"), also called the Sierpinski gasket or the Sierpinski Sieve, is a fractal and attractive fixed set with the overall shape of an equilateral triangle, subdivided recursively into smaller equilateral triangles. Originally constructed as a curve, this is one of the basic examples of self-similar sets, i.e., it is a mathematically generated pattern that is reproducible at any magnification or reduction. It is named after the Polish mathematician Wacław Sierpiński, but appeared as a decorative pattern many centuries before the work of Sierpiński. 

There are many different ways of constructing the Sierpinski triangle.

The Sierpinski triangle may be constructed from an equilateral triangle by repeated removal of triangular subsets:

Each removed triangle (a "trema") is topologically an open set.
This process of recursively removing triangles is an example of a finite subdivision rule.

The same sequence of shapes, converging to the Sierpinski triangle, can alternatively be generated by the following steps:

Note that this infinite process is not dependent upon the starting shape being a triangle—it is just clearer that way. The first few steps starting, for example, from a square also tend towards a Sierpinski triangle. Michael Barnsley used an image of a fish to illustrate this in his paper "V-variable fractals and superfractals."
The actual fractal is what would be obtained after an infinite number of iterations. More formally, one describes it in terms of functions on closed sets of points. If we let "d" denote the dilation by a factor of about a point A, then the Sierpinski triangle with corners A, B, and C is the fixed set of the transformation "d" ∪ "d" ∪ "d".

This is an attractive fixed set, so that when the operation is applied to any other set repeatedly, the images converge on the Sierpinski triangle. This is what is happening with the triangle above, but any other set would suffice.

If one takes a point and applies each of the transformations "d", "d", and "d" to it randomly, the resulting points will be dense in the Sierpinski triangle, so the following algorithm will again generate arbitrarily close approximations to it:

Start by labeling p, p and p as the corners of the Sierpinski triangle, and a random point v. Set , where "r" is a random number 1, 2 or 3. Draw the points v to v. If the first point v was a point on the Sierpiński triangle, then all the points v lie on the Sierpinski triangle. If the first point v to lie within the perimeter of the triangle is not a point on the Sierpinski triangle, none of the points v will lie on the Sierpinski triangle, however they will converge on the triangle. If v is outside the triangle, the only way v will land on the actual triangle, is if v is on what would be part of the triangle, if the triangle was infinitely large.

Or more simply:

"Note:" This method is also called the chaos game, and is an example of an iterated function system. You can start from any point outside or inside the triangle, and it would eventually form the Sierpinski Gasket with a few leftover points (if the starting point lies on the outline of the triangle, there are no leftover points). It is interesting to do this with pencil and paper. A brief outline is formed after placing approximately one hundred points, and detail begins to appear after a few hundred. An interactive version of the chaos game can be found here.

Another construction for the Sierpinski triangle shows that it can be constructed as a curve in the plane. It is formed by a process of repeated modification of simpler curves, analogous to the construction of the Koch snowflake:
The resulting fractal curve is called the Sierpiński arrowhead curve, and its limiting shape is the Sierpinski triangle.

The Sierpinski triangle also appears in certain cellular automata (such as Rule 90), including those relating to Conway's Game of Life. For instance, the Life-like cellular automaton B1/S12 when applied to a single cell will generate four approximations of the Sierpinski triangle. A very long one cell thick line in standard life will create two mirrored Sierpinski triangles. The time-space diagram of a replicator pattern in a cellular automaton also often resembles a Sierpinski triangle, such as that of the common replicator in HighLife.

If one takes Pascal's triangle with 2 rows and colors the even numbers white, and the odd numbers black, the result is an approximation to the Sierpinski triangle. More precisely, the limit as "n" approaches infinity of this parity-colored 2-row Pascal triangle is the Sierpinski triangle.

The Towers of Hanoi puzzle involves moving disks of different sizes between three pegs, maintaining the property that no disk is ever placed on top of a smaller disk. The states of an "n"-disk puzzle, and the allowable moves from one state to another, form an undirected graph that can be represented geometrically as the intersection graph of the set of triangles remaining after the "n"th step in the construction of the Sierpinski triangle. Thus, in the limit as "n" goes to infinity, this sequence of graphs can be interpreted as a discrete analogue of the Sierpinski triangle.

For integer number of dimensions "d", when doubling a side of an object, 2 copies of it are created, i.e. 2 copies for 1-dimensional object, 4 copies for 2-dimensional object and 8 copies for 3-dimensional object. For the Sierpinski triangle, doubling its side creates 3 copies of itself. Thus the Sierpinski triangle has Hausdorff dimension / = log 3 ≈ 1.585, which follows from solving 2 = 3 for "d".

The area of a Sierpinski triangle is zero (in Lebesgue measure). The area remaining after each iteration is clearly of the area from the previous iteration, and an infinite number of iterations results in zero.

The points of a Sierpinski triangle have a simple characterization in barycentric coordinates. If a point has coordinates (0."u""u""u"…, 0."v""v""v"…, 0."w""w""w"…), expressed as binary numerals, then the point is in Sierpinski's triangle if and only if for all "i".

A generalization of the Sierpinski triangle can also be generated using Pascal's triangle if a different Modulo is used. Iteration "n" can be generated by taking a Pascal's triangle with "P" rows and coloring numbers by their value for "x" mod "P". As "n" approaches infinity, a fractal is generated.

The same fractal can be achieved by dividing a triangle into a tessellation of "P" similar triangles and removing the triangles that are upside-down from the original, then iterating this step with each smaller triangle.

Conversely, the fractal can also be generated by beginning with a triangle and duplicating it and arranging of the new figures in the same orientation into a larger similar triangle with the vertices of the previous figures touching, then iterating that step.

The Sierpinski tetrahedron or tetrix is the three-dimensional analogue of the Sierpinski triangle, formed by repeatedly shrinking a regular tetrahedron to one half its original height, putting together four copies of this tetrahedron with corners touching, and then repeating the process. This can also be done with a square pyramid and five copies instead.

A tetrix constructed from an initial tetrahedron of side-length "L" has the property that the total surface area remains constant with each iteration. The initial surface area of the (iteration-0) tetrahedron of side-length "L" is "L". The next iteration consists of four copies with side length "L"/2, so the total area is 4("L"/2) = 4"L"/4 = "L" again. Meanwhile the volume of the construction is halved at every step and therefore approaches zero. The limit of this process has neither volume nor surface but, like the Sierpinski gasket, is an intricately connected curve. Its Hausdorff dimension is log(4)/log(2) = 2. If all points are projected onto a plane that is parallel to two of the outer edges, they exactly fill a square of side length L/ without overlap.

A short code in the Mathematica internal language: the recursive procedure SiPyramid generates a 3D pyramid of arbitrary order "n" as the displayable graphic object Graphics3D:

Wacław Sierpiński described the Sierpinski triangle in 1915. However, similar patterns appear already in the 13th-century Cosmati mosaics in the cathedral of Anagni, Italy, and other places of central Italy, for carpets in many places such as the nave of the Roman Basilica of Santa Maria in Cosmedin, and for isolated triangles positioned in rotae in several churches and basilicas. In the case of the isolated triangle, it is interesting to notice that the iteration is at least of three levels.

The Apollonian gasket was first described by Apollonius of Perga (3rd century BC) and further analyzed by Gottfried Leibniz (17th century), and is a curved precursor of the 20th-century Sierpiński triangle.

The usage of the word "gasket" to refer to the Sierpinski triangle refers to gaskets such as are found in motors, and which sometimes feature a series of holes of decreasing size, similar to the fractal; this usage was coined by Benoît Mandelbrot, who thought the fractal looked similar to "the part that prevents leaks in motors".




</doc>
<doc id="29639" url="https://en.wikipedia.org/wiki?curid=29639" title="Siberia">
Siberia

Siberia (; ) is an extensive geographical region, and by the broadest definition is also known as Eurasia and North Asia. Siberia has historically been a part of modern Russia since the 16th and 17th centuries.

The territory of Siberia extends eastwards from the Ural Mountains to the watershed between the Pacific and Arctic drainage basins. The Yenisei River conditionally divides Siberia into two parts, Western and Eastern. Siberia stretches southwards from the Arctic Ocean to the hills of north-central Kazakhstan and to the national borders of Mongolia and China. With an area of , Siberia accounts for 77% of Russia's land area, but it is home to approximately 36 million people—27% of the country's population. This is equivalent to an average population density of about (approximately equal to that of Australia), making Siberia one of the most sparsely populated regions on Earth. If it were a country by itself, it would still be the largest country in area, but in population it would be the world's 35th-largest and Asia's 14th-largest.

Worldwide, Siberia is well known primarily for its long, harsh winters, with a January average of −25 °C (−13 °F), as well as its extensive history of use by Russian and Soviet administrations as a place for prisons, labour camps, and exile.

The origin of the name is unknown. Some sources say that "Siberia" originates from the Siberian Tatar word for "sleeping land" (Sib Ir). Another account sees the name as the ancient tribal ethnonym of the (also "Syopyr" (sʲɵpᵻr)), an ethnic group which spoke a language that later evolved into the Ugric languages. The Sirtya people were later assimilated into the Siberian Tatars.

The modern usage of the name was recorded in the Russian language after the Empire's conquest of the Siberian Khanate. A further variant claims that the region was named after the Xibe people. The Polish historian Chycliczkowski has proposed that the name derives from the proto-Slavic word for "north" (север, "sever"), but Anatole Baikaloff has dismissed this explanation. He said that the neighbouring Chinese, Turks, and Mongolians, who have similar names for the region, would not have known Russian. He suggests that the name might be a combination of two words with Turkic origin, ""su"" (water) and ""bir"" (wild land).

The region has paleontological significance, as it contains bodies of prehistoric animals from the Pleistocene Epoch, preserved in ice or in permafrost. Specimens of Goldfuss cave lion cubs, Yuka (mammoth) and another woolly mammoth from Oymyakon, a woolly rhinoceros from the Kolyma River, and bison and horses from Yukagir have been found.

The Siberian Traps were formed by one of the largest-known volcanic events of the last 500 million years of Earth's geological history. Their activity continued for a million years and some scientists consider it a possible cause of the "Great Dying" about 250 million years ago, – estimated to have killed 90% of species existing at the time.

At least three species of human lived in Southern Siberia around 40,000 years ago: "H. sapiens", "H. neanderthalensis", and the Denisovans.
In 2010 DNA evidence identified the last as a separate species.

Siberia was inhabited by different groups of nomads such as the Enets, the Nenets, the Huns, the Scythians and the Uyghurs. The Khan of Sibir in the vicinity of modern Tobolsk was known as a prominent figure who endorsed Kubrat as "Khagan" of Old Great Bulgaria in 630. The Mongols conquered a large part of this area early in the 13th century. 

With the breakup of the Golden Horde, the autonomous Khanate of Sibir was established in the late 15th century. Turkic-speaking Yakut migrated north from the Lake Baikal region under pressure from the Mongol tribes during the 13th to 15th century. Siberia remained a sparsely populated area. Historian John F. Richards wrote: "... it is doubtful that the total early modern Siberian population exceeded 300,000 persons."

The growing power of Russia in the West began to undermine the Siberian Khanate in the 16th century. First, groups of traders and Cossacks began to enter the area. The Russian Army was directed to establish forts farther and farther east to protect new settlers from European Russia. Towns such as Mangazeya, Tara, Yeniseysk and Tobolsk were developed, the last being declared the capital of Siberia. At this time, "Sibir" was the name of a fortress at Qashlik, near Tobolsk. Gerardus Mercator, in a map published in 1595, marks "Sibier" both as the name of a settlement and of the surrounding territory along a left tributary of the Ob. Other sources contend that the Xibe, an indigenous Tungusic people, offered fierce resistance to Russian expansion beyond the Urals. Some suggest that the term "Siberia" is a Russification of their ethnonym.

By the mid-17th century, Russia had established areas of control that extended to the Pacific. Some 230,000 Russians had settled in Siberia by 1709. Siberia was a destination for sending exiles.

The first great modern change in Siberia was the Trans-Siberian Railway, constructed during 1891–1916. It linked Siberia more closely to the rapidly industrialising Russia of Nicholas II. Around seven million people moved to Siberia from European Russia between 1801 and 1914. From 1859 to 1917, more than half a million people migrated to the Russian Far East. Siberia has extensive natural resources. During the 20th century, large-scale exploitation of these was developed, and industrial towns cropped up throughout the region.
At 7:15 a.m. on 30 June 1908, millions of trees were felled near the Podkamennaya Tunguska (Stony Tunguska) River in central Siberia in the Tunguska Event. Most scientists believe this resulted from the air burst of a meteor or a comet. Even though no crater has ever been found, the landscape in the (sparsely inhabited) area still bears the scars of this event.

In the early decades of the Soviet Union (especially the 1930s and 1940s), the government established the GULAG state agency to administer a system of penal labour camps, replacing the previous katorga system. According to semi-official Soviet estimates, which were not made public until after the fall of the Soviet government, from 1929 to 1953 more than 14 million people passed through these camps and prisons, many of which were in Siberia. Another seven to eight million people were internally deported to remote areas of the Soviet Union (including entire nationalities or ethnicities in several cases).

Half a million (516,841) prisoners died in camps from 1941 to 1943 due to food shortages caused by World War II. At other periods, mortality was comparatively lower. The size, scope, and scale of the GULAG slave labour camps remains a subject of much research and debate. Many Gulag camps were positioned in extremely remote areas of northeastern Siberia. The best known clusters are "Sevvostlag" ("The North-East Camps") along the Kolyma River and "Norillag" near Norilsk, where 69,000 prisoners were kept in 1952. Major industrial cities of Northern Siberia, such as Norilsk and Magadan, developed from camps built by prisoners and run by former prisoners.

With an area of , Siberia makes up roughly 77% of Russia's total territory and almost 10% of Earth's land surface (). While Siberia falls entirely within Asia, many authorities such as the UN geoscheme will not subdivide countries and will place all of Russia as part of Europe and/or Eastern Europe. Major geographical zones include the West Siberian Plain and the Central Siberian Plateau.

Eastern and central Sakha comprises numerous north-south mountain ranges of various ages. These mountains extend up to almost , but above a few hundred metres they are almost completely devoid of vegetation. The Verkhoyansk Range was extensively glaciated in the Pleistocene, but the climate was too dry for glaciation to extend to low elevations. At these low elevations are numerous valleys, many of them deep and covered with larch forest, except in the extreme north where the tundra dominates. Soils are mainly turbels (a type of gelisol). The active layer tends to be less than one metre deep, except near rivers.

The highest point in Siberia is the active volcano Klyuchevskaya Sopka, on the Kamchatka Peninsula. Its peak is at .




The West Siberian Plain consists mostly of Cenozoic alluvial deposits and is somewhat flat. Many deposits on this plain result from ice dams which produced a large glacial lake. This mid- to late-Pleistocene lake blocked the northward flow of the Ob and Yenisei rivers, resulting in a redirection southwest into the Caspian and Aral seas via the Turgai Valley. The area is very swampy, and soils are mostly peaty histosols and, in the treeless northern part, histels. In the south of the plain, where permafrost is largely absent, rich grasslands that are an extension of the Kazakh Steppe formed the original vegetation, most of which is no longer visible.

The Central Siberian Plateau is an ancient craton (sometimes named "Angaraland") that formed an independent continent before the Permian (see the Siberian continent). It is exceptionally rich in minerals, containing large deposits of gold, diamonds, and ores of manganese, lead, zinc, nickel, cobalt and molybdenum. Much of the area includes the Siberian Traps—a large igneous province. This massive eruptive period was approximately coincident with the Permian–Triassic extinction event. The volcanic event is said to be the largest known volcanic eruption in Earth's history. Only the extreme northwest was glaciated during the Quaternary, but almost all is under exceptionally deep permafrost, and the only tree that can thrive, despite the warm summers, is the deciduous Siberian Larch ("Larix sibirica") with its very shallow roots. Outside the extreme northwest, the taiga is dominant, covering a significant fraction of the entirety of Siberia. Soils here are mainly turbels, giving way to spodosols where the active layer becomes thicker and the ice content lower.

The "Lena-Tunguska petroleum province" includes the Central Siberian platform (some authors refer to it as the Eastern Siberian platform), bounded on the northeast and east by the Late Carboniferous through Jurassic Verkhoyansk foldbelt, on the northwest by the Paleozoic Taymr foldbelt, and on the southeast, south and southwest by the Middle Silurian to Middle Devonian Baykalian foldbelt. A regional geologic reconnaissance study begun in 1932, followed by surface and subsurface mapping, revealed the Markova-Angara Arch (anticline). This led to the discovery of the Markovo Oil Field in 1962 with the Markovo 1 well, which produced from the Early Cambrian Osa Horizon bar-sandstone at a depth of . The "Sredne-Botuobin Gas Field" was discovered in 1970, producing from the Osa and the Proterozoic Parfenovo Horizon. The Yaraktin Oil Field was discovered in 1971, producing from the Vendian Yaraktin Horizon at depths of up to , which lies below Permian to Lower Jurassic basalt traps.

The climate of Siberia varies dramatically, but all of it basically has short summers and long and extremely cold winters. On the north coast, north of the Arctic Circle, there is a very short (about one-month-long) summer.

Almost all the population lives in the south, along the Trans-Siberian Railway. The climate in this southernmost part is Humid continental climate (Köppen "Dfb") with cold winters but fairly warm summers lasting at least four months. The annual average is about . January averages about and July about while daytime temperatures in summer typically are above . With a reliable growing season, an abundance of sunshine and exceedingly fertile chernozem soils, southern Siberia is good enough for profitable agriculture, as was proven in the early 20th century.

By far the most commonly occurring climate in Siberia is continental subarctic (Koppen "Dfc" or "Dwc"), with the annual average temperature about and an average for January of and an average for July of , although this varies considerably, with a July average about in the taiga–tundra ecotone. The Business oriented website and blog "Business Insider" lists Verkhoyansk and Oymyakon, in Siberia's Sakha Republic, as being in competition for the title of the Northern Hemisphere's "Pole of Cold". Oymyakon is a village which recorded a temperature of on 6 February 1933. Verkhoyansk, a town further north and further inland, recorded a temperature of for 3 consecutive nights: 5, 6 and 7 February 1933. Each town is alternately considered the Northern Hemisphere's Pole of Cold, meaning the coldest inhabited point in the Northern hemisphere. Each town also frequently reaches in the summer, giving them, and much of the rest of Russian Siberia, the world's greatest temperature variation between summer's highs and winter's lows, often being well over between the seasons.

Southwesterly winds bring warm air from Central Asia and the Middle East. The climate in West Siberia (Omsk, Novosibirsk) is several degrees warmer than in the East (Irkutsk, Chita) where in the north an extreme winter subarctic climate (Köppen "Dfd" or "Dwd") prevails. But summer temperatures in other regions can reach . In general, Sakha is the coldest Siberian region, and the basin of the Yana River has the lowest temperatures of all, with permafrost reaching . Nevertheless, as far as Imperial Russian plans of settlement were concerned, cold was never viewed as an impediment. In the winter, southern Siberia sits near the center of the semi-permanent Siberian High, so winds are usually light in the winter.

Precipitation in Siberia is generally low, exceeding only in Kamchatka where moist winds flow from the Sea of Okhotsk onto high mountains – producing the region's only major glaciers, though volcanic eruptions and low summer temperatures allow limited forests to grow. Precipitation is high also in most of Primorye in the extreme south where monsoonal influences can produce quite heavy summer rainfall.
Researchers, including Sergei Kirpotin at Tomsk State University and Judith Marquand at Oxford University, warn that Western Siberia has begun to thaw as a result of global warming. The frozen peat bogs in this region may hold billions of tons of methane gas, which may be released into the atmosphere. Methane is a greenhouse gas 22 times more powerful than carbon dioxide. In 2008, a research expedition for the American Geophysical Union detected levels of methane up to 100 times above normal in the atmosphere above the Siberian Arctic, likely the result of methane clathrates being released through holes in a frozen 'lid' of seabed permafrost, around the outfall of the Lena River and the area between the Laptev Sea and East Siberian Sea.





]
The term "Siberia" has a long history. Its meaning has gradually changed during ages. Historically, Siberia was defined as the whole part of Russia to the east of Ural Mountains, including the Russian Far East. According to this definition, Siberia extended eastward from the Ural Mountains to the Pacific coast, and southward from the Arctic Ocean to the border of Russian Central Asia and the national borders of both Mongolia and China.

Soviet-era sources ("Great Soviet Encyclopedia" and others) and modern Russian ones usually define Siberia as a region extending eastward from the Ural Mountains to the watershed between Pacific and Arctic drainage basins, and southward from the Arctic Ocean to the hills of north-central Kazakhstan and the national borders of both Mongolia and China. By this definition, Siberia includes the federal subjects of the Siberian Federal District, and some of the Ural Federal District, as well as Sakha (Yakutia) Republic, which is a part of the Far Eastern Federal District. Geographically, this definition includes subdivisions of several other subjects of Urals and Far Eastern federal districts, but they are not included administratively. This definition excludes Sverdlovsk Oblast and Chelyabinsk Oblast, both of which are included in some wider definitions of Siberia.

Other sources may use either a somewhat wider definition that states the Pacific coast, not the watershed, is the eastern boundary (thus including the whole Russian Far East) or a somewhat narrower one that limits Siberia to the Siberian Federal District (thus excluding all subjects of other districts). In Russian, the word for Siberia is used as a substitute for the name of the federal district by those who live in the district itself and less commonly used to denote the federal district by people residing outside of it.

The most populous city of Siberia, as well as the third most populous city of Russia, is the city of Novosibirsk. Other major cities include:


Wider definitions of Siberia also include:


Siberia is extraordinarily rich in minerals, containing ores of almost all economically valuable metals. It has some of the world's largest deposits of nickel, gold, lead, coal, molybdenum, gypsum, diamonds, diopside, silver and zinc, as well as extensive unexploited resources of oil and natural gas. Around 70% of Russia's developed oil fields are in the Khanty-Mansiysk region. Russia contains about 40% of the world's known resources of nickel at the Norilsk deposit in Siberia. Norilsk Nickel is the world's biggest nickel and palladium producer.

Siberian agriculture is severely restricted by the short growing season of most of the region. However, in the southwest where soils are exceedingly fertile black earths and the climate is a little more moderate, there is extensive cropping of wheat, barley, rye and potatoes, along with the grazing of large numbers of sheep and cattle. Elsewhere food production, owing to the poor fertility of the podzolic soils and the extremely short growing seasons, is restricted to the herding of reindeer in the tundra—which has been practiced by natives for over 10,000 years. Siberia has the world's largest forests. Timber remains an important source of revenue, even though many forests in the east have been logged much more rapidly than they are able to recover. The Sea of Okhotsk is one of the two or three richest fisheries in the world owing to its cold currents and very large tidal ranges, and thus Siberia produces over 10% of the world's annual fish catch, although fishing has declined somewhat since the collapse of the USSR.

While the development of renewable energy in Russia is held back by the lack of a conducive government policy framework, Siberia still offers special opportunities for off-grid renewable energy developments. Remote parts of Siberia are too costly to connect to central electricity and gas grids, and have therefore historically been supplied with costly diesel, sometimes flown in by helicopter. In such cases renewable energy is often cheaper. 

Professional football teams include FC Tom Tomsk, FC Sibir Novosibirsk and FK Yenisey Krasnoyarsk.

The Yenisey Krasnoyarsk basketball team has played in the VTB United League since 2011–12.

Russia's third most popular sport, bandy, is important in Siberia. In the 2015–16 Russian Bandy Super League season Yenisey from Krasnoyarsk became champions for the third year in a row by beating Baykal-Energiya from Irkutsk in the final. Two or three more teams (depending on the definition of Siberia) play in the Super League, the 2016-17 champions SKA-Neftyanik from Khabarovsk as well as Kuzbass from Kemerovo and Sibselmash from Novosibirsk. In 2007 Kemerovo got Russia's first indoor arena specifically built for bandy. Now Khabarovsk has the world's biggest indoor arena specifically built for bandy, Arena Yerofey. It will be the venue for Division A of the 2018 World Championship.

The 2019 Winter Universiade will be hosted by Krasnoyarsk.

According to the Russian Census of 2010, the Siberian and Far Eastern Federal Districts, located entirely east of the Ural Mountains, together have a population of about 25.6 million. Tyumen and Kurgan Oblasts, which are geographically in Siberia but administratively part of the Urals Federal District, together have a population of about 4.3 million. Thus, the whole region of Asian Russia (or Siberia in the broadest usage of the term) is home to approximately 30 million people. It has a population density of about three people per square kilometre.

All Siberians are Russian citizens, and of these Russian citizens of Siberia, most are Slavic-origin Russians and russified Ukrainians. The remaining Russian citizens of Siberia consists of other groups of non-indigenous ethnic origins and those of indigenous Siberian origin.

Among the largest non-Slavic group of Russian citizens of Siberia are the approximately 400,000 ethnic Volga Germans. The original indigenous groups of Siberia, including Mongol and Turkic groups such as Buryats, Tuvinians, Yakuts, and Siberian Tatars still mostly reside in Siberia, though they are minorities outnumbered by all other non-indigenous Siberians. Indeed, Slavic-origin Russians by themselves outnumber all of the indigenous peoples combined, both in Siberia as a whole and its cities, except in the Republic of Tuva.

Slavic-origin Russians make up the majority in the Buryat, Sakha, and Altai Republics, outnumbering the indigenous Buryats, Sakha, and Altai. The Buryat make up only 25% of their own republic, and the Sakha and Altai each are only one-third, and the Chukchi, Evenk, Khanti, Mansi, and Nenets are outnumbered by non-indigenous peoples by 90% of the population.

According to the 2002 census there are 500,000 Tatars in Siberia, but of these, 300,000 are Volga Tatars who also settled in Siberia during periods of colonization and are thus also non-indigenous Siberians, in contrast to the 200,000 Siberian Tatars which are indigenous to Siberia.

Of the indigenous Siberians, the Buryats, numbering approximately 500,000, are the most numerous group in Siberia, and they are mainly concentrated in their homeland, the Buryat Republic. According to the 2002 census there were 443,852 indigenous Yakuts. Other ethnic groups indigenous to Siberia include Kets, Evenks, Chukchis, Koryaks, Yupiks, and Yukaghirs.

About seventy percent of Siberia's people live in cities, mainly in apartments. Many people also live in rural areas, in simple, spacious, log houses. Novosibirsk is the largest city in Siberia, with a population of about 1.5 million. Tobolsk, Tomsk, Tyumen, Krasnoyarsk, Irkutsk, and Omsk are the older, historical centers.

There are a variety of beliefs throughout Siberia, including Orthodox Christianity, other denominations of Christianity, Tibetan Buddhism and Islam. The Siberian Federal District alone has an estimation of 250,000 Muslims.
An estimated 70,000 Jews live in Siberia, some in the Jewish Autonomous Region. The predominant religious group is the Russian Orthodox Church.

Tradition regards Siberia the archetypal home of shamanism, and polytheism is popular. These native sacred practices are considered by the tribes to be very ancient. There are records of Siberian tribal healing practices dating back to the 13th century. The vast territory of Siberia has many different local traditions of gods. These include: Ak Ana, Anapel, Bugady Musun, Kara Khan, Khaltesh-Anki, Kini'je, Ku'urkil, Nga, Nu'tenut, Numi-Torem, Numi-Turum, Pon, Pugu, Todote, Toko'yoto, Tomam, Xaya Iccita, Zonget. Places with sacred areas include Olkhon, an island in Lake Baikal.

Many cities in northern Siberia, such as Petropavlovsk-Kamchatsky, cannot be reached by road, as there are virtually none connecting from other major cities in Russia or Asia. The best way to tour Siberia is through the Trans-Siberian Railway. The Trans-Siberian Railway operates from Moscow in the west to Vladivostok in the east. Cities that are located far from the railway are best reached by air or by the separate Baikal-Amur-Railway (BAM).

Stroganina is a raw fish dish of the indigenous people of northern Arctic Siberia made from raw, thin, long-sliced frozen fish. It is a popular dish with native Siberians.




</doc>
<doc id="29640" url="https://en.wikipedia.org/wiki?curid=29640" title="Standard Arabic Technical Transliteration System">
Standard Arabic Technical Transliteration System

The Standard Arabic Technical Transliteration System, commonly referred to by its acronym SATTS, is a system for writing and transmitting Arabic language text using the one-for-one substitution of ASCII-range characters for the letters of the Arabic alphabet. Unlike more common systems for transliterating Arabic, SATTS does not provide the reader with any more phonetic information than standard Arabic orthography does; that is, it provides the bare Arabic alphabetic spelling with no notation of short vowels, doubled consonants, etc. In other words, it is intended as a transliteration tool for Arabic linguists, and is of limited use to those who do not know Arabic.

SATTS, a legacy of Morse and teleprinter systems (see "Background," below), has historically been employed by military and communications elements of Western countries for handling Arabic text without the need for native fonts or special software. Although its use has decreased in recent years with the demise of Morse code and the obsolescence of the teleprinter, and with the increased availability of native-font software, it is still used for the quick and handy platform-independent recording and transmission of Arabic terms and text.

SATTS employs all the Latin alphabetic letters except P, plus four punctuation marks, for a total of 29 symbols (all the letters of the Arabic alphabet, plus the glottal-stop symbol hamzah).

In some words, lām 'alif was sent as a single character •—••••— or LA as a single character. The symbol for the glottal stop hamzah (ء) is written following its seat, if it has one. It is omitted when it occurs with an initial 'alif. 
RIEIS رئيس MAEDB? مأدبة
MSWEWL مسؤول BDE بدء
AHMD أحمد ASLAM إسلام

The chief deficiencies of SATTS are that it does not distinguish between hā' (ه) and tā' marbūţah (ة), or between final yā' (ي) and 'alif maksūrah (ى), and it cannot depict an 'alif maddah ( آ ). Satts can also not distinguish between a final seated hamza and a final independent hamza, if the word ends in "AE", "IE", or "WE".

The Latin alphabetic letter employed for each Arabic letter in the SATTS system is its Morse-code equivalent. For example, Morse code for the Arabic letter ţā' (ط) is • • — (dit-dit-dah). That same Morse code sequence represents the letter U in the Latin alphabet. Hence the SATTS equivalent for ţā' is U.

In the Morse-code era, when Arabic language Morse signals were copied down by non-Arab code clerks, the text came out in SATTS. Text in SATTS was also automatically produced when teleprinters reproduced Arabic text, if the technician had failed to replace the printer's Latin-character pallet with an Arabic-character one.



</doc>
<doc id="29641" url="https://en.wikipedia.org/wiki?curid=29641" title="Sound change">
Sound change

Research on sound change is usually conducted on the working assumption that it is "regular", which means that it is expected to apply mechanically whenever its structural conditions are met, irrespective of any non-phonological factors (such as the meaning of the words affected). However, apparent exceptions to regular change can occur—due to dialect borrowing, grammatical analogy, or other causes known and unknown—and some changes are described as "sporadic", meaning that they affect only one particular word or a few words, without any apparent regularity.

The Neogrammarian linguists of the 19th century introduced the term "sound law" to refer to rules of regular change, perhaps in imitation of the laws of physics. and the term "law" is still used in referring to specific sound rules named after their authors, such as Grimm's Law, Grassmann's Law, . Real-world sound changes often admit exceptions; nevertheless, the expectation of their regularity or absence of exceptions is of great heuristic value, since it allows historical linguists to define the notion of "regular correspondence" (see: comparative method).

Each sound change is limited in space and time. This means it functions within a limited area (within certain dialects) and during a limited period of time. For these (and other) reasons, the term "sound law" has been criticized for implying a universality that is unrealistic with regard to sound change.

Sound change that affects the phonological system, in the number or distribution of its phonemes, is covered more fully at phonological change.

A statement of the form

is to be read, "sound A changes into (or is replaced by, is reflected as, etc) sound B". Therefore, A belongs to an older stage of the language in question, whereas B belongs to a more recent stage. The symbol ">" can be reversed, B < A, still meaning that the (more recent) B derives from the (older) A".

For example,

The two sides of such a statement indicate start and end points only, and do not imply that there are no additional intermediate stages. The example above is actually a compressed account of a "sequence" of changes; *t changed first into a voiceless dental fricative (like the initial consonant of English "thin"), which has yielded present-day [f]. This can be represented more fully as:

Unless a change operates unconditionally (in all environments), the context in which it applies must be specified:

For example:

A second example:

The symbol "#" stands for a word boundary (initial or final). Thus the notation "/__#" means "word-finally", and "/#__" means "word-initially". For example:

This can be simplified to

where capital P stands for any plosive.

The following statements are used as heuristics in formulating sound changes as understood within the Neogrammarian model. However, for modern linguistics, they are not taken as inviolable rules; rather, they are seen as guidelines.

Sound change has no memory: Sound change does not discriminate between the sources of a sound. If a previous sound change causes X,Y > Y (features X and Y merge as Y), a new one cannot affect only an original X.

Sound change ignores grammar: A sound change can only have phonological constraints, like X > Z in unstressed syllables. For example, it cannot only affect adjectives. The only exception to this is that a sound change may or may not recognise word boundaries, even when they are not indicated by prosodic clues. Also, sound changes may be regularized in inflectional paradigms (such as verbal inflection), in which case the change is no longer phonological but morphological in nature.

Sound change is exceptionless: if a sound change can happen at a place, it will. It affects all sounds that meet the criteria for change. Apparent exceptions are possible, due to analogy and other regularization processes, or another sound change, or an unrecognized conditioning factor. This is the traditional view, expressed by the Neogrammarians. In past decades it has been shown that sound change does not necessarily affect all the words that in principle it could. However, when a sound change is initiated, it often expands to the whole lexicon given enough time, though not always. For example, in Spanish the fronting of the Vulgar Latin [g] (voiced velar stop) before [i e ɛ] seems to have reached every possible word it could. By contrast, the voicing of word-initial Latin [k] to [g] occurred in "colaphus" > "golpe" and "cattus" > "gato", but not in "canna" > "caña". See also lexical diffusion.

Sound change is unstoppable: "All" languages vary from place to place and time to time, and neither writing nor media prevent this change.

In historical linguistics, a number of traditional terms designate types of phonetic change, either by nature or result. A number of such types are often (or usually) sporadic, that is, more or less accidents that happen to a specific form. Others affect a whole phonological system. Sound changes that affect a whole phonological system are also classified according to how they affect the overall shape of the system; see "phonological change".





</doc>
<doc id="29644" url="https://en.wikipedia.org/wiki?curid=29644" title="Sulpicius Severus">
Sulpicius Severus

Sulpicius Severus (; c. 363 – c. 425) was a Christian writer and native of Aquitania in modern-day France. He is known for his chronicle of sacred history, as well as his biography of Saint Martin of Tours.

Almost all that we know of Severus' life comes from a few allusions in his own writings, some passages in the letters of his friend Paulinus, bishop of Nola, and a short biography by the historian Gennadius of Massilia.

Born of noble parents in Aquitaine, Severus enjoyed excellent educational advantages. He was imbued with the culture of his time and of his country, a center of Latin letters and learning. He studied jurisprudence and was renowned as an eloquent lawyer; his knowledge of Roman law is reflected in parts of his writings. He married the daughter of a wealthy consular family, who died young, leaving him no children.

At this time Severus came under the powerful influence of Saint Martin, bishop of Tours, by whom he was led to devote his wealth to the Christian poor, and his own powers to a life of good works and the contemplative vision of God. This choice incurred his father's displeasure, but was encouraged in his determination by his mother-in-law. To use the words of his friend Paulinus, he broke with his father, followed Christ, and set the teachings of the "fishermen" far above all his "Tullian learning." He rose to no higher rank in the church than that of presbyter. His ordination is vouched for by Gennadius, but no details of his priestly activity have reached us. He is said to have been led away in his old age by Pelagianism, but to have repented and inflicted long-enduring penance on himself. His time was passed chiefly in the neighbourhood of Toulouse, and such literary efforts as he permitted to himself were made in the interests of Christianity.

In many respects no two men could be more unlike than Severus, the scholar and orator, well versed in the ways of the world, and Martin, the rough Pannonian bishop, champion of the monastic life, seer and worker of miracles. Yet the spirit of the rugged saint subdued that of the polished scholar, and the works of Severus are important because they reflect the ideas, influence and aspirations of Martin, the foremost ecclesiastic of Gaul.

The chief work of Severus is the "Chronicle" ("Chronica", "Chronicorum Libri duo" or "Historia sacra", c. 403), a summary of sacred history from the beginning of the world to his own times, with the omission of the events recorded in the Gospels and the Acts, "lest the form of his brief work should detract from the honour due to those events". It is a source of primary importance for the history of Priscillianism and contains considerable information respecting the Arian controversy. The book was a textbook, and was used as such in the schools of Europe for about a century and a half after the "editio princeps" was published by Flacius Illyricus in 1556.

Severus nowhere clearly points to the class of readers for whom his book is designed. He disclaims the intention of making his work a substitute for the actual narrative contained in the Bible. "Worldly historians" had been used by him, he says, to make clear the dates and the connexion of events and for supplementing the sacred sources, and with the intent at once to instruct the unlearned and to "convince" the learned. Probably the "unlearned" are the mass of Christians and the learned are the cultivated Christians and pagans alike, to whom the rude language of the sacred texts, whether in Greek or Latin, would be distasteful. The literary structure of the narrative shows that Severus had in his mind principally readers on the same level of culture with himself. He was anxious to show that sacred history might be presented in a form which lovers of Sallust and Tacitus could appreciate and enjoy. The style is lucid and almost classical. Though phrases and even sentences from many classical authors are inwoven here and there, the narrative flows easily, with no trace of the jolts and jerks which offend us in almost every line of an imitator of the classics like Sidonius. It is free from useless digressions. In order that his work might fairly stand beside that of the old Latin writers, Severus ignored the allegorical methods of interpreting sacred history to which the heretics and the orthodox of his age were wedded.

As an authority for times antecedent to his own, Severus is of little moment. At only a few points does he enable us to correct or supplement other records. Jakob Bernays suggested that he based his narrative of the destruction of Jerusalem by Titus on the account given by Tacitus in his "Histories", a portion of which has been lost. In his allusions to the Gentile rulers with whom the Jews came into contact from the time of the Maccabees onwards, Severus discloses some points which are not without importance.

The real interest of his work lies, first, in the incidental glimpses it affords all through of the history of his own time; next and more particularly, in the information he has preserved concerning the struggle over the Priscillianist heresy, which disorganized and degraded the churches of Spain and Gaul, and particularly affected Aquitaine. The sympathies here betrayed by Severus are wholly those of St. Martin. The bishop had withstood Maximus, who ruled for some years a large part of the western portion of the empire, though he never conquered Italy. He had reproached him with attacking and overthrowing his predecessors. on the throne, and for his dealings with the church. Severus loses no opportunity for laying stress on the crimes and follies of rulers, and on their cruelty, though he once declares that, cruel as rulers. could be, priests could be crueller still. This last statement has reference to the bishops who had left Maximus no peace till he had stained his hands with the blood of Priscillian and his followers. Martin, too, had denounced the worldliness and greed of the Gaulish bishops and clergy. Accordingly we find that Severus, in narrating the division of Canaan among the tribes, calls the special attention of ecclesiastics to the fact that no portion of the land was assigned to the tribe of Levi, lest they should be hindered in their service of God. "Our clergy seem", he says, "not merely forgetful of the lesson but ignorant of it, such a passion for possessions has in our days fastened like a pestilence on their souls". We here catch a glimpse of the circumstances which were winning over good men to monasticism in the West, though the evidence of an enthusiastic votary of the solitary life, such as Severus was, is probably not free from exaggeration. Severus also fully sympathized with the action of St. Martin touching Priscillianism. This mysterious Western, offshoot of Gnosticism had no single feature about it which could soften the hostility of a character such as Martin's, but he resisted the introduction of secular punishment for evil doctrine, and withdrew from communion with those bishops in Gaul, a large majority, who invoked the aid of Maximus against their erring brethren. In this connexion it is interesting to note the account given by Severus of the Council of Rimini in 359, where the question arose whether the bishops attending the assembly might lawfully receive money from the imperial treasury to recoup their travelling and other expenses. Severus evidently approves the action of the British and Gaulish bishops, who deemed it unbecoming that they should lie under pecuniary obligation to the emperor. His ideal of the church required that it should stand clear and above the state.

More popular during the Middle Ages was Severus' "Life of St. Martin", as were also the dialogues and letters which relate to the same subject. These works did much to establish the great reputation which that wonder-working saint maintained throughout the Middle Ages. The book is not properly a biography, but a catalogue of miracles, told in all the simplicity of absolute belief. The power to work miraculous signs is assumed to be in direct proportion to holiness, and is by Severus valued merely as an evidence of holiness, which he is persuaded can only be attained through a life of isolation from the world. In the first of his Dialogues (fair models of Cicero), Severus puts into the mouth of an interlocutor (Posthumianus) a pleasing description of the life of coenobites and solitaries in the deserts bordering on Egypt. The main evidence of the virtue attained by them lies in the voluntary subjection to them of the savage beasts among which they lived. But Severus was no indiscriminating adherent of monasticism. The same dialogue shows him to be alive to its dangers and defects. The second dialogue is a large appendix to the Life of Martin, and really supplies more information of his life as bishop and of his views than the work which bears the title Vita S. Martini. The two dialogues occasionally make interesting references to personages of the epoch. In Dial. 1, cc. 6, 7, we have a vivid picture of the controversies which raged at Alexandria over the works of Origen. The judgment of Severus himself is no doubt that which he puts in the mouth of his interlocutor Posthumianus: "I am astonished that one and the same man could have so far differed from himself that in the approved portion of his works he has no equal since the apostles, while in that portion for which he is justly blamed it is proved that no man has committed more unseemly errors." Three Epistles on the death of Martin (ad Eusebium, ad Aurelium diaconum, ad Bassulam) complete the list of Severus' genuine works. Other letters (to his sister), on the love of God and the renunciation of the world, have not survived.

Beside the above-mentioned three letters, seven others have been attributed to Severus. These are rejected as spurious by some critics, whilst the genuineness of the first two is admitted, rightly it would seem, by others. The "World Chronicle" of the so-called Sulpicius Severus has nothing to do with the subject of this biography; it was written in Spain in the sixth century.

The text of the "Chronicle" rests on a single 11th century MS., one of the Palatine collection now in the Vatican; of the other works MSS. are abundant, the best being one of the 6th century at Verona. Some spurious letters bear the name of Severus; also in a MS. at Madrid is a work falsely professing to be an epitome of the "Chronicle" of Severus, and going down to 511. The chief editions of the complete works of Severus are those by De Prato (Verona, 1741) and by Halm (forming volume i. of the "Corpus scriptorum ecclesiasticorum Latinorum", Vienna, 1866). There is a most admirable monograph on the "Chronicle" by J. Bernays (Berlin, 1861). See also Goelzer, Grammaticae in Sulp. Severum observationes (1884) (thesis).

Severus' works are to be found in P.L. 20, 95-248; later edition by Karl Halm, "Opera", CSEL 1 (Vienna, 1866) (on Google Books)






</doc>
<doc id="29645" url="https://en.wikipedia.org/wiki?curid=29645" title="Scared to Death">
Scared to Death

Scared to Death is a 1947 thriller film directed by Christy Cabanne and starring Bela Lugosi. The picture was filmed in Cinecolor. The film is historically important as the only color film in which Bela Lugosi has a starring role.

The film opens with the disclosure by morgue examiners that a beautiful woman has literally died of fright. The plot reveals how she reached the fatal stage of terror. 

The woman is married to the son of a doctor, the proprietor of a private sanatorium, where she is under unwilling treatment. Both the son and the doctor indicate they want the marriage dissolved. Arriving at the scene is a mysterious personage (Bela Lugosi) identified as the doctor's cousin who had been a stage magician in Europe. He is accompanied by a threatening dwarf (Angelo Rossitto). 

After it is apparent that the wife is terrified of the foreigners, it is disclosed that she is the former wife and stage partner of a Paris magician known as René, who was believed to have been shot by the Nazis. Attempts to draw a confession that she had betrayed her magician husband and had collaborated with the Nazis led to the use of a device employing a death mask of the supposedly dead patriot, which literally frightens her to death. 

Although the young newspaperman hero and his sweetheart guess the answer to the story, they allow the diagnosis "scared to death" to stand.


The film was based on a one-act play which in turn was based on a 1933 murder case involving Dr. Alice Wynekoop.

The film was announced in March 1946 as "Accent on Horror".

The film was featured in an episode of "Deadly Cinema".



</doc>
<doc id="29646" url="https://en.wikipedia.org/wiki?curid=29646" title="Stefan Banach">
Stefan Banach

Stefan Banach ( ; 30 March 1892 – 31 August 1945) was a Polish mathematician who is generally considered one of the world's most important and influential 20th-century mathematicians. He was the founder of modern functional analysis, and an original member of the Lwów School of Mathematics. His major work was the 1932 book, "Théorie des opérations linéaires" (Theory of Linear Operations), the first monograph on the general theory of functional analysis.

Born in Kraków, Banach attended IV Gymnasium, a secondary school, and worked on mathematics problems with his friend . After graduating in 1910, Banach moved to Lwów. However, during World War I Banach returned to Kraków, where he befriended Hugo Steinhaus. After Banach solved some mathematics problems which Steinhaus considered difficult, they published their first joint work. In 1919, with several other mathematicians, Banach formed a mathematical society. In 1920 he received an assistantship at the Lwów Polytechnic. He soon became a professor at the Polytechnic, and a member of the Polish Academy of Learning. He organized the "Lwów School of Mathematics". Around 1929 he began writing his "Théorie des opérations linéaires".

After the outbreak of World War II, in September 1939, Lwów was taken over by the Soviet Union. Banach became a member of the Academy of Sciences of Ukraine and was dean of Lwów University's Department of Mathematics and Physics. In 1941, when the Germans took over Lwów, all institutions of higher education were closed to Poles. As a result, Banach was forced to earn a living as a feeder of lice at Rudolf Weigl's Institute for Study of Typhus and Virology. While the job carried the risk of infection with typhus, it protected him from being sent to slave labor in Germany and from other forms of repression. When the Soviets recaptured Lwów in 1944, Banach reestablished the University. However, because the Soviets were removing Poles from Soviet-annexed formerly-Polish territories, Banach prepared to return to Kraków. Before he could do so, he died in August 1945, having been diagnosed seven months earlier with lung cancer.

Some of the notable mathematical concepts that bear Banach's name include Banach spaces, Banach algebras, Banach measures, the Banach–Tarski paradox, the Hahn–Banach theorem, the Banach–Steinhaus theorem, the Banach–Mazur game, the Banach–Alaoglu theorem, and the Banach fixed-point theorem.

Stefan Banach was born on 30 March 1892 at St. Lazarus General Hospital in Kraków, then part of the Austro-Hungarian Empire, into a Góral Roman Catholic family and was subsequently baptised by his father, while his mother abandoned him upon this event and her identity is ambiguous. Banach's parents were Stefan Greczek and Katarzyna Banach, both natives of the Podhale region. Greczek was a soldier in the Austro-Hungarian Army stationed in Kraków. Little is known about Banach's mother. According to his baptismal certificate, she was born in Borówna and worked as a domestic help.

Unusually, Stefan's surname was his mother's instead of his father's, though he received his father's given name, Stefan. Since Stefan Greczek was a private and was prevented by military regulations from marrying, and the mother was too poor to support the child, the couple decided that he should be reared by family and friends. Stefan spent the first few years of his life with his grandmother, but when she took ill Greczek arranged for his son to be raised by Franciszka Płowa and her niece Maria Puchalska in Kraków. Young Stefan would regard Franciszka as his foster mother and Maria as his older sister. In his early years Banach was tutored by Juliusz Mien, a French intellectual and friend of the Płowa family, who had emigrated to Poland and supported himself with photography and translations of Polish literature into French. Mien taught Banach French and most likely encouraged him in his early mathematical pursuits.

In 1902 Banach, aged 10, enrolled in Kraków's "IV Gymnasium" (also known as the "Goetz Gymnasium"). While the school specialized in the humanities, Banach and his best friend Witold Wiłkosz (also a future mathematician) spent most of their time working on mathematics problems during breaks and after school. Later in life Banach would credit Dr. Kamil Kraft, the mathematics and physics teacher at the gymnasium with kindling his interests in mathematics. While generally Banach was a diligent student he did on occasion receive low grades (he failed Greek during his first semester at the gymnasium) and would later speak critically of the school's math teachers.

After obtaining his "matura" (high school degree) at age 18 in 1910, Banach moved to Lwów with the intention of studying at the Lwów Polytechnic. He initially chose engineering as his field of study since at the time he was convinced that there was nothing new to discover in mathematics. At some point he also attended Jagiellonian University in Kraków on a part-time basis. As Banach had to earn money to support his studies it was not until 1914 that he finally, at age 22, passed his high school graduation exams.

When World War I broke out, Banach was excused from military service due to his left-handedness and poor vision. When the Russian Army opened its offensive toward Lwów, Banach left for Kraków, where he spent the rest of the war. He made his living as a tutor at the local gymnasiums, worked in a bookstore and as a foreman of road building crew. He attended some lectures at the Jagiellonian University at that time, including those of the famous Polish mathematicians Stanisław Zaremba and Kazimierz Żorawski, but little is known of that period of his life.

In 1916, in Kraków's "Planty" gardens, Banach encountered Professor Hugo Steinhaus, one of the renowned mathematicians of the time. According to Steinhaus, while he was strolling through the gardens he was surprised to overhear the term ""Lebesgue integral"" (Lebesgue integration was at the time still a fairly new idea in mathematics) and walked over to investigate. As a result, he met Banach, as well as Otto Nikodym. Steinhaus became fascinated with the self-taught young mathematician. The encounter resulted in a long-lasting collaboration and friendship. In fact, soon after the encounter Steinhaus invited Banach to solve some problems he had been working on but which had proven difficult. Banach solved them within a week and the two soon published their first joint work ("On the Mean Convergence of Fourier Series"). Steinhaus, Banach and Nikodym, along with several other Kraków mathematicians (Władysław Ślebodziński, Leon Chwistek, Alfred Rosenblatt and Włodzimierz Stożek) also established a mathematical society, which eventually became the Polish Mathematical Society. The society was officially founded on 2 April 1919. It was also through Steinhaus that Banach met his future wife, Łucja Braus.

Steinhaus introduced Banach to academic circles and substantially accelerated his career. After Poland regained independence in 1920, Banach was given an assistantship at the Lwów Polytechnic. Steinhaus' backing also allowed him to receive a doctorate without actually graduating from a university. The doctoral thesis, accepted by King John II Casimir University of Lwów in 1920 and published in 1922, included the basic ideas of functional analysis, which was soon to become an entirely new branch of mathematics. The thesis was widely discussed in academic circles and allowed him in 1922 to become a professor at the Lwów Polytechnic. Initially an assistant to Professor Antoni Łomnicki, in 1927 Banach received his own chair. In 1924 he was also accepted as a member of the Polish Academy of Learning. At the same time, from 1922, Banach also headed the second Chair of Mathematics at University of Lwów.

Young and talented, Banach gathered around him a large group of mathematicians. The group, meeting in the Scottish Café, soon gave birth to the "Lwów School of Mathematics". In 1929 the group began publishing its own journal, "Studia Mathematica", devoted primarily to Banach's field of study — functional analysis. Around that time, Banach also began working on his best-known work, the first monograph on the general theory of linear-metric space. First published in Polish in 1931, the following year it was also translated into French and gained wider recognition in European academic circles. The book was also the first in a long series of mathematics monographs edited by Banach and his circle. In 17 June 1924 Banach become a correspondence member of the Polish Academy of Sciences and Fine Arts in Kraków.

Following the invasion of Poland by Nazi Germany and the Soviet Union, Lwów came under the control of the Soviet Union for almost two years. Banach, from 1939 a corresponding member of the Academy of Sciences of Ukraine, and on good terms with Soviet mathematicians, had to promise to learn Ukrainian to be allowed to keep his chair and continue his academic activities. Following the German takeover of Lwów in 1941 during Operation Barbarossa, all universities were closed and Banach, along with many colleagues and his son, was employed as lice feeder at Professor Rudolf Weigl's Typhus Research Institute. Employment in Weigl's Institute provided many unemployed university professors and their associates protection from random arrest and deportation to Nazi concentration camps.

After the Red Army recaptured Lviv in the Lvov–Sandomierz Offensive of 1944, Banach returned to the University and helped re-establish it after the war years. However, because the Soviets were removing Poles from annexed formerly Polish territories, Banach began preparing to leave the city and settle in Kraków, Poland, where he had been promised a chair at the Jagiellonian University. He was also considered a candidate for Minister of Education of Poland. In January 1945, however, he was diagnosed with lung cancer and was allowed to stay in Lwów. He died on 31 August 1945, aged 53. His funeral at the Lychakiv Cemetery was attended by hundreds of people.

Banach's dissertation, completed in 1920 and published in 1922, formally axiomatized the concept of a complete normed vector space and laid the foundations for the area of functional analysis. In this work Banach called such spaces ""class E-spaces"", but in his 1932 book, "Théorie des opérations linéaires", he changed terminology and referred to them as ""spaces of type B"", which most likely contributed to the subsequent eponymous naming of these spaces after him. The theory of what came to be known as Banach spaces had antecedents in the work of the Hungarian mathematician Frigyes Riesz (published in 1916) and contemporaneous contributions from Hans Hahn and Norbert Wiener. For a brief period in fact, complete normed linear spaces were referred to as "Banach–Wiener" spaces in mathematical literature, based on terminology introduced by Wiener himself. However, because Wiener's work on the topic was limited, the established name became just "Banach spaces".

Likewise, Banach's fixed point theorem, based on earlier methods developed by Charles Émile Picard, was included in his dissertation, and was later extended by his students (for example in the Banach–Schauder theorem) and other mathematicians (in particular Brouwer and Poincaré and Birkhoff). The theorem did not require linearity of the space, and applied to any Cauchy space (complete metric space).

The Hahn–Banach theorem, is one of the fundamental theorems of functional analysis.


Stanislaw Ulam, another mathematician of the Lwów School of Mathematics, in his autobiography, quotes Banach as saying:

Hugo Steinhaus said of Banach:





</doc>
<doc id="29648" url="https://en.wikipedia.org/wiki?curid=29648" title="Single-lens reflex camera">
Single-lens reflex camera

A single-lens reflex camera (SLR) is a camera that typically uses a mirror and prism system (hence "reflex" from the mirror's reflection) that permits the photographer to view through the lens and see exactly what will be captured. With twin lens reflex and rangefinder cameras, the viewed image could be significantly different from the final image. When the shutter button is pressed on a mechanical SLR, the mirror flips out of the light path, allowing light to pass through to the light receptor and the image to be captured.

Prior to the development of SLR, all cameras with viewfinders had two optical light paths: one path through the lens to the film, and another path positioned above (TLR or "twin-lens reflex") or to the side (rangefinder). Because the viewfinder and the film lens cannot share the same optical path, the viewing lens is aimed to intersect with the film lens at a fixed point somewhere in front of the camera. This is not problematic for pictures taken at a middle or longer distance, but parallax causes framing errors in close-up shots. Moreover, focusing the lens of a fast reflex camera when it is opened to wider apertures (such as in low light or while using low-speed film) is not easy.

Most SLR cameras permit upright and laterally correct viewing through use of a roof pentaprism situated in the optical path between the reflex mirror and viewfinder. Light, which comes both horizontally and vertically inverted after passing through the lens, is reflected upwards by the reflex mirror, into the pentaprism where it is reflected several times to correct the inversions caused by the lens, and align the image with the viewfinder. When the shutter is released, the mirror moves out of the light path, and the light shines directly onto the film (or in the case of a DSLR, the CCD or CMOS imaging sensor). The Canon Pellix film camera was an exception to the moving mirror system, wherein the mirror was a fixed beamsplitting pellicle.

Focus can be adjusted manually by the photographer or automatically by an autofocus system. The viewfinder can include a matte focusing screen located just above the mirror system to diffuse the light. This permits accurate viewing, composing and focusing, especially useful with interchangeable lenses.

Up until the 1990s, SLR was the most advanced photographic preview system available, but the recent development and refinement of digital imaging technology with an on-camera live LCD preview screen has overshadowed SLR's popularity. Nearly all inexpensive compact digital cameras now include an LCD preview screen allowing the photographer to see what the CCD is capturing. However, SLR is still popular in high-end and professional cameras because they are system cameras with interchangeable parts, allowing customization. They also have far less shutter lag, allowing photographs to be timed more precisely. Also the pixel resolution, contrast ratio, refresh rate, and color gamut of an LCD preview screen cannot compete with the clarity and shadow detail of a direct-viewed optical SLR viewfinder.

Large format SLR cameras were probably first marketed with the introduction of C.R. Smith's "Monocular Duplex" (U.S., 1884). SLRs for smaller exposure formats were launched in the 1920s by several camera makers. The first 35mm SLR available to the mass market, Leica's PLOOT reflex housing along with a 200mm f4.5 lens paired to a 35mm rangefinder camera body, debuted in 1935. The Soviet "Спорт" (“Sport”), also a 24mm by 36mm image size, was prototyped in 1934 and went to market in 1937. K. Nüchterlein's Kine Exakta (Germany, 1936) was the first integrated 35mm SLR to enter the market. Additional Exakta models, all with waist-level finders, were produced up to and during World War II. Another ancestor of the modern SLR camera was the Swiss-made Alpa, which was innovative, and influenced the later Japanese cameras. The first eye-level SLR viewfinder was patented in Hungary on August 23, 1943 by Jenő Dulovits, who then designed the first 35 mm camera with one, the Duflex, which used a system of mirrors to provide a laterally correct, upright image in the eye-level viewfinder. The Duflex, which went into serial production in 1948, was also the world's first SLR with an instant-return (a.k.a. autoreturn) mirror.

The first commercially produced SLR that employed a roof pentaprism was the Italian Rectaflex A.1000, shown in full working condition on Milan fair April 1948 and produced from September the same year, thus being on the market one year before the east German Zeiss Ikon VEB Contax S, announced on May 20, 1949, produced from September.

The Japanese adopted and further developed the SLR. In 1952, Asahi developed the Asahiflex and in 1954, the Asahiflex IIB. In 1957, the Asahi Pentax combined the fixed pentaprism and the right-hand thumb wind lever. Nikon, Canon and Yashica introduced their first SLRs in 1959 (the F, Canonflex, and Pentamatic, respectively).

As a small matter of history, the first 35 mm camera (non-SLR) to feature through the lens light metering may have been Nikon, with a prototype rangefinder camera, the SPX. According to the website below, the camera used Nikon 'S' type rangefinder lenses.

Through-the-lens light metering is also known as "behind-the-lens metering". In the SLR design scheme, there were various placements made for the metering cells, all of which used CdS (Cadmium sulfide) photocells. The cells were either located in the pentaprism housing, where they metered light transmitted through the focusing screen; underneath the reflex mirror glass itself, which was Topcon's design; or in front of the shutter mechanism, which was the design used by Canon with their Canon Pellix.

Pentax was the first manufacturer to show an early prototype 35 mm behind-the-lens metering SLR camera, which was named the "Pentax Spotmatic". The camera was shown at the 1960 photokina show. However, the first Through-the-lens (TTL) light metering SLR on the market was the 1963 Topcon RE Super, which had the CdS metering cell placed behind the reflex mirror. The mirror had narrow slits cut into the surface to let the light reach the cell providing average metering. Late in the following year, a production model of the Pentax Spotmatic was shown whose CdS light meter cells were on the pentaprism, reading the light off the focusing screen providing average reading, yet keeping the Spotmatic name, but now written in one word. Another clever design appeared in 1965, the Canon Pellix employing a pellicle mirror that is semi-transparent, placing the meter cell on an arm swinging into the lightpass behind the mirror for meter reading.

Mamiya Sekor came out with cameras such as the Mamiya Sekor TL and various other versions. Yashica introduced the TL Super. Both of these cameras used M42 screw thread lenses as did the Pentax Spotmatic. Later on Fujica introduced their ST-701, then ST-801 and ST-901 cameras. The ST-701 was the first SLR to use a silicon cell photodiode, which was more sensitive than CdS and was immune to the memory effect that the CdS cell suffered from in bright sunlight. Gradually, other 35 mm SLR camera manufacturers changed their behind-the-lens meters from CdS cells to Silicon Diode photocells.

Other manufacturers responded and introduced their own behind-the-lens metering cameras. Nikon and Miranda, at first, simply upgraded their interchangeable pentaprisms to include behind-the-lens metering (for Nikon F, and Miranda D, F, Fv and G models) and these manufacturers also bought out other camera models with built-in behind-the-lens metering capability, such as the Nikkormat FT and the Miranda Sensorex (which used an external coupling diaphragm). Minolta introduced the SRT-101, which used Minolta's proprietary system they referred to as "CLC", which was an acronym for "contrast light compensation", which metered differently from an average metering behind-the-lens camera.

Some German manufacturers also introduced cameras such as the Zeiss Ikon Contarex family, which was one of very few 35 mm SLR to use interchangeable film backs.

Inexpensive leaf-shutter cameras also benefited from behind-the-lens metering as, Topcon introduced the Auto 100 with front-mount interchangeable lenses designed only for that camera, and one of the Zeiss Ikon Contaflex leaf shutter cameras. Kowa manufactured their SET-R, which had similar specifications.

Within months, manufacturers decided to bring out models that provided limited area metering, such as Nikon's Photomic Tn finder, which concentrated 60% of the CdS cells sensitivity on the inner circle of the focusing screen and 30% on the surrounding area. Canon used spot metering in the unusual Canon Pellix camera, which also had a stationary mirror system that allowed approximately 70% of the light to travel to the film plane and 30% to the photographer's eye. This system, unfortunately, degraded the native resolution of the attached lens and provided less illumination to the eyepiece. It did have the advantage of having less vibration than other SLR cameras but this was not sufficient to attract professionals to the camera in numbers.

While auto-exposure was commonly used in the early 1960s with various 35 mm fixed lens rangefinder cameras such as the Konica Auto 'S', and other cameras such as the Polaroid Land cameras whose early models used selenium cell meters, auto-exposure for interchangeable lens SLRs was a feature that was largely absent, except for a few early leaf-shutter SLRs such as the Kowa SE-R and Topcon Auto 100.

The types of automation found in some of these cameras consisted of the simple programmed shutter, whereby the camera's metering system would select a mechanically set series of apertures with shutter speeds, one setting of which would be sufficient for the correct exposure. In the case of the above-mentioned Kowa and Topcon, automation was semi-automatic, where the camera's CDs meter would select the correct aperture only.

Autoexposure, technically known as semi-automatic exposure, where the camera's metering system chooses either the shutter speed or the aperture, was finally introduced by the Savoyflex and popularized by Konishiroku in the 1965 Konica Auto-Reflex. This camera was of the 'shutter-priority' type automation, which meant that the camera selected the correct aperture automatically. This model also had the interesting ability to photograph in 35 mm full-frames or half-frames, all selected by a lever.

Other SLRs soon followed, but because of limitations with their lens mounts, the manufacturers of these cameras had to choose 'aperture-priority' automation, where the camera's metering system selects the correct shutter speed. As one example, Pentax introduced the Electro Spotmatic, which was able to use the then considerable bulk of 42 mm screw-mount lenses produced by various manufacturers. Yashica, another screw-mount camera manufacturer, soon followed.

Canon, which produced the FD lens mount (known as the breech-mount; a unique lens mounting system that combines the advantages of screw-mount and bayonet-mount) introduced their shutter priority 35 mm SLR, the Canon EF in 1976 or so. This camera's build quality was almost the equal of their flagship camera, the Canon F1, and featured a copal-square vertically travelling focal plane shutter that could synchronize electronic flash at shutter speeds up to and including 1/125 of a second, thus making this a good second-body camera for the professional photographer.

Nikon at first produced an aperture-priority camera, but later made subtle changes on the inside of their bayonet mount, which allowed for shutter-priority automation without obsoleting the photographers lenses.

Full-program auto-exposure soon followed with the advent of the Canon A-1 in 1978. This SLR had a 'P' mode on the shutter speed dial, and a lock on the aperture ring to allow the lens to be put on 'Auto' mode. Other manufacturers soon followed with Nikon introducing the FA, Minolta introducing the X-700 in 1981, and Pentax introducing the Super Program. Olympus, however, continued with 'aperture-priority' automation in their OM system line.

The 1970s and 1980s saw steadily increasing use of electronics, automation, and miniaturization, including integrated motor driven film advance with the Konica FS-1 in 1979, and motor rewind functions.

The first autofocus 35 mm SLR was the Pentax ME-F released in 1981.

The Minolta Maxxum 7000, released in 1985, was the first 35 mm SLR with integrated autofocus and motorized film-advance winder, which became the standard configuration for SLR cameras from then on. This development had significant impact on the photographic industry.

Some manufacturers discarded their existing lens systems to compete with other manufacturer's autofocus capability in their new cameras. This was the case for Canon, with its new EOS lens line. Other manufacturers chose to adapt their existing lens systems for autofocus capability, as was the case with Nikon and Pentax. This allowed photographers to continue using their existing lenses, which greatly reduced the cost of upgrading. For example, almost all Nikon lenses from the 1960s and later still function on the current Nikon bodies, only lacking autofocus. Still some manufacturers, notably Leica with its R-system lenses, and Contax with its Zeiss lenses, decided to keep their lens mounts non-autofocus.
From the late 1980s competition and technical innovations made 35 mm camera systems more versatile and sophisticated by adding more advanced light metering capabilities such as spot-metering; limited area metering such as used by Canon with the F1 series; matrix metering as used by Nikon, exposure communication with dedicated electronic flash units. The user interface also changed on many cameras, replacing meter needle displays that were galvanometer-based and thereby fragile, with light-emitting diodes (LEDs) and then with more comprehensive liquid crystal displays (LCDs) both in the SLR viewfinder and externally on the cameras' top plate using an LCD screen. Wheels and buttons replaced the shutter dial on the camera and the aperture ring on the lens on many models, although some photographers still prefer shutter dials and aperture rings. Some manufacturers introduced image stabilization on certain lenses to combat camera shake and to allow longer hand-held exposures without using a tripod. This feature is especially useful with long telephoto lenses.

Canon, Nikon and Pentax have all developed digital SLR cameras (DSLRs) using the same lens mounts as on their respective film SLR cameras. Konica Minolta did the same, but in 2006 sold their camera technology to Sony, which built DSLRs based on the Minolta lens mount before abandoning the technology in favor of cameras built around a semi-transparent fixed mirror. Samsung builds DSLRs based on the Pentax lens mount. Olympus, on the other hand, chose to create a new digital-only Four Thirds System SLR standard, adopted later by Panasonic and Leica.

Contax came out with a DSLR model, the Contax N-Digital. This model was too late and too expensive to be competitive with other camera manufacturers. The Contax N-digital was the last Contax to use that maker's lens system, and the camera, while having impressive features such as a full-frame sensor, was expensive and lacked sufficient write-speed to the memory card for it to be seriously considered by some professional photographers.

The digital single-lens reflex camera have largely replaced film SLR's design in convenience, sales and popularity at the start of 21st century.

A cross-section ("or" 'side-view') of the optical components of a typical SLR camera shows how the light passes through the lens assembly (1), is reflected by the mirror (2) placed at a 45-degree angle, and is projected on the matte focusing screen (5). Via a condensing lens (6) and internal reflections in the roof pentaprism (7) the image appears in the eyepiece (8). When an image is taken, the mirror moves upwards from its resting position in the direction of the arrow, the focal plane shutter (3) opens, and the image is projected onto the film or sensor (4) in exactly the same manner as on the focusing screen.

This feature distinguishes SLRs from other cameras as the photographer sees the image composed exactly as it will be captured on the film or sensor (see Advantages below).

Most 35 mm SLRs use a roof pentaprism or penta-mirror to direct the light to the eyepiece, first used on the 1948 Duflex constructed by Jenő Dulovits and patented August 1943 (Hungary). With this camera also appeared the first Instant-return mirror.
The first Japanese pentaprism SLR was the 1955 Miranda T, followed by the Asahi Pentax, Minolta SR-2, Zunow, Nikon F and the Yashica Pentamatic. Some SLRs offered removable pentaprisms with optional viewfinder capabilities, such as the waist-level finder, the interchangeable sports finders used on the Canon F1 and F1n; the Nikon F, F2, F3, F4 and F5; and the Pentax LX.

Another prism design was the porro prism system used in the Olympus Pen F, the Pen FT, the Pen FV half-frame 35 mm SLR cameras. This was later used on the Olympus EVOLT E-3x0 series, the Leica Digilux 3 and the Panasonic DMC-L1.

A right-angle finder is available that slips onto the eyepiece of most SLRs and D-SLRs and allows viewing through a waist-level viewfinder. There is also a finder that provides EVF remote capability.

Almost all contemporary SLRs use a focal-plane shutter located in front of the film plane, which prevents the light from reaching the film even if the lens is removed, except when the shutter is actually released during the exposure. There are various designs for focal plane shutters. Early focal-plane shutters designed from the 1930s onwards usually consisted of two curtains that travelled horizontally across the film gate: an opening shutter curtain followed by a closing shutter curtain. During fast shutter speeds, the focal-plane shutter would form a 'slit' whereby the second shutter curtain was closely following the first opening shutter curtain to produce a narrow, vertical opening, with the shutter slit moving horizontally. The slit would get narrower as shutter speeds were increased. Initially these shutters were made from a cloth material (which was in later years often rubberised), but some manufacturers used other materials instead. Nippon Kōgaku (now Nikon Corporation), for example, used titanium foil shutters for several of their flagship SLR cameras, including the Nikon F, F2, and F3.

Other focal-plane shutter designs, such as the Copal Square, travelled vertically — the shorter travelling distance of 24 millimetres (as opposed to 36 mm horizontally) meant that minimum exposure and flash synchronisation times could be reduced. These shutters are usually manufactured from metal, and use the same moving-slit principle as horizontally travelling shutters. They differ, though, in usually being formed of several slats or blades, rather than single curtains as with horizontal designs, as there is rarely enough room above and below the frame for a one-piece shutter. Vertical shutters became very common in the 1980s (though Konica, Mamiya, and Copal first pioneered their use in the 1950s and 1960s, and are almost exclusively used for new cameras. Nikon used Copal-made vertical plane shutters in their Nikomat/Nikkormat -range, enabling x-sync speeds from to while the only choice for focal plane shutters at that time was . Later, Nikon again pioneered the use of titanium for vertical shutters, using a special honeycomb pattern on the blades to reduce their weight and achieve world-record speeds in 1982 of second for non-sync shooting, and with x-sync. Nowadays most such shutters are manufactured from cheaper aluminium (though some high-end cameras use materials such as carbon-fibre and Kevlar).

One unusual design, the Olympus Pen half-frame 35 mm SLR system, manufactured by Olympus in Japan, used a rotary focal-plane shutter mechanism that was extremely simple and elegant in design. This shutter used titanium foil but consisted of one piece of metal with a fixed opening, which allowed electronic flash synchronisation up to and including its maximum speed of 1/500 of a second – rivalling the capabilities of leaf-shutter systems

Another 35 mm camera system that used a rotary shutter, was the Robot Royal cameras, most of which were rangefinder 35 mm cameras. Some of these cameras were full-frame; some were half-frame, and at least one Robot camera produced an unusual square-sized image on the 35 mm frame.

The Mercury II, produced in 1946, also used a rotary shutter. This was a half-frame 35mm camera.

Another shutter system is the leaf shutter, whereby the shutter is constructed of diaphragm-like blades and can be situated either between the lens or behind the lens. If the shutter is part of a lens assembly some other mechanism is required to ensure that no light reaches the film between exposures.

An example of a behind-the-lens leaf shutter is found in the 35 mm SLRs produced by Kodak, with their Retina Reflex camera line; Topcon, with their Auto 100; and Kowa with their SE-R and SET-R reflexes.

A primary example of a medium-format SLR with a between-the-lens leaf shutter system would be Hasselblad, with their 500C, 500CM, 500 EL-M (a motorized Hasselblad) and other models (producing a 6 cm square negative). Hasselblads use an auxiliary shutter blind situated behind the lens mount and the mirror system to prevent the fogging of film.

Other medium-format SLRs also using leaf shutters include the now discontinued Zenza-Bronica camera system lines such as the Bronica ETRs, the ETRs'i (both producing a 6 × 4.5 cm. image), the SQ and the SQ-AI (producing a 6 × 6 cm image like the Hasselblad), and the Zenza-Bronica G system (6 × 7 cm). Certain Mamiya medium-format SLRs, discontinued camera systems such as the Kowa 6 and a few other camera models also used between-the-lens leaf shutters in their lens systems.

Thus, any time a photographer purchased one of these lenses, that lens included a leaf shutter in its lens mount.

Because leaf shutters synchronized electronic flash at all shutter speeds especially at fast shutter speeds of of a second or faster, cameras using leaf shutters were more desirable to studio photographers who used sophisticated studio electronic flash systems.

Some manufacturers of medium-format 120 film SLR cameras also made leaf-shutter lenses for their focal-plane-shutter models. Rollei made at least two such lenses for their Rolleiflex SL-66 medium format which was a focal-plane shutter SLR. Rollei later switched to a camera system of leaf-shutter design (e.g., the 6006 and 6008 reflexes) and their current medium-format SLRs are now all of the between-the-lens shutter design.

Since the technology became widespread in the 1970s, SLRs have become the main photographic instrument used by dedicated amateur photographers and professionals. Some photographers of static subjects (such as architecture, landscape, and some commercial subjects), however, prefer view cameras because of the capability to control perspective. With a triple-extension bellows 4" × 5" camera such as the Linhof SuperTechnika V, the photographer can correct certain distortions such as "keystoning", where the image 'lines' converge (i.e., photographing a building by pointing a typical camera upward to include the top of the building). Perspective correction lenses are available in the 35 mm and medium formats to correct this distortion with film cameras, and it can also be corrected after the fact with photo software when using digital cameras. The photographer can also extend the bellows to its full length, tilt the front standard and perform photomacrography (commonly known as 'macro photography'), producing a sharp image with depth-of-field without stopping down the lens diaphram.

Early SLRs were built for large format photography, but this film format has largely lost favor among professional photographers. SLR film-based cameras have been produced for most film formats as well as for digital formats. These film-based SLRs use the 35 mm format as, this film format offers a variety of emulsions and film sensitivity speeds, usable image quality and a good market cost. 35 mm film comes in a variety of exposure lengths: 20 exposure, 24 exposure and 36 exposure rolls. Medium format SLRs provide a higher-quality image with a negative that can be more easily retouched than the smaller 35 mm negative, when this capability is required.

A small number of SLRs were built for APS such as the Canon IX series and the Nikon Pronea cameras. SLRs were also introduced for film formats as small as Kodak's 110, such as the Pentax Auto 110, which had interchangeable lenses.

The Narciss camera is an all-metal 16mm subminiature single lens reflex camera made by Russian optic firm Krasnogorsky Mekhanichesky Zavod (KMZ) Narciss (Soviet Union; Нарцисс) between 1961 and 1965.

Other features found on many SLR cameras include through-the-lens (TTL) metering and sophisticated flash control referred to as "dedicated electronic flash". In a dedicated system, once the dedicated electronic flash is inserted into the camera's hot shoe and turned on, there is then communication between camera and flash. The camera's synchronization speed is set, along with the aperture. Many camera models measure the light that reflects off of the film plane, which controls the flash duration of the electronic flash. This is denoted TTL flash metering.

Some electronic flash units can send out several short bursts of light to aid the autofocus system or for wireless communication with off-camera flash units. A pre-flash is often used to determine the amount of light that is reflected from the subject, which sets the duration of the main flash at time of exposure. Some cameras also employ automatic fill-flash, where the flash light and the available light are balanced. While these capabilities are not unique to the SLR, manufacturers included them early on in the top models, whereas the best rangefinder cameras adopted such features later.

Many of the advantages of SLR cameras derive from viewing and focusing the image through the attached lens. Most other types of cameras do not have this function; subjects are seen through a viewfinder that is near the lens, making the photographer's view different from that of the lens. SLR cameras provide photographers with precision; they provide a viewing image that will be exposed onto the negative exactly as it is seen through the lens. There is no parallax error, and exact focus can be confirmed by eye—especially in macro photography and when photographing using long focus lenses. The depth of field may be seen by stopping down to the attached lens aperture, which is possible on most SLR cameras except for the least expensive models. Because of the SLR's versatility, most manufacturers have a vast range of lenses and accessories available for them.

Compared to most fixed-lens compact cameras, the most commonly used and inexpensive SLR lenses offer a wider aperture range and larger maximum aperture (typically to for a 50 mm lens). This allows photographs to be taken in lower light conditions without flash, and allows a narrower depth of field, which is useful for blurring the background behind the subject, making the subject more prominent. "Fast" lenses are commonly used in theater photography, portrait photography, surveillance photography, and all other photography requiring a large maximum aperture.
The variety of lenses also allows for the camera to be used and adapted in many different situations. This provides the photographer with considerably more control (i.e., how the image is viewed and framed) than would be the case with a view camera. In addition, some SLR lenses are manufactured with extremely long focal lengths, allowing a photographer to be a considerable distance away from the subject and yet still expose a sharp, focused image. This is particularly useful if the subject includes dangerous animals (e.g., wildlife); the subject prefers anonymity to being photographed; or else, the photographer's presence is unwanted (e.g., celebrity photography or surveillance photography). Practically all SLR and DSLR camera bodies can also be attached to telescopes and microscopes via an adapter tube to further enhance their imaging capabilities.

In most cases, single-lens reflex cameras cannot be made as small or as light as other camera designs—such as rangefinder cameras, autofocus compact cameras and digital cameras with electronic viewfinders (EVF)—owing to the mirror box and pentaprism/pentamirror. The mirror box also prevents lenses with deeply recessed rear elements from being mounted close to the film or sensor unless the camera has a mirror lockup feature; this means that simple designs for wide angle lenses cannot be used. Instead, larger and more complex retrofocus designs are required.

The SLR mirror 'blacks-out' the viewfinder image during the exposure. In addition, the movement of the reflex mirror takes time, limiting the maximum shooting speed. The mirror system can also cause noise and vibration. Partially reflective (pellicle) fixed mirrors avoid these problems and have been used in a very few designs including the Canon Pellix and the Canon EOS-1N RS, but these designs introduce their own problems. These pellicle mirrors reduce the amount of light travelling to the film plane or sensor and also can distort the light passing through them, resulting in a less-sharp image. To avoid the noise and vibration, many professional cameras offer a mirror lock-up feature, however, this feature totally disables the SLR's automatic focusing ability. Electronic viewfinders have the potential to give the 'viewing-experience' of a DSLR (through-the-lens viewing) without many of the disadvantages. More recently, Sony have resurrected the pellicle mirror concept in their "single-lens translucent" (SLT) range of cameras.

SLRs vary widely in their construction and typically have bodies made of plastic or magnesium. Most manufacturers do not cite durability specifications, but some report shutter life expectancies for professional models. For instance, the Canon EOS 1Ds MkII is rated for 200,000 shutter cycles and the newer Nikon D3 is rated for 300,000 with its exotic carbon fiber/kevlar shutter. Because many SLRs have interchangeable lenses, there is a tendency for dust, sand and dirt to get into the main body of the camera through the mirror box when the lens is removed, thus dirtying or even jamming the mirror movement mechanism or the shutter curtain mechanism itself. In addition, these particles can also jam or otherwise hinder the focusing feature of a lens if they enter into the focusing helicoid. The problem of sensor cleaning has been somewhat reduced in DSLRs as some cameras have a built-in sensor cleaning unit.

The price of SLRs in general also tends to be somewhat higher than that of other types of cameras, owing to their internal complexity. This is compounded by the expense of additional components, such as flashes or lenses. The initial investment in equipment can be prohibitive enough to keep some casual photographers away from SLRs, although the market for used SLRs has become larger particularly as photographers migrate to digital systems.

The digital single-lens reflex camera has largely replaced the film SLR for its convenience, sales, and popularity at the start of 21st century. These cameras are currently the marketing favorite among advanced amateur and professional photographers. Film-based SLRs are still used by a niche market of enthusiasts and format lovers.





</doc>
<doc id="29651" url="https://en.wikipedia.org/wiki?curid=29651" title="SAS">
SAS

SAS or Sas may refer to:





















</doc>
<doc id="29652" url="https://en.wikipedia.org/wiki?curid=29652" title="Senary">
Senary

The senary numeral system (also known as base-6, heximal, or seximal) has six as its base. It has been adopted independently by a small number of cultures. Like decimal, it is a semiprime, though being the product of the only two consecutive numbers that are both prime (2 and 3) it has a high degree of mathematical properties for its size. As six is a superior highly composite number, many of the arguments made in favor of the duodecimal system also apply to this base-6.

Senary may be considered interesting in the study of prime numbers, since all primes other than 2 and 3, when expressed in senary, have 1 or 5 as the final digit. In senary the prime numbers are written

That is, for every prime number "p" greater than 3, one has the modular arithmetic relations that either "p" ≡ 1 or 5 (mod 6) (that is, 6 divides either "p" − 1 or "p" − 5); the final digit is a 1 or a 5. This is proved by contradiction.
For any integer "n":

Additionally, since the smallest four primes (2, 3, 5, 7) are either divisors or neighbors of 6, senary has simple divisibility tests for many numbers.

Furthermore, all even perfect numbers besides 6 have 44 as the final two digits when expressed in senary, which is proven by the fact that every even perfect number is of the form 2(2−1), where 2−1 is prime.

Senary is also the largest number base "r" that has no totatives other than 1 and "r" − 1, making its multiplication table highly regular for its size, minimizing the amount of effort required to memorize its table. This property maximizes the probability that the result of an integer multiplication will end in zero, given that neither of its factors do.

Because six is the product of the first two prime numbers and is adjacent to the next two prime numbers, many senary fractions have simple representations:

Each regular human hand may be said to have six unambiguous positions; a fist, one finger (or thumb) extended, two, three, four and then all five extended.

If the right hand is used to represent a unit, and the left to represent the 'sixes', it becomes possible for one person to represent the values from zero to 55 (35) with their fingers, rather than the usual ten obtained in standard finger counting. e.g. if three fingers are extended on the left hand and four on the right, 34 is represented. This is equivalent to 3 × 6 + 4 which is 22.

Which hand is used for the 'sixes' and which the units is down to preference on the part of the counter, however when viewed from the counter's perspective, using the left hand as the most significant digit correlates with the written representation of the same senary number. Flipping the 'sixes' hand around to its backside may help to further disambiguate which hand represents the 'sixes' and which represents the units.

Additionally, this method is the least abstract way to count using two hands that reflects the concept of positional notation, as the movement from one position to the next is done by switching from one hand to another. While most developed cultures count by fingers up to 5 in very similar ways, beyond 5 non-Western cultures deviate from Western methods, such as with Chinese number gestures. As senary finger counting also deviates only beyond 5, this counting method rivals the simplicity of traditional counting methods, a fact which may have implications for the teaching of positional notion to young students.

In NCAA basketball, the players' uniform numbers are restricted to be senary numbers of at most two digits, so that the referees can signal which player committed an infraction by using this finger-counting system.

More abstract finger counting systems, such as chisanbop or finger binary, allow counting to 99, 1,023, or even higher depending on the method (though not necessarily senary in nature). The English monk and historian Bede, described in the first chapter of his work De temporum ratione, (725), titled "Tractatus de computo, vel loquela per gestum digitorum," a system which allowed counting up to 9,999 on two hands.
Despite the rarity of cultures that group large quantities by 6, a review of the development of numeral systems suggests a threshold of numerosity at 6 (possibly being conceptualized as "whole", "fist", or "beyond five fingers"), with 1–6 often being pure forms, and numerals thereafter being constructed or borrowed.

The Ndom language of Papua New Guinea is reported to have senary numerals. "Mer" means 6, "mer an thef" means 6 × 2 = 12, "nif" means 36, and "nif thef" means 36 × 2 = 72.

Another example from Papua New Guinea are the Morehead-Maro languages. In these languages, counting is connected to ritualized yam-counting. These languages count from a base six, employing words for the powers of six; running up to 6 for some of the languages. One example is Kómnzo with the following numerals: "nimbo" (6), "féta" (6), "tarumba" (6), "ntamno" (6), "wärämäkä" (6), "wi" (6).

Some Niger-Congo languages have been reported to use a senary number system, usually in addition to another, such as decimal or vigesimal.

Proto-Uralic has also been suspected to have had senary numerals, with a numeral for 7 being borrowed later, though evidence for constructing larger numerals (8 and 9) subtractively from ten suggests that this may not be so.

For some purposes, base 6 might be too small a base for convenience. This can be worked around by using its square, base 36 (hexatrigesimal), as then conversion is facilitated by simply making the following replacements:

Thus, the base-36 number WIKIPEDIA is equal to the senary number 523032304122213014. In decimal, it is 91,730,738,691,298.

The choice of 36 as a radix is convenient in that the digits can be represented using the Arabic numerals 0–9 and the Latin letters A–Z: this choice is the basis of the base36 encoding scheme. The compression effect of 36 being the square of 6 causes a lot of patterns and representations to be shorter in base 36:

1/9 = 0.04 = 0.4

1/16 = 0.0213 = 0.29

1/5 = 0. = 0.

1/7 = 0. = 0.





</doc>
