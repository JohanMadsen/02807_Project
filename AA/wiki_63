<doc id="8400" url="https://en.wikipedia.org/wiki?curid=8400" title="Duodecimal">
Duodecimal

The duodecimal system (also known as base 12 or dozenal) is a positional notation numeral system using twelve as its base. In this system, the number ten may be written by a rotated "2" (2) and the number eleven by a rotated "3" (3). This notation was introduced by Sir Isaac Pitman. These digit forms are available as Unicode characters on computerized systems since June 2015 as ↊ (Code point 218A) and ↋ (Code point 218B), respectively. Other notations use "A", "T", or "X" for ten and "B" or "E" for eleven. The number twelve (that is, the number written as "12" in the base ten numerical system) is instead written as "10" in duodecimal (meaning "1 dozen and 0 units", instead of "1 ten and 0 units"), whereas the digit string "12" means "1 dozen and 2 units" (i.e. the same number that in decimal is written as "14"). Similarly, in duodecimal "100" means "1 gross", "1000" means "1 great gross", and "0.1" means "1 twelfth" (instead of their decimal meanings "1 hundred", "1 thousand", and "1 tenth").

The number twelve, a superior highly composite number, is the smallest number with four non-trivial factors (2, 3, 4, 6), and the smallest to include as factors all four numbers (1 to 4) within the subitizing range, and the smallest abundant number. As a result of this increased factorability of the radix and its divisibility by a wide range of the most elemental numbers (whereas ten has only two non-trivial factors: 2 and 5, and not 3, 4, or 6), duodecimal representations fit more easily than decimal ones into many common patterns, as evidenced by the higher regularity observable in the duodecimal multiplication table. As a result, duodecimal has been described as the optimal number system. Of its factors, 2 and 3 are prime, which means the reciprocals of all 3-smooth numbers (such as 2, 3, 4, 6, 8, 9, 12, 16, 18, 24, 27, 32, 36, ...) have a terminating representation in duodecimal. In particular, the five most elementary fractions (, , , and ) all have a short terminating representation in duodecimal (0.6, 0.4, 0.8, 0.3 and 0.9, respectively), and twelve is the smallest radix with this feature (because it is the least common multiple of 3 and 4). This all makes it a more convenient number system for computing fractions than most other number systems in common use, such as the decimal, vigesimal, binary, octal and hexadecimal systems. Although the trigesimal and sexagesimal systems (where the reciprocals of all 5-smooth numbers terminate) do even better in this respect, this is at the cost of unwieldy multiplication tables and a much larger number of symbols to memorize.

Languages using duodecimal number systems are uncommon. Languages in the Nigerian Middle Belt such as Janji, Gbiri-Niragu (Gure-Kahugu), Piti, and the Nimbia dialect of Gwandara; the Chepang language of Nepal and the Mahl language of Minicoy Island in India are known to use duodecimal numerals. 

Germanic languages have special words for 11 and 12, such as "eleven" and "twelve" in English. However, they are considered to come from Proto-Germanic *"ainlif" and *"twalif" (respectively "one left" and "two left"), both of which were decimal.

Historically, units of time in many civilizations are duodecimal. There are twelve signs of the zodiac, twelve months in a year, and the Babylonians had twelve hours in a day (although at some point this was changed to 24, which is twice as 12). Traditional Chinese calendars, clocks, and compasses are based on the twelve Earthly Branches. There are 12 inches in an imperial foot, 12 troy ounces in a troy pound, 12 old British pence in a shilling, 24 (12×2) hours in a day, and many other items counted by the dozen, gross (144, square of 12) or great gross (1728, cube of 12). The Romans used a fraction system based on 12, including the uncia which became both the English words "ounce" and "inch". Pre-decimalisation, Ireland and the United Kingdom used a mixed duodecimal-vigesimal currency system (12 pence = 1 shilling, 20 shillings or 240 pence to the pound sterling or Irish pound), and Charlemagne established a monetary system that also had a mixed base of twelve and twenty, the remnants of which persist in many places.

The importance of 12 has been attributed to the number of lunar cycles in a year, and also to the fact that humans have 12 finger bones (phalanges) on one hand (three on each of four fingers). It is possible to count to 12 with the thumb acting as a pointer, touching each finger bone in turn. A traditional finger counting system still in use in many regions of Asia works in this way, and could help to explain the occurrence of numeral systems based on 12 and 60 besides those based on 10, 20 and 5. In this system, the one (usually right) hand counts repeatedly to 12, displaying the number of iterations on the other (usually left), until five dozens, i. e. the 60, are full.

In a duodecimal place system twelve is written as 10, but there are numerous proposals for how to write ten and eleven. The simplified notations use only basic and easy to access letters such as "T" and "E" (for "ten" and "eleven"), "X" and "Z", "t" and "e", "d" and "k", others use "A" and "B" or "a" and "b" as in the hexadecimal system. Some employ Greek letters such as δ (standing for Greek δέκα 'ten') and ε (for Greek ένδεκα 'eleven'), or τ and ε. Frank Emerson Andrews, an early American advocate for duodecimal, suggested and used in his book "New Numbers" an X (from the Roman numeral for ten) and a script E (ℰ, ).
The Dozenal Society of Great Britain proposes a rotated digit two 2 (↊, ) for ten and a reversed or rotated digit three 3 (↋, ) for eleven. This notation was introduced by Sir Isaac Pitman.

Until 2015, the Dozenal Society of America (DSA) used and , the symbols devised by William Addison Dwiggins. After the Pitman digits (↊, and ↋, ) were added to Unicode in 2015, the DSA took a vote and then began publishing content using the Pitman digits instead. They still use the letters X and E as the equivalent in ASCII text.

Other proposals are more creative or aesthetic, for example, Edna Kramer in her 1951 book "The Main Stream of Mathematics" used a six-pointed asterisk (sextile) ⚹ for ten and a hash (or octothorpe) # for eleven. The symbols were chosen because they are available in typewriters and already present in telephone dials. This notation was used in publications of the Dozenal Society of America in the period 1974–2008. Many don't use any of the Hindu-Arabic symbols, under the principle of "separate identity."

There are also varying proposals of how to distinguish a duodecimal number from a decimal one, or one in a different base. They include italicizing duodecimal numbers ("54" = 64), adding a "Humphrey point" (a semicolon ";" instead of a decimal point ".") to duodecimal numbers (54; = 64.) (54;0 = 64.0), or some combination of the two. More also add extra marking to one or more bases. Others use subscript or affixed labels to indicate the base, allowing for more than decimal and duodecimal to be represented:

This allows one to write "54 = 64," "54 = 64" or "doz 54 = dec 64." In programming, binary, octal, and hexadecimal often use a similar scheme: a binary number starts with codice_1, octal with codice_2, and hexadecimal with codice_3.

The Dozenal Society of America suggests the pronunciation of ten and eleven as "dek" and "el", each order has its own name and the prefix "e"- is added for fractions. The symbol corresponding to the decimal point or decimal comma, separating the whole number part from the fractional part, is the semicolon ";". The overall system is:
Multiple digits in this are pronounced differently. 12 is "one do two", 30 is "three do", 100 is "one gro", BA9 (ET9) is "el gro dek do nine", B8,65A,300 (E8,65T,300) is "el do eight bi-mo, six gro five do dek mo, three gro", and so on.

William James Sidis used 12 as the base for his constructed language Vendergood in 1906, noting it being the smallest number with four factors and the prevalence in commerce.

The case for the duodecimal system was put forth at length in F. Emerson Andrews' 1935 book "New Numbers: How Acceptance of a Duodecimal Base Would Simplify Mathematics". Emerson noted that, due to the prevalence of factors of twelve in many traditional units of weight and measure, many of the computational advantages claimed for the metric system could be realized "either" by the adoption of ten-based weights and measure "or" by the adoption of the duodecimal number system.
Both the Dozenal Society of America and the Dozenal Society of Great Britain promote widespread adoption of the base-twelve system. They use the word "dozenal" instead of "duodecimal" to avoid the more overtly base-ten terminology. It should be noted that the etymology of 'dozenal' is itself also an expression based on base-ten terminology since 'dozen' is a direct derivation of the French word 'douzaine' which is a derivative of the French word for twelve, "douze" which is related to the old French word 'doze' from Latin 'duodecim'. 

It has been suggested by some members of the Dozenal Society of America and Duodecimal Society of Great Britain that a more apt word would be 'uncial'. Uncial is a derivation of the Latin word 'one-twelfth' which is 'uncia' and also the base-twelve analogue of the Latin word 'one-tenth' which is 'decima'. In the same manner as "decimal" comes from the Latin word for one-tenth decima, (Latin for ten was decem), the direct analogue for a base-twelve system is "uncial". An early use of this word can be found in Vol 1 Issue 2 of "The Duodecimal Bulletin" of the DSA dated June 1945 in which a submission on page 9 by a Pvt William S. Crosby titled "The Uncial Jottings of a Harried Infantryman", he includes the same argument for the word 'uncial'. Although not accepted by either of these two 'Uncial' societies, the use is beginning to grow.

The renowned mathematician and mental calculator Alexander Craig Aitken was an outspoken advocate of the advantages and superiority of duodecimal over decimal:

In Jorge Luis Borges' short story Tlön, Uqbar, Orbis Tertius Herbert Ashe, a melancholy English engineer, working for the Southern Argentine Railway company, is converting a duodecimal number system to a hexadecimal system. He leaves behind on his death in 1937 a manuscript Orbis Tertius that posthumously identifies him as one of the anonymous authors of the encyclopaedia of Tlön.

In Leo Frankowski's Conrad Stargard novels, Conrad introduces a duodecimal system of arithmetic at the suggestion of a merchant, who is accustomed to buying and selling goods in dozens and grosses, rather than tens or hundreds. He then invents an entire system of weights and measures in base twelve, including a clock with twelve hours in a day, rather than twenty-four hours.

In Lee Carroll's "Kryon: Alchemy of the Human Spirit", a chapter is dedicated to the advantages of the duodecimal system. The duodecimal system is supposedly suggested by Kryon (a fictional entity believed in by New Age circles) for all-round use, aiming at better and more natural representation of nature of the Universe through mathematics. An individual article "Mathematica" by James D. Watt (included in the above publication) exposes a few of the unusual symmetry connections between the duodecimal system and the golden ratio, as well as provides numerous number symmetry-based arguments for the universal nature of the base-12 number system.

In "Little Twelvetoes", American television series "Schoolhouse Rock!" portrayed an alien child using base-twelve arithmetic, using "dek", "el" and "doh" as names for ten, eleven and twelve, and Andrews' script-X and script-E for the digit symbols.

In March 2013, a proposal was submitted to include the digit forms for ten and eleven propagated by the Dozenal Societies of Great Britain and America in the Unicode Standard. Of these, the British forms were accepted for encoding as characters at code points (↊) and (↋) They have been included in the Unicode 8.0 release in June 2015.

Unicode points and seem to be reserved for the Dwiggins digits (stylized X and E).

Few fonts support these new characters, but Abibas, EB Garamond, Everson Mono, Squarish Sans CT, and Symbola do.

Also, the turned digits two and three are available in LaTeX as codice_4 and codice_5.


Systems of measurement proposed by dozenalists include:

The number 12 has six factors, which are 1, 2, 3, 4, 6, and 12, of which 2 and 3 are prime. The decimal system has only four factors, which are 1, 2, 5, and 10, of which 2 and 5 are prime. Vigesimal (base 20) adds two factors to those of ten, namely 4 and 20, but no additional prime factor. Although twenty has 6 factors, 2 of them prime, similarly to twelve, it is also a much larger base, and so the digit set and the multiplication table are much larger. Binary has only two factors, 1 and 2, the latter being prime. Hexadecimal (base 16) has five factors, adding 4, 8 and 16 to those of 2, but no additional prime. Trigesimal (base 30) is the smallest system that has three different prime factors (all of the three smallest primes: 2, 3 and 5) and it has eight factors in total (1, 2, 3, 5, 6, 10, 15, and 30). Sexagesimal—which the ancient Sumerians and Babylonians among others actually used—adds the four convenient factors 4, 12, 20, and 60 to this but no new prime factors. The smallest system that has four different prime factors is base 210 and the pattern follows the primorials. In all base systems, there are similarities to the representation of multiples of numbers which are one less than the base.

To convert numbers between bases, one can use the general conversion algorithm (see the relevant section under positional notation). Alternatively, one can use digit-conversion tables. The ones provided below can be used to convert any duodecimal number between 0.01 and ƐƐƐ,ƐƐƐ.ƐƐ to decimal, or any decimal number between 0.01 and 999,999.99 to duodecimal. To use them, the given number must first be decomposed into a sum of numbers with only one significant digit each. For example:

This decomposition works the same no matter what base the number is expressed in. Just isolate each non-zero digit, padding them with as many zeros as necessary to preserve their respective place values. If the digits in the given number include zeroes (for example, 102,304.05), these are, of course, left out in the digit decomposition (102,304.05 = 100,000 + 2,000 + 300 + 4 + 0.05). Then the digit conversion tables can be used to obtain the equivalent value in the target base for each digit. If the given number is in duodecimal and the target base is decimal, we get:

Now, because the summands are already converted to base ten, the usual decimal arithmetic is used to perform the addition and recompose the number, arriving at the conversion result:

That is, 123,456.78 equals 296,130.63 ≈ 296,130.64

If the given number is in decimal and the target base is duodecimal, the method is basically same. Using the digit conversion tables:

However, in order to do this sum and recompose the number, now the addition tables for the duodecimal system have to be used, instead of the addition tables for decimal most people are already familiar with, because the summands are now in base twelve and so the arithmetic with them has to be in duodecimal as well. In decimal, 6 + 6 equals 12, but in duodecimal it equals 10; so, if using decimal arithmetic with duodecimal numbers one would arrive at an incorrect result. Doing the arithmetic properly in duodecimal, one gets the result:

That is, 123,456.78 equals 5Ɛ,540.9... ≈ 5Ɛ,540.94

All squares end with square digits (i.e. end with 0, 1, 4 or 9), if "n" is divisible by both 2 and 3, then "n" ends with 0, if "n" is not divisible by 2 or 3, then "n" ends with 1, if "n" is divisible by 2 but not by 3, then "n" ends with 4, if "n" is not divisible by 2 but by 3, then "n" ends with 9. If the unit digit of "n" is 0, then the dozens digit of "n" is either 0 or 3, if the unit digit of "n" is 1, then the dozens digit of "n" is even, if the unit digit of "n" is 4, then the dozen digit of "n" is 0, 1, 4, 5, 8 or 9, if the unit digit of "n" is 9, then the dozen digit of "n" is either 0 or 6. (More specially, all squares of (primes ≥ 5) end with 1)

The digital root of a square is 1, 3, 4, 5 or Ɛ.

No repdigits with more than one digit are squares, in fact, a square cannot end with three same digits except 000. (In contrast, in the decimal (base ᘔ) system squares may end in 444, the smallest example is 32 = ᘔ04 = 1444)

No four-digit palindromic numbers are squares. (we can easily to prove it, since all four-digit palindromic number are divisible by 11, and since they are squares, thus they must be divisible by 11 = 121, and the only four-digit palindromic number divisible by 121 are 1331, 2662, 3993, 5225, 6556, 7887, 8ƐƐ8, 9119, ᘔ44ᘔ and Ɛ77Ɛ, but none of them are squares)

It is conjectured that if "n" is divisible by 4, then there are no "n"-digit palindromic squares.

"R" (where "R" is the repunit with length "n") is a palindromic number for "n" ≤ Ɛ, but not for "n" ≥ 10 (thus, for all odd number "n" ≤ 19, ther is "n"-digit palindromic square 123...321), besides, 11 (also 1{0}1, i.e. 101, 1001, 10001, etc.) is a palindromic number for "n" ≤ 5, but not for "n" ≥ 6, and it is conjectured that no palindromic numbers are "n"-th powers if "n" ≥ 6.

A cube can end with all digits except 2, 6 and ᘔ (in fact, no perfect powers end with 2, 6 or ᘔ), if "n" is not congruent to 2 mod 4, then "n" ends with the same digit as "n"; if "n" is congruent to 2 mod 4, then "n" ends with the digit (the last digit of "n" +− 6).

The digital root of a cube can be any number.

If "k"≥2, then "n" ends with the same digit as "n", thus, if "i"≥2, "j"≥2 and "i" and "j" have the same parity, then "n" and "n" end with the same digit.

Squares (and every powers) of 0, 1, 4, 9, 54, 69, 369, 854, 3854, 8369, Ɛ3854, 1Ɛ3854, ᘔ08369, ... end with the same digits as the number itself. (since they are automorphic numbers, from the only four solutions of "x"−"x"=0 in the ring of 10-adic numbers, these solutions are 0, 1, ...2Ɛ21Ɛ61Ɛ3854 and ...909ᘔ05ᘔ08369, since 10 is neither a prime not a prime power, the ring of the 10-adic numbers is not a field, thus there are solutions other than 0 and 1 for this equation in 10-adic numbers)

Except for 6 and 24, all even perfect numbers end with 54. Additionally, except for 6, 24 and 354, all even perfect numbers end with 054 or 854. Besides, if any odd perfect number exists, then it must end with 1, 09, 39, 69 or 99.

The digital root of an even perfect number is 1, 4, 6 or ᘔ.

Since 10 is the smallest abundant number, all numbers end with 0 are abundant numbers, besides, all numbers end with 6 except 6 itself are also abundant numbers.

The period of the unit digits of powers of a number must be a divisor of 2 (= λ(10), where λ is the Carmichael function).

The period of the final two digits of powers of a number must be a divisor of 10 (= λ(100)).

More generally, for every "n"≥2, the period of the final "n" digits of powers of a number must be a divisor of 10 (= λ(10)).

The period of the digital roots of powers of a number must be a divisor of ᘔ (= λ(Ɛ)).

The unit digit of a Fibonacci number can be any digit except 6 (if the unit digit of a Fibonacci number is 0, then the dozens digit of this number must also be 0, thus, all Fibonacci numbers divisible by 6 are also divisible by 100), and the unit digit of a Lucas number cannot be 0 or 9 (thus, no Lucas number is divisible by 10), besides, if a Lucas number ends with 2, then it must end with 0002, i.e., this number is congruent to 2 mod 10.

In the following table, "F" is the "n"-th Fibonacci number, and "L" is the "n"-th Lucas number.

The period of the digit root of Fibonacci numbers is ᘔ.

The period of the unit digit of Fibonacci numbers is 20, the final two digits is also 20, the final three digits is 200, the final four digits is 2000, ..., the final "n" digits is 2×10 ("n"≥2). (see Pisano period)

There are only 13 possible values (of the totally 100 values, thus only 13%) of the final two digits of a Fibonacci number (see ).

Except 0 = "F" and 1 = "F" = "F", the only square Fibonacci number is 100 = "F" (100 is indeed the square of 10), thus, 10 is the only base such that 100 is a Fibonacci number (since 100 in a base is just the square of this base, and 0 and 1 cannot be the base of numeral system), and thus we can make the near value of the golden ratio: "F"/"F" = 175/100 = 1.75 (since the ratio of two connected Fibonacci numbers is close to the golden ratio, as the numbers get large). Besides, the only cube Fibonacci number is 8 = "F".

The smallest power of 2 starts with the digit Ɛ is 2 = Ɛ2ᘔ20ᘔ8. For all digits 1≤"d"≤Ɛ, there exists 0≤"n"≤21 such that 2 starts with the digit "d".

2 = 59Ɛ18922Ɛ81631ᘔ39875663Ɛ89ᘔ853ᘔ91Ɛ595336ᘔ6114815ᘔ5ᘔ6929933ᘔ288Ɛ774Ɛ479575ᘔ628 may be the largest power of 2 not contain the digit 0, it has 65 digits. (Note that in the decimal (base ᘔ) system, the largest power of 2 not contain the digit 0 is 2 = Ɛ8196855ᘔ752550Ɛ455ᘔ1594 = 77371252455336267181195264, it has only 22 digits in base ᘔ)

The number 2 = 2 (see power of 2#Powers of two whose exponents are powers of two) is very close to googol (10), since it has ƐƐ digits. (thus, the Fermat number "F" (=2+1) is very close to googol)

1001 is the first four-digit palindromic number, and it is also the smallest number expressible as the sum of two cubes in two different ways, i.e. 1001 = 1 + 1000 (=1 + 10) = 509 + 6Ɛ4 (=9 + ᘔ) (see taxicab number for other numbers), and it is also the smallest absolute Euler pseudoprime, note that there is no absolute Euler-Jacobi pseudoprime and no absolute strong pseudoprime. Since 1001 = 7×11×17, we can use the divisibility rule of 1001 (i.e. form the alternating sum of blocks of three from right to left) for the divisibility rule of 7, 11 and 17. Besides, if 6"k"+1, 10"k"+1 and 16"k"+1 are all primes, then the product of them must be a Carmichael number (absolute Fermat pseudoprime), the smallest case is indeed 1001 (for "k" = 1), but 1001 is not the smallest Carmichael number (the smallest Carmichael number is 3ᘔ9).

formula_1 is very close to 1.5, since a near-value for formula_1 is 15/10 (="N"/"P", where "N" is "n"th NSW number, and "P" is "n"th Pell number, "N"/"P" is very close to formula_1 when "n" is large). Besides, formula_4 is very close to 2.2ᘔ, since a near-value for formula_4 is 22ᘔ/100 (="L"/"F", where "L" is "n"th Lucas number, and "F" is "n"th Fibonacci number, "L"/"F" is very close to formula_4 when "n" is large).

The reciprocal of "n" is terminating number if and only if "n" is 3-smooth, the 3-smooth numbers up to 1000 are 1, 2, 3, 4, 6, 8, 9, 10, 14, 16, 20, 23, 28, 30, 40, 46, 54, 60, 69, 80, 90, ᘔ8, 100, 116, 140, 160, 183, 194, 200, 230, 280, 300, 346, 368, 400, 460, 509, 540, 600, 690, 714, 800, 900, ᘔ16, ᘔ80, 1000.

If and only if "n" is a divisor of 20, then "m" = 1 mod "n" for every integer "m" coprime to "n".

If and only if "n" is a divisor of 20, then all Dirichlet characters for "n" are all real.

If and only if "n" is a divisor of 20, then "n" is divisible by all numbers less than or equal to the square root of "n".

If and only if "n"+1 is a divisor of 20, then formula_7 is squarefree for all 0 ≤ "k" ≤ "n".

All prime numbers end with prime digits or 1 (i.e. end with 1, 2, 3, 5, 7 or Ɛ), more generally, except for 2 and 3, all prime numbers end with 1, 5, 7 or Ɛ (1 and all prime digits that do not divide 10), since all prime numbers other than 2 and 3 are coprime to 10.

The density of primes end with 1 is a relatively low, but the density of primes end with 5, 7 and Ɛ are nearly equal. (since all prime squares except 4 and 9 end with 1, no prime squares end with 5, 7 or Ɛ)

Except (3, 5), all twin primes end with (5, 7) or (Ɛ, 1).

If "n" ≥ 3 and "n" is not divisible by Ɛ, then there are infinitely many primes with digit sum "n".

All palindromic primes except 11 has an odd number of digits, since all even-digit palindromic numbers are divisible by 11. The palindromic primes below 1000 are 2, 3, 5, 7, Ɛ, 11, 111, 131, 141, 171, 181, 1Ɛ1, 535, 545, 565, 575, 585, 5Ɛ5, 727, 737, 747, 767, 797, Ɛ1Ɛ, Ɛ2Ɛ, Ɛ6Ɛ.

All lucky numbers end with digit 1, 3, 7 or 9.

Except for 3, all Fermat primes end with 5.

Except for 3, all Mersenne primes end with 7.

Except for 2 and 3, all Sophie Germain primes end with 5 or Ɛ.

Except for 5 and 7, all safe primes end with Ɛ.

A prime "p" is Gaussian prime (prime in the ring formula_8, where formula_9) if and only if "p" ends with 7 or Ɛ (or "p"=3).

A prime "p" is Eisenstein prime (prime in the ring formula_10, where formula_11) if and only if "p" ends with 5 or Ɛ (or "p"=2).

A prime "p" can be written as "x" + "y" if and only if "p" ends with 1 or 5 (or "p"=2).

A prime "p" can be written as "x" + 3"y" if and only if "p" ends with 1 or 7 (or "p"=3).

All full reptend primes end with 5 or 7. (in fact, for all primes "p" ≥ 5, ("p"-1)/(the period length of 1/"p") is odd if and only if "p" is end with 5 or 7, since 10 is a quadratic nonresidue mod "p" (i.e. formula_12, where formula_13 is the Legendre symbol) if and only if "p" is end with 5 or 7, by quadratic reciprocity, and if 10 is a quadratic residue mod a prime, then 10 cannot be a primitive root mod this prime) However, the converse is not true, 17 is not a full reptend prime, since the recurring digits of 1/17 is 0.076Ɛ45076Ɛ45..., which has only period 6. If and only if "p" is a full reptend prime, then the recurring digits of 1/"p" is cyclic number, e.g. the recurring digits of 1/5 is the cyclic number 2497 (the cyclic permutations of the digits are this number multiplied by 1 to 4), and the recurring digits of 1/7 is the cyclic number 186ᘔ35 (the cyclic permutations of the digits are this number multiplied by 1 to 6). The full reptend primes below 1000 are 5, 7, 15, 27, 35, 37, 45, 57, 85, 87, 95, ᘔ7, Ɛ5, Ɛ7, 105, 107, 117, 125, 145, 167, 195, 1ᘔ5, 1Ɛ5, 1Ɛ7, 205, 225, 255, 267, 277, 285, 295, 315, 325, 365, 377, 397, 3ᘔ5, 3Ɛ5, 3Ɛ7, 415, 427, 435, 437, 447, 455, 465, 497, 4ᘔ5, 517, 527, 535, 545, 557, 565, 575, 585, 5Ɛ5, 615, 655, 675, 687, 695, 6ᘔ7, 705, 735, 737, 745, 767, 775, 785, 797, 817, 825, 835, 855, 865, 8Ɛ5, 8Ɛ7, 907, 927, 955, 965, 995, 9ᘔ7, 9Ɛ5, ᘔ07, ᘔ17, ᘔ35, ᘔ37, ᘔ45, ᘔ77, ᘔ87, ᘔ95, ᘔƐ7, Ɛ25, Ɛ37, Ɛ45, Ɛ95, Ɛ97, Ɛᘔ5, ƐƐ5, ƐƐ7. (Note that for the primes end with 5 or 7 below 30 (5, 7, 15, 17, 25 and 27, all numbers end with 5 or 7 below 30 are primes), 5, 7, 15 and 27 are full reptend primes, and since 5×25 = 101 = formula_14, the period of 25 is 4, which is the same as the period of 5, and we can use the test of the divisiblity of 5 to test that of 25 (form the alternating sum of blocks of two from right to left), and since 7×17 = Ɛ1 = formula_15, the period of 17 is 6, which is the same as the period of 7, and we can use the test of the divisiblity of 7 to test that of 17 (form the alternating sum of blocks of three from right to left), thus, 17 and 25 are not full reptend primes, and they are the only two non-full reptend primes end with 5 or 7 below 30)

By Midy theorem, if "p" is a prime with even period length (let its period length be "n"), then if we let formula_16, then "a" + "a" = Ɛ for every 1 ≤ "i" ≤ "n"/2. e.g. 1/5 = 0.249724972497..., and 24 + 97 = ƐƐ, and 1/7 = 0.186ᘔ35186ᘔ35..., and 186 + ᘔ35 = ƐƐƐ, all primes (other than 2 and 3) ≤ 37 except Ɛ, 1Ɛ and 31 have even period length, thus they can use Midy theorem to get an Ɛ-repdigit number, the length of this number is the period length of this prime. (see below for the recurring digits for 1/"n" for all "n" ≤ 30)

The unique primes below 10 are Ɛ, 11, 111, Ɛ0Ɛ1, ƐƐ01, 11111, 24727225, Ɛ0Ɛ0Ɛ0Ɛ0Ɛ1, Ɛ00Ɛ00ƐƐ0ƐƐ1, 100ƐƐƐᘔƐᘔƐƐ000101, 1111111111111111111, ƐƐƐƐ0000ƐƐƐƐ0000ƐƐƐƐ0001, 100ƐƐƐᘔƐƐ0000ƐƐƐᘔƐƐ000101, 10ƐƐƐᘔᘔᘔƐ011110ƐᘔᘔᘔƐ00011, ƐƐƐƐƐƐƐƐ00000000ƐƐƐƐƐƐƐƐ00000001, ƐƐƐ000000ƐƐƐ000000ƐƐƐƐƐƐ000ƐƐƐƐƐƐ001, and the period length of their reciprocals are 1, 2, 3, ᘔ, 10, 5, 18, 1ᘔ, 19, 50, 17, 48, 70, 5ᘔ, 68, 53.

If "p" is a safe prime other than 5, 7 and Ɛ, then the period length of 1/"p" is ("p"-1)/2. (this is not true for all primes ends with Ɛ (other than Ɛ itself), the first counterexample is "p" = 2ƐƐ, where the period length of 1/"p" is only 37)

There is no full reptend prime ends with 1, since 10 is quadratic residue for all primes end with 1. (In contrast, in decimal (base ᘔ) system there are some such primes, and may be infinitely many such primes, the first few such primes in that base are 61 = 51, 131 = ᘔƐ, 181 = 131, 461 = 325, 491 = 34Ɛ, see ) (if so, then this prime "p" is a proper prime (i.e. for the reciprocal of such primes (1/"p"), each digit 0, 1, 2, ..., Ɛ appears in the repeating sequence the same number of times as does each other digit (namely, ("p"−1)/10 times)), see repeating decimal#Fractions with prime denominators) (In fact, not only for base 10 such primes do not exist, for all bases = 0 mod 4 (i.e. bases end with digit 0, 4 or 8), such primes do not exist)

5 and 7 are the only two safe primes which are also full reptend primes, since except 5 and 7, all safe primes end with Ɛ, and 10 is quadratic residue for all primes end with Ɛ. (In contrast, in decimal (base ᘔ) system there may be infinitely many such primes, the first few such primes in that base are 7 = 7, 23 = 1Ɛ, 47 = 3Ɛ, 59 = 4Ɛ, 167 = 11Ɛ, see ) (if so, then this prime "p" produces a stream of "p"−1 pseudo-random digits, see repeating decimal#Fractions with prime denominators) (In fact, not only for base 10 there are only finitely many such primes, of course for square bases (bases of the form "k") only 2 may be full reptend prime (if the base is odd), and all odd primes are not full reptend primes, but since all safe primes are odd primes, for these bases such primes do not exist, besides, for the bases of the form 3"k", only 5 and 7 can be such primes, the proof for these bases is completely the same as that for base 10)

The period level of a prime "p" ≥ 5 is ("p"−1)/(period length of 1/"p"), e.g., formula_17 has period level 3, thus the numbers formula_18 with integer 1 ≤ "a" ≤ 16 from 3 different cycles: 076Ɛ45 (for "a" = 1, 7, 8, Ɛ, 10, 16), 131ᘔ8ᘔ (for "a" = 2, 3, 5, 12, 14, 15) and 263958 (for "a" = 4, 6, 9, ᘔ, 11, 13). Besides, formula_19 has period level 1, thus this number is a cyclic number and 15 is a full-reptend prime, and all of the numbers formula_20 with integer 1 ≤ "a" ≤ 14 from the cycle 08579214Ɛ36429ᘔ7.

There are only 9 repunit primes below "R": "R", "R", "R", "R", "R", "R", "R", "R" and "R" ("R" is the repunit with length "n"). If "p" is a Sophie Germain prime other than 2, 3 and 5, then "R" is divisible by 2"p"+1, thus "R" is not prime. (The length for the repunit (probable) primes are 2, 3, 5, 17, 81, 91, 225, 255, 4ᘔ5, 5777, 879Ɛ, 198Ɛ1, 23175, 311407, ..., note that 879Ɛ is the smallest (and the only known) such number ends with Ɛ)

By Fermat's little theorem, if "p" is a prime other than 2, 3 and Ɛ, then "p" divides the repunit with length "p"−1. (The converse is not true, the first counterexample is 55, which is composite (equals 5×11) but divides the repunit with length 54, the counterexamples up to 1000 are 55, 77, Ɛ1, 101, 187, 275, 4ᘔ7, 777, 781, Ɛ55, they are exactly the Fermat pseudoprimes for base 10 (composite numbers "c" such that 10 = 1 mod "c") which are not divisible by Ɛ, they are called "deceptive primes", if "n" is deceptive prime, then "R" is also deceptive prime, thus there are infinitely may deceptive primes) Thus, we can prove that every positive integer coprime to 10 has a repunit multiple, and every positive integer has a multiple uses only 0's and 1's.

For every prime "p" except Ɛ, the repunit with length "p" is congruent to 1 mod "p". (The converse is also not true, the counterexamples up to 1000 are 4, 6, 10, 33, 55, 77, Ɛ1, 101, 187, 1Ɛ0, 275, 444, 4ᘔ7, 777, 781, Ɛ55, they are called "repunit pseudoprimes" (or weak deceptive primes), all deceptive primes are also repunit pseudoprimes, if "n" is repunit pseudoprime, then "R" is also repunit pseudoprime, thus there are infinitely may repunit pseudoprimes. No repunit pseudoprimes are divisible by 8, 9 or Ɛ. (in fact, the repunit pseudoprimes are exactly the weak pseudoprimes for base 10 (composite numbers "c" such that 10 = 10 mod "c") which are not divisible by Ɛ) Besides, the deceptive primes are exactly the repunit pseudoprimes which are coprime to 10)

Smallest multiple of "n" with digit sum 2 are: (0 if not exist)

Smallest multiple of "n" with digit sum 3 are: (0 if not exist)

Smallest multiple of "n" with digit sum 4 are: (0 if not exist)

Smallest multiple of "n" with digit sum "n" are:

Write the recurring digits of 1/45 (=0., which has period 44) to 44/45, we get a 44×44 prime reciprocal magic square (its magic number is 1Ɛᘔ), it is conjectured that there are infinitely many such primes, but 45 is the only such prime below 1000, all such primes are full reptend primes, i.e. the reciprocal of them are cyclic numbers, and 10 is a primitive root modulo these primes.

All numbers of the form 34{1} are composite (proof: 34{1} = 34×10+(10−1)/Ɛ = (309×10−1)/Ɛ and it can be factored to ((19×10−1)/Ɛ) × (19×10+1) for even "n" and divisible by 11 for odd "n"). Besides, 34 was proven to be the smallest "n" such that all numbers of the form "n"{1} are composite. However, the smallest prime of the form 23{1} is 23{1}, it has Ɛ7ᘔ digits. The only other two "n"≤100 such that all numbers of the form "n"{1} are composite are 89 and 99 (the reason of 89 is the same as 34, and the reason of 99 is 99{1} is divisible by 5, 11 or 25).

The only known of the form 1{0}1 is 11 (see generalized Fermat prime), these are the primes obtained as the concatenation of a power of 10 followed by a 1. If "n" = 1 mod 11, then all numbers obtained as the concatenation of a power of n (>1) followed by a 1 are divisible by 11 and thus composite. Except 10, the smallest "n" not = 1 mod 11 such that all numbers obtained as the concatenation of a power of "n" (>1) followed by a 1 are composite was proven by Ɛᘔ, since all numbers obtained as the concatenation of a power of Ɛᘔ (>1) followed by a 1 are divisible by either Ɛ or 11 and thus composite. However, the smallest prime obtained as the concatenation of a power of 58 (>1) followed by a 1 is 10×58+1, it has 459655 digits.

All numbers of the form 1{5}1 are composite (proof: 1{5}1 = (14×10−41)/Ɛ and it can be factored to (4×10−7) × ((4×10−7)/Ɛ) for odd "n" and divisible by 11 for even "n").

The emirps below 1000 are 15, 51, 57, 5Ɛ, 75, Ɛ5, 107, 117, 11Ɛ, 12Ɛ, 13Ɛ, 145, 157, 16Ɛ, 17Ɛ, 195, 19Ɛ, 1ᘔ7, 1Ɛ5, 507, 51Ɛ, 541, 577, 587, 591, 59Ɛ, 5Ɛ1, 5ƐƐ, 701, 705, 711, 751, 76Ɛ, 775, 785, 7ᘔ1, 7ƐƐ, Ɛ11, Ɛ15, Ɛ21, Ɛ31, Ɛ61, Ɛ67, Ɛ71, Ɛ91, Ɛ95, ƐƐ5, ƐƐ7.

The non-repdigit permutable primes below 10 are 15, 57, 5Ɛ, 117, 11Ɛ, 5ƐƐƐ (the smallest representative prime of the permutation set).

The non-repdigit circular primes below 10 are 15, 57, 5Ɛ, 117, 11Ɛ, 175, 1Ɛ7, 157Ɛ, 555Ɛ, 115Ɛ77 (the smallest representative prime of the cycle).

The first few Smarandache primes are the concatenation of the first 5, 15, 4Ɛ, 151, ... positive integers.

The only known Smarandache–Wellin primes are 2 and 2357Ɛ11.

There are exactly 15 minimal primes, and they are 2, 3, 5, 7, Ɛ, 11, 61, 81, 91, 401, ᘔ41, 4441, ᘔ0ᘔ1, ᘔᘔᘔᘔ1, 44ᘔᘔᘔ1, ᘔᘔᘔ0001, ᘔᘔ000001.

The smallest weakly prime is 6Ɛ8ᘔƐ77.

The largest left-truncatable prime is 28-digit 471ᘔ34ᘔ164259Ɛᘔ16Ɛ324ᘔƐ8ᘔ32Ɛ7817, and the largest right-truncatable prime is ᘔ-digit 375ƐƐ5Ɛ515.

The only two base 10 Wieferich primes below 10 are 1685 and 5Ɛ685, note that both of the numbers end with 685, and it is conjectured that all base 10 Wieferich primes end with 685. (there is also a note for the only two known base 2 Wieferich primes (771 and 2047) minus 1 written in base 2, 8 (= 2) and 14 (= 2), 770 = 010001000100 = 444 is a repdigit in base 14, and 2046 = 110110110110 = 6666 is also a repdigit in base 8, see Wieferich prime#Binary periodicity of p − 1)

There are 1, 2, 3, 5 and 6-digit (but not 4-digit) narcissistic numbers, there are totally 73 narcissistic numbers, the first few of which are 1, 2, 3, 4, 5, 6, 7, 8, 9, ᘔ, Ɛ, 25, ᘔ5, 577, 668, ᘔ83, 14765, 938ᘔ4, 369862, ᘔ2394ᘔ, ..., the largest of which is 43-digit 15079346ᘔ6Ɛ3Ɛ14ƐƐ56Ɛ395898Ɛ96629ᘔ8Ɛ01515344Ɛ4Ɛ0714Ɛ. (see )

The only two factorions are 1 and 2.

The only seven happy numbers below 1000 are 1, 10, 100, 222, 488, 848 and 884, almost all natural numbers are unhappy. All unhappy numbers get to one of these four cycles: {5, 21}, {8, 54, 35, 2ᘔ, 88, ᘔ8, 118, 56, 51, 22}, {18, 55, 42}, {68, 84}, or one of the only two fixed points other than 1: 25 and ᘔ5. (In contrast, in the decimal (base ᘔ) system there are Ɛᘔ happy numbers below 1000 (=6Ɛ4), and all unhappy number get to this cycle: {4, 16, 37, 58, 89, 145, 42, 20}, there are no fixed points other than 1)

If we use the sum of the cubes (instead of squares) of the digits, then every natural numbers get to either 1 or the cycle {8, 368, 52Ɛ, ᘔ20, 700, 247, 2ᘔ7, 947, 7ᘔ8, 10ᘔ7, 940, 561, 246, 200}. (In contrast, in the decimal (base ᘔ) system all multiple of 3 get to 153 (=109), and other numbers get to either one of these four fixed points: 1, 370, 371, 407, or one of these four cycles: {55, 250, 133}, {136, 244}, {160, 217, 352}, {919, 1459}) (for the example of the famous Hardy–Ramanujan number 1001 = 9 + ᘔ, we know that this sequence with initial term 9ᘔ is 9ᘔ, 1001, 2, 8, 368, 52Ɛ, ᘔ20, 700, 247, 2ᘔ7, 947, 7ᘔ8, 10ᘔ7, 940, 561, 246, 200, 8, 368, 52Ɛ, ᘔ20, 700, 247, 2ᘔ7, 947, 7ᘔ8, 10ᘔ7, 940, 561, 246, 200, 8, ...)

The harshad numbers up to 200 are 1, 2, 3, 4, 5, 6, 7, 8, 9, ᘔ, Ɛ, 10, 1ᘔ, 20, 29, 30, 38, 40, 47, 50, 56, 60, 65, 70, 74, 80, 83, 90, 92, ᘔ0, ᘔ1, Ɛ0, 100, 10ᘔ, 110, 115, 119, 120, 122, 128, 130, 134, 137, 146, 150, 153, 155, 164, 172, 173, 182, 191, 1ᘔ0, 1Ɛ0, 1Ɛᘔ, 200, although the sequence of factorials begins with harshad numbers, not all factorials are harshad numbers, after 7! (=2Ɛ00, with digit sum 11 but 11 does not divide 7!), 8ᘔ4! is the next that is not (8ᘔ4! has digit sum 8275 = Ɛ×8Ɛ7, thus not divide 8ᘔ4!). There are no 21 consecutive integers that are all harshad numbers, but there are infinitely many 20-tuples of consecutive integers that are all harshad numbers.

The Kaprekar numbers up to 10000 are 1, Ɛ, 56, 66, ƐƐ, 444, 778, ƐƐƐ, 12ᘔᘔ, 1640, 2046, 2929, 3333, 4973, 5Ɛ60, 6060, 7249, 8889, 9293, 9Ɛ76, ᘔ580, ᘔ912, ƐƐƐƐ.

The Kaprekar's routine of any four-digit number which is not repdigit converges to either the cycle {3ƐƐ8, 8284, 6376} or the cycle {4198, 8374, 5287, 6196, 7ƐƐ4, 7375}, and the Kaprekar map of any three-digit number which is not repdigit converges to the fixed point 5Ɛ6, and the Kaprekar map of any two-digit number which is not repdigit converges to the cycle {0Ɛ, ᘔ1, 83, 47, 29, 65}.

The self numbers up to 600 are 1, 3, 5, 7, 9, Ɛ, 20, 31, 42, 53, 64, 75, 86, 97, ᘔ8, Ɛ9, 10ᘔ, 110, 121, 132, 143, 154, 165, 176, 187, 198, 1ᘔ9, 1Ɛᘔ, 20Ɛ, 211, 222, 233, 244, 255, 266, 277, 288, 299, 2ᘔᘔ, 2ƐƐ, 310, 312, 323, 334, 345, 356, 367, 378, 389, 39ᘔ, 3ᘔƐ, 400, 411, 413, 424, 435, 446, 457, 468, 479, 48ᘔ, 49Ɛ, 4Ɛ0, 501, 512, 514, 525, 536, 547, 558, 569, 57ᘔ, 58Ɛ, 5ᘔ0, 5Ɛ1.

The Friedman numbers up to 1000 are 121=11, 127=7×21, 135=5×31, 144=4×41, 163=3×61, 368=8, 376=6×73, 441=(4+1), 445=5+4.

The Keith numbers up to 1000 are 11, 15, 1Ɛ, 22, 2ᘔ, 31, 33, 44, 49, 55, 62, 66, 77, 88, 93, 99, ᘔᘔ, ƐƐ, 125, 215, 24ᘔ, 405, 42ᘔ, 654, 80ᘔ, 8ᘔ3, ᘔ59.

There are totally 71822 polydivisible numbers, the largest of which is 24-digit 606890346850Ɛᘔ6800Ɛ036206464. However, there are no Ɛ-digit polydivisible numbers contain the digits 1 to Ɛ exactly once each.

The candidate Lychrel numbers up to 1000 are 179, 1Ɛ9, 278, 2Ɛ8, 377, 3Ɛ7, 476, 4Ɛ6, 575, 5Ɛ5, 674, 6Ɛ4, 773, 7Ɛ3, 872, 8Ɛ2, 971, 9Ɛ1, ᘔ2Ɛ, ᘔ3Ɛ, ᘔ5Ɛ, ᘔ70, ᘔᘔƐ, ᘔƐ0, Ɛ2ᘔ, Ɛ3ᘔ, Ɛ5ᘔ, Ɛᘔᘔ. The only suspected Lychrel seed numbers up to 1000 are 179, 1Ɛ9, ᘔ3Ɛ and ᘔ5Ɛ. However, it is unknown whether any Lychrel number exists. (Lychrel numbers only known to exist in these bases: Ɛ, 15, 18, 22 and all powers of 2)

Most numbers that end with 2 are nontotient (in fact, all nontotients < 58 except 2ᘔ end with 2), except 2 itself, the first counterexample is 92, which equals φ(ᘔ1) = φ(Ɛ) and φ(182) = φ(2×Ɛ), next counterexample is 362, which equals φ(381) = φ(1Ɛ) and φ(742) = φ(2×1Ɛ), there are only 9 such numbers ≤ 10000 (the number 2 itself is not counted), all such numbers (except the number 2 itself) are of the form φ("p") = "p"("p"−1), where "p" is a prime ends with Ɛ.

If we let the musical notes in an octave be numbers in the cyclic group "Z": C=0, C#=1, D=2, Eb=3, E=4, F=5, F#=6, G=7, Ab=8, A=9, Bb=ᘔ, B=Ɛ (see pitch class and music scale) (thus, if we let the middle C be 0, then the notes in a piano are -33 to 40), then "x" and "x"+3 are small 3-degree, "x" and "x"+4 are big 3-degree, "x" and "x"+7 are perfect 5 degree (thus, we can use 7"x" for "x" = 0 to Ɛ to get the five degree cycle), etc. (since an octave is 10 semitones, a small 3-degree is 3 semitones, a big 3-degree is 4 semitones, and a perfect 5 degree is 7 semitones, etc.) (if we let an octave be 1, then a semitone will be 0.1, and we can write all 10 notes on a cycle, the difference of two connected notes is 26 degrees or formula_21 radians) Besides, the "x" major chord ("x") is {"x", "x"+4, "x"+7} in "Z", and the "x" minor chord ("x"m) is {"x", "x"+3, "x"+7} in "Z", and the "x" major 7th chord ("x") is {"x", "x"+4, "x"+7, "x"+Ɛ}, and the "x" minor 7th chord ("x") is {"x", "x"+3, "x"+7, "x"+ᘔ}, and the "x" dominant 7th chord ("x") is {"x", "x"+4, "x"+7, "x"+ᘔ}, and the "x" diminished 7th triad ("x") is {"x", "x"+3, "x"+6, "x"+9}, since the frequency of "x" and "x"+6 is not simple integer fraction, they are not harmonic, and this diminished 7th triad is corresponding the beast number 666 (three 6's). Besides, "x" major scale uses the notes {"x", "x"+2, "x"+4, "x"+5, "x"+7, "x"+9, "x"+Ɛ}, and "x" minor scale uses the notes {"x", "x"+2, "x"+3, "x"+5, "x"+7, "x"+8, "x"+ᘔ}. Besides, the frequency of "x"+10 is twice as that of "x", the frequency of "x"+7 is 1.6 (=3/2) times as that of "x", and the frequency of "x"+5 is 1.4 (=4/3) times as that of "x", they are all simple integer fractions (ratios of small integers), and they all have at most one digit after the duodecimal point, and we can found that 1.6 = ᘔ9.8Ɛ5809 is very close to 2 = ᘔ8, since 2 = 2134ᘔ8 is very close to 3 = 217669, the simple frequency fractions found for the scales are only 0.6, 0.8, 0.9, 1.4, 1.6 and 2, however, since the frequency of "x"+10 is twice as that of "x", thus the frequency of "x"+1 (i.e. a semitone higher than "x") is formula_22 (=2) times as that of "x". Let "f"("x") be the frequency of "x", then we have "f"(2)/"f"(0) = 9/8 (=1.16), "f"(4)/"f"(2) = ᘔ/9 (=1.14), and "f"(5)/"f"(4) = 14/13 (this number is very close to formula_22), and thus we have that "f"(5)/"f"(0) = (9/8) × (ᘔ/9) × (14/13) = 4/3. Also, we can found that 2 is very close to 1.4, and 2 is very close to 1.6.

All orders of non-cyclic simple group end with 0 (thus, all orders of unsolvable group end with 0), however, we can prove that no groups with order 10, 20, 30 or 40 are simple, thus 50 is the smallest order of non-cyclic simple group (thus, all groups with order < 50 are solvable), (50 is the order of the alternating group "A", which is a non-cyclic simple group, and thus an unsolvable group) next three orders of non-cyclic simple group are 120, 260 and 360. (Edit: I found that this is not completely true (although this is true for all orders ≤ 14000), the smallest counterexample is 14ᘔ28, however, all such orders are divisible by 4 and either 3 or 5 (i.e. divisible by either 10 or 18), and all such orders have at least 3 distinct prime factors, by these conditions, the smallest possible such order is indeed 50 = 2 × 3 × 5, next possible such order is 70 = 2 × 3 × 7, however, by Sylow theorems, the number of Sylow 7-subgroups of all groups with order 70 (i.e. the number of subgroups with order 7 of all groups with order 70) is congruent to 1 mod 7 and divides 70, hence must be 1, thus the subgroup with order 7 is a normal subgroup of the group with order 70, thus all groups with order 70 have a nontrivial normal subgroup and cannot be simple groups)

In duodecimal, as in decimal, there are special numbers that exhibit digit patterns when, for example, multiplied by small integers:

A natural number (i.e. 1, 2, 3, 4, 5, 6, etc.) is called a prime number (or a prime) if it has exactly two positive divisors, 1 and the number itself. Natural numbers greater than 1 that are not prime are called composite.

The first 1ᘔ5 prime numbers (all the prime numbers less than 1000) are:

Except 2 and 3, all primes end with 1, 5, 7 or Ɛ. The first "k" such that all of 10"k", 10"k" + 1, 10"k" + 2, ..., 10"k" + Ɛ are all composite is 38, i.e. all of 380, 381, 382, ..., 38Ɛ are composite.

The density of primes end with 1 is a relatively low (< 1/4), but the density of primes end with 5, 7 and Ɛ are nearly equal (all are a little more than 1/4). (i.e. for a given natural number "N", the number of primes end with 1 less than "N" is usually smaller than the number of primes end with 5 (or 7, or Ɛ) less than "N") e.g. For all 1426 primes < 10000, there are 3Ɛ8 primes (2Ɛ.3%) end with 1, 410 primes (30.3%) end with 5, 412 primes (30.5%) end with 7, 406 primes (2Ɛ.Ɛ%) end with Ɛ. It is conjectured that for every natural number "N" ≥ 10, the number of primes end with 1 less than "N" is smaller than the number of primes end with 5 (or 7, or Ɛ) less than "N". (Note: the percentage in this sequence are also in duodecimal, i.e. 20% means 0.2 or 20/100 = 1/6, 36% means 0.36 or 36/100 = 7/20, 58.7% means 0.587 or 587/1000)

13665 is the smallest prime "p" such that the number of primes end with 1 or 5 ≤ "p" is more than the number of primes end with 3, 7 or Ɛ ≤ "p" (see , of course, 3 is the only prime ends with 3). Besides, 9ᘔ03693ᘔ831 is the smallest prime "p" such that the number of primes end with 1 or 7 ≤ "p" is more than the number of primes end with 2, 5 or Ɛ ≤ "p" (see , of course, 2 is the only prime ends with 2). Question: What is the smallest prime "p" such that the number of primes end with 1 ≤ "p" is more than the number of primes end with "d" ≤ "p" for at least one of "d" = 5, 7 or Ɛ?

All squares of primes (except 2 and 3) end with 1.

There are 2ᘔ primes between 1 and 100, 23 primes between 101 and 200, 1ᘔ primes between 201 and 300, 1ᘔ primes between 301 and 400, 1Ɛ primes between 401 and 500, 1ᘔ primes between 501 and 600, 16 primes between 601 and 700, 1ᘔ primes between 701 and 800, 18 primes between 801 and 900, 16 primes between 901 and ᘔ00, 1ᘔ primes between ᘔ01 and Ɛ00, 17 primes between Ɛ01 and 1000.

There are about "N"/ln("N") primes less than "N", where ln is the natural logarithm, i.e. the logarithm with base "e" = 2.875236069821... (see prime number theorem), thus there are about formula_24 primes less than 10 (i.e. with at most "n" digits), and ln(10) = 2.599Ɛ035Ɛ8169...

In the following table, numbers shaded in cyan are primes.

This section is about the divisibility rules in duodecimal.

Any integer is divisible by 1.

If a number is divisible by 2 then the unit digit of that number will be 0, 2, 4, 6, 8 or ᘔ.

If a number is divisible by 3 then the unit digit of that number will be 0, 3, 6 or 9.

If a number is divisible by 4 then the unit digit of that number will be 0, 4 or 8.

To test for divisibility by 5, double the units digit and subtract the result from the number formed by the rest of the digits. If the result is divisible by 5 then the given number is divisible by 5.

This rule comes from 21(5*5)

Examples: <br>
13     rule => |1-2*3| = 5 which is divisible by 5.<br>
2Ɛᘔ5   rule => |2Ɛᘔ-2*5| = 2Ɛ0(5*70) which is divisible by 5(or apply the rule on 2Ɛ0).

OR

To test for divisibility by 5, subtract the units digit and triple of the result to the number formed by the rest of the digits. If the result is divisible by 5 then the given number is divisible by 5.

This rule comes from 13(5*3)

Examples: <br>
13     rule => |3-3*1| = 0 which is divisible by 5.<br>
2Ɛᘔ5   rule => |5-3*2Ɛᘔ| = 8Ɛ1(5*195) which is divisible by 5(or apply the rule on 8Ɛ1).

OR

Form the alternating sum of blocks of two from right to left. If the result is divisible by 5 then the given number is divisible by 5.

This rule comes from 101, since 101 = 5*25, thus this rule can be also tested for the divisibility by 25.

Example:<br>

97,374,627 => 27-46+37-97 = -7Ɛ which is divisible by 5.

If a number is divisible by 6 then the unit digit of that number will be 0 or 6.

To test for divisibility by 7, triple the units digit and add the result to the number formed by the rest of the digits. If the result is divisible by 7 then the given number is divisible by 7.

This rule comes from 2Ɛ(7*5)

Examples:<br>
12     rule => |3*2+1| = 7 which is divisible by 7.<br>
271Ɛ    rule => |3*Ɛ+271| = 29ᘔ(7*4ᘔ) which is divisible by 7(or apply the rule on 29ᘔ).<br>

OR

To test for divisibility by 7, subtract the units digit and double the result from the number formed by the rest of the digits. If the result is divisible by 7 then the given number is divisible by 7.

This rule comes from 12(7*2)

Examples:<br>
12     rule => |2-2*1| = 0 which is divisible by 7.<br>
271Ɛ    rule => |Ɛ-2*271| = 513(7*89) which is divisible by 7(or apply the rule on 513).<br>

OR

To test for divisibility by 7, 4 times the units digit and subtract the result from the number formed by the rest of the digits. If the result is divisible by 7 then the given number is divisible by 7.

This rule comes from 41(7*7)

Examples:<br>
12     rule => |4*2-1| = 7 which is divisible by 7.<br>
271Ɛ    rule => |4*Ɛ-271| = 235(7*3Ɛ) which is divisible by 7(or apply the rule on 235).<br>

OR

Form the alternating sum of blocks of three from right to left. If the result is divisible by 7 then the given number is divisible by 7.

This rule comes from 1001, since 1001 = 7*11*17, thus this rule can be also tested for the divisibility by 11 and 17.

Example:<br>

386,967,443 => 443-967+386 = -168 which is divisible by 7.

If the 2-digit number formed by the last 2 digits of the given number is divisible by 8 then the given number is divisible by 8.

Example: 1Ɛ48, 4120

If the 2-digit number formed by the last 2 digits of the given number is divisible by 9 then the given number is divisible by 9.

Example: 7423, 8330

If the number is divisible by 2 and 5 then the number is divisible by ᘔ.

If the sum of the digits of a number is divisible by Ɛ then the number is divisible by Ɛ (the equivalent of casting out nines in decimal).

Example: 29, 61Ɛ13

If a number is divisible by 10 then the unit digit of that number will be 0.

Sum the alternate digits and subtract the sums. If the result is divisible by 11 the number is divisible by 11 (the equivalent of divisibility by eleven in decimal).

Example: 66, 9427

If the number is divisible by 2 and 7 then the number is divisible by 12.

If the number is divisible by 3 and 5 then the number is divisible by 13.

If the 2-digit number formed by the last 2 digits of the given number is divisible by 14 then the given number is divisible by 14.

Example: 1468, 7394

Duodecimal fractions may be simple:

or complicated:

As explained in recurring decimals, whenever an irreducible fraction is written in radix point notation in any base, the fraction can be expressed exactly (terminates) if and only if all the prime factors of its denominator are also prime factors of the base. Thus, in base-ten (= 2×5) system, fractions whose denominators are made up solely of multiples of 2 and 5 terminate:  = ,  =  and  =  can be expressed exactly as 0.125, 0.05 and 0.002 respectively. and , however, recur (0.333... and 0.142857142857...). In the duodecimal (= 2×2×3) system, is exact; and recur because they include 5 as a factor; is exact; and recurs, just as it does in decimal.

The number of denominators which give terminating fractions within a given number of digits, say "n", in a base "b" is the number of factors (divisors) of "b", the "n"th power of the base "b" (although this includes the divisor 1, which does not produce fractions when used as the denominator). The number of factors of "b" is given using its prime factorization.

For decimal, 10 = 2 * 5. The number of divisors is found by adding one to each exponent of each prime and multiplying the resulting quantities together.
Factors of 10 = ("n"+1)("n"+1) = ("n"+1).

For example, the number 8 is a factor of 10 (1000), so 1/8 and other fractions with a denominator of 8 can not require more than 3 fractional decimal digits to terminate. 5/8 = 0.625

For duodecimal, 12 = 2 * 3. This has (2"n"+1)("n"+1) divisors. The sample denominator of 8 is a factor of a gross (12 = 144), so eighths can not need more than two duodecimal fractional places to terminate. 5/8 = 0.76

Because both ten and twelve have two unique prime factors, the number of divisors of "b" for "b" = 10 or 12 grows quadratically with the exponent "n" (in other words, of the order of "n").

The Dozenal Society of America argues that factors of 3 are more commonly encountered in real-life division problems than factors of 5. Thus, in practical applications, the nuisance of repeating decimals is encountered less often when duodecimal notation is used. Advocates of duodecimal systems argue that this is particularly true of financial calculations, in which the twelve months of the year often enter into calculations.

However, when recurring fractions "do" occur in duodecimal notation, they are less likely to have a very short period than in decimal notation, because 12 (twelve) is between two prime numbers, 11 (eleven) and 13 (thirteen), whereas ten is adjacent to the composite number 9. Nonetheless, having a shorter or longer period doesn't help the main inconvenience that one does not get a finite representation for such fractions in the given base (so rounding, which introduces inexactitude, is necessary to handle them in calculations), and overall one is more likely to have to deal with infinite recurring digits when fractions are expressed in decimal than in duodecimal, because one out of every three consecutive numbers contains the prime factor 3 in its factorization, whereas only one out of every five contains the prime factor 5. All other prime factors, except 2, are not shared by either ten or twelve, so they do not
influence the relative likeliness of encountering recurring digits (any irreducible fraction that contains any of these other factors in its denominator will recur in either base). Also, the prime factor 2 appears twice in the factorization of twelve, whereas only once in the factorization of ten; which means that most fractions whose denominators are powers of two will have a shorter, more convenient terminating representation in duodecimal than in decimal representation (e.g. 1/(2) = 0.25 = 0.3 ; 1/(2) = 0.125 = 0.16 ; 1/(2) = 0.0625 = 0.09 ; 1/(2) = 0.03125 = 0.046 ; etc.).

Values in bold indicate that value is exact.

The duodecimal period length of 1/"n" are

The duodecimal period length of 1/("n"th prime) are

Smallest prime with duodecimal period "n" are

As for irrational numbers, none of them have a finite representation in "any" of the rational-based positional number systems (such as the decimal and duodecimal ones); this is because a rational-based positional number system is essentially nothing but a way of expressing quantities as a sum of fractions whose denominators are powers of the base, and by definition no "finite" sum of rational numbers can ever result in an irrational number. For example, 123.456 = 1 × 10 + 2 × 10 + 3 × 10 + 4 × 1/10 + 5 × 1/10 + 6 × 1/10 (this is also the reason why fractions that contain prime factors in their denominator not in common with those of the base do not have a terminating representation in that base). Moreover, the infinite series of digits of an irrational number does not exhibit a strictly repeating pattern; instead, the different digits often succeed in a seemingly random fashion. The following chart compares the first few digits of the decimal and duodecimal representation of several of the most important algebraic and transcendental irrational numbers. Some of these numbers may be perceived as having fortuitous patterns, making them easier to memorize, when represented in one base or the other.

The first few digits of the decimal and duodecimal representation of another important number, the Euler–Mascheroni constant (the status of which as a rational or irrational number is not yet known), are:





</doc>
<doc id="8401" url="https://en.wikipedia.org/wiki?curid=8401" title="David Hayes Agnew">
David Hayes Agnew

David Hayes Agnew (November 24, 1818March 22, 1892) was an American surgeon.

Agnew was born on November 24, 1818, Nobleville, Pennsylvania, (present-day Christiana). His parents were Robert Agnew and Agnes Noble. Agnew grew up as a Christian. He was surrounded by a family of doctors and had always known he was going to become a physician. “From the time that he was first able to play, he would ride a cane for a horse, and, clad in one of his father’s vests, which reached nearly to his heels, he would stuff his pockets with bottles and powders, and pretend to visit his patients.”—Jeddiah Adams (Author of History of the Life of D. Hayes Agnew).

As a young boy, he had a sharp sense of humor and was very intelligent. He graduated from the University of Pennsylvania School of Medicine in 1838. He returned to Nobleville to help his father in his clinic. He worked there for two years. His father was an asthmatic and moved to Maryland in 1840 because the climate was more suited to his condition. Agnew moved with him. On November 21, 1841, he married Margaret Irwin. In 1852, he bought and revived the Philadelphia School of Anatomy. He held responsibility for ten years until 1862. During the American Civil War he was consulting surgeon in the Mower Army Hospital, near Philadelphia, and acquired a considerable reputation for his operations in cases of gunshot wounds.On December 21, 1863, he became the Demonstrator of Anatomy and Assistant Lecturer on Clinical Surgery at The University of Pennsylvania. Later, he was requested to assist the Professor of Surgery in the Conduct of the surgical clinics. In the year 1865, he gave summer instruction courses. For the next seven years, he worked for the University as Demonstrator of Anatomy. A large portion of his success was due to his wife’s energy, intelligence, and determination. She gave him an impetus to try harder and not be satisfied with his first try.

On July 2, 1881, President James A. Garfield was shot by Charles J. Guiteau. He held the position of chief consulting surgeon. When a committee came to give him his money for helping, Agnew said, “Gentlemen, I present no bill for my attendance to President Garfield. I gave my services freely and gratuitously”. He was never optimistic about the President’s case and was not fooled by fallacious beliefs. This procedure helped create Agnew’s reputation.

The Agnew Clinic is a famous painting by Thomas Eakins. It was painted in 1889. In the painting, he is depicted conducting a mastectomy operation before a gallery of students and doctors. Agnew became the subject of the largest painting ever made by the Philadelphia artist Thomas Eakins.

David Agnew wrote The Principles and Practice of Surgery. It was a 3 volume set that he published from 1878-1883. He also helped found the Irwin & Agnew Iron Foundry in 1846.

Agnew caught a severe attack of epidemic influenza in 1890. He never fully recovered. Following this, he had an attack of broncho-vesicular catarrh. On March 9, 1892, he was put in bed for a series of medical problems. After a few days it started to get better but suddenly on March 12 it became much worse. On March 20, he fell into a comatose condition. Agnew stayed like this until he died at 3:20 p.m. on March 22, 1892. He is now buried in West Laurel Hill Cemetery.




</doc>
<doc id="8402" url="https://en.wikipedia.org/wiki?curid=8402" title="Diving">
Diving

Diving is the sport of jumping or falling into water from a platform or springboard, usually while performing acrobatics. Diving is an internationally recognized sport that is part of the Olympic Games. In addition, unstructured and non-competitive diving is a recreational pastime.

Diving is one of the most popular Olympic sports with spectators. Competitors possess many of the same characteristics as gymnasts and dancers, including strength, flexibility, kinaesthetic judgment and air awareness. Some professional divers were originally gymnasts or dancers as both the sports have similar characteristics to diving. Dmitri Sautin holds the record for most Olympic diving medals won, by winning eight medals in total between 1992 and 2008.

Although diving has been a popular pastime across the world since ancient times, the first modern diving competitions were held in England in the 1880s. The exact origins of the sport are unclear, though it likely derives from the act of diving at the start of swimming races. The 1904 book "Swimming" by Ralph Thomas notes English reports of plunging records dating back to at least 1865. The 1877 edition to "British Rural Sports" by John Henry Walsh makes note of a "Mr. Young" plunging 56 feet in 1870, and also states that 25 years prior, a swimmer named Drake could cover 53 feet.

The English Amateur Swimming Association (at the time called the Swimming Association of Great Britain) first started a "plunging championship" in 1883. The Plunging Championship was discontinued in 1937.

Diving into a body of water had also been a method used by gymnasts in Germany and Sweden since the early 19th century. The soft landing allowed for more elaborate gymnastic feats in midair as the jump could be made from a greater height. This tradition evolved into 'fancy diving', while diving as a preliminary to swimming became known as 'Plain diving'.

In England, the practice of high diving – diving from a great height – gained popularity; the first diving stages were erected at the Highgate Ponds at a height of 15 feet in 1893 and the first world championship event, the National Graceful Diving Competition, was held there by the Royal Life Saving Society in 1895. The event consisted of standing and running dives from either 15 or 30 feet.

It was at this event that the Swedish tradition of fancy diving was introduced to the sport by the athletes Otto Hagborg and C F Mauritzi. They demonstrated their acrobatic techniques from the 10m diving board at Highgate Pond and stimulated the establishment of the Amateur Diving Association in 1901, the first organization devoted to diving in the world (later amalgamated with the Amateur Swimming Association). Fancy diving was formally introduced into the championship in 1903.

Plain diving was first introduced into the Olympics at the 1904 event. The 1908 Olympics in London added 'fancy diving' and introduced elastic boards rather than fixed platforms. Women were first allowed to participate in the diving events for the 1912 Olympics in Stockholm.

In the 1928 Olympics, 'plain' and 'fancy' diving was amalgamated into one event – 'Highboard Diving'. The diving event was first held indoors in the Empire Pool for the 1934 British Empire Games and 1948 Summer Olympics in London.

Most diving competitions consist of three disciplines: 1 m and 3 m springboards, and the platform. Competitive athletes are divided by gender, and often by age group. In platform events, competitors are allowed to perform their dives on either the five, seven and a half (generally just called seven), nine, or ten meter towers. In major diving meets, including the Olympic Games and the World Championships, platform diving is from the 10 meter height.
Divers have to perform a set number of dives according to established requirements, including somersaults and twists. Divers are judged on whether and how well they completed all aspects of the dive, the conformance of their body to the requirements of the dive, and the amount of splash created by their entry to the water. A possible score out of ten is broken down into three points for the takeoff (meaning the hurdle), three for the flight (the actual dive), and three for the entry (how the diver hits the water), with one more available to give the judges flexibility.

The raw score is multiplied by a degree of difficulty factor, derived from the number and combination of movements attempted. The diver with the highest total score after a sequence of dives is declared the winner.

Synchronized diving was adopted as an Olympic sport in 2000. Two divers form a team and perform dives simultaneously. The dives are identical. It used to be possible to dive opposites, also known as a pinwheel, but this is no longer part of competitive synchronized diving. For example, one diver would perform a forward dive and the other an inward dive in the same position, or one would do a reverse and the other a back movement. In these events, the diving would be judged both on the quality of execution and the synchronicity – in timing of take-off and entry, height and forward travel.

There are rules governing the scoring of a dive. Usually a score considers three elements of the dive: the approach, the flight, and the entry. The primary factors affecting the scoring are:


Each dive is assigned a "degree of difficulty" (DD), which is determined from a combination of the moves undertaken, position used, and height. The DD value is multiplied by the scores given by the judges.

To reduce the subjectivity of scoring in major meets, panels of five or seven judges are assembled; major international events such as the Olympics use seven-judge panels. For a five-judge panel, the highest and lowest scores are discarded and the middle three are summed and multiplied by the DD. For seven-judge panels, as of the 2012 London Olympics, the two highest scores and two lowest are discarded, leaving three to be summed and multiplied by the DD. (Prior to the London Olympics, the highest and lowest scores were eliminated, and the remaining five scores were multiplied by , to allow for comparison to five-judge panels.) The canceling of scores is used to make it difficult for a single judge to manipulate scores.

There is a general misconception about scoring and judging. In serious meets, the absolute score is somewhat meaningless. It is the relative score, not the absolute score that wins meets. Accordingly, good judging implies consistent scoring across the dives. Specifically, if a judge consistently gives low scores for all divers, or consistently gives high scores for the same divers, the judging will yield fair relative results and will cause divers to place in the correct order. However, absolute scores have significance to the individual divers. Besides the obvious instances of setting records, absolute scores are also used for rankings and qualifications for higher level meets.

In synchronised diving events, there is a panel of seven, nine, or eleven judges; two or three to mark the execution of one diver, two or three to mark the execution of the other, and the remaining three or five to judge the synchronisation. The execution judges are positioned two on each side of the pool, and they score the diver which is nearer to them. The 2012 London Olympics saw the first use of eleven judges.

The score is computed similarly to the scores from other diving events, but has been modified starting with the 2012 London Olympics for the use of the larger judging panels. Each group of judges will have the highest and lowest scores dropped, leaving the middle score for each diver's execution and the three middle scores for synchronization. The total is then weighted by and multiplied by the DD. The result is that the emphasis is on the synchronization of the divers.

The synchronisation scores are based on:

The judges may also disqualify the diver for certain violations during the dive, including:

To win dive meets, divers create a dive list in advance of the meet. To win the meet the diver must accumulate more points than other divers. Often, simple dives with low DDs will look good to spectators but will not win meets. The competitive diver will attempt the highest DD dives possible with which they can achieve consistent, high scores. If divers are scoring 8 or 9 on most dives, it may be a sign of their extreme skill, or it may be a sign that their dive list is not competitive, and they may lose the meet to a diver with higher DDs and lower scores.

In competition, divers must submit their lists beforehand, and once past a deadline (usually when the event is announced or shortly before it begins) they cannot change their dives. If they fail to perform the dive announced, even if they physically cannot execute the dive announced or if they perform a more difficult dive, they will receive a score of zero. Under exceptional circumstances, a redive may be granted, but these are exceedingly rare (usually for very young divers just learning how to compete, or if some event outside the diver's control has caused them to be unable to perform-such as a loud noise).

In the Olympics or other highly competitive meets, many divers will have nearly the same list of dives as their competitors. The importance for divers competing at this level is not so much the DD, but how they arrange their list. Once the more difficult rounds of dives begin it is important to lead off with a confident dive to build momentum. They also tend to put a very confident dive in front of a very difficult dive to ensure that they will have a good mentality for the difficult dive. Most divers have pre-dive and post-dive rituals that help them either maintain or regain focus. Coaches also play a role in this aspect of the sport. Many divers rely on their coaches to help keep their composure during the meet. In a large meet coaches are rarely allowed on the deck to talk to their athlete so it is common to see coaches using hand gestures or body movements to communicate.

There are some American meets which will allow changes of the position of the dive even after the dive has been announced immediately before execution, but these are an exception to the rules generally observed internationally.

Generally, NCAA rules allow for dives to be changed while the diver is on the board, but the diver must request the change directly after the dive is announced. This applies especially in cases where the wrong dive is announced. If the diver pauses during his or her hurdle to ask for a change of dive, it will be declared a balk (when the diver stops mid-hurdle) and the change of dive will not be permitted.

Under FINA law, no dive may be changed after the deadline for the dive-sheet to be submitted (generally a period ranging from one hour to 24 hours, depending on the rulings made by the event organiser).

It is the diver's responsibility to ensure that the dive-sheet is filled in correctly, and also to correct the referee or announcer before the dive if they describe it incorrectly. If a dive is performed which is as submitted but not as (incorrectly) announced, it is declared failed and scores zero according to a strict reading of the FINA law. But in practice, a re-dive would usually be granted in these circumstances.

The global governing body of diving is FINA, which also governs swimming, synchronised swimming, water polo and open water swimming. Almost invariably, at national level, diving shares a governing body with the other aquatic sports.

This is frequently a source of political friction as the committees are naturally dominated by swimming officials who do not necessarily share or understand the concerns of the diving community. Divers often feel, for example, that they do not get adequate support over issues like the provision of facilities. Other areas of concern are the selection of personnel for the specialised Diving committees and for coaching and officiating at events, and the team selection for international competitions.

There are sometimes attempts to separate the governing body as a means to resolve these frustrations, but they are rarely successful. For example, in the UK the Great Britain Diving Federation was formed in 1992 with the intention of taking over the governance of Diving from the ASA (Amateur Swimming Association). Although it initially received widespread support from the diving community, the FINA requirement that international competitors had to be registered with their National Governing Body was a major factor in the abandonment of this ambition a few years later.

Since FINA refused to rescind recognition of the ASA as the British governing body for all aquatic sports including diving, this meant that the elite divers had to belong to ASA-affiliated clubs to be eligible for selection to international competition.

In the United States scholastic diving is almost always part of the school's swim team. Diving is a separate sport in Olympic and Club Diving. The NCAA will separate diving from swimming in special diving competitions after the swim season is completed.

Despite the apparent risk, the statistical incidence of injury in supervised training and competition is extremely low.

The majority of accidents that are classified as 'diving-related' are incidents caused by individuals jumping from structures such as bridges or piers into water of inadequate depth. Many accidents also occur when divers do not account for rocks and logs in the water. Because of this many beaches and pools prohibit diving in shallow waters or when a lifeguard is not on duty.

After an incident in Washington in 1993, most US and other pool builders are reluctant to equip a residential swimming pool with a diving springboard so home diving pools are much less common these days. In the incident, 14-year-old Shawn Meneely made a "suicide dive" (holding his hands at his sides, so that his head hit the bottom first) in a private swimming pool and became a tetraplegic. The lawyers for the family, Jan Eric Peterson and Fred Zeder, successfully sued the diving board manufacturer, the pool builder, and the National Spa and Pool Institute over the inappropriate depth of the pool.
The NSPI had specified a minimum depth of 7 ft 6 in (2.29 m) which proved to be insufficient in the above case. The pool into which Meneely dived was not constructed to the published standards. The standards had changed after the diving board was installed on the non-compliant pool by the homeowner. But the courts held that the pool "was close enough" to the standards to hold NSPI liable. The multimillion-dollar lawsuit was eventually resolved in 2001 for US$6.6 million ($8 million after interest was added) in favor of the plaintiff. The NSPI was held to be liable, and was financially strained by the case. It filed twice for Chapter 11 bankruptcy protection and was successfully reorganized into a new swimming pool industry association.

In competitive diving, FINA takes regulatory steps to ensure that athletes are protected from the inherent dangers of the sport. For example, they impose restrictions according to age on the heights of platforms which divers may compete on.


Group D divers have only recently been allowed to compete on the tower. In the past, the age group could compete only springboard, to discourage children from taking on the greater risks of tower diving. Group D tower was introduced to counteract the phenomenon of coaches pushing young divers to compete in higher age categories, thus putting them at even greater risk.

However, some divers may safely dive in higher age categories to dive on higher platforms. Usually this occurs when advanced Group C divers wish to compete on the 10 m.

Points on pool depths in connection with safety:


There are six "groups" into which dives are classified: "Forward, Back, Inward, Reverse, Twist," and "Armstand". The latter applies only to Platform competitions, whereas the other five apply to both Springboard and Platform.

During the flight of the dive, one of four positions is assumed:

These positions are referred to by the letters A, B, C and D respectively.

Additionally, some dives can be started in a flying position. The body is kept straight with the arms extended to the side, and the regular dive position is assumed at about half the dive.

Difficulty is rated according to the Degree of Difficulty of the dives. Some divers may find pike easier in a flip than tuck, and most find straight the easiest in a front/back dive, although it is still rated the most difficult because of the risk of overrotation.

An armstand dive may have a higher degree of difficulty outdoors compared to indoors as wind can destabilize the equilibrium of the diver.

In competition, the dives are referred to by a schematic system of three- or four-digit numbers. The letter to indicate the position is appended to the end of the number.

The first digit of the number indicates the dive group as defined above.

For groups 1 to 4, the number consists of three digits and a letter of the alphabet. The third digit represents the number of half-somersaults. The second digit is either 0 or 1, with 0 representing a normal somersault, and 1 signifying a "flying" variation of the basic movement (i.e. the first half somersault is performed in the straight position, and then the pike or tuck shape is assumed). No flying dive has been competed at a high level competition for many years.

For example:

For Group 5, the dive number has 4 digits. The first digit indicates that it is a twisting dive. The second digit indicates the group (1–4) of the underlying movement; the third digit indicates the number of half-somersaults, and the fourth indicates the number of half-twists.

For example:

For Group 6 – Armstand – the dive number has either three or four digits: Three digits for dives without twist and four for dives with twists.

In non-twisting armstand dives, the second digit indicates the direction of rotation (0 = no rotation, 1 = forward, 2 = backward, 3 = reverse, 4 = inward) and the third digit indicates the number of half-somersaults. Inward-rotating armstand dives have never been performed, and are generally regarded as physically impossible.

For example:

For twisting Armstand dives, the dive number again has 4 digits, but rather than beginning with the number 5, the number 6 remains as the first digit, indicating that the "twister" will be performed from an Armstand. The second digit indicates the direction of rotation – as above, the third is the number of half-somersaults, and the fourth is the number of half-twists:

e.g. 6243D – armstand back double-somersault with one and a half twists in the free position

All of these dives come with DD (degree of difficulty) this is an indication of how difficult/complex a dive is. The score that the dive receives is multiplied by the DD (also known as tariff) to give the dive a final score. Before a diver competes they must decide on a "list" this is a number of optional dives and compulsory dives. The optionals come with a DD limit. this means that a diver must select X number of dives and the combined DD limit must be no more than the limit set by the competition/organisation etc.

Until the mid-1990s the tariff was decided by the FINA diving committee, and divers could only select from the range of dives in the published tariff table. Since then, the tariff is calculated by a formula based on various factors such as the number of twist and somersaults, the height, the group etc., and divers are free to submit new combinations. This change was implemented because new dives were being invented too frequently for an annual meeting to accommodate the progress of the sport.

At the moment of take-off, two critical aspects of the dive are determined, and cannot subsequently be altered during the execution. One is the trajectory of the dive, and the other is the magnitude of the angular momentum.

The speed of rotation – and therefore the total amount of rotation – may be varied from moment to moment by changing the shape of the body, in accordance with the law of conservation of angular momentum.

The center of mass of the diver follows a parabolic path in free-fall under the influence of gravity (ignoring the effects of air resistance, which are negligible at the speeds involved).

Since the parabola is symmetrical, the travel away from the board as the diver passes it is twice the amount of the forward travel at the peak of the flight. Excessive forward distance to the entry point is penalized when scoring a dive, but obviously an adequate clearance from the diving board is essential on safety grounds.

The greatest possible height that can be achieved is desirable for several reasons:


The magnitude of angular momentum remains constant throughout the dive, but since

and the moment of inertia is larger when the body has an increased radius, the speed of rotation may be increased by moving the body into a compact shape, and reduced by opening out into a straight position.

Since the tucked shape is the most compact, it gives the most control over rotational speed, and dives in this position are easier to perform. Dives in the straight position are hardest, since there is almost no scope for altering the speed, so the angular momentum must be created at take-off with a very high degree of accuracy. (A small amount of control is available by moving the position of the arms and by a slight hollowing of the back).

The opening of the body for the entry does not stop the rotation, but merely slows it down. The vertical entry achieved by expert divers is largely an illusion created by starting the entry slightly short of vertical, so that the legs are vertical as they disappear beneath the surface. A small amount of additional tuning is available by 'entry save' techniques, whereby underwater movements of the upper body and arms against the viscosity of the water affect the position of the legs.

Dives with multiple twists and somersaults are some of the most spectacular movements, as well as the most challenging to perform.

The rules state that twisting 'must not be generated manifestly on take-off'. Consequently, divers must use some of the somersaulting angular momentum to generate twisting movements. The physics of twisting can be explained by looking at the components of the angular momentum vector.

As the diver leaves the board, the total angular momentum vector is horizontal, pointing directly to the left for a forward dive for example. For twisting rotation to exist, it is necessary to tilt the body sideways after takeoff, so that there is now a small component of this horizontal angular momentum vector along the body's long axis. The tilt can be seen in the photo.

The tilting is done by the arms, which are outstretched to the sides just before the twist. When one arm is moved up and the other is moved down (like turning a big steering wheel), the body reacts by tilting to the side, which then begins the twisting rotation. At the completion of the required number of twist rotations, the arm motion is reversed (the steering wheel is turned back), which removes the body's tilt and stops the twisting rotation.

An alternative explanation is that the moving arms have precession torque on them which set the body into twisting rotation. Moving the arms back produces opposite torque which stops the twisting rotation.

The rules state that the body should be vertical, or nearly so, for entry. Strictly speaking, it is physically impossible to achieve a literally vertical position throughout the entry as there will inevitably still be some rotational momentum while the body is entering the water. Divers therefore attempt to create the illusion of being vertical, especially when performing rapidly rotating multiple somersault movements. For back entries, one technique is to allow the upper body to enter slightly short of vertical so that the continuing rotation leaves the final impression of the legs entering vertically. This is called "Pike save". Another is to use "knee save" movements of scooping the upper body underwater in the direction of rotation so as to counteract the rotation of the legs.

The arms must be beside the body for feet-first dives, which are typically competed only on the 1m springboard and only at fairly low levels of 3m springboard, and extended forwards in line for "head-first" dives, which are much more common competitively. It used to be common for the hands to be interlocked with the fingers extended towards the water, but a different technique has become favoured during the last few decades. Now the usual practice is for one hand to grasp the other with palms down to strike the water with a flat surface. This creates a vacuum between the hands, arms and head which, with a vertical entry, will pull down and under any splash until deep enough to have minimal effect on the surface of the water (the so-called "rip entry").

Once a diver is completely under the water they may choose to roll or scoop in the same direction their dive was rotating to pull their legs into a more vertical position. Apart from aesthetic considerations, it is important from a safety point of view that divers reinforce the habit of rolling in the direction of rotation, especially for forward and inward entries. Back injuries hyperextention are caused by attempting to re-surface in the opposite direction. Diving from the higher levels increases the danger and likelihood of such injuries.

In Canada, elite competitive diving is regulated by DPC (Diving Plongeon Canada), although the individual provinces also have organizational bodies. The main competitive season runs from February to July, although some competitions may be held in January or December, and many divers (particularly international level athletes) will train and compete year round.

Most provincial level competitions consist of events for 6 age groups (Groups A, B, C, D, E, and Open) for both genders on each of the three board levels. These age groups roughly correspond to those standardized by FINA, with the addition of a youngest age group for divers 9 and younger, Group E, which does not compete nationally and does not have a tower event (although divers of this age may choose to compete in Group D). The age group Open is so called because divers of any age, including those over 18, may compete in these events, so long as their dives meet a minimum standard of difficulty.

Although Canada is internationally a fairly strong country in diving, the vast majority of Canadian high schools and universities do not have diving teams, and many Canadian divers accept athletic scholarships from American colleges.

Adult divers who are not competitive at an elite level may compete in masters diving. Typically, masters are either adults who never practiced the sport as children or teenagers, or former elite athletes who have retired but still seek a way to be involved in the sport. Many diving clubs have masters teams in addition to their primary competitive ones, and while some masters dive only for fun and fitness, there are also masters competitions, which range from the local to world championship level.

Divers can qualify to compete at the age group national championships, or junior national championships, in their age groups as assigned by FINA up to the age of 18. This competition is held annually in July. Qualification is based on achieving minimum scores at earlier competitions in the season, although athletes who place very highly at a national championship will be automatically qualified to compete at the next. Divers must qualify at two different competitions, at least one of which must be a level 1 competition, i.e. a competition with fairly strict judging patterns. Such competitions include the Polar Bear Invitational in Winnipeg, the Sting in Victoria, and the Alberta Provincial Championships in Edmonton or Calgary. The qualifying scores are determined by DPC according to the results of the preceding year's national competition, and typically do not have much variation from year to year.

Divers older than 18, or advanced divers of younger ages, can qualify for the senior national championships, which are held twice each year, once roughly in March and once in June or July. Once again, qualification is based on achieving minimum scores at earlier competitions (in this case, within the 12 months preceding the national championships, and in an Open age group event), or high placements in previous national championships or international competitions. It is no longer the case that divers may use results from age group events to qualify for senior nationals, or results from Open events to qualify for age group nationals.

In the Republic of Ireland facilities are limited to one pool at the National Aquatic Centre in Dublin.

National championships take place late in the year, usually during November. The competition is held at the National Aquatic Centre in Dublin and consists of four events:

In the United Kingdom, diving competitions on all boards run throughout the year. National Masters' Championships are held two or three times per year.

In the United States, summer diving is usually limited to one meter diving at community or country club pools. Some pools organize to form intra-pool competitions. These competitions are usually designed to accommodate all school-age children. One of the largest and oldest summer leagues in the United States is found in the Northern Virginia area where teams from 47 pools compete against each other every summer. NVSL-Dive annually holds the Wally Martin 3-Meter Championship and concludes the season with its Individual All Stars Championship. In addition, NVSL-Dive annually hosts the largest one-day dive meet in the world, with over 350 developmental divers in NVSL's "Cracker Jack" Invitational! Champions from each of these events have gone on to compete at the collegiate and Olympic levels.

In the United States scholastic diving at the high school level is usually limited to one meter diving (but some schools use three meter springboards.). Scores from those one meter dives contribute to the swim team's overall score. High school diving and swimming concludes their season with a state competition. Depending on the state and the number of athletes competing in the state, certain qualifications must be achieved to compete in the state's championship meet. There are often regional championships and district championships which are necessary to compete in before reaching the state meet to narrow the field to only the most competitive athletes. Most state championship meets consist of eleven dives. The eleven dives are usually split up between two categories: five required (voluntary) dives and six optional dives.

In the United States, pre-college divers interested in learning one and three meter or platform diving should consider a club sanctioned by either USA Diving or AAU Diving. In USA Diving, Future Champions is the entry level or novice diver category with 8 levels of competition. From Future Champions, divers graduate to "Junior Olympic", or JO. JO divers compete in age groups at inter-club competitions, at invitationals, and if qualified, at regional, zone and national competitions. Divers over the age of 19 years of age cannot compete in these events as a JO diver.

USA Diving sanctions the Winter Nationals championship with one, three meter, and platform events. In the summer USA Diving sanctions the Summer Nationals including all three events with both Junior and Senior divers. USA Diving is sanctioned by the United States Olympic Committee to select team representatives for international diving competitions including the World Championships and Olympic Games.

AAU Diving sanctions one national event per year in the summer. AAU competes on the one, three, and tower to determine the All-American team.

In the United States scholastic diving at the college level requires one and three meter diving. Scores from the one and three meter competition contribute to the swim team's overall meet score. College divers interested in tower diving may compete in the NCAA separate from swim team events. NCAA Divisions II and III do not usually compete platform; if a diver wishes to compete platform in college, he or she must attend a Division I school.

Each division also has rules on the number of dives in each competition. Division II schools compete with 10 dives in competition whereas Division III schools compete with 11. Division I schools only compete with 6 dives in competition. These 6 dives consist of either 5 optionals and 1 voluntary, or 6 optionals. If the meet is a 5 optional meet, then the divers will perform 1 optional from each category (Front, Back, Inward, Reverse, and Twister) and then 1 voluntary from the category of their choice. The voluntary in this type of meet is always worth a DD (Degree of Difficulty) of 2.0 even if the real DD is worth more or less on a DD sheet. In a 6 optional meet, the divers will yet again perform one dive from each category, but this time they will perform a 6th optional from the category of their choosing, which is worth its actual DD from the DD sheet.

The highest level of collegiate competition is the NCAA Division 1 Swimming and Diving Championship. Events at the championship include 1 meter springboard, 3 meter springboard, and platform, as well as various swimming individual and relay events. The points scored by swimmers and divers are combined to determine a team swimming & diving champion. To qualify for a diving event at the NCAA championships, a competitor must first finish in the top three at one of five zone championships, which are held after the various conference championship meets. A diver who scores at least 310 points on the 3 meter springboard and 300 points on the 1 meter springboard in a 6 optional meet can participate in the particular zone championship corresponding to the geographic region in which his or her school lies.

A number of colleges and universities offer scholarships to men and women who have competitive diving skills. These scholarships are usually offered to divers with age-group or club diving experience.

The NCAA limits the number of years a college student can represent any school in competitions. The limit is four years, but could be less under certain circumstances.

Divers who continue diving past their college years can compete in Masters' Diving programs. Masters' diving programs are frequently offered by college or club programs.

Masters' Diving events are normally conducted in age-groups separated by five or ten years, and attract competitors of a wide range of ages and experience (many, indeed, are newcomers to the sport); the oldest competitor in a Masters' Diving Championship was Viola Krahn, who at the age of 101 was the first person in any sport, male or female, anywhere in the world, to compete in an age-group of 100+ years in a nationally organized competition.


Diving is also popular as a non-competitive activity. Such diving usually emphasizes the airborne experience, and the height of the dive, but does not emphasize what goes on once the diver enters the water. The ability to dive underwater can be a useful emergency skill, and is an important part of watersport and navy safety training. Entering water from a height is an enjoyable leisure activity, as is underwater swimming.

Such non-competitive diving can occur indoors and outdoors. Outdoor diving typically takes place from cliffs or other rock formations either into fresh or salt water. However, man-made diving platforms are sometimes constructed in popular swimming destinations. Outdoor diving requires knowledge of the water depth and currents as conditions can be dangerous.
On occasion, the diver will inadvertently belly flop, entering the water horizontally or nearly so. The diver typically displaces a larger than usual amount of water.

A recently developing section of the sport is "High Diving" (e.g. see 2013 World Aquatics Championships), conducted in open air locations, usually from improvised platforms up to high (as compared with as used in Olympic and World Championship events). Entry to the water is invariably feet-first to avoid the risk of injury that would be involved in head-first entry from that height. The final half-somersault is almost always performed backwards, enabling the diver to spot the entry point and control their rotation.




</doc>
<doc id="8406" url="https://en.wikipedia.org/wiki?curid=8406" title="Dative case">
Dative case

The dative case (abbreviated , or sometimes when it is a core argument) is a grammatical case used in some languages to indicate, among other uses, the noun to which something is given, as in "Maria Jacobī potum dedit", Latin for "Maria gave Jacob a drink". In these examples, the dative marks what would be considered the indirect object of a verb in English.

Sometimes the dative has functions unrelated to giving. In Scottish Gaelic and Irish, the term "dative case" is used in traditional grammars to refer to the prepositional case-marking of nouns following simple prepositions and the definite article. In Georgian, the dative case also marks the subject of the sentence with some verbs and some tenses. This is called the dative construction.

The dative was common among early Indo-European languages and has survived to the present in the Balto-Slavic branch and the Germanic branch, among others. It also exists in similar forms in several non-Indo-European languages, such as the Uralic family of languages. In some languages, the dative case has assimilated the functions of other, now extinct cases. In Ancient Greek, the dative has the functions of the Proto-Indo-European locative and instrumental as well as those of the original dative.

Under the influence of English, which uses the preposition "to" for (among other uses) both indirect objects ("give to") and directions of movement ("go to"), the term "dative" has sometimes been used to describe cases that in other languages would more appropriately be called lative.

"Dative" comes from Latin "cāsus datīvus" ("case for giving"), a translation of Greek δοτικὴ πτῶσις, "dotikē ptôsis" ("inflection for giving"), from its use with the verb "didónai" "to give". Dionysius Thrax in his Art of Grammar also refers to it as "epistaltikḗ" "for sending (a letter)", from the verb "epistéllō" "send to", a word from the same root as epistle.

The Old English language, which continued in use until after the Norman Conquest of 1066, had a dative case; however, the English case system gradually fell into disuse during the Middle English period, when the accusative and dative of pronouns merged into a single oblique case that was also used with all prepositions. This conflation of case in Middle and Modern English has led most modern grammarians to discard the "accusative" and "dative" labels as obsolete in reference to English, often using the term "objective" for oblique.

The dative case is rare in modern English usage, but it can be argued that it survives in a few set expressions. One example is the word "methinks", with the meaning "it seems to me". It survives in this fixed form from Old English (having undergone, however, phonetic changes with the rest of the language), in which it was constructed as "[it]" + "me" (the dative case of the personal pronoun) + "thinks" (i.e., "seems", < Old English þyncan, "to seem", a verb closely related to the verb þencan, "to think", but distinct from it in Old English; later it merged with "think" and lost this meaning).

The modern objective case pronoun whom is derived from the dative case in Old English, specifically the Old English dative pronoun "hwām" (as opposed to the modern subjective "who", which descends from Old English "hwā") — though "whom" "also" absorbed the functions of the Old English accusative pronoun "hwone". It is also cognate to the word ""wem"" (the dative form of ""wer"") in German. The OED defines all classical uses of the word "whom" in situations where the indirect object "is not known" – in effect, indicating the anonymity of the indirect object.

Likewise, some of the object forms of personal pronouns are remnants of Old English datives. For example, "him" goes back to the Old English dative "him" (accusative was "hine"), and "her" goes back to the dative "hire" (accusative was "hīe"). These pronouns are not datives in modern English; they are also used for functions previously indicated by the accusative.

A grammatical "object" is an object "of something", either an object "of a preposition" or an object "of a verb". Objects of verbs can be either "direct" or "indirect", while objects of prepositions are neither direct nor indirect. The indirect object of the verb is expressed between the verb and the direct object of the verb: "he gave me a book" or "he wrote me a poem."

An indirect object can often be "re-worded" with a prepositional phrase using "to" or "for", but it is then no longer an indirect object. For example, "He gave a book to me" and "He wrote a poem for me" have the same meaning the examples above, but are now "adverbial prepositional phrases". Of course it is not unusual that two "different grammatical structures" can describe the "same situation"; however referring to these "prepositional objects" mistakenly as "indirect objects" is a common error.

In general, the dative (German: "Dativ") is used to mark the indirect object of a German sentence. For example:

In English, the first sentence can be rendered as "I sent the book "to the man"" and as "I sent "the man" the book", where the indirect object is identified in English by standing in front of the direct object. The normal word order in German is to put the dative in front of the accusative (as in the example above). However, since the German dative is marked in form, it can also be put "after" the accusative: "Ich schickte das Buch dem Mann(e). The (e)" after "Mann" and "Kind" signifies a now largely archaic -e ending for certain nouns in the dative. It survives today almost exclusively in set phrases such as "zu Hause" (to the house, lit. going home), "im Zuge" (in the course of), and "am Tage" (in the afternoon), as well as in occasional usage in formal prose, poetry, and song lyrics.

Some masculine nouns (and one neuter noun, "Herz" [heart]), referred to as "weak nouns" or "n-nouns", take an -n or -en in the dative singular and plural. Many are masculine nouns ending in -e in the nominative (such as "Name" [name], "Beamte" [officer], and "Junge" [boy]), although not all such nouns follow this rule. Many also, whether or not they fall into the former category, refer to people, animals, professions, or titles; exceptions to this include the aforementioned "Herz" and "Name", as well as "Buchstabe" (letter), "Friede" (peace), "Obelisk" (obelisk), "Planet" (planet), and others.

Certain German prepositions require the dative: "aus" (from), "außer" (out of), "bei" (at, near), "entgegen" (against), "gegenüber" (opposite), "mit" (with), "nach" (after, to), "seit" (since), "von" (from), and "zu" (at, in, to). Some other prepositions ("an" [at], "auf" [on], "entlang" [along], "hinter" [behind], "in" [in, into], "neben" (beside, next to), "über" [over, across], "unter" [under, below], "vor" [in front of], and "zwischen" [among, between]) may be used with dative (indicating current location), or accusative (indicating direction toward something). "Das Buch liegt auf dem Tisch(e)" (dative: The book is lying on the table), but "Ich lege das Buch auf den Tisch" (accusative: I put the book onto the table).

In addition the four prepositions "[an]statt" (in place of), "trotz" (in spite of), "während" (during), and "wegen" (because of) which require the genitive in modern formal language, are most commonly used with the dative in colloquial German. For example, "because of the weather" is expressed as "wegen dem Wetter" instead of the formally correct "wegen des Wetters". Other prepositions requiring the genitive in formal language, are combined with "von" ("of") in colloquial style, e.g. "außerhalb vom Garten" instead of "außerhalb des Gartens" ("outside the garden").

Note that the concept of an indirect object may be rendered by a prepositional phrase. In this case, the noun's or pronoun's case is determined by the preposition, NOT by its function in the sentence. Consider this sentence:
Here, the subject, "Ich", is in the nominative case, the direct object, "das Buch", is in the accusative case, and "zum Verleger" is in the dative case, since "zu" always requires the dative ("zum" is a contraction of "zu" + "dem"). However:
In this sentence, "Freund" is the indirect object, but, because it follows "an" (direction), the accusative is required, not the dative.

All of the articles change in the dative case.
Some German verbs require the dative for their direct objects. Common examples are "antworten" (to answer), "danken" (to thank), "gefallen" (to please), "folgen" (to follow), "glauben" (to believe), "helfen" (to help), and "raten" (to advise). In each case, the direct object of the verb is rendered in the dative. For example:

These verbs cannot be used in normal passive constructions, because German allows these only for verbs with accusative objects. It is therefore ungrammatical to say: *"Ich werde geholfen." "I am helped." Instead a special construction called "impersonal passive" must be used: "Mir wird geholfen", literally: "To me is helped." A colloquial (non-standard) and rarely used way to form the passive voice for dative verbs is the following: "Ich kriege geholfen", or: "Ich bekomme geholfen", literally: "I get helped". The use of the verb "to get" here reminds us that the dative case has something to do with giving and receiving. In German, help is not something you "perform on" somebody, but rather something you "offer" them.

The dative case is also used with reflexive ("sich") verbs when specifying what part of the self the verb is being done to:
Cf. the respective "accord" in French: "Les enfants se sont lavés" ("the children have washed themselves") vs. "Les enfants se sont lavé" [uninflected] "les mains" ("... their hands").

German can use two datives to make sentences like: "Sei mir meinem Sohn(e) gnädig!" "For my sake, have mercy on my son!" Literally: "Be for me to my son merciful." The first dative "mir" ("for me") expresses the speaker's commiseration (much like the "dativus ethicus" in Latin, see below). The second dative "meinem Sohn(e)" ("to my son") names the actual object of the plea. Mercy is to be given "to" the son "for" or "on behalf of" his mother/father.

Adjective endings also change in the dative case. There are three inflection possibilities depending on what precedes the adjective. They most commonly use "weak inflection" when preceded by a definite article (the), "mixed inflection" after an indefinite article (a/an), and "strong inflection" when a quantity is indicated (many green apples).

There are several uses for the dative case ("Dativus"):

In addition to its main function as the "dativus", the dative case has other functions in Classical Greek: (The chart below uses the Latin names for the types of dative; the Greek name for the dative is δωτική πτώση, like its Latin equivalent, derived from the verb "to give"; in Ancient Greek, δίδωμι.)

The articles in the Greek dative are
Nouns as well as adjectives receive suffixes. These vary according to the declension.

The dative case, strictly speaking, no longer exists in Modern Greek, except in fossilized expressions like δόξα τω Θεώ (from the ecclesiastical τῷ Θεῷ δόξα, "Glory to God") or εν τάξει (ἑν τάξει, lit. "in order", i.e. "all right" or "OK"). Otherwise, most of the functions of the dative have been subsumed in the accusative.

In Russian, the dative case is used for indicating the indirect object of an action (that to which something is given, thrown, read, etc.). In the instance where a person is the goal of motion, dative is used instead of accusative to indicate motion toward. This is usually achieved with the preposition "κ" + destination in dative case; "К врачу", meaning "to the doctor."

Dative is also the necessary case taken by certain prepositions when expressing certain ideas. For instance, when the preposition "по" is used to mean "along," its object is always in dative case, as in "По бокам", meaning "along the sides."

Other Slavic languages apply the dative case (and the other cases) more or less the same way as does Russian; some languages may use the dative in other ways. The following examples are from Polish:


Some other kinds of dative use as found in the Serbo-Croatian language are: "Dativus finalis" (Titaniku u pomoć "to Titanic's rescue"), "Dativus commodi/incommodi" (Operi svojoj majci suđe "Wash the dishes for your mother"), "Dativus possessivus" (Ovcama je dlaka gusta "Sheep's hair is thick"), "Dativus ethicus" (Šta mi radi Boni? "What is Boni doing? (I am especially interested in what it is)") and Dativus auctoris (Izgleda mi okej "It seems okay to me").

Unusual in other Indo-European branches but common among Slavic languages, endings of nouns and adjectives are different based on grammatical function. Other factors are gender and number. In some cases, the ending may not be obvious, even when those three factors (function, gender, number) are considered. For example, in Polish, 'syn' ("son") and 'ojciec' ("father") are both masculine singular nouns, yet appear as "syn → synowi and "ojciec → ojcu in the dative.

Both Lithuanian and Latvian have a distinct dative case in the system of nominal declensions.

Lithuanian nouns preserve Indo-European inflections in the dative case fairly well: (o-stems) vaikas -> sg. vaikui, pl. vaikams; (ā-stems) ranka -> sg. rankai, pl. rankoms; (i-stems) viltis -> sg. vilčiai, pl. viltims; (u-stems) sūnus -> sg. sūnui, pl. sūnums; (consonant stems) vanduo -> sg. vandeniui, pl. vandenims.

Adjectives in the dative case receive pronominal endings (this might be the result of a more recent development): tas geras vaikas -> sg. tam geram vaikui, pl. tiems geriems vaikams.

The dative case in Latvian underwent further simplifications - the original masculine endings of "both" nouns and adjectives have been replaced with pronominal inflections: tas vīrs -> sg. tam vīram, pl. vīriem. Also, the final "s" in all Dative forms has been dropped. The only exception is personal pronouns in the plural: mums (to us), jums (to you). Note that in colloquial Lithuanian the final "s" in the dative is often omitted, as well: time geriem vaikam.

In both Latvian and Lithuanian, the main function of the dative case is to render the indirect object in a sentence: (lt) aš duodu vyrui knygą; (lv) es dodu [duodu] vīram grāmatu - "I am giving a book to the man".

The dative case can also be used with gerundives to indicate an action preceding or simultaneous with the main action in a sentence: (lt) jam įėjus, visi atsistojo - "when he walked in, everybody stood up", lit. "to him having walked in, all stood up"; (lt) jai miegant, visi dirbo - "while she slept, everybody was working", lit. "to her sleeping, all were working".

In modern standard Lithuanian, Dative case is not required by prepositions, although in many dialects it is done frequently: (dial.) iki (+D) šiai dienai, (stand.) iki (+G) šios dienos - "up until this day".

In Latvian, the dative case is taken by several prepositions in the singular and all prepositions in the plural (due to peculiar historical changes): sg. bez (+G) tevis "(without thee)" ~ pl. bez (+D) jums "(without you)"; sg. pa (+A) ceļu "(along the road)" ~ pl. pa (+D) ceļiem "(along the roads)".

In modern Eastern Armenian, the dative is attained by adding any article to the genitive:

"dog" = շուն

GEN > շան "(of the dog; dog's)" with no articles

DAT > շանը or շանն "(to the dog)" with definite articles (-ն if preceding a vowel)

DAT > մի շան "(to a dog)" with indefinite article

DAT > շանս "(to my dog)" with 1st person possessive article

DAT > շանդ "(to your dog)" with 2nd person possessive article

There is a general tendency to view -ին as the standard dative suffix, but only because that is its most productive (and therefore common) form. The suffix -ին as a dative marker is nothing but the standard, most common, genitive suffix -ի accompanied by the definite article -ն. But the dative case encompasses indefinite objects as well, which will not be marked by -ին:

Definite DAT > Ես գիրքը տվեցի տղային: "(I gave the book to the boy)"

Indefinite DAT> Ես գիրքը տվեցի մի տղայի: "(I gave the book to a boy)"

The main function of the dative marking in Armenian is to indicate the receiving end of an action, more commonly the indirect object which in English is preceded by the preposition "to". In the use of "giving" verbs like "give, donate, offer, deliver, sell, bring..." the dative marks the recipient. With communicative verbs like "tell, say, advise, explain, ask, answer..." the dative marks the listener. Other verbs whose indirect objects are marked by the dative case in Armenian are "show, reach, look, approach..."

Eastern Armenian also uses the dative case to mark the time of an event, in the same way English uses the preposition "at", as in "Meet me at nine o' clock."

The dative case is known as the "fourth case" (chaturthi-vibhakti) in the usual procedure in the declension of nouns. Its use is mainly for the indirect object as Sanskrit has seven other cases including an instrumental. The term "dative" is grammatically similar to the Sanskrit word "datta". "Datta" means "gift" or "the act of giving".

As with many other languages, the dative case is used in Hungarian to show the indirect object of a verb. For example, "Dánielnek adtam ezt a könyvet" (I gave this book to Dániel).

It has two suffixes, "-nak" and "-nek"; the correct one is selected by vowel harmony. The personal dative pronouns follow the "-nek" version: "nekem", "neked", etc.

This case is also used to express "for" in certain circumstances, such as "I bought a gift for Mother".

In possessive constructions the nak/nek endings are also used but this is NOT the dative form (rather, the attributive or possessive case)

Finnish does not have a separate dative case. However, the allative case can fulfill essentially the same role as dative, beyond its primary meaning of directional movement (that is, going somewhere or approaching someone). For example: "He lahjoittivat kaikki rahansa köyhille (They donated all their money to the poor.)

In the Northeast Caucasian languages, such as Tsez, the dative also takes the functions of the lative case in marking the direction of an action. By some linguists, they are still regarded as two separate cases in those languages, although the suffixes are exactly the same for both cases. Other linguists list them separately only for the purpose of separating syntactic cases from locative cases. An example with the ditransitive verb "show" (literally: "make see") is given below:

The dative/lative is also used to indicate possession, as in the example below, because there is no such verb as "to have".
As in the examples above, the dative/lative case usually occurs in combination with another suffix as poss-lative case; this should not be regarded as a separate case, however, as many of the locative cases in Tsez are constructed analytically; hence, they are, in fact, a combination of two case suffixes. See Tsez language#Locative case suffixes for further details.

Verbs of perception or emotion (like "see", "know", "love", "want") also require the logical subject to stand in the dative/lative case. Note that in this example the "pure" dative/lative without its POSS-suffix is used.




</doc>
<doc id="8407" url="https://en.wikipedia.org/wiki?curid=8407" title="Dodecahedron">
Dodecahedron

In geometry, a dodecahedron (Greek , from "dōdeka" "twelve" + "hédra" "base", "seat" or "face") is any polyhedron with twelve flat faces. The most familiar dodecahedron is the regular dodecahedron, which is a Platonic solid. There are also three regular star dodecahedra, which are constructed as stellations of the convex form. All of these have icosahedral symmetry, order 120.

The pyritohedron, a common crystal form in pyrite, is an irregular pentagonal dodecahedron, having the same topology as the regular one but pyritohedral symmetry while the tetartoid has tetrahedral symmetry. The rhombic dodecahedron, seen as a limiting case of the pyritohedron, has octahedral symmetry. The elongated dodecahedron and trapezo-rhombic dodecahedron variations, along with the rhombic dodecahedra, are space-filling. There are a large number of other dodecahedra.

The convex regular dodecahedron is one of the five regular Platonic solids and can be represented by its Schläfli symbol {5, 3}.

The dual polyhedron is the regular icosahedron {3, 5}, having five equilateral triangles around each vertex.

In crystallography, two important dodecahedra can occur as crystal forms in some symmetry classes of the cubic crystal system that are topologically equivalent to the regular dodecahedron but less symmetrical: the pyritohedron with pyritohedral symmetry, and the tetartoid with tetrahedral symmetry:

A pyritohedron is a dodecahedron with pyritohedral (T) symmetry. Like the regular dodecahedron, it has twelve identical pentagonal faces, with three meeting in each of the 20 vertices. However, the pentagons are not constrained to be regular, and the underlying atomic arrangement has no true fivefold symmetry axes. Its 30 edges are divided into two sets – containing 24 and 6 edges of the same length. The only axes of rotational symmetry are three mutually perpendicular twofold axes and four threefold axes.

Although regular dodecahedra do not exist in crystals, the pyritohedron form occurs in the crystals of the mineral pyrite, and it may be an inspiration for the discovery of the regular Platonic solid form. Note that the true regular dodecahedron can occur as a shape for quasicrystals with icosahedral symmetry, which includes true fivefold rotation axes.
Its name comes from one of the two common crystal habits shown by pyrite, the other one being the cube.

The coordinates of the eight vertices of the original cube are:

The coordinates of the 12 vertices of the cross-edges are:

where "h" is the height of the wedge-shaped "roof" above the faces of the cube. When "h" = 1, the six cross-edges degenerate to points and a rhombic dodecahedron is formed. When "h" = 0, the cross-edges are absorbed in the facets of the cube, and the pyritohedron reduces to a cube. When "h" = , the inverse of the golden ratio, the result is a regular dodecahedron.

A reflected pyritohedron is made by swapping the nonzero coordinates above. The two pyritohedra can be superimposed to give the compound of two dodecahedra as seen in the image here.

The pyritohedron has a geometric degree of freedom with limiting cases of a cubic convex hull at one limit of colinear edges, and a rhombic dodecahedron as the other limit as 6 edges are degenerated to length zero. The regular dodecahedron represents a special intermediate case where all edges and angles are equal.

A tetartoid (also tetragonal pentagonal dodecahedron, pentagon-tritetrahedron, and tetrahedric pentagon dodecahedron) is a dodecahedron with chiral tetrahedral symmetry (T). Like the regular dodecahedron, it has twelve identical pentagonal faces, with three meeting in each of the 20 vertices. However, the pentagons are not regular and the figure has no fivefold symmetry axes.

Although regular dodecahedra do not exist in crystals, the tetartoid form does. The name tetartoid comes from the Greek root for one-fourth because it has one fourth of full octahedral symmetry, and half of pyritohedral symmetry. The mineral cobaltite can have this symmetry form.
Its topology can be as a cube with square faces bisected into 2 rectangles like the pyritohedron, and then the bisection lines are slanted retaining 3-fold rotation at the 8 corners.

The following points are vertices of a tetartoid pentagon under tetrahedral symmetry:
under the following conditions:

It can be seen as a tetrahedron, with edges divided into 3 segments, along with a center point of each triangular face. In Conway polyhedron notation it can be seen as gT, a gyro tetrahedron.

A lower symmetry form of the regular dodecahedron can be constructed as the dual of a polyhedra constructed from two triangular anticupola connected base-to-base, called a "triangular gyrobianticupola." It has D symmetry, order 12. It has 2 sets of 3 identical pentagons on the top and bottom, connected 6 pentagons around the sides which alternate upwards and downwards. This form has a hexagonal cross-section and identical copies can be connected as a partial hexagonal honeycomb, but all vertices will not match.

The "rhombic dodecahedron" is a zonohedron with twelve rhombic faces and octahedral symmetry. It is dual to the quasiregular cuboctahedron (an Archimedean solid) and occurs in nature as a crystal form. The rhombic dodecahedron packs together to fill space.

The "rhombic dodecahedron" can be seen as a degenerate pyritohedron where the 6 special edges have been reduced to zero length, reducing the pentagons into rhombic faces.

The rhombic dodecahedron has several stellations, the first of which is also a parallelohedral spacefiller.

Another important rhombic dodecahedron, the Bilinski dodecahedron, has twelve faces congruent to those of the rhombic triacontahedron, i.e. the diagonals are in the ratio of the golden ratio. It is also a zonohedron and was described by Bilinski in 1960. This figure is another spacefiller, and can also occur in non-periodic spacefillings along with the rhombic triacontahedron, the rhombic icosahedron and rhombic hexahedra.

There are 6,384,634 topologically distinct "convex" dodecahedra, excluding mirror images—the number of vertices ranges from 8 to 20. (Two polyhedra are "topologically distinct" if they have intrinsically different arrangements of faces and vertices, such that it is impossible to distort one into the other simply by changing the lengths of edges or the angles between edges or faces.)

Topologically distinct dodecahedra (excluding pentagonal and rhombic forms)




</doc>
<doc id="8408" url="https://en.wikipedia.org/wiki?curid=8408" title="Darwin, Northern Territory">
Darwin, Northern Territory

Darwin ( )
is the capital city of the Northern Territory of Australia. Situated on the Timor Sea, Darwin is the largest city in the sparsely populated Northern Territory, with a population of 145,916. It is the smallest and most northerly of the Australian capital cities, and acts as the Top End's regional centre.

Darwin's proximity to South East Asia makes it a link between Australia and countries such as Indonesia and East Timor. The Stuart Highway begins in Darwin, ending at Port Augusta in South Australia. The city itself is built on a low bluff overlooking the harbour. Its suburbs spread out over some area, beginning at Lee Point in the north and stretching to Berrimah in the east. Past Berrimah, the Stuart Highway goes on to Darwin's satellite city, Palmerston, and its suburbs. The Darwin region, like the rest of the Top End, has a tropical climate, with a wet and a dry season. Prone to cyclone activity during the wet season, Darwin experiences heavy monsoonal downpours and spectacular lightning shows. During the dry season, the city is met with clear skies and mild sea breezes from the harbour.

The greater Darwin area is the ancestral home of the Larrakia people. On 9 September 1839, sailed into Darwin harbour during its surveying of the area. John Clements Wickham named the region "Port Darwin" in honour of their former shipmate Charles Darwin, who had sailed with them on the ship's previous voyage which had ended in October 1836. The settlement there became the town of Palmerston in 1869, and was renamed Darwin in 1911. The city has been almost entirely rebuilt four times, following devastation caused by the 1897 cyclone, the 1937 cyclone, Japanese air raids during World War II, and Cyclone Tracy in 1974.

The Aboriginal people of the Larrakia language group are the traditional custodians and the first inhabitants of the greater Darwin area. They had trading routes with Southeast Asia (see Macassan contact with Australia), and imported goods from as far afield as South and Western Australia. Established songlines penetrated throughout the country, allowing stories and histories to be told and retold along the routes. The extent of shared songlines and history of multiple clan groups within this area is still contestable.

The Dutch visited Australia's northern coastline in the 1600s and landed on the Tiwi Islands only to be repelled by the Tiwi peoples. The Dutch created the first European maps of the area. This accounts for the Dutch names in the area, such as Arnhem Land and Groote Eylandt. The first British person to see Darwin harbour appears to have been Lieutenant John Lort Stokes of on 9 September 1839. The ship's captain, Commander John Clements Wickham, named the port after Charles Darwin, the British naturalist who had sailed with them both on the earlier second expedition of the "Beagle".

In 1863, the Northern Territory was transferred from New South Wales to South Australia. In 1864 South Australia sent B. T. Finniss north as Government Resident to survey and found a capital for its new territory. Finniss chose a site at Escape Cliffs, near the entrance to Adelaide River, about 60 km northeast of the modern city. This attempt was short-lived, however, and the settlement abandoned by 1865. On 5 February 1869, George Goyder, the Surveyor-General of South Australia, established a small settlement of 135 people at Port Darwin between Fort Hill and the escarpment. Goyder named the settlement Palmerston, after the British Prime Minister Lord Palmerston. In 1870, the first poles for the Overland Telegraph were erected in Darwin, connecting Australia to the rest of the world. The discovery of gold by employees of the Australian Overland Telegraph Line digging holes for telegraph poles at Pine Creek in the 1880s spawned a gold rush which further boosted the young colony's development.

In February 1872 the brigatine "Alexandra" was the first private vessel to set sail from an English port directly to Darwin, carrying people many of whom were coming to recent gold finds.

In early 1875 Darwin's white population had grown to approximately 300 because of the gold rush. On 17 February 1875 the left Darwin "en route" for Adelaide. The approximately 88 passengers and 34 crew (surviving records vary) included government officials, circuit-court judges, Darwin residents taking their first furlough, and miners. While travelling south along the north Queensland coast, the "Gothenburg" encountered a cyclone-strength storm and was wrecked on a section of the Great Barrier Reef. Only 22 men survived, while between 98 and 112 people perished. Many passengers who perished were Darwin residents and news of the tragedy severely affected the small community, which reportedly took several years to recover.

In the 1870s, relatively large numbers of Chinese settled at least temporarily in the Northern Territory; many were contracted to work the goldfields and later to build the Palmerston to Pine Creek railway. By 1888 there were 6122 Chinese in the Northern Territory, mostly in or around Darwin. The early Chinese settlers were mainly from the Kwantung Province in south China. However at the end of the nineteenth century anti-Chinese feelings grew in response to the 1890s economic depression and the White Australia policy meant many Chinese left the Territory. However, some families stayed and became Australian citizens, and established a commercial base in Darwin.

Darwin became the city's official name in 1911.

The period between 1911 and 1919 was filled with political turmoil, particularly with trade union unrest, which culminated on 17 December 1918. Led by Harold Nelson, some 1000 demonstrators marched to Government House at Liberty Square in Darwin where they burnt an effigy of the Administrator of the Northern Territory John Gilruth and demanded his resignation. The incident became known as the 'Darwin Rebellion'. Their grievances were against the two main Northern Territory employers: Vestey's Meatworks and the federal government. Both Gilruth and the Vestey company left Darwin soon afterwards.

Around 10,000 Australian and other Allied troops arrived in Darwin at the outset of World War II, in order to defend Australia's northern coastline. On 19 February 1942 at 0957, 188 Japanese warplanes attacked Darwin in two waves. It was the same fleet that had bombed Pearl Harbor, though a considerably larger number of bombs were dropped on Darwin than on Pearl Harbor. The attack killed at least 243 people and caused immense damage to the town, airfields and aircraft. These were by far the most serious attacks on Australia in time of war, in terms of fatalities and damage. They were the first of many raids on Darwin.
Darwin was further developed after the war, with sealed roads constructed connecting the region to Alice Springs to the south and Mount Isa to the south-east, and Manton Dam built in the south to provide the city with water. On Australia Day (26 January) 1959, Darwin was granted city status.

On 25 December 1974, Darwin was struck by Cyclone Tracy, which killed 71 people and destroyed over 70% of the city's buildings, including many old stone buildings such as the Palmerston Town Hall, which could not withstand the lateral forces generated by the strong winds. After the disaster, 30,000 people of the population of 46,000 were evacuated, in what turned out to be the biggest airlift in Australia's history. The town was subsequently rebuilt with newer materials and techniques during the late 1970s by the Darwin Reconstruction Commission, led by former Brisbane Lord Mayor Clem Jones. A satellite city of Palmerston was built east of Darwin in the early 1980s.

On 17 September 2003 the Adelaide–Darwin railway was completed, with the opening of the Alice Springs-Darwin standard gauge line.

Darwin lies in the Northern Territory, on the Timor Sea. The city proper occupies a low bluff overlooking Darwin Harbour, flanked by Frances Bay to the east and Cullen Bay to the west. The remainder of the city is flat and low-lying, and coastal areas are home to recreational reserves, extensive beaches, and excellent fishing.

Darwin is closer to the capitals of five other countries than to the capital of Australia: Darwin is away from Canberra. Dili (East Timor) is , Port Moresby (Papua New Guinea) is , Jakarta (Indonesia) is , Bandar Seri Begawan (Brunei) is , and Ngerulmud (Palau) is from Darwin.

Even Malaysia and Singapore are only slightly farther away at , as is Manila (Philippines) at , and Honiara (Solomon Islands) at . Ambon, Indonesia, is only away from Darwin.

Along with its importance as a gateway to Asia, Darwin also acts as an access point for the Kakadu National Park, Arnhem Land, and northerly islands such as Groote Eylandt and the Tiwi Islands. As the largest city in the area, it provides services for these remote settlements.

Darwin and its suburbs spread in an approximately triangular shape, with the older south-western suburbs—and the city itself—forming one corner, the newer northern suburbs another, and the eastern suburbs, progressing towards Palmerston, forming the third.

The older part of Darwin is separated from the newer northern suburbs by Darwin International Airport and RAAF Base Darwin. Palmerston is a satellite city east of Darwin that was established in the 1980s and is one of the fastest growing municipalities in Australia. The rural areas of Darwin including Howard Springs, Humpty Doo and Berry Springs are experiencing strong growth.

Darwin's central business district is bounded by Daly Street in the north-west, McMinn Street in the north-east, Mitchell Street on the south-west and Bennett Street on the south-east. The CBD has been the focus of a number of major projects, including the billion dollar redevelopment of the Stokes Hill wharf waterfront area including a convention centre with seating for 1500 people and approximately of exhibition space. The development will also include hotels, residential apartments and public space. The city's main industrial areas are along the Stuart Highway going towards Palmerston, centred on Winnellie. The largest shopping precinct in the area is Casuarina Square.

The most expensive residential areas stand along the coast in suburbs such as Larrakeyah and Brinkin, despite the slight risk these low-lying regions face during cyclones and higher tides. The inner northern suburbs of Millner and Coconut Grove and the eastern suburb of Karama are home to lower-income households, although low-income Territory Housing units are scattered throughout the metropolitan area. The suburb of Lyon was an addition to the Northern Suburbs. Development and construction took place in 2009 and 2010 and became home for a number of affluent Darwin residents and local/recently posted military families above the rank of Sergeant or Flying Officer.

Darwin has a tropical savanna climate (Köppen "Aw") with distinct wet and dry seasons and the average maximum temperature is remarkably similar all year round. The dry season runs from about May to September, during which nearly every day is sunny, and afternoon relative humidity averages around 30%.

The driest period of the year, seeing only approximately of monthly rainfall on average, is between May and September. In the coolest months of June and July, the daily minimum temperature may dip as low as , but very rarely lower, and a temperature lower than has never been recorded in the city centre. Outer suburbs away from the coast, however, can occasionally record temperatures as low as in the dry season. For an exceedingly lengthy 147‑day period during the 2012 dry season, from 5 May to 29 September, Darwin recorded no precipitation whatsoever. Prolonged periods of no precipitation are common in the dry season in Northern Australia (particularly in the Northern Territory and northern regions of Western Australia) although a no-rainfall event of this extent is rare. The 3pm dewpoint average in the wet season is at around .

Extreme temperatures at the Darwin Post Office Station have ranged from on 17 October 1892 to on 25 June 1891; while extreme temperatures at the Darwin Airport station (which is further from the coast and routinely records cooler temperatures than the post office station which is located in Darwin's CBD) have ranged from on 18 October 1982 to on 29 July 1942. The highest minimum temperature on record is on 18 January 1928 for the post office station and on both 25 November 1987 and 17 December 2014 for the airport station; while the lowest maximum temperature on record is on 3 June 1904 for the post office station and on 14 July 1968 for the airport station.

The wet season is associated with tropical cyclones and monsoon rains. The majority of rainfall occurs between December and March (the southern hemisphere summer), when thunderstorms are common and afternoon relative humidity averages over 70 percent during the wettest months. It does not rain every day during the wet season, but most days have plentiful cloud cover; January averages under 6 hours of bright sunshine daily. Darwin's highest Bureau of Meteorology verified daily rainfall total is , which fell when Cyclone Carlos bore down on the Darwin area on 16 February 2011. February 2011 was also Darwin's wettest month ever recorded, with recorded for the month at the airport.

The hottest month is November, just before the onset of the main rain season. The heat index sometimes rises above , while the actual temperature is usually below , because of humidity levels that most would find uncomfortable. Because of its long dry season, Darwin has the second most daily average sunshine hours (8.4) of any Australian capital with the most sunshine from April to November; only Perth, Western Australia averages more (8.8). The sun passes directly overhead in mid October and mid February.

The average temperature of the sea ranges from in July to in December.

Darwin occupies one of the most lightning-prone areas in Australia. On 31 January 2002 an early-morning squall line produced over 5,000 cloud-to-ground lightning strikes within a radius of Darwin alone – about three times the amount of lightning that Perth, Western Australia, experiences on average in an entire year.

In 2006, the largest ancestry groups in Darwin were Australian (42,221 or 36.9%), English (29,766 or 26%), Indigenous Australians (10,259 or 9.7%), Irish (9,561 or 8.3%), Scottish (7,815 or 6.8%), Chinese (3,502 or 3%), Greek (2,828 or 2.4%), and Italian (2,367 or 2%).

Darwin's population is notable for the highest proportional population of Indigenous Australians of any Australian capital city. In the 2006 census, 10,259 (9.7 per cent) of Darwin's population was Aboriginal.

Darwin's population changed after the Second World War. Darwin, like many other Australian cities, experienced influxes from Europe, with significant numbers of Italians and Greeks during the 1960s and 1970s. Darwin also started to experience an influx from other European countries, which included the Dutch, Germans, and many others. A significant percentage of Darwin's residents are recent immigrants from South East Asia (Asian Australians were 9.3% of Darwin's population in 2001).

Darwin's population comprises people from many ethnic backgrounds. The 2006 Census revealed that the most common places of birth for overseas migrants were the United Kingdom (3.4 per cent), New Zealand (2.1 per cent), the Philippines (1.4 per cent) and East Timor (0.9 per cent). 18.3 percent of the city's population was born overseas, which is less than the Australian average of 22%.

Darwin has a youthful population with an average age of 33 years (compared to the national average of around 37 years) assisted to a large extent by the military presence and the fact that many people opt to retire elsewhere.

The most common languages spoken in Darwin after English are Greek, Australian Aboriginal languages, Italian, Indonesian, Vietnamese and Cantonese.

Christianity has the most adherents in Darwin, with 56,613 followers accounting for 49.5 per cent of the population of the city. The largest denominations of Christianity are Roman Catholicism (24,538 or 21.5 per cent), Anglicanism (14,028 or 12.3 per cent) and Greek Orthodoxy (2,964 or 2.6 per cent). Buddhists, Muslims, Hindus and Jews account for 3.2 per cent of Darwin's population. There were 26,695 or 23.3 per cent of people professing no religion.

Darwin is one of the fastest growing capital cities in Australia, with an annual growth rate of 2.6 per cent since the 2006 census. In recent years, the Palmerston and Litchfield parts of the Darwin statistical division have recorded the highest growth in population of any Northern Territory local government area and by 2016 Litchfield could overtake Palmerston as the second largest municipality in metropolitan Darwin. It is predicted by 2021 that the combined population of both Palmerston and Litchfield would be 101,546 people.

The Darwin City Council (Incorporated under the Northern Territory Local Government Act 1993) governs the City of Darwin which takes in the CBD and the suburbs. The Darwin City Council has governed the City of Darwin since 1957. The Darwin City Council consists of 13 elected members, the Lord Mayor and 12 aldermen.

The City of Darwin electorate is organised into four electoral units or wards. The names of the wards are Chan, Lyons, Richardson, and Waters. The constituents of each ward are directly responsible for electing three aldermen. Constituents of all wards are directly responsible for electing the Lord Mayor of Darwin. The mayor is Kon Vatskalis after council elections in August 2017.

The rest of the Darwin area is divided into 2 local government areas—the Palmerston City Council and the Shire of Coomalie. These areas have elected councils which are responsible for functions delegated to them by the Northern Territory Government, such as planning and garbage collection.

The Legislative Assembly of the Northern Territory convenes in Darwin in the Northern Territory Parliament House. Government House, the official residence of the Administrator of the Northern Territory, is located on The Esplanade.

Also located on the Esplanade is the Supreme Court of the Northern Territory. Darwin has a Magistrate's Court also which is located on the corner of Cavenagh and Bennett Streets quite close to the Darwin City Council Chambers.
Darwin's police force are members of the Northern Territory Police Force. Darwin's Mitchell Street, with its numerous pubs, clubs and other entertainment venues, is policed by the CitySafe Unit. The CitySafe unit was recently credited with reducing violent crime in and around Darwin City. Darwin has a long record of alcohol abuse and violent crime with 6,000 assaults in 2009, of which 350 resulted in broken jaws and noses – more than anywhere else in the world, according to the Royal Darwin Hospital.

Darwin is split between nine electoral divisions in the Legislative Assembly—Port Darwin, Fannie Bay, Fong Lim, Nightcliff, Sanderson, Johnston, Casuarina, Wanguri, and Karama. Historically, Darwin was a stronghold for the Country Liberal Party. However, since the turn of the century, Labor has been much more competitive, particularly in the more diverse northern section.

The two largest economic sectors are mining and tourism. Given its location, Darwin serves as a "gateway" for Australian travellers to Asia.

Mining and energy industry production exceeds $2.5 billion per annum. The most important mineral resources are gold, zinc and bauxite, along with manganese and many others. The energy production is mostly off shore with oil and natural gas from the Timor Sea, although there are significant uranium deposits near Darwin. Tourism employs 8% of Darwin residents, and is expected to grow as domestic and international tourists are now spending time in Darwin during the Wet and Dry seasons. Federal spending is a major contributor to the local economy as well.

The military presence that is maintained both within Darwin, and the wider Northern Territory, is a substantial source of employment.
Darwin's importance as a port is expected to grow, due to the increased exploitation of petroleum in the nearby Timor Sea, and to the completion of the railway link and continued expansion in trade with Asia.
During 2005, a number of major construction projects started in Darwin. One is the redevelopment of the Wharf Precinct, which includes a large convention and exhibition centre, apartment housing including Outrigger Pandanas and Evolution on Gardiner, retail and entertainment outlets including a large wave pool and safe swimming lagoon. The Chinatown project has also started with plans to construct Chinese-themed retail and dining outlets.

Education is overseen territory-wide by the Department of Education and Training (DET), whose role is to continually improve education outcomes for all students, with a focus on Indigenous students.

Darwin is served by a number of public and private schools that cater to local and overseas students. Over 16,500 primary and secondary students are enrolled in schools in Darwin, with 10,524 students attending primary education, and 5,932 students attending secondary education. There are over 12,089 students enrolled in government schools and 2,124 students enrolled in independent schools.
There were 9,764 students attending schools in the City of Darwin area. 6,045 students attended primary schools and 3,719 students attended secondary schools. There are over 7,161 students enrolled in government schools and 1,108 students enrolled in independent schools. There are over 35 primary and pre – schools, and 12 secondary schools including both government and non-government. Most schools in the city are secular, but there are a small number of Christian, Catholic and Lutheran institutions. Students intending to complete their secondary education can work towards either the Northern Territory Certificate of Education or the International Baccalaureate (only offered at Kormilda College). Schools have been restructured into Primary, Middle and High schools since the beginning of 2007.

Darwin's largest University is the Charles Darwin University, which is the central provider of tertiary education in the Northern Territory. It covers both vocational and academic courses, acting as both a university and an Institute of TAFE. There are over 5,500 students enrolled in tertiary and further education courses.

On 1 July, Territorians celebrate Territory Day. This is the only day of the year, apart from the Chinese New Year and New Year's Eve, when fireworks are permitted. In Darwin, the main celebrations occur at Mindil Beach, where a large firework display is commissioned by the government.

Weekly markets include Mindil Beach Sunset Markets (Thursdays and Sundays during the dry season), Parap Market, Nightcliff Market and Rapid Creek market. Mindil Beach Sunset Markets are very popular with locals and tourists alike and feature food, souvenirs, clothes and local performing artists.

The Darwin Festival held annually, includes comedy, dance, theatre, music, film and visual art and the NT Indigenous Music Awards. Other festivals include the Glenti, which showcases Darwin's large Greek community, and India@Mindil, a similar festival held by the smaller Indian community. The Chinese New Year is also celebrated with great festivity, highlighting the Asian influence in Darwin.

The Seabreeze festival, which first started in 2005, is held on the second week of May in the suburb of Nightcliff. It offers the opportunity for local talent to be showcased and a popular event is Saturday family festivities along the Nightcliff foreshore which is one of Darwin's most popular fitness tracks.

The Speargrass Festival is held annually the week prior to July's first full moon and celebrates the alternative Top End lifestyle. The festival activities include music, screening of locally produced films, screen printing, basket weaving, sweat lodge, water slides, human pyramid, hot tub, frisbee golf, spear throwing, Kubb competition, bingo, communal organic cooking, morning yoga, meditation, greasy pig and healing circles. The festival occurs at the Speargrass property, northeast of Pine Creek.

The Darwin beer-can regatta, held in August, celebrates Darwin's love affair with beer and contestants' race boats made exclusively of beer cans. Also in Darwin during the month of August, are the Darwin Cup horse race, and the Rodeo and Mud Crab Tying Competition.

The World Solar Challenge race attracts teams from around the world, most of which are fielded by universities or corporations although some are fielded by high schools. The race has a 20-year history spanning nine races, with the inaugural event taking place in 1987.

The Royal Darwin Show is held annually in July at the Winnellie Showgrounds. Exhibitions include agriculture and livestock. Horse events. Entertainment and side shows are also included over the 3 days of the event.

The Darwin Symphony Orchestra was first assembled in 1989, and has performed throughout the Territory. The Darwin Theatre Company is a locally produced professional theatre production company, performing locally and nationally.

The Darwin Entertainment Centre is the city's main concert venue and hosts theatre and orchestral performances. Other theatres include the Darwin Convention Centre, opened in July 2008. The Darwin Convention Centre is part of the $1.1 billion Darwin Waterfront project.

Darwin's only casino opened in 1979 as the "Don Casino" operating out of the Don Hotel on Cavenagh Street. The present site of the hotel and casino on Darwin's Mindil Beach opened in 1983 at which point gambling operations ceased at the Don Hotel and commenced at the newly built facilities. The new hotel and casino was named "Mindil Beach Casino" up until 1985 when the name changed to the "Diamond Beach Hotel Casino". Upon the acquisition by MGM Grand the hotel was re-branded as the MGM Grand Darwin, before it changed to Skycity Darwin after Skycity Entertainment Group purchased the hotel in 2004.

The Northern Territory Museum and Art Gallery (MAGNT) in Darwin gives an overview of the history of the area, including exhibits on Cyclone Tracy and the boats of the Pacific Islands. The MAGNT also organises the annual Telstra National Aboriginal and Torres Strait Islander Art Award, the longest running Indigenous art award in Australia. The MAGNT also manages the Defence of Darwin Experience, a multi-media installation that tells the story of the Japanese air raids on Darwin during World War II.

The Darwin Festival and the Darwin Fringe Festival are annual events. A range of art galleries including specialised Aboriginal art galleries are a feature of Darwin.

Local and visiting musical bands can be heard at venues including the Darwin Entertainment Centre, The Vic Hotel, Happy Yess, and Brown's Mart. A yearly music festival, Bass in the Grass, is very popular with youth from the surrounding area. Artists such as Jessica Mauboy and The Groovesmiths call Darwin home.

There have been no major films set in Darwin; however, some scenes for "Australia" by Baz Luhrmann and "Black Water" were both shot in Darwin in 2007

Mitchell Street in the central business district is lined with nightclubs, takeaways, and restaurants. This is the city's entertainment hub. There are several smaller theatres, three cinema complexes (CBD, Casuarina, and Palmerston), and the Deckchair Cinema. This is an open-air cinema which operates through the dry season, from April to October, and screens independent and arthouse films.

The city has many kilometres of wide, unpolluted beaches, including the Casuarina Beach and renowned Mindil Beach, home of the Mindil Beach markets. Darwin City Council has designated an area of Casuarina Beach as a free beach which offers a designated nudist beach area since 1976.
Swimming in the sea during the months of October–May should be avoided due to the presence of deadly box jellyfish, known locally as Stingers or Sea Wasps.

Saltwater crocodiles are very common in all waterways surrounding Darwin and are even occasionally found swimming in Darwin Harbour and on local beaches. An active trapping program is carried out by the NT Government to limit numbers of crocodiles within the Darwin urban waterway area.

Fishing is one of the recreations of Darwin locals. Visitors from around the world flock to Darwin aiming to catch the prized barramundi, an iconic fish for the region. The Mary River, Daly River, South and East Alligator River are just a few of the water bodies where the barramundi thrive.

Blue-water fishing is also available off the coast of Darwin; Spanish mackerel, Black Jewfish, queenfish, snapper and other varieties are all found in the area and accessible in a day trip from Darwin. Lake Alexander is a man-made swimming lake which is located at East Point Reserve. It is generally considered crocodile and jellyfish safe, however a freak outbreak of non-deadly jellyfish in 2003 caused its closure for a brief period of time. 

The Darwin Surf Lifesaving Club operates long boats and surf skis and provides events and lifesaving accreditations.

Darwin has extensive parks and gardens. These include the George Brown Darwin Botanic Gardens, East Point Reserve, Casuarina Coastal Reserve, Charles Darwin National Park, Knuckey Lagoons Conservation Reserve, Leanyer Recreation Park, the Nightcliff Foreshore, Bicentennial Park and the Jingili Water Gardens.

The Marrara Sports Complex near the airport has stadiums for Aussie Rules (TIO Stadium), cricket, rugby union, basketball (and indoor court sports), soccer, athletics and field hockey. Every two years since 1991 (excluding 2003 due to the SARS outbreak), Darwin has played host to the Arafura Games, a major regional sporting event. In July 2003, the city hosted its first international test cricket match between Australia and Bangladesh, followed by Australia and Sri Lanka in 2004.

Australian-rules football is played all year round. Melbourne's Western Bulldogs Australian Football League side plays one home game at Marrara Oval each year. The ATSIC Aboriginal All-Stars also participate in the AFL pre-season competition. In 2003, a record crowd of 17,500 attended a pre-season game between the All-Stars and Carlton Football Club at Marrara.

Rugby League and Rugby Union club competitions are played in Darwin each year, organised by the NTRL and NTRU respectively. The Heineken Hottest 7s in the World tournament is hosted in Darwin each January, with Rugby Sevens club teams from countries including Australia, New Zealand, Papua New Guinea, Malaysia, and Singapore competing. Darwin's Hottest 7s is the richest Rugby 7s tournament in the Southern Hemisphere.

Darwin hosts a round of the Supercars Championship every year bringing thousands of motorsports fans to the Hidden Valley Raceway. Also located Hidden Valley, adjacent to the road racing circuit, is Darwin's Dirt track racing venue, Northline Speedway. The speedway has hosted a number of Australian Championships over the years for different categories including Sprintcars, Speedcars, and Super Sedans.

The Darwin Cup culminating on the first Monday of August is a very popular horse race event for Darwin and draws large crowds every year to Fannie Bay Racecourse. While it is not as popular as the Melbourne Cup, it does draw a crowd and, in 2003, Sky Racing began televising most of the races. The Darwin Cup day is a public holiday for the Northern Territory (Picnic Day public holiday).

Darwin's major newspapers are the "Northern Territory News" (Monday – Saturday), "The Sunday Territorian" (Sunday), and the national daily, "The Australian" (Monday–Friday) and "The Weekend Australian" (Saturday), all published by News Limited. Free weekly community newspapers include the "Darwin Sun", the "Litchfield Sun", and "Palmerston Sun"; all published by a News Limited subsidiary.

Five free-to-air channels service Darwin. Commercial television channels are provided by Seven Darwin (Seven Network affiliate), Nine Darwin (formerly branded as Channel 8) and Ten Darwin (Network Ten relay), which launched on 28 April 2008. The two Government owned national broadcast services in Darwin are the ABC and SBS. Subscription Television (Pay TV) service Austar is available via cable in the Darwin region.

Darwin has radio stations on both AM and FM frequencies. ABC stations include ABC News Radio (102.5FM), ABC Local Radio (105.7FM), ABC Radio National (657AM), ABC Classic FM (107.3FM) and Triple J (103.3FM). SBS (100.9FM) also broadcasts its national radio network to Darwin.

Darwin has two commercial radio stations Hot 100 and Mix 104.9. Other stations in Darwin include university-based station 104.1 Territory FM, dance music station KIK FM 91.5, Italian-language channel Rete Italia 1611AM, community based stations includes Radio Larrakia 94.5 and Yolngu Radio 1530AM and Rhema FM 97.7.

The Government of the Northern Territory Department of Health and Families oversees one public hospital in the Darwin metropolitan region. The Royal Darwin Hospital, located in Tiwi, is the city's major teaching and referral hospital, and the largest in the Northern Territory.

There is one major private hospital Darwin Private Hospital located at Tiwi, adjacent to the Royal Darwin Hospital.
Darwin Private Hospital is operated and owned by Healthscope Ltd, a private hospital corporation.

The Territory's public transport services are managed by the Department of Lands and Planning, Public Transport Division. Darwin has a bus network serviced by a range of contracted bus operators, which provides transport to the main suburbs of Darwin.

Darwin has no commuter rail system; however, long-distance passenger rail services do operate out of the city. The Alice Springs to Darwin rail line was completed in 2003 linking Darwin to Adelaide. The first service ran in 2004. The Ghan passenger train service from Adelaide via Alice Springs and Katherine runs two to three times per week depending on the season.

Darwin International Airport, located in the suburb of Marrara, is Darwin's only airport, which shares its runways with the Royal Australian Air Force's RAAF Base Darwin.

Darwin can be reached via the Stuart Highway which runs the length of the Northern Territory from Darwin through Katherine, Tennant Creek, Alice Springs and on to Adelaide. Other major roads in Darwin include, Tiger Brennan Drive, Amy Johnson Avenue, Dick Ward Drive, Bagot Road, Trower Road and McMillans Road. Bus service in the greater Darwin area is served by Darwinbus.

Ferries leave from Port Darwin to island locations, mainly for tourists. A ferry service to the Tiwi Islands, the "Arafura Pearl" operates from Cullen Bay.

Darwin has a new deepwater port, East Arm Wharf, which opened in 2000. It has 754-metres of wharfline and is capable of handling Panamax-sized ships of a maximum length of 274 metres and a DWT of up to 80,000 tonnes.

Water storage, supply and Power for Darwin is managed by Power and Water Corporation, which is owned by the Government of the Northern Territory. The corporation is also responsible for management of sewage and the major water catchments in the region. Water is mainly stored in the largest dam, The Darwin River Dam which holds up to 90% of Darwin's water supply. For many years, Darwin's principal water supply came from Manton Dam.

Darwin, its suburbs, Palmerston and Katherine are powered by the Channel Island Power Station, the largest power plant in the Northern Territory.

A new power plant, the Weddell Power Station, is near completion. The first two generators came on line in 2008–09. The third generator is due to be completed in 2011–12. When the power station is fully operational, it will add 30% capacity to Darwin's power supply.

Tourism is one of Darwin's largest industries. Tourism is a major industry and employment sector for the Northern Territory.
In 2005/06, 1.38 million people visited the Northern Territory. They stayed for 9.2 million nights and spent over $1.5 billion.
The tourism industry directly employed 8,391 Territorians in June 2006 and when indirect employment is included, tourism typically accounts for more than 14,000 jobs across the Territory.

Darwin is a hub for tours to Kakadu National Park, Litchfield National Park and Katherine Gorge.
The Territory is traditionally divided into the wet and dry, but there are up to six traditional seasons in Darwin.
It is warm and sunny from May to September. Humidity rises during the green season, from October to April bringing thunderstorms and monsoonal rains which rejuvenates the landscape. Tourism is largely seasonal with most tourists visiting during the cooler dry season which runs from April to September.

Darwin has played host to many of aviation's early pioneers. On 10 December 1919 Captain Ross Smith and his crew landed in Darwin and won a £10,000 Prize from the Australian Government for completing the first flight from London to Australia in under thirty days. Smith and his Crew flew a Vickers Vimy, G-EAOU and landed on an airstrip that has now become Ross Smith Avenue.

Other aviation pioneers include Amy Johnson, Amelia Earhart, Sir Charles Kingsford Smith and Bert Hinkler. The original QANTAS Empire Airways Ltd Hangar, a registered heritage site, was part of the original Darwin Civil Aerodrome in Parap and is now a museum and still bears scars from the bombing of Darwin during World War II.

Darwin was home to Australian and US pilots during the war, with air strips being built in and around Darwin. Today Darwin provides a staging ground for military exercises.

Darwin was a compulsory stop over/check point in the London to Melbourne Centenary Air Race in 1934. The official name of the race was the MacRobertson Air Race. Winners of the great race were Tom Campbell Black and C. W. A. Scott.

The following is an excerpt from "Time" magazine, 29 October 1934, Volume XXIV, Number 18.

The Australian Aviation Heritage Centre is located approximately from the City centre on the Stuart Highway and is one of only two places outside the United States where a B52 bomber (on permanent loan from the United States Air Force) is on public display.

On 16 November 2011, Prime Minister Julia Gillard and President Barack Obama announced that the United States would station troops in Australia for the first time since World War II. The agreement between the United States and Australia would involve a contingent of 250 Marines arriving in Darwin in 2012, with the total number rising to a maximum of 2,500 troops by 2017 on six-month rotations as well as a supporting air element including F-22 Raptors, F-35 Joint Strike Fighters and KC-135 refuelers. China and Indonesia have expressed concern about the decision. Some analysts have argued that an expanded U.S. presence could pose a threat to security.
Gillard announced that the first 200 U.S. Marines had arrived in Darwin from Hawaii on late 3 April 2012. In 2013, further news of other expansion vectors was aired in USA media, with no comment or confirmation from Australian authorities. The agreement between the two governments remains hidden from public scrutiny. Marine numbers based in Darwin have increased to more than 1150 troops by 2014.

Darwin hosts biennial multi-nation exercises named "Pitch Black"; in 2014 this involved military personnel from Australia, New Zealand, Singapore, Thailand, United Arab Emirates, and the United States.




</doc>
<doc id="8409" url="https://en.wikipedia.org/wiki?curid=8409" title="Dictator">
Dictator

A dictator is a political leader who possesses absolute power. A state which is ruled by a dictator is called a dictatorship. The word originated as the title of a magistrate in the Roman Republic appointed by the Senate to rule the republic in times of emergency (see Roman dictator and "justitium").

Like the term "tyrant" (which was originally a respectable Ancient Greek title), and to a lesser degree "autocrat", "dictator" came to be used almost exclusively as a non-titular term for oppressive, even abusive rule, yet it had rare modern titular use.

In modern usage, the term "dictator" is generally used to describe a leader who holds and/or abuses an extraordinary amount of personal power. Dictatorships are often characterised by some of the following traits: suspension of elections and civil liberties; proclamation of a state of emergency; rule by decree; repression of political opponents without abiding by the rule of law procedures; these include one-party state, and cult of personality.

The term "dictator" is comparable to but not synonymous with the ancient concept of a tyrant; initially "tyrant", like "dictator", did not carry negative connotations. A wide variety of leaders coming to power in a number of different kinds of regimes, such as military juntas, one-party states and civilian governments under a personal rule, have been described as dictators. They, in a sense, may hold left or right-wing views, or they may be apolitical.

Originally an emergency legal appointment in the Roman Republic, the term "Dictator" did not have the negative meaning it has now. A Dictator was a magistrate given sole power for a limited duration. At the end of the term, the Dictator's power was returned to normal Consular rule whereupon a dictator provided accountability, though not all dictators accepted a return to power sharing.

The term started to get its modern negative meaning with Cornelius Sulla's ascension to the dictatorship following Sulla's second civil war, making himself the first Dictator in more than a century (during which the office was ostensibly abolished) as well as "de facto" eliminating the time limit and need of senatorial acclamation. He avoided a major constitutional crisis by resigning the office after about one year, dying a few years later. Julius Caesar followed Sulla's example in 49 BC and in February 44 BC was proclaimed "Dictator perpetuo", "Dictator in perpetuity", officially doing away with any limitations on his power, which he kept until his assassination the following month.

Following Julius' assassination, his heir Augustus was offered the title of dictator, but he declined it. Later successors also declined the title of dictator, and usage of the title soon diminished among Roman rulers.

As late as the second half of the 19th century, the term "dictator" had occasional positive implications. For example, when creating a provisional executive in Sicily during the Expedition of the Thousand in 1860, Giuseppe Garibaldi officially assumed the title of "Dictator" (see Dictatorship of Garibaldi). Shortly afterwards, during the 1863 January Uprising in Poland, "Dictator" was also the official title of four leaders, the first being Ludwik Mierosławski. 
Past that time, however, the term "dictator" assumed an invariably negative connotation. In popular usage, a "dictatorship" is often associated with brutality and oppression. As a result, it is often also used as a term of abuse against political opponents. The term has also come to be associated with megalomania. Many dictators create a cult of personality around themselves and they have also come to grant themselves increasingly grandiloquent titles and honours. For instance, Idi Amin Dada, who had been a British army lieutenant prior to Uganda's independence from Britain in October 1962, subsequently styled himself ""His Excellency, President for Life, Field Marshal Al Hadji Doctor Idi Amin Dada, VC, DSO, MC, Conqueror of the British Empire in Africa in General and Uganda in Particular"". In the movie "The Great Dictator" (1940), Charlie Chaplin satirized not only Adolf Hitler but the institution of dictatorship itself.

The association between a dictator and the military is a common one; many dictators take great pains to emphasize their connections with the military and they often wear military uniforms. In some cases, this is perfectly legitimate; Francisco Franco was a lieutenant general in the Spanish Army before he became Chief of State of Spain; Manuel Noriega was officially commander of the Panamanian Defense Forces. In other cases, the association is mere pretense.

Some dictators have been masters at Crowd manipulation, such as Mussolini and Hitler. Others were more prosaic speakers, such as Stalin and Franco. Typically the dictator's people seize control of all media, censor or destroy the opposition, and give strong doses of propaganda daily, often built around a Cult of personality.

Because of its negative associations, modern leaders very rarely (if ever) use the term "dictator" in their formal titles. In the 19th century, however, its official usage was more common:
Russia during the Civil War

Under the Soviet leaders Vladimir Lenin and Joseph Stalin, government policy was enforced by extrajudicial killings, secret police (originally known as the "Cheka") and the notorious Gulag system of concentration camps. Most Gulag inmates were not political prisoners, although significant numbers of political prisoners could be found in the camps at any one time. Data collected from Soviet archives gives the death toll from Gulags at 1,053,829. Other human rights abuses by the Soviet state included human experimentation, the use of psychiatry as a political weapon and the denial of freedoms of religion, assembly, speech and association.

Pol Pot became dictator of Cambodia in 1975. In all, an estimated 1.7 million people (out of a population of 7 million) died due to the policies of his four-year dictatorship. As a result, Pol Pot is sometimes described as "the Hitler of Cambodia" and "a genocidal tyrant".
The International Criminal Court issued an arrest warrant for Sudan's military dictator Omar al-Bashir over alleged war crimes in Darfur.

In social choice theory, the notion of a dictator is formally defined as a person who can achieve any feasible social outcome he/she wishes. The formal definition yields an interesting distinction between two different types of dictators.
Note that these definitions disregard some alleged dictators who are not interested in the actual achieving of social goals, as much as in propaganda and controlling public opinion. Monarchs and military dictators are also excluded from these definitions, because their rule relies on the consent of other political powers (the nobility or the army).






</doc>
<doc id="8410" url="https://en.wikipedia.org/wiki?curid=8410" title="Decibel">
Decibel

The decibel (symbol: dB) is a unit of measurement used to express the ratio of one value of a physical property to another on a logarithmic scale. It can be used to express a change in value (e.g., +1 dB or −1 dB) or an absolute value. In the latter case, it expresses the ratio of a value to a reference value; when used in this way, the decibel symbol should be appended with a suffix that indicates the reference value or some other property. For example, if the reference value is 1 volt, then the suffix is "V" (e.g., "20 dBV"), and if the reference value is one milliwatt, then the suffix is "m" (e.g., "20 dBm").

There are two different scales used when expressing a ratio in decibels depending on the nature of the quantities: field, power, and root-power. When expressing power quantities, the number of decibels is ten times the logarithm to base 10 of the ratio of two power quantities. That is, a change in power by a factor of 10 corresponds to a 10 dB change in level. When expressing field quantities, a change in amplitude by a factor of 10 corresponds to a 20 dB change in level. The extra factor of two is due to the logarithm of the quadratic relationship between power and amplitude. The decibel scales differ so that direct comparisons can be made between related power and field quantities when they are expressed in decibels.

The definition of the decibel is based on the measurement of power in telephony of the early 20th century in the Bell System in the United States. One decibel is one tenth (deci-) of one bel, named in honor of Alexander Graham Bell; however, the bel is seldom used. Today, the decibel is used for a wide variety of measurements in science and engineering, most prominently in acoustics, electronics, and control theory. In electronics, the gains of amplifiers, attenuation of signals, and signal-to-noise ratios are often expressed in decibels.

In the International System of Quantities, the decibel is defined as a unit of measurement for quantities of type level or level difference, which are defined as the logarithm of the ratio of power- or field-type quantities.

The decibel originates from methods used to quantify signal loss in telegraph and telephone circuits. The unit for loss was originally "Miles of Standard Cable" (MSC). 1 MSC corresponded to the loss of power over a 1 mile (approximately 1.6 km) length of standard telephone cable at a frequency of 5000 radians per second (795.8 Hz), and matched closely the smallest attenuation detectable to the average listener. The standard telephone cable implied was "a cable having uniformly distributed resistance of 88 ohms per loop mile and uniformly distributed shunt capacitance of 0.054 microfarad per mile" (approximately 19 gauge).

In 1924, Bell Telephone Laboratories received favorable response to a new unit definition among members of the International Advisory Committee on Long Distance Telephony in Europe and replaced the MSC with the "Transmission Unit" (TU). 1 TU was defined such that the number of TUs was ten times the base-10 logarithm of the ratio of measured power to a reference power.
The definition was conveniently chosen such that 1 TU approximated 1 MSC; specifically, 1 MSC was 1.056 TU. In 1928, the Bell system renamed the TU into the decibel, being one tenth of a newly defined unit for the base-10 logarithm of the power ratio. It was named the "bel", in honor of the telecommunications pioneer Alexander Graham Bell.
The bel is seldom used, as the decibel was the proposed working unit.

The naming and early definition of the decibel is described in the NBS Standard's Yearbook of 1931:

In 1954, C. W. Horton argued that the use of the decibel as a unit for quantities other than transmission loss led to confusion, and suggested the name 'logit' for "standard magnitudes which combine by addition".

In April 2003, the International Committee for Weights and Measures (CIPM) considered a recommendation for the inclusion of the decibel in the International System of Units (SI), but decided against the proposal. However, the decibel is recognized by other international bodies such as the International Electrotechnical Commission (IEC) and International Organization for Standardization (ISO). The IEC permits the use of the decibel with field quantities as well as power and this recommendation is followed by many national standards bodies, such as NIST, which justifies the use of the decibel for voltage ratios. The term "field quantity" is deprecated by ISO 80000-1, which favors root-power. In spite of their widespread use, suffixes (such as in dBA or dBV) are not recognized by the IEC or ISO.

ISO 80000-3 describes definitions for quantities and units of space and time. The decibel for use in acoustics is defined in ISO 80000-8. The major difference from the article below is that for acoustics the decibel has no absolute value.

The ISO Standard 80000-3:2006 defines the following quantities. The decibel (dB) is one-tenth of a bel: . The bel (B) is  ln(10) nepers: . The neper is the change in the level of a field quantity when the field quantity changes by a factor of e, that is , thereby relating all of the units as nondimensional natural log of field-quantity ratios, . Finally, the level of a quantity is the logarithm of the ratio of the value of that quantity to a reference value of the same kind of quantity.

Therefore, the bel represents the logarithm of a ratio between two power quantities of 10:1, or the logarithm of a ratio between two field quantities of :1.

Two signals whose levels differ by one decibel have a power ratio of 10, which is approximately 1.25893, and an amplitude (field quantity) ratio of 10 (1.12202).

The bel is rarely used either without a prefix or with SI unit prefixes other than "deci"; it is preferred, for example, to use "hundredths of a decibel" rather than "millibels". Thus, five one-thousandths of a bel would normally be written '0.05 dB', and not '5 mB'.

The method of expressing a ratio as a level in decibels depends on whether the measured property is a "power quantity" or a "field quantity"; see Field, power, and root-power quantities for details.

When referring to measurements of "power" quantities, a ratio can be expressed as a level in decibels by evaluating ten times the base-10 logarithm of the ratio of the measured quantity to reference value. Thus, the ratio of "P" (measured power) to "P" (reference power) is represented by "L", that ratio expressed in decibels, which is calculated using the formula:

The base-10 logarithm of the ratio of the two power quantities is the number of bels. The number of decibels is ten times the number of bels (equivalently, a decibel is one-tenth of a bel). "P" and "P" must measure the same type of quantity, and have the same units before calculating the ratio. If in the above equation, then "L" = 0. If "P" is greater than "P" then "L" is positive; if "P" is less than "P" then "L" is negative.

Rearranging the above equation gives the following formula for "P" in terms of "P" and "L":

When referring to measurements of field quantities, it is usual to consider the ratio of the squares of "F" (measured field) and "F" (reference field). This is because in most applications power is proportional to the square of field, and it is desirable for the two decibel formulations to give the same result in such typical cases. Thus, the following definition is used:

The formula may be rearranged to give

Similarly, in electrical circuits, dissipated power is typically proportional to the square of voltage or current when the impedance is held constant. Taking voltage as an example, this leads to the equation:
where "V" is the voltage being measured, "V" is a specified reference voltage, and "G" is the power gain expressed in decibels. A similar formula holds for current.

The term "root-power quantity" is introduced by ISO Standard 80000-1:2009 as a substitute of "field quantity". The term "field quantity" is deprecated by that standard.

Since logarithm differences measured in these units are used to represent power ratios and field ratios, the values of the ratios represented by each unit are also included in the table.

All of these examples yield dimensionless answers in dB because they are relative ratios expressed in decibels. The unit dBW is often used to denote a ratio for which the reference is 1 W, and similarly dBm for a reference point.
, illustrating the consequence from the definitions above that "G" has the same value, 30, regardless of whether it is obtained from powers or from amplitudes, provided that in the specific system being considered power ratios are equal to amplitude ratios squared.

A change in power ratio by a factor of 10 corresponds to a change in level of . A change in power ratio by a factor of 2 or is approximately a change of 3 dB. More precisely, the change is ±3.0103 dB, but this is almost universally rounded to "3 dB" in technical writing. This implies an increase in voltage by a factor of . Likewise, a doubling or halving of the voltage, and quadrupling or quartering of the power, is commonly described as "6 dB" rather than ±6.0206 dB.

Should it be necessary to make the distinction, the number of decibels is written with additional significant figures. 3.00 dB is a power ratio of 10, or 1.9953, about 0.24% different from exactly 2, and a voltage ratio of 1.4125, 0.12% different from exactly . Similarly, an increase of 6.00 dB is the power ratio is , about 0.5% different from 4.

The decibel is useful for representing large ratios and for simplifying representation of multiplied effects such as attenuation from multiple sources along a signal chain. Its application in systems with additive effects is less intuitive.

The logarithmic scale nature of the decibel means that a very large range of ratios can be represented by a convenient number, in a similar manner to scientific notation. This allows one to clearly visualize huge changes of some quantity. See Bode plot and semi-log plot. For example, 120 dB SPL may be clearer than "a trillion times more intense than the threshold of hearing".

Level values in decibels can be added instead of multiplying the underlying power values, which means that the overall gain of a multi-component system, such as a series of amplifier stages, can be calculated by summing the gains in decibels of the individual components, rather than multiply the amplification factors; that is, log("A" × "B" × "C") = log("A") + log("B") + log("C"). Practically, this means that, armed only with the knowledge that 1 dB is approximately 26% power gain, 3 dB is approximately 2× power gain, and 10 dB is 10× power gain, it is possible to determine the power ratio of a system from the gain in dB with only simple addition and multiplication. For example:
However, according to its critics, the decibel creates confusion, obscures reasoning, is more related to the era of slide rules than to modern digital processing, and is cumbersome and difficult to interpret.

According to Mitschke, "The advantage of using a logarithmic measure is that in a transmission chain, there are many elements concatenated, and each has its own gain or attenuation. To obtain the total, addition of decibel values is much more convenient than multiplication of the individual factors." However, for the same reason that humans excel at additive operation over multiplication, decibels are awkward in inherently additive operations: "if two machines each individually produce a [sound pressure] level of, say, 90 dB at a certain point, then when both are operating together we should expect the combined sound pressure level to increase to 93 dB, but certainly not to 180 dB!" "suppose that the noise from a machine is measured (including the contribution of background noise) and found to be 87 dBA but when the machine is switched off the background noise alone is measured as 83 dBA. ... the machine noise [level (alone)] may be obtained by 'subtracting' the 83 dBA background noise from the combined level of 87 dBA; i.e., 84.8 dBA." "in order to find a representative value of the sound level in a room a number of measurements are taken at different positions within the room, and an average value is calculated. (...) Compare the logarithmic and arithmetic averages of ... 70 dB and 90 dB: logarithmic average = 87 dB; arithmetic average = 80 dB."

Quantities in decibels are not necessarily additive, thus being "of unacceptable form for use in dimensional analysis".

The human perception of the intensity of sound and light approximates the logarithm of intensity rather than a linear relationship (Weber–Fechner law), making the dB scale a useful measure.

The decibel is commonly used in acoustics as a unit of sound pressure level. The reference pressure for sound in air is set at the typical threshold of perception of an average human and there are common comparisons used to illustrate different levels of sound pressure. Sound pressure is a field quantity, therefore the field version of the unit definition is used:
where "p" is the root mean square of the measured sound pressure in pascals and "p" is the standard reference sound pressure of 20 micropascals in air or 1 micropascal in water.

Use of the decibel in underwater acoustics leads to confusion, in part because of this difference in reference value.

The human ear has a large dynamic range in sound reception. The ratio of the sound intensity that causes permanent damage during short exposure to that of the quietest sound that the ear can hear is greater than or equal to 1 trillion (10). Such large measurement ranges are conveniently expressed in logarithmic scale: the base-10 logarithm of 10 is 12, which is expressed as a sound pressure level of 120 dB re 20 μPa.

Since the human ear is not equally sensitive to all sound frequencies, noise levels at maximum human sensitivity, somewhere between 2 and 4 kHz, are factored more heavily into some measurements using frequency weighting. (See also Stevens' power law.)

According to Hickling, "Decibels are a useless affectation, which is impeding the development of noise control as an engineering discipline".
In electronics, the decibel is often used to express power or amplitude ratios (gains), in preference to arithmetic ratios or percentages. One advantage is that the total decibel gain of a series of components (such as amplifiers and attenuators) can be calculated simply by summing the decibel gains of the individual components. Similarly, in telecommunications, decibels denote signal gain or loss from a transmitter to a receiver through some medium (free space, waveguide, coaxial cable, fiber optics, etc.) using a link budget.

The decibel unit can also be combined with a suffix to create an absolute unit of electric power. For example, it can be combined with "m" for "milliwatt" to produce the "dBm". A power level of 0 dBm corresponds to one milliwatt, and 1 dBm is one decibel greater (about 1.259 mW).

In professional audio specifications, a popular unit is the dBu. This is relative to the root mean square voltage which delivers 1 mW (0 dBm) into a 600-ohm resistor, or ≈ 0.775 V. When used in a 600-ohm circuit (historically, the standard reference impedance in telephone circuits), dBu and dBm are identical.

In an optical link, if a known amount of optical power, in dBm (referenced to 1 mW), is launched into a fiber, and the losses, in dB (decibels), of each component (e.g., connectors, splices, and lengths of fiber) are known, the overall link loss may be quickly calculated by addition and subtraction of decibel quantities.

In spectrometry and optics, the blocking unit used to measure optical density is equivalent to −1 B.

In connection with video and digital image sensors, decibels generally represent ratios of video voltages or digitized light intensities, using 20 log of the ratio, even when the represented optical power is directly proportional to the voltage, not to its square, as in a CCD imager where response voltage is linear in intensity.
Thus, a camera signal-to-noise ratio or dynamic range quoted as 40 dB represents a power ratio of 100:1 between signal power and noise power, not 10,000:1.
Sometimes the 20 log ratio definition is applied to electron counts or photon counts directly, which are proportional to intensity without the need to consider whether the voltage response is linear.

However, as mentioned above, the 10 log intensity convention prevails more generally in physical optics, including fiber optics, so the terminology can become murky between the conventions of digital photographic technology and physics. Most commonly, quantities called "dynamic range" or "signal-to-noise" (of the camera) would be specified in 20 log dB, but in related contexts (e.g. attenuation, gain, intensifier SNR, or rejection ratio) the term should be interpreted cautiously, as confusion of the two units can result in very large misunderstandings of the value.

Photographers typically use an alternative base-2 log unit, the stop, to describe light intensity ratios or dynamic range.

Suffixes are commonly attached to the basic dB unit in order to indicate the reference value by which the ratio is calculated. For example, dBm indicates power measurement relative to 1 milliwatt.

In cases where the unit value of the reference is stated, the decibel value is known as "absolute". If the unit value of the reference is not explicitly stated, as in the dB gain of an amplifier, then the decibel value is considered relative.

The SI does not permit attaching qualifiers to units, whether as suffix or prefix, other than standard SI prefixes. Therefore, even though the decibel is accepted for use alongside SI units, the practice of attaching a suffix to the basic dB unit, forming compound units such as dBm, dBu, dBA, etc., is not. The proper way, according to the IEC 60027-3, is either as "L" (re "x") or as "L", where "x" is the quantity symbol and "x" is the value of the reference quantity, e.g., "L" (re 1 μV/m) = "L" for the electric field strength "E" relative to 1 μV/m reference value.

Outside of documents adhering to SI units, the practice is very common as illustrated by the following examples. There is no general rule, with various discipline-specific practices. Sometimes the suffix is a unit symbol ("W","K","m"), sometimes it is a transliteration of a unit symbol ("uV" instead of μV for microvolt), sometimes it is an acronym for the unit's name ("sm" for square meter, "m" for milliwatt), other times it is a mnemonic for the type of quantity being calculated ("i" for antenna gain with respect to an isotropic antenna, "λ" for anything normalized by the EM wavelength), or otherwise a general attribute or identifier about the nature of the quantity ("A" for A-weighted sound pressure level). The suffix is often connected with a dash (dB-Hz), with a space (dB HL), with no intervening character (dBm), or enclosed in parentheses, dB(sm).

Since the decibel is defined with respect to power, not amplitude, conversions of voltage ratios to decibels must square the amplitude, or use the factor of 20 instead of 10, as discussed above.





Probably the most common usage of "decibels" in reference to sound level is dB SPL, sound pressure level referenced to the nominal threshold of human hearing: The measures of pressure (a field quantity) use the factor of 20, and the measures of power (e.g. dB SIL and dB SWL) use the factor of 10.

See also dBV and dBu above.











Np or cNp

Attenuation constants, in fields such as optical fiber communication and radio propagation path loss, are often expressed as a fraction or ratio to distance of transmission. "dB/m" means decibels per meter, "dB/mi" is decibels per mile, for example. These quantities are to be manipulated obeying the rules of dimensional analysis, e.g., a 100-meter run with a 3.5 dB/km fiber yields a loss of 0.35 dB = 3.5 dB/km × 0.1 km.





</doc>
<doc id="8411" url="https://en.wikipedia.org/wiki?curid=8411" title="Darwinism">
Darwinism

Darwinism is a theory of biological evolution developed by the English naturalist Charles Darwin (1809–1882) and others, stating that all species of organisms arise and develop through the natural selection of small, inherited variations that increase the individual's ability to compete, survive, and reproduce. Also called Darwinian theory, it originally included the broad concepts of transmutation of species or of evolution which gained general scientific acceptance after Darwin published "On the Origin of Species" in 1859, including concepts which predated Darwin's theories. It subsequently referred to the specific concepts of natural selection, the Weismann barrier, or the central dogma of molecular biology. Though the term usually refers strictly to biological evolution, creationists have appropriated it to refer to the origin of life, and it has even been applied to concepts of cosmic evolution, both of which have no connection to Darwin's work. It is therefore considered the belief and acceptance of Darwin's and of his predecessors' work—in place of other theories, including divine design and extraterrestrial origins.

English biologist Thomas Henry Huxley coined the term "Darwinism" in April 1860. It was used to describe evolutionary concepts in general, including earlier concepts published by English philosopher Herbert Spencer. Many of the proponents of Darwinism at that time, including Huxley, had reservations about the significance of natural selection, and Darwin himself gave credence to what was later called Lamarckism. The strict neo-Darwinism of German evolutionary biologist August Weismann gained few supporters in the late 19th century. During the approximate period of the 1880s to about 1920, sometimes called "the eclipse of Darwinism", scientists proposed various alternative evolutionary mechanisms which eventually proved untenable. The development of the modern synthesis in the early 20th century, incorporating natural selection with population genetics and Mendelian genetics, revived Darwinism in an updated form.

While the term "Darwinism" has remained in use amongst the public when referring to modern evolutionary theory, it has increasingly been argued by science writers such as Olivia Judson and Eugenie Scott that it is an inappropriate term for modern evolutionary theory. For example, Darwin was unfamiliar with the work of the Moravian scientist and Augustinian friar Gregor Mendel, and as a result had only a vague and inaccurate understanding of heredity. He naturally had no inkling of later theoretical developments and, like Mendel himself, knew nothing of genetic drift, for example. In the United States, creationists often use the term "Darwinism" as a pejorative term in reference to beliefs such as scientific materialism, but in the United Kingdom the term has no negative connotations, being freely used as a shorthand for the body of theory dealing with evolution, and in particular, with evolution by natural selection.

While the term "Darwinism" had been used previously to refer to the work of Erasmus Darwin in the late 18th century, the term as understood today was introduced when Charles Darwin's 1859 book "On the Origin of Species" was reviewed by Thomas Henry Huxley in the April 1860 issue of the "Westminster Review". Having hailed the book as "a veritable Whitworth gun in the armoury of liberalism" promoting scientific naturalism over theology, and praising the usefulness of Darwin's ideas while expressing professional reservations about Darwin's gradualism and doubting if it could be proved that natural selection could form new species, Huxley compared Darwin's achievement to that of Nicolaus Copernicus in explaining planetary motion:
These are the basic tenets of evolution by natural selection as defined by Darwin:


Another important evolutionary theorist of the same period was the Russian geographer and prominent anarchist Peter Kropotkin who, in his book "" (1902), advocated a conception of Darwinism counter to that of Huxley. His conception was centred around what he saw as the widespread use of co-operation as a survival mechanism in human societies and animals. He used biological and sociological arguments in an attempt to show that the main factor in facilitating evolution is cooperation between individuals in free-associated societies and groups. This was in order to counteract the conception of fierce competition as the core of evolution, which provided a rationalization for the dominant political, economic and social theories of the time; and the prevalent interpretations of Darwinism, such as those by Huxley, who is targeted as an opponent by Kropotkin. Kropotkin's conception of Darwinism could be summed up by the following quote:

"Darwinism" soon came to stand for an entire range of evolutionary (and often revolutionary) philosophies about both biology and society. One of the more prominent approaches, summed in the 1864 phrase "survival of the fittest" by Herbert Spencer, later became emblematic of Darwinism even though Spencer's own understanding of evolution (as expressed in 1857) was more similar to that of Jean-Baptiste Lamarck than to that of Darwin, and predated the publication of Darwin's theory in 1859. What is now called "Social Darwinism" was, in its day, synonymous with "Darwinism"—the application of Darwinian principles of "struggle" to society, usually in support of anti-philanthropic political agenda. Another interpretation, one notably favoured by Darwin's half-cousin Francis Galton, was that "Darwinism" implied that because natural selection was apparently no longer working on "civilized" people, it was possible for "inferior" strains of people (who would normally be filtered out of the gene pool) to overwhelm the "superior" strains, and voluntary corrective measures would be desirable—the foundation of eugenics.
In Darwin's day there was no rigid definition of the term "Darwinism", and it was used by opponents and proponents of Darwin's biological theory alike to mean whatever they wanted it to in a larger context. The ideas had international influence, and Ernst Haeckel developed what was known as "Darwinismus" in Germany, although, like Spencer's "evolution", Haeckel's "Darwinism" had only a rough resemblance to the theory of Charles Darwin, and was not centered on natural selection. In 1886, Alfred Russel Wallace went on a lecture tour across the United States, starting in New York and going via Boston, Washington, Kansas, Iowa and Nebraska to California, lecturing on what he called "Darwinism" without any problems.

In his book "Darwinism" (1889), Wallace had used the term "pure-Darwinism" which proposed a "greater efficacy" for natural selection. George Romanes dubbed this view as "Wallaceism", noting that in contrast to Darwin, this position was advocating a "pure theory of natural selection to the exclusion of any supplementary theory." Taking influence from Darwin, Romanes was a proponent of both natural selection and the inheritance of acquired characteristics. The latter was denied by Wallace who was a strict selectionist. Romanes' definition of Darwinism conformed directly with Darwin's views and was contrasted with Wallace's definition of the term.

The term "Darwinism" is often used in the United States by promoters of creationism, notably by leading members of the intelligent design movement, as an epithet to attack evolution as though it were an ideology (an "ism") of philosophical naturalism, or atheism. For example, UC Berkeley law professor and author Phillip E. Johnson makes this accusation of atheism with reference to Charles Hodge's book "What Is Darwinism?" (1874). However, unlike Johnson, Hodge confined the term to exclude those like American botanist Asa Gray who combined Christian faith with support for Darwin's natural selection theory, before answering the question posed in the book's title by concluding: "It is Atheism." Creationists use the term "Darwinism", often pejoratively, to imply that the theory has been held as true only by Darwin and a core group of his followers, whom they cast as dogmatic and inflexible in their belief. In the 2008 documentary film "", which promotes intelligent design (ID), American writer and actor Ben Stein refers to scientists as Darwinists. Reviewing the film for "Scientific American", John Rennie says "The term is a curious throwback, because in modern biology almost no one relies solely on Darwin's original ideas... Yet the choice of terminology isn't random: Ben Stein wants you to stop thinking of evolution as an actual science supported by verifiable facts and logical arguments and to start thinking of it as a dogmatic, atheistic ideology akin to Marxism." 

However, "Darwinism" is also used neutrally within the scientific community to distinguish the modern evolutionary synthesis, sometimes called "neo-Darwinism", from those first proposed by Darwin. "Darwinism" also is used neutrally by historians to differentiate his theory from other evolutionary theories current around the same period. For example, "Darwinism" may be used to refer to Darwin's proposed mechanism of natural selection, in comparison to more recent mechanisms such as genetic drift and gene flow. It may also refer specifically to the role of Charles Darwin as opposed to others in the history of evolutionary thought—particularly contrasting Darwin's results with those of earlier theories such as Lamarckism or later ones such as the modern evolutionary synthesis.

In political discussions in the United States, the term is mostly used by its enemies. "It's a rhetorical device to make evolution seem like a kind of faith, like 'Maoism,'" says Harvard University biologist E. O. Wilson. He adds, "Scientists don't call it 'Darwinism'." In the United Kingdom the term often retains its positive sense as a reference to natural selection, and for example British ethologist and evolutionary biologist Richard Dawkins wrote in his collection of essays "A Devil's Chaplain", published in 2003, that as a scientist he is a Darwinist.

In his 1995 book "Darwinian Fairytales", Australian philosopher David Stove used the term "Darwinism" in a different sense than the above examples. Describing himself as non-religious and as accepting the concept of natural selection as a well-established fact, Stove nonetheless attacked what he described as flawed concepts proposed by some "Ultra-Darwinists." Stove alleged that by using weak or false "ad hoc" reasoning, these Ultra-Darwinists used evolutionary concepts to offer explanations that were not valid (e.g., Stove suggested that sociobiological explanation of altruism as an evolutionary feature was presented in such a way that the argument was effectively immune to any criticism). Philosopher Simon Blackburn wrote a rejoinder to Stove, though a subsequent essay by Stove's protegee James Franklin's suggested that Blackburn's response actually "confirms Stove's central thesis that Darwinism can 'explain' anything."



</doc>
<doc id="8412" url="https://en.wikipedia.org/wiki?curid=8412" title="Doraemon">
Doraemon

Doraemon () is a Japanese manga series written and illustrated by Fujiko F. Fujio. The series has also been adapted into a successful anime series and media franchise. The story revolves around a robotic cat named Doraemon, who travels back in time from the 22nd century to aid a boy named .

The Doraemon manga series was first published in December 1969 in six different magazines. A total of 1,345 stories were created in the original series, which are published by Shogakukan. The volumes are collected in the Takaoka Central Library in Toyama, Japan, where Fujiko Fujio was born. Turner Broadcasting System bought the rights to the Doraemon anime series in the mid-1980s for an English-language release in the United States, but cancelled it without explanation before broadcasting any episodes. In July 2013 Voyager Japan announced the manga would be released digitally in English via the Amazon Kindle e-book service. It is one of the best-selling manga in the world, having sold over 100 million copies as of 2015.

Awards for Doraemon include the Japan Cartoonists Association Award for excellence in 1973, the first Shogakukan Manga Award for children's manga in 1982, and the first Osamu Tezuka Culture Award in 1997. In March 2008, Japan's Foreign Ministry appointed Doraemon as the nation's first "anime ambassador." A Ministry spokesperson explained the novel decision as an attempt to help people in other countries understand Japanese anime better and to deepen their interest in Japanese culture. The Foreign Ministry action confirms that Doraemon has come to be considered a Japanese cultural icon. In India, its Hindi, Telugu and Tamil translation has been telecasted, where the anime version is the highest-rated kids' show; winning the "Best Show For Kids" award twice at the Nickelodeon Kids' Choice Awards India in 2013 and 2015. In 2002 "Time Asia" magazine acclaimed the character as an "Asian Hero" in a special feature survey. An edited English dub distributed by TV Asahi aired on Disney XD in the United States started on July 7, 2014. In Epcot, Doraemon toys are on the Japan shop. On August 17, 2015, another English dubbed version distributed by Luk Internacional began broadcasting on Boomerang UK. The film series is the largest by number of admissions in Japan.

Nobita Nobi is a young boy who suffers from poor grades, frequent bullying and negative emotions like sadness and jealousy. Many years in the future, one of his descendants sends the robotic cat Doraemon back in time to protect and guide Nobita. Doraemon has a four-dimensional pocket from which he produces items known as "gadgets", which range from toys and medicine, to technology from the future. Examples include the "Bamboo-Copter" (Japanese: "Take-Koputa"), a small piece of headgear that allows flight and the "Anywhere Door" (Japanese: "Doko Demo Doa"), a door that opens up to any place the user wishes.

Nobita's closest friend is Shizuka Minamoto, who also serves as his romantic interest and eventually becomes his wife. Nobita is usually tormented by the bullying Takeshi Goda (nicknamed "Gian"), and the cunning and arrogant Suneo Honekawa. A typical story consists of Doraemon using one of his gadgets in order to assist Nobita in various ways, often causing more trouble than he was trying to solve.

In December 1969 the "Doraemon" manga appeared in six different children's monthly magazines published by Shogakukan. The magazines were aimed at children from nursery school to fourth grade. In 1977 "CoroCoro Comic" was launched as the flagship magazine of "Doraemon."

Since the debut of "Doraemon" in 1969, the stories have been selectively collected into forty-five tankōbon volumes, which were published under Shogakukan's "Tentōmushi Comics" imprint, from 1974 to 1996. Shogakukan published a "master works" collection consisting of Twenty volumes between July 24, 2009 and September 25, 2012.

In addition, Doraemon has appeared in a variety of manga series by Shōgakukan. In 2005 Shōgakukan published a series of five more manga volumes under the title "Doraemon+" ("Doraemon Plus"), which were not found in the forty-five original volumes. On December 1, 2014, a sixth volume of "Doraemon Plus" was published. This was the first volume in eight years.

There have been two series of bilingual, Japanese and English, volumes of the manga by SHOGAKUKAN ENGLISH COMICS under the title "Doraemon: Gadget Cat from the Future", and two audio versions. The first series has ten volumes and the second six.

In July 2013, Fujiko Fujio Productions announced that they would be collaborating with ebook publisher Voyager Japan and localization company AltJapan Co., Ltd. to release an English language version of the manga in full-color digitally via the Amazon Kindle platform in North America. Shogakukan released the first volume in November 2013. This English version incorporates a variety of changes to character names; Nobita is "Noby", Shizuka is "Sue", Suneo is "Sneech", and Gian is "Big G", while dorayaki is "Yummy Bun/Fudgy Pudgy Pie." A total of 200 volumes have been released.

The manga has been published in English in print by Shogakukan Asia, using the same translation as the manga available on Amazon Kindle. Unlike the Amazon Kindle releases these volumes are in black and white instead of color. They have released four volumes.

Shogakukan started digital distribution of all forty-five original volumes throughout Japan from July 16, 2015.

After a brief animated series in 1973 by Nippon Television, "Doraemon" remained fairly exclusive in manga form until 1979 when a newly formed animation studio, Shin-Ei Animation (now owned by TV Asahi) produced an anime series of "Doraemon." This series became incredibly popular, and ended with 1,787 episodes on March 25, 2005. In Asia, this version is sometimes referred to as the Ōyama Edition, after the voice actress who voiced Doraemon in this series.

Celebrating the anniversary of the franchise, a new "Doraemon" series began airing on TV Asahi on April 15, 2005 with new voice actors and staff, and updated character designs. This version is sometimes referred to in Asia as the Mizuta Edition, as Wasabi Mizuta is the voice actress for Doraemon in this series.

On May 12, 2014, TV Asahi Corporation announced an agreement with The Walt Disney Company to beginning in the summer of that year. Besides using the name changes that were used in AltJapan's English adaptation of the original manga, other changes and edits have also been made to make the show more relatable to an American audience, such as Japanese text being replaced with English text on certain objects like signs and graded papers, items such as yen notes being replaced by US dollar bills, and the setting being changed from Tokyo to a small town in the state of North Carolina. Confirmed cast member of the new American adaptation include veteran anime voice actress Mona Marshall of "South Park" fame in the title role of Doraemon and Johnny Yong Bosch of "Power Rangers" and "Bleach" fame as Noby. The English dub is produced by Bang Zoom! Entertainment. Initial response to the edited dub was positive. The Disney adaptation began broadcast in Japan on Disney Channel from February 1, 2016. The broadcast offered the choice of the English voice track or a newly recorded Japanese track by the US cast.

In EMEA regions, the series is licensed by LUK International. The series began broadcast in the United Kingdom on August 17, 2015 on Boomerang.

In 1980, Toho released the first of a series of annual feature length animated films based on the lengthy special volumes published annually. Unlike the anime and manga (some based on the stories in select volumes), they are more action-adventure oriented and have more of a shōnen demographic, taking the familiar characters of "Doraemon" and placing them in a variety of exotic and perilous settings. Nobita and his friends have visited the age of the dinosaurs, the far reaches of the galaxy, the heart of darkest Africa (where they encountered a race of sentient bipedal dogs), the depths of the ocean, and a world of magic. Some of the films are based on legends such as Atlantis, and on literary works including "Journey to the West" and "Arabian Nights." Some films also have serious themes, especially on environmental topics and the use of technology. Overall, the films have a somewhat darker tone in their stories, unlike the manga and anime.

There are a total of 63 Japanese-only video games ranging from platformer games to RPG games, which began with the Emerson's Arcadia 2001 system. Doraemon can also be seen in Namco's popular "Taiko no Tatsujin" rhythm game series like "Taiko no Tatsujin" (11 – 14 only), "", "Taiko no Tatsujin Wii", "Taiko no Tatsujin Plus", and "". The Chinese version of Microsoft's "3D Movie Maker" contained a Doraemon-themed expansion pack.

 was a 2008 musical based on the 1990 anime film . It debuted at Tokyo Metropolitan Art Space on September 4, 2008 running through September 14. Wasabi Mizuta voiced Doraemon.

Until 2015, more than 100 million copies of the manga have been sold and the animated series is available in over 30 countries.

Doraemon was awarded the first Shogakukan Manga Award for children's manga in 1982. In 1997, it was awarded the first Osamu Tezuka Culture Award. In 2008, the Japanese Ministry of Foreign Affairs appointed Doraemon as the first anime cultural ambassador.

On 22 April 2002, on the special issue of "Asian Hero" in "Time" magazine, Doraemon was selected as one of the 22 Asian Heroes. Being the only anime character selected, Doraemon was described as "The Cuddliest Hero in Asia". In 2005, the Taiwan Society of New York selected "Doraemon" as a culturally significant work of Japanese otaku pop-culture in its exhibit "Little Boy: The Arts of Japan's Exploding Subculture", curated by renowned artist Takashi Murakami.

Jason Thompson praised the "silly situations" and "old fashioned, simple artwork", with Doraemon's expression and comments adding to the "surrounding elementary-school mischief".

On September 3, 2012, Doraemon was granted official residence in the city of Kawasaki, one hundred years before he was born.

With the 2013 film, "", Doraemon has surpassed Godzilla in terms of overall ticket sales for a film franchise as Toho's most lucrative movie property. The 33-year series (1980–2013) has sold a combined 100 million tickets vs. the 50-year Godzilla series (1954–2004), which sold a combined 99 million tickets. It also became the largest franchise by numbers of admissions in Japan.

In Pakistan, the series has been targeted by Pakistan Tehreek-e-Insaf as having a negative impact on children, because of Nobita's constant reliance on Doraemon's gadgets to solve problems. It also attempts to ban the Hindi dub of the series for teaching kids Hindi words not in Urdu (Pakistan's official language). It also intends to ban 24 hour cartoon channels in general, because of their supposed ruining of children's minds. Legal notice also been served against several companies in India against Doraemon and Crayon Shin-chan as having an adverse effect on children.

A Fujiko F. Fujio museum opened in Kawasaki on September 3, 2011, featuring Doraemon as the star of the museum.

As one of the oldest, continuously running icons, Doraemon is a recognizable character in this contemporary generation. Nobita, the show's protagonist, is a break from other characters typically portrayed as special or extraordinary, and this portrayal has been seen as reasons of its appeal as well as the contrary, especially in the United States. Mexican filmmaker Guillermo del Toro considers "Doraemon" to be "the greatest kids series ever created".

ESP Guitars have made several Doraemon guitars aimed at children.

In late 2011, Shogakukan and Toyota joined forces to create a series of live-action commercials as part of Toyota's ReBorn ad campaign. The commercials depict the characters nearly 20 years older. Hollywood actor Jean Reno plays Doraemon.

Doraemon has become a prevalent part of popular culture in Japan. Newspapers also regularly make references to Doraemon and his pocket as something with the ability to satisfy all wishes. The series is frequently referenced in other series such as "Gin Tama" and "Great Teacher Onizuka".

Doraemon appears in appeals for charity. TV Asahi launched the "Doraemon Fund" charity fund to raise money for natural disasters.

Doraemon, Nobita, and the other characters also appear in various educational manga.

Doraemon appeared in the 2016 Summer Olympics closing ceremony to promote the 2020 Summer Olympics in Tokyo. In his appearance, he helped prime minister Shinzō Abe by planting a Warp Pipe from Shibuya Crossing to Maracanã Stadium.




</doc>
<doc id="8414" url="https://en.wikipedia.org/wiki?curid=8414" title="Dartmoor Preservation Association">
Dartmoor Preservation Association

Dartmoor Preservation Association (DPA) is one of the oldest environmental or amenity bodies in the UK. It was founded in 1883. It concerns itself with Dartmoor, a National Park in Devon, south-west England. It began with two main areas of concern. Firstly, commoners’ rights were being eroded through army use, including the firing of live artillery shells, and piecemeal enclosure of land around the margins. Secondly, there was increasing public interest in Dartmoor’s scenery, archaeology, history and wildlife

The DPA has opposed what it considered to be unsuitable developments on Dartmoor throughout its history. In its founding year, the secretary, Robert Burnard persuaded the War Department not to fire on the Okehampton Firing Range on Saturdays to allow access to the public. Many battles have been fought since, particularly against the military presence and the proposed building of reservoirs on the moor, notably under the Chairmanship of Lady Sayer, granddaughter of Robert Burnard.

The DPA continues to follow the same objectives as when it was founded. For example, in June 2015, it supported the inhabitants of Widecombe-in-the-Moor against the erecting of a telecommunications mast in an area of pristine countryside against the wishes of the local population.

Dartmoor Preservation Association is a registered charity, Number 215665.

Dartmoor is said to be one of the last remaining areas of wilderness in Britain, but it has been a managed landscape since the late Neolithic (3,000-2,500 BCE). The Bronze Age inhabitants (from 2,500 to 750 BCE) cleared ancient forest and developed farming. They made extensive use of surface moorstone in the construction of roundhouses (their remains now seen as "hut circles"), enclosures, land-dividing reaves, stone rows, stone circles, menhirs and kistvaens.

Farming has continued through the Medieval period to the present day, but a more disruptive activity to the landscape was the appearance of tin-mining, firstly by stream-working, then by lode-working and finally by underground mining. Many valleys have been dug over and scarred, leaving a rich industrial archaeology. Other activities such as newtake wall building, peat cutting, rabbit warrening, quarrying, clay extraction and the building of a prominent prison have all left marks on the moor. Recent undertakings have left more obvious changes: the building of reservoirs and the planting of conifer forests.

The use of moorstone continued up to recent times with the extensive building of dry stone walls around farm newtakes. Later, stone was cut and dressed. The use of moorstone continued to such an extent that in 1847 boundary markers were cut around Pew Tor to protect it. Marker stones were erected around Roos Tor. The taking of stone started to change the Dartmoor landscape: for example Eric Hemery (writing in 1983) stated that Swell Tor had been "decapitated and disembowelled by the quarrymen".

In August 1881, a public meeting was convened by the Portreeve of Tavistock in the Guildhall to discuss the continued taking of stone, particularly from landmark tors. The DPA was founded in 1883. The protected area around Pew Tor was extended in December 1896. In 1901, the DPA commissioned a report into damage to ancient monuments, caused by the taking of stone for building and road-mending, and into unlawful enclosures of common land.

The first publication of the DPA, in 1890, was a short history of commoners’ rights on Dartmoor and the commons of Devon. This notes a decrease in the numbers of animals even in medieval times: in 1296 – 5,000 cattle, 487 horses, 131 folds of sheep; in 1316 – 3,292 cattle, 368 horses, 100 folds of sheep. "An important battle occurred in 1894 when the Corporation of London attempted to buy the whole of Dartmoor in order to pipe its water to Paddington alongside Brunel’s recently converted railway, when it went from broad gauge to standard gauge. The DPA led the revolt against this". In 1897, the DPA went to court to fight successfully the enclosure of a section of Peter Tavy Great Common, in support of a farmer. Commoners rights seem to have been a settled issue in recent years: except for where they are impinged upon by the military presence.

Dartmoor Training Area has been used regularly for military training since 1873, although it was used earlier during the Napoleonic and Crimean Wars. In 1906-07, seven miles of roads were built on the north moor to facilitate the movement of guns. There are three established firing ranges at Okehampton, Willsworthy and Merrivale. The area taken up with live firing ranges is 9,187 hectares (22,664 acres) and they are used on average 120 days each year. They are used for small arms, mortars and artillery smoke and illuminating shells.

The use of the moor by the military has been a major concern of the DPA since its founding. In its first year, Robert Burnard (DPA Secretary) persuaded the War Department not to fire on the Okehampton Firing Range on Saturdays so that there may be some public access to the area. Lady Sylvia Sayer was very outspoken about it being totally at odds with the area being designated as a National Park. In 1963 the DPA published a widely circulated 24-page booklet entitled "Misuse of a National Park" which includes photographs of unexploded shells lying on the open moor, corrugated iron buildings, large craters, a derelict tank used as a target, bullet marks on standing stones, etc. It also contains details of a 1958 incident in which a young boy was killed by a mortar shell near Cranmere Pool.

Since the 1960s there has been much less military damage and litter as a result of the DPA persuading the Services to be more cautious. The military have changed since the Victorian era, they now have 120 conservation groups across the Ministry of Defence (MOD), including Dartmoor Military Conservation Group. The current leases run for many years, with Cramber Tor most recently being granted a further 40-year licence.

Early afforestation occurred when Brimpts was planted with trees in 1862. The Forestry Commission was founded in 1919, following World War I and in that year the Duchy of Cornwall planted 800 acres of conifers at Fernworthy. In 1921, Plymouth Corporation planted conifers around Burrator Reservoir. The Forestry Commission planted Bellever and Laughter Tor farms in 1930-32 and in 1944-1945 Soussons Down was also planted. The DPA opposed these post-war plantings and R. Hansford Worth (1868-1950, a Plymouth engineer, scientist and antiquarian) delivered a lecture fiercely critical of the Duchy of Cornwall as the landowners at The Plymouth Athenaeum, using the argument of encroachment on the rights of common and loss of ancient monuments. DPA opposition to forestry on Dartmoor arose again in 1953 when it wrote a policy on woodlands in the then-new national park. Opposition was exercised when Hawn, Dendles and High House Wastes, all near Cornwood, were designated for tree planting in 1959. Argument continued while Hawns and Dendles Wastes were ploughed in 1960. High House Waste was purchased by the DPA in 1964 and the Nature Conservancy (UK) bought neighbouring Dendles in 1965. The situation in 2015 is that some of the Dartmoor plantations have been affected by the fungal disease Phytophthora ramorum which results in widespread clear felling to prevent further spread of the disease. The policy now is to replant with more native hardwood trees although more resistant conifers are also being used.

There are eight Dartmoor reservoirs, with the earliest being Tottiford Reservoir, 1861. Three were built in the mid-20th century: Fernworthy, 1942; Avon, 1957 and Meldon, 1972, and the DPA fought many battles over these. It opposed plans for reservoirs on Brent Moor (1899) and Holne Moor (1901) where, later, the Avon Reservoir and Venford Reservoirs were respectively built. The DPA’s opposition was supported in the House of Commons with argument made regarding the effects on the local water table. The DPA was one of many local and national amenity bodies that fought the building of the Meldon dam. The preservation battle for the Meldon valley was recorded in a DPA publication. The DPA offered a viable alternative site, Gorhuish Valley, for various reasons, including the fact that minerals such as arsenic would leach into the water supply if Meldon were selected. The Meldon story was discussed many times in Parliament. Another battle was fought against the flooding of the Swincombe valley to form another reservoir. This was rejected in parliament in 1970, revived in 1974 and finally resolved by the building of the Roadford Reservoir to the west of the moor. In 1985 the DPA used funds from a bequest to purchase 50 acres of land where the dam of a reservoir at Swincombe would have to be.

The National Parks and Access to the Countryside Act 1949 led to Dartmoor being one of the first four parks to be designated, by an order made on 15 August 1951 and confirmed on 30 October 1951. Shortly after this, the DPA tried to ensure that the new National Park was run by an independent committee and not by the Dartmoor Standing Committee that was a subcommittee of Devon County Council Planning Committee. The committee was reformed as Dartmoor National Park Committee under the Local Government Act 1972 but it was still a subcommittee of Devon County Council and as such it was not seen to be an independent guardian of the moor by the DPA. It was not until 1997 that an independent Dartmoor National Park Authority was enabled under the Environment Act 1995 as a free-standing local authority, forty-four years after the park was created, although it is still dominated by local authorities and government appointees.

The DPA learned in October 1951 that the BBC planned to build a 750-foot television mast on North Hessary Tor, near Princetown, that was erected in 1955. This was to be a relay from a transmitting station at Wenvoe, South Wales. The DPA objected to this threat and sought expert opinion, offered alternative solutions, pressed for a public enquiry, engaged a lawyer, held public meetings, distributed pamphlets, wrote to the press and petitioned parliament. Eventually, a public enquiry was announced. When the decision was made to permit the mast, there were a number of conditions, included among them was that the development was built near the tor, leaving it still intact, and that its new approach road should not be fenced. During the process of obtaining land for the transmitter, one MP asked in the House of Commons: "Will the Assistant Postmaster-General bear in mind that we have no desire to hinder the provision of this station but that it is felt that ancient common rights such as these, that have existed for a thousand years, should be adequately protected or properly extinguished by due process of law?"

During World War II, the Royal Air Force (RAF) built a mast and buildings on Peek Hill, as RAF Sharpitor. In 1956, permission was granted to rebuild the station as part of the "Gee" radio navigation system, to be occupied for ten years. There followed delay in leaving and a proposal was made in 1970 by Devon & Cornwall Police to use the mast, which was rejected. Then later that year Plymouth Corporation wanted to use the exposed site for housing juvenile offenders. This was also rejected, but Plymouth appealed. At a public enquiry in June 1973 Lady Sylvia Sayer represented the DPA and permission for development on the site was refused. A few years later, DPA fought successfully in support of South West Water (SWW) against renewed calls for a new reservoir at Swincombe. To mark the victory, Sylvia Sayer asked SWW if DPA could purchase the rocky outcrop of Sharpitor. The DPA purchased 32 acres in February 1984.

Okehampton lies on the A30 main road, the shortest route from London to west Devon and Cornwall. The need for a bypass was mooted in 1963. In 1975, three routes were considered: a northern route through mainly farmland, a central route using a railway, and a southern route through Dartmoor National Park. In August 1976, the Department of the Environment announced the preferred route was through the National Park. A major event on the timeline of this project was a 96-day public enquiry from 1 May 1979 to 4 February 1980 held in Okehampton. In March 1984, the DPA with other organisations petitioned Parliament opposing compulsory purchase orders on public open spaces. The Secretary of State announced in July 1985 that he was introducing a bill to reverse the decision of a Joint Parliamentary Committee and confirm a route through the National Park. This was followed by a confirmation bill in November 1985 that was passed in the House of Lords on 5 December 1985. Construction started in November 1986 and the road was opened on 19 July 1988.

The DPA continues to follow the same objectives as when it was founded. The activities have widened, involving local partners, it has a calendar of events, walks and work days with its Conservation Team undertaking a variety of moorland projects, it funds the supply of walking boots to some children who need them for the Duke of Edinburgh Award Scheme through the Moor Boots Scheme, it collaborates with the Campaign for National Parks, it monitors the activities of Dartmoor National Park Authority who run the National Park. It objected to eight planning proposals (with success in seven cases), with many other achievements in the DPA Director’s Annual Report. The DPA remains true to its original objectives and has also added other activities in support of Dartmoor and its inhabitants.

The china clay industry on Dartmoor was established long before the DPA was founded. The earliest record of a china clay pit refers to Hook Lake in 1502. The area was surveyed around 1827 by Cornishmen with thirty years experience in the clay industry. They obtained a 21-year lease in 1830, from the Earl of Morley who owned the land, to work the area between Lee Moor and Shaugh Moor. A rival pit was opened at Leftlake in about 1850 and at Hemerdon and Broomage in about 1855. Further pits were opened at Cholwichtown, Whitehill Yeo and Wigford Down/Brisworthy (circa 1860). Others followed at Smallhanger and Headon in the 1870s. Redlake started working in 1910. China clay pits are open cast mines that result in large holes in the ground accompanied by large waste tips. Over time, the pits become larger and more ground is needed for the waste, changing the landscape: the effect of this can be seen from space.

The DPA argues that this is an activity that does not agree with the ethos of a National Park, whose purpose is to protect landscape from unsuitable development. In 1994, the National Park boundaries were changed to include common land at Shaugh Moor and exclude china clay worked land at Lee Moor. The DPA revived its campaign with the publication of a booklet in 1999 when the Blackabrook Valley, Crownhill Down and Shaugh Moor, near the popular tourist area of Cadover Bridge, all came under threat from exploitation or dumping of waste. The china clay companies relinquished planning permissions in 2001. However, in November 2009, the clay companies, Sibelco and Imerys, produced a report reviewing old mineral permissions under the Environment Act 1995 with a view to joining up two pits. A presumed Bronze Age barrow, known as Emmets Post, was to be removed and three other monuments may be affected. The DPA were recorded twice, with other bodies, in a Devon County Council Development Management Committee Report for their representations in securing the future of the three areas where planning permissions were relinquished in 2001. Oxford Archaeology held an open day during their excavation of Emmets Post in 2014 prior to its removal.

The DPA and Exmoor Society held a joint reception at the House of Lords on 6 November 2008, hosted by Baroness Mallalieu, to lobby members of both Houses of Parliament and relevant Ministers about ensuring that environmental schemes for the uplands are "fit for purpose". Both organisations funded an invited number of upland hill farmers to attend.

The excavation in August 2011 on the north moor of a Bronze Age burial kistvaen, or cist, that was originally uncovered in 2001 was part-funded by the DPA, along with other bodies.

A conference for the upland farmers of Bodmin Moor, Exmoor and Dartmoor was held as a joint venture between the South West Uplands Federation and the DPA. It was run by the DPA at Exeter Racecourse in October 2012, with 150 delegates. Speakers came from the Foundation for Common Land, the Forest of Dartmoor Commoners, the University of Gloucestershire, the National Farmers Union of England and Wales and the Open Spaces Society. The CEO raised sponsorship from Dartmoor National Park, Exmoor National Park, Natural England, Duchy of Cornwall and the Exmoor Society - this reflecting the standing of the DPA with those bodies.

Two major projects to underground overhead power cables in Dartmoor National Park have been completed in a joint project between Western Power Distribution, the South West Protected Landscapes Forum (SWPLF) and Dartmoor National Park Authority. The two schemes on Holne Moor and Walkhampton Common between them remove nearly 6 km of overhead line from open moorland. At nearly 5 km, the Walkhampton scheme is the largest to be undertaken in the South West region by Western Power Distribution. The old overhead line was readily visible from the B3212 Princetown to Yelverton Road, strung across Walkhampton Common from Devil’s Elbow to just above Horseyeatt at Peek Hill. The works to provide the new underground supply were mainly undertaken on the highway to minimise the impact on the sensitive moorland landscape, its archaeology, wildlife and livestock. The DPA has supported the undergrounding of these visually intrusive power lines for many years.

The Dartmoor Conservation Garden is a joint project between DPA and Dartmoor National Park Authority (DNPA) and is located in the Jack Wigmore Garden behind the High Moorland Centre in Princetown: this is a memorial garden to a former Chair of the Authority. It is planted with a cross-section of typical native Dartmoor plants. It also houses some typical Dartmoor archaeological features, such as a 4,000-year-old Bronze Age burial kistvaen (or cist) and a Medieval granite cross from Ter Hill. This marked the Monk's Path but was constantly being pushed over by cattle. The purpose of the Garden is to illustrate the biodiversity on Dartmoor. The project came online in June 2015.

The DPA were involved in a campaign in June 2015 against four telecommunications masts planned for Dartmoor, with the first to be erected in the village of Widecombe. At short notice, the DPA banners were taken out, letters written, press interviews given and support given to the villagers when an inflatable mast was demonstrated – with the effect that the planning application was withdrawn.

In common with other amenity bodies, such as those for the Lake District, Peak District, Pembrokeshire Coast, Yorkshire Dales Three Peaks and the New Forest Trust, the image of Dartmoor Preservation Association is evolving from its Victorian origins, although the original name is being retained. Friends of Dartmoor projects a more modern image of preservation where several years of diplomacy have achieved good relations with the partner agencies that operate in the Dartmoor arena. This is due mainly to the efforts of the previous CEO, James Paxman and his successor, Phil Hutt.

The DPA Constitution, objectives and policies are published on the DPA web site.

The objectives enshrined in the constitution are the protection, preservation and enhancement in the public interest of the landscape, antiquities, flora and fauna, natural beauty, cultural heritage and scientific interest of Dartmoor. Also the protection and preservation of public access to and on Dartmoor subject to the ancient rights of commoners. Co-operation with the commoners and any organisation in achieving DPA objectives, also the study of and the recording and publication of information upon the antiquities, history and natural history of Dartmoor. There is also an interest in the acquisition of land and rights to further DPA objectives, concomitant with being a charity.

The DPA has twenty-two policies listed on its web site: regarding access and rights of way, fencing, protecting monuments, diverse habitats, bracken, china clay quarrying, military training and live firing, hill farming and small scale traditional local industries, quarrying, television and telephone masts, wind farms, planning applications, housing developments, woodlands and forestry, ponies, swaling, and recreational activities.

The DPA logo incorporates a representation of a Dartmoor rock feature known as Bowerman's Nose. The logo that includes a representation of Nun’s Cross appeared on the DPA Dartmoor Newsletter No. 48, October 1966, with a comment that designs based on the initial letters DPA had been exhausted. The simpler logo appeared in November 1969, when Newsletter 52 carried the logo with "DPA" on it. This was replaced in 2004 with the multicoloured logo.




</doc>
<doc id="8418" url="https://en.wikipedia.org/wiki?curid=8418" title="Dartmouth College">
Dartmouth College

Dartmouth College ( ) is a private Ivy League research university in Hanover, New Hampshire, United States. Established in 1769 by Eleazar Wheelock, it is the ninth-oldest institution of higher education in the United States and one of the nine colonial colleges chartered before the American Revolution. Although founded as a school to educate Native Americans in Christian theology and the English way of life, Dartmouth primarily trained Congregationalist ministers throughout its early history before it gradually secularized, emerging at the turn of the 20th century from relative obscurity into national prominence.

Following a liberal arts curriculum, the university provides undergraduate instruction in 40 academic departments and interdisciplinary programs including 57 majors in the humanities, social sciences, natural sciences, and engineering, and enables students to design specialized concentrations or engage in dual degree programs. Dartmouth comprises five constituent schools: the original undergraduate college, the Geisel School of Medicine, the Thayer School of Engineering, the Tuck School of Business, and the Guarini School of Graduate and Advanced Studies. The university also has affiliations with the Dartmouth–Hitchcock Medical Center, the Rockefeller Institute for Public Policy, and the Hopkins Center for the Arts. With a student enrollment of about 6,400, Dartmouth is the smallest university in the Ivy League. Undergraduate admissions is highly competitive, with an acceptance rate of 8.7% for the Class of 2022.

Situated on a hill above the Connecticut River, Dartmouth's 269-acre main campus is in the rural Upper Valley region of New England. The university functions on a quarter system, operating year-round on four ten-week academic terms. Dartmouth is known for its undergraduate focus, strong Greek culture, and wide array of enduring campus traditions. Its 34 varsity sports teams compete intercollegiately in the Ivy League conference of the NCAA Division I.

Dartmouth is consistently included among the highest-ranked universities in the United States by several institutional rankings, and has been cited as a leading university for undergraduate teaching and research by "U.S. News & World Report". In 2018, the Carnegie Classification of Institutions of Higher Education listed Dartmouth as the only "majority-undergraduate," "arts-and-sciences focused," "doctoral university" in the country that has "some graduate coexistence" and "very high research activity." In a "New York Times" corporate study, Dartmouth graduates were shown to be among the most sought-after and valued in the world.

The university has produced many prominent alumni, including 170 members of the U.S. Senate and the U.S. House of Representatives, 24 U.S. governors, 10 billionaire alumni, 10 U.S. Cabinet secretaries, 3 Nobel Prize laureates, 2 U.S. Supreme Court justices, and a U.S. vice president. Other notable alumni include 79 Rhodes Scholars, 26 Marshall Scholarship recipients, 13 Pulitzer Prize winners, and numerous MacArthur Genius fellows, Fulbright Scholars, CEOs and founders of Fortune 500 corporations, high-ranking U.S. diplomats, scholars in academia, literary and media figures, professional athletes, and Olympic medalists.

Dartmouth was founded by Eleazar Wheelock, a Congregational minister from Columbia, Connecticut, who had sought to establish a school to train Native Americans as Christian missionaries. Wheelock's ostensible inspiration for such an establishment resulted from his relationship with Mohegan Indian Samson Occom. Occom became an ordained minister after studying under Wheelock from 1743 to 1747, and later moved to Long Island to preach to the Montauks.

Wheelock founded Moor's Indian Charity School in 1755. The Charity School proved somewhat successful, but additional funding was necessary to continue school's operations, and Wheelock sought the help of friends to raise money. The first major donation to the school was given by Dr. John Phillips in 1762, who would go on to found Phillips Exeter Academy. Occom, accompanied by the Reverend Nathaniel Whitaker, traveled to England in 1766 to raise money from churches. With these funds, they established a trust to help Wheelock. The head of the trust was a Methodist named William Legge, 2nd Earl of Dartmouth.
Although the fund provided Wheelock ample financial support for the Charity School, Wheelock initially had trouble recruiting Indians to the institution, primarily because its location was far from tribal territories. In seeking to expand the school into a college, Wheelock relocated it to Hanover, in the Province of New Hampshire. The move from Connecticut followed a lengthy and sometimes frustrating effort to find resources and secure a charter. The Royal Governor of New Hampshire, John Wentworth, provided the land upon which Dartmouth would be built and on December 13, 1769, issued a royal charter in the name of King George III establishing the College. That charter created a college "for the education and instruction of Youth of the Indian Tribes in this Land in reading, writing & all parts of Learning which shall appear necessary and expedient for civilizing & christianizing Children of Pagans as well as in all liberal Arts and Sciences and also of English Youth and any others." The reference to educating Native American youth was included to connect Dartmouth to the Charity School and enable use of the Charity School's unspent trust funds. Named for William Legge, 2nd Earl of Dartmouth—an important supporter of Eleazar Wheelock's earlier efforts but who, in fact, opposed creation of the College and never donated to it—Dartmouth is the nation's ninth oldest college and the last institution of higher learning established under Colonial rule. The College granted its first degrees in 1771.

Given the limited success of the Charity School, however, Wheelock intended his new college as one primarily for whites. Occom, disappointed with Wheelock's departure from the school's original goal of Indian Christianization, went on to form his own community of New England Indians called Brothertown Indians in New York.

In 1819, Dartmouth College was the subject of the historic Dartmouth College case, which challenged New Hampshire's 1816 attempt to amend the college' charter to make the school a public university. An institution called Dartmouth University occupied the college buildings and began operating in Hanover in 1817, though the college continued teaching classes in rented rooms nearby. Daniel Webster, an alumnus of the class of 1801, presented the College's case to the Supreme Court, which found the amendment of Dartmouth's charter to be an illegal impairment of a contract by the state and reversed New Hampshire's takeover of the college. Webster concluded his peroration with the famous words: "It is, Sir, as I have said, a small college. And yet there are those who love it."

In 1866, the New Hampshire College of Agriculture and the Mechanic Arts was incorporated in Hanover, in connection with Dartmouth College. The institution was officially associated with Dartmouth and was directed by Dartmouth's president. The new college was moved to Durham, New Hampshire, in 1891, and later became known as the University of New Hampshire.

Dartmouth emerged onto the national academic stage at the turn of the 20th century. Prior to this period, the college had clung to traditional methods of instruction and was relatively poorly funded. Under President William Jewett Tucker (1893–1909), Dartmouth underwent a major revitalization of facilities, faculty, and the student body, following large endowments such as the $10,000 given by Dartmouth alumnus and law professor John Ordronaux. 20 new structures replaced antiquated buildings, while the student body and faculty both expanded threefold. Tucker is often credited for having "refounded Dartmouth" and bringing it into national prestige. Presidents Ernest Fox Nichols (1909–16) and Ernest Martin Hopkins (1916–45) continued Tucker's trend of modernization, further improving campus facilities and introducing selective admissions in the 1920s. In 1945, Hopkins was subject to no small amount of controversy, as he openly admitted to Dartmouth's practice of using racial quotas to deny Jews entry into the university. John Sloan Dickey, serving as president from 1945 until 1970, strongly emphasized the liberal arts, particularly public policy and international relations. During World War II, Dartmouth was one of 131 colleges and universities nationally that took part in the V-12 Navy College Training Program which offered students a path to a navy commission.

In 1970, longtime professor of mathematics and computer science John George Kemeny became president of Dartmouth. Kemeny oversaw several major changes at the college. Dartmouth, which had been a men's institution, began admitting women as full-time students and undergraduate degree candidates in 1972 amid much controversy. At about the same time, the college adopted its "Dartmouth Plan" of academic scheduling, permitting the student body to increase in size within the existing facilities. In 1988, Dartmouth's alma mater song's lyrics changed from "Men of Dartmouth" to "Dear old Dartmouth".

During the 1990s, the college saw a major academic overhaul under President James O. Freedman and a controversial (and ultimately unsuccessful) 1999 initiative to encourage the school's single-sex Greek houses to go coed. The first decade of the 21st century saw the commencement of the $1.3 billion Campaign for the Dartmouth Experience, the largest capital fundraising campaign in the college's history, which surpassed $1 billion in 2008. The mid- and late first decade of the 21st century have also seen extensive campus construction, with the erection of two new housing complexes, full renovation of two dormitories, and a forthcoming dining hall, life sciences center, and visual arts center. In 2004, Booz Allen Hamilton selected Dartmouth College as a model of institutional endurance "whose record of endurance has had implications and benefits for all American organizations, both academic and commercial," citing "Trustees of Dartmouth College v. Woodward" and Dartmouth's successful self-reinvention in the late 19th century.

Since the election of a number of petition-nominated trustees to the Board of Trustees starting in 2004, the role of alumni in Dartmouth governance has been the subject of ongoing conflict. President James Wright announced his retirement in February 2008 and was replaced by Harvard University professor and physician Jim Yong Kim on July 1, 2009.

In May 2010 Dartmouth joined the Matariki Network of Universities (MNU) together with Durham University (UK), Queen's University (Canada), University of Otago (New Zealand), University of Tübingen (Germany), University of Western Australia (Australia) and Uppsala University (Sweden).

Dartmouth's close association and involvement in the development of the downhill skiing industry is featured in the 2010 book "Passion for Skiing" as well as the 2013 documentary based on the book "Passion for Snow".

Dartmouth, a liberal arts institution, offers a four-year Bachelor of Arts and ABET-accredited Bachelor of Engineering degree to undergraduate students. The college has 39 academic departments offering 56 major programs, while students are free to design special majors or engage in dual majors. For the graduating class of 2017, the most popular majors were economics, government, computer science, engineering sciences, and history. The Government Department, whose prominent professors include Stephen Brooks, Richard Ned Lebow, and William Wohlforth, was ranked the top solely undergraduate political science program in the world by researchers at the London School of Economics in 2003. The Economics Department, whose prominent professors include David Blanchflower and Andrew Samwick, also holds the distinction as the top-ranked bachelor's-only economics program in the world.

In order to graduate, a student must complete 35 total courses, eight to ten of which are typically part of a chosen major program. Other requirements for graduation include the completion of ten "distributive requirements" in a variety of academic fields, proficiency in a foreign language, and completion of a writing class and first-year seminar in writing. Many departments offer honors programs requiring students seeking that distinction to engage in "independent, sustained work," culminating in the production of a thesis. In addition to the courses offered in Hanover, Dartmouth offers 57 different off-campus programs, including Foreign Study Programs, Language Study Abroad programs, and Exchange Programs.

Through the Graduate Studies program, Dartmouth grants doctorate and master's degrees in 19 Arts & Sciences graduate programs. Although the first graduate degree, a PhD in classics, was awarded in 1885, many of the current PhD programs have only existed since the 1960s. Furthermore, Dartmouth is home to three professional schools: the Geisel School of Medicine (established 1797), Thayer School of Engineering (1867)—which also serves as the undergraduate department of engineering sciences—and Tuck School of Business (1900). With these professional schools and graduate programs, conventional American usage would accord Dartmouth the label of "Dartmouth University"; however, because of historical and nostalgic reasons (such as "Dartmouth College v. Woodward"), the school uses the name "Dartmouth College" to refer to the entire institution.

Dartmouth employs a total of 607 tenured or tenure-track faculty members, including the highest proportion of female tenured professors among the Ivy League universities. Faculty members have been at the forefront of such major academic developments as the Dartmouth Workshop, the Dartmouth Time Sharing System, Dartmouth BASIC, and Dartmouth ALGOL 30. In 2005, sponsored project awards to Dartmouth faculty research amounted to $169 million.

Dartmouth serves as the host institution of the University Press of New England, a university press founded in 1970 that is supported by a consortium of schools that also includes Brandeis University, the University of New Hampshire, Northeastern University, Tufts University and the University of Vermont.

Dartmouth was ranked 11th among undergraduate programs at national universities by "U.S. News & World Report" in its 2018 rankings. Dartmouth's strength in undergraduate education is highlighted by "U.S. News" when in 2009 through 2013 it ranked Dartmouth first in undergraduate teaching at national universities. It was ranked 2nd in this area in the 2018 rankings. The institution also ranked 5th in High School Counselor Rankings in 2018. The college ranks 7th in "The Wall Street Journal"s ranking of top feeder schools.

The 2017 Academic Ranking of World Universities ranked Dartmouth among the 71-99th best universities in the nation, alongside institution such as Georgetown University and University of Notre Dame. AWRU ranks Dartmouth among the 76–100 best schools in the world for Business Administration and 101–150 for Management and Psychology.

In "Forbes" 2016 rankings of colleges, Dartmouth ranked 17th overall in the combined liberal arts college and national universities ranking and 2nd in "grateful graduates", with a financial grade of A+.

The 2006 Carnegie Foundation classification listed Dartmouth as the only "majority-undergraduate", "arts-and-sciences focus[ed]", "research university" in the country that also had "some graduate coexistence" and "very high research activity."

For its graduate programs, "U.S. News" ranks Dartmouth's MBA program 9th overall and 6th for management. Among its other highly ranked graduate offerings, the school is ranked 40th in computer science, 29th in medicine for primary care, and 37th in medicine for research. Its global ranking places is at 242nd.

Undergraduate admission to Dartmouth College is characterized by the Carnegie Foundation and "U.S. News & World Report" as "most selective." The "Princeton Review", in its 2018 edition, gave the university an admissions selectivity rating of 98 out of 99.

For the freshman class entering Fall 2018, Dartmouth received 22,033 applications of which 1,925 were accepted for an 8.7% admissions rate. Of those admitted students who reported class rank, a record 46.3% were valedictorian or salutatorian, with 97% ranking in the top decile of their class. The admitted students’ academic profile showed an all-time high SAT average score of 1497, while the average composite ACT score remained at 33. More than 51% identified as being students of color, 15% are among the first generation in their families to matriculate to college, 11% are international students, and 9% are legacies.

Additionally, for the 2016–2017 academic year, Dartmouth received 685 transfer applications of which 5.1% were accepted, with an average SAT composite score of 1490, average composite ACT score of 34, and average college GPA of about 3.85. Dartmouth meets 100% of students' demonstrated financial need in order to attend the College, and currently admits all students, with the exception of internationals, on a need-blind basis.

Dartmouth guarantees to meet 100% of the demonstrated need of every admitted student who applies for financial aid at the time of admission. Dartmouth practices need-blind admissions for all applicants who are U.S. citizens, permanent residents, and undocumented students in the U.S. These applicants are admitted to the college without regard to their financial circumstances. For international students, financial need is taken into consideration as one of many factors at the time of admission. At Dartmouth, free tuition is provided for students from families with total incomes of $100,000 or less and possessing typical assets. In 2015, $88.8 million in need-based scholarships were awarded to Dartmouth students.

Dartmouth functions on a quarter system, operating year-round on four ten-week academic terms. The Dartmouth Plan (or simply "D-Plan") is an academic scheduling system that permits the customization of each student's academic year. All undergraduates are required to be in residence for the fall, winter, and spring terms of their freshman and senior years, as well as the summer term of their sophomore year. However, students may petition to alter this plan so that they may be off during their freshman, senior, or sophomore summer terms. During all terms, students are permitted to choose between studying on-campus, studying at an off-campus program, or taking a term off for vacation, outside internships, or research projects. The typical course load is three classes per term, and students will generally enroll in classes for 12 total terms over the course of their academic career.

The D-Plan was instituted in the early 1970s at the same time that Dartmouth began accepting female undergraduates. It was initially devised as a plan to increase the enrollment without enlarging campus accommodations, and has been described as "a way to put 4,000 students into 3,000 beds." Although new dormitories have been built since, the number of students has also increased and the D-Plan remains in effect. It was modified in the 1980s in an attempt to reduce the problems of lack of social and academic continuity.

Dartmouth is governed by a Board of Trustees comprising the college president ("ex officio"), the state governor ("ex officio"), 13 trustees nominated and elected by the board (called "charter trustees"), and eight trustees nominated by alumni and elected by the board ("alumni trustees"). The nominees for alumni trustee are determined by a poll of the members of the Association of Alumni of Dartmouth College, selecting from among names put forward by the Alumni Council or by alumni petition.

Although the board elected its members from the two sources of nominees in equal proportions between 1891 and 2007, the board decided in 2007 to add several new members, all charter trustees. In the controversy that followed the decision, the Association of Alumni filed a lawsuit, although it later withdrew the action. In 2008, the Board added five new charter trustees.

Dartmouth College is situated in the rural town of Hanover, New Hampshire, located in the Upper Valley along the Connecticut River in New England. Its campus is centered on a "Green", a former field of pine trees cleared in 1771. Dartmouth is the largest private landowner of the town of Hanover, and its total landholdings and facilities are worth an estimated $434 million. In addition to its campus in Hanover, Dartmouth owns of Mount Moosilauke in the White Mountains and a tract of land in northern New Hampshire known as the Second College Grant.

Dartmouth's campus buildings vary in age from Wentworth and Thornton Halls of the 1820s (the oldest surviving buildings constructed by the college) to new dormitories and mathematics facilities completed in 2006. Most of Dartmouth's buildings are designed in the Georgian colonial architecture style, a theme which has been preserved in recent architectural additions. The College has actively sought to reduce carbon emissions and energy usage on campus, earning it the grade of A- from the Sustainable Endowments Institute on its College Sustainability Report Card 2008.

A notable feature of the Dartmouth campus is its many trees which (despite Dutch elm disease) include some 200 American elms.

The college's creative and performing arts facility is the Hopkins Center for the Arts ("the Hop"). Opened in 1962, the Hop houses the College's drama, music, film, and studio arts departments, as well as a woodshop, pottery studio, and jewelry studio which are open for use by students and faculty. The building was designed by the famed architect Wallace Harrison, who would later design the similar-looking façade of Manhattan's Metropolitan Opera House at Lincoln Center. Its facilities include two theaters and one 900-seat auditorium. The Hop is also the location of all student mailboxes ("Hinman boxes") and the Courtyard Café dining facility. The Hop is connected to the Hood Museum of Art, arguably North America's oldest museum in continuous operation, and the Loew Auditorium, where films are screened.
In addition to its 19 graduate programs in the arts and sciences, Dartmouth is home to three separate graduate schools. The Geisel School of Medicine is located in a complex on the north side of campus and includes laboratories, classrooms, offices, and a biomedical library. The Dartmouth–Hitchcock Medical Center, located several miles to the south in Lebanon, New Hampshire, contains a 396-bed teaching hospital for the Medical School. The Thayer School of Engineering and the Tuck School of Business are both located at the end of Tuck Mall, west of the center of campus and near the Connecticut River. The Thayer School comprises two buildings; Tuck has seven academic and administrative buildings, as well as several common areas. The two graduate schools share a library, the Feldberg Business & Engineering Library.

Dartmouth's nine libraries are all part of the collective Dartmouth College Library, which comprises 2.48 million volumes and 6 million total resources, including videos, maps, sound recordings, and photographs. Its specialized libraries include the Biomedical Libraries, Evans Map Room, Feldberg Business & Engineering Library, Jones Media Center, Kresge Physical Sciences Library, Paddock Music Library, Rauner Special Collections Library, and Sherman Art Library. Baker-Berry Library is the main library at Dartmouth, consisting of a merger of the Baker Memorial Library (opened 1928) and the Berry Library (completed 2002). Located on the northern side of the Green, Baker's tower is an iconic symbol of the College.

Dartmouth's original sports field was the Green, where students played cricket and old division football during the 19th century. Today, two of Dartmouth's athletic facilities are located in the southeast corner of campus. The center of athletic life is the Alumni Gymnasium, which includes the Karl Michael Competition Pool and the Spaulding Pool, a state of the art fitness center, a weight room, and a 1/13th-mile (123 m) indoor track. Attached to Alumni Gymnasium is the Berry Sports Center, which contains basketball and volleyball courts (Leede Arena), as well as the Kresge Fitness Center. Behind the Alumni Gymnasium is Memorial Field, a 15,600-seat stadium overlooking Dartmouth's football field and track. The nearby Thompson Arena, designed by Italian engineer Pier Luigi Nervi and constructed in 1975, houses Dartmouth's ice rink. Also visible from Memorial Field is the Nathaniel Leverone Fieldhouse, home to the indoor track. The new softball field, Dartmouth Softball Park, was constructed in 2012, sharing parking facilities with Thompson arena and replacing Sachem Field, located over a mile from campus, as the primary softball facility.

Dartmouth's other athletic facilities in Hanover include the Friends of Dartmouth Rowing Boathouse and the old rowing house storage facility (both located along the Connecticut River), the Hanover Country Club, Dartmouth's oldest remaining athletic facility (established in 1899), and the Corey Ford Rugby Clubhouse. The college also maintains the Dartmouth Skiway, a skiing facility located over two mountains near the Hanover campus in Lyme Center, New Hampshire, that serves as the winter practice grounds for the Dartmouth ski team, which is a perennial contender for the NCAA Division I championship.

Beginning in the fall term of 2016, Dartmouth placed all undergraduate students in one of six House communities, similar to residential colleges, including Allen House, East Wheelock House, North Park House, School House, South House, and West House, alongside independent Living Learning Communities. Dartmouth used to have nine residential communities located throughout campus, instead of ungrouped dormitories or residential colleges. The dormitories varied in design from modern to traditional Georgian styles, and room arrangements range from singles to quads and apartment suites. Since 2006, the college has guaranteed housing for students during their freshman and sophomore years. More than 3,000 students elect to live in housing provided by college.

Campus meals are served by Dartmouth Dining Services, which operates 11 dining establishments around campus. Four of them are located at the center of campus in the Class of 1953 Commons, formerly Thayer Dining Hall.

The Collis Center is the center of student life and programming, serving as what would be generically termed the "student union" or "campus center." It contains a café, study space, common areas, and a number of administrative departments, including the Academic Skills Centre. Robinson Hall, next door to both Collis and Thayer, contains the offices of a number of student organizations including the Dartmouth Outing Club and "The Dartmouth" daily newspaper.

In 2006, "The Princeton Review" ranked Dartmouth third in its "Quality of Life" category, and sixth for having the "Happiest Students." Athletics and participation in the Greek system are the most popular campus activities. In all, Dartmouth offers more than 350 organizations, teams, and sports. The school is also home to a variety of longstanding traditions and celebrations and has a loyal alumni network; Dartmouth ranked #2 in "The Princeton Review" in 2006 for Best Alumni Network.

In 2014, Dartmouth College was the third highest in the nation in "total of reports of rape" on their main campus, with 42 reports of rape. The "Washington Post" attributed the high number of rape reports to the fact that a growing number of sexual assault victims feel comfortable enough to report sexual assaults that would have gone unreported in previous years. In 2015, the Huffington Post reported that Dartmouth College had the highest rate of bystander intervention of any college surveyed, with 57.7% of Dartmouth students reporting that they would take some sort of action if they saw someone acting in a "sexually violent or harassing manner," compared to 45.5% of students nationally.

Dartmouth fraternities have an extensive history of hazing and alcohol abuse, leading to police raids and accusations of sexual harassment.

Dartmouth's more than 200 student organizations and clubs cover a wide range of interests. In 2007, the college hosted eight academic groups, 17 cultural groups, two honor societies, 30 "issue-oriented" groups, 25 performing groups, 12 pre-professional groups, 20 publications, and 11 recreational groups. Notable student groups include the nation's largest and oldest collegiate outdoors club, the Dartmouth Outing Club, which includes the nationally recognized Big Green Bus; the campus's oldest a cappella group, The Dartmouth Aires; the controversial conservative newspaper "The Dartmouth Review"; and "The Dartmouth", arguably the nation's oldest university newspaper. "The Dartmouth" describes itself as "America's Oldest College Newspaper, Founded 1799."

Partially because of Dartmouth's rural, isolated location, the Greek system dating from the 1840s is one of the most popular social outlets for students. Dartmouth is home to 32 recognized Greek houses: 17 fraternities, 12 sororities, and three coeducational organizations. In 2007, roughly 70% of eligible students belonged to a Greek organization; since 1987, students have not been permitted to join Greek organizations until their sophomore year. Dartmouth College was among the first institutions of higher education to desegregate fraternity houses in the 1950s, and was involved in the movement to create coeducational Greek houses in the 1970s. In the early first decade of the 21st century, campus-wide debate focused on a Board of Trustees recommendation that Greek organizations become "substantially coeducational"; this attempt to change the Greek system eventually failed. The fraternities have an extensive history of hazing and alcohol abuse, leading to police raids and accusations of sexual harassment.

Dartmouth also has a number of secret societies, which are student- and alumni-led organizations often focused on preserving the history of the college and initiating service projects. Most prominent among them is the Sphinx society, housed in a prominent Egyptian tomb-like building near the center of campus. The Sphinx has been the subject of numerous rumors as to its facilities, practices, and membership.

The college has an additional classification of social/residential organizations known as undergraduate societies.

Approximately 20% of students participate in a varsity sport, and nearly 80% participate in some form of club, varsity, intramural, or other athletics. In 2007, Dartmouth College fielded 34 intercollegiate varsity teams: 16 for men, 16 for women, and coeducational sailing and equestrian programs. Dartmouth's athletic teams compete in the National Collegiate Athletic Association (NCAA) Division I eight-member Ivy League conference; some teams also participate in the Eastern College Athletic Conference (ECAC). As is mandatory for the members of the Ivy League, Dartmouth College does not offer athletic scholarships. In addition to the traditional American team sports (football, basketball, baseball, and ice hockey), Dartmouth competes at the varsity level in many other sports including track and field, softball, squash, sailing, tennis, rowing, soccer, skiing, and lacrosse.

The college also offers 26 club and intramural sports such as fencing, rugby, water polo, figure skating, boxing, volleyball, ultimate frisbee, and cricket, leading to a 75% participation rate in athletics among the undergraduate student body. The Dartmouth Fencing Team, despite being entirely self-coached, won the USACFC club national championship in 2014. The Dartmouth Men's Rugby Team, founded in 1951, has been ranked among the best collegiate teams in that sport, winning for example the Ivy Rugby Conference every year between 2008 and 2015. The figure skating team won the national championship five straight times from 2004 through 2008. In addition to the academic requirements for graduation, Dartmouth requires every undergraduate to complete a swim and three terms of physical education.

It is often pointed out that the charter of Dartmouth College, granted to Eleazar Wheelock in 1769, proclaims that the institution was created "for the education and instruction of Youth of the Indian Tribes in this Land in reading, writing and all parts of Learning... as well as in all liberal Arts and Sciences; and also of English Youth and any others." However, Wheelock primarily intended the college to educate White youth, and the few Native students that attended Dartmouth experienced much difficulty in an institution ostensibly dedicated to their education. The funds for the Charity School for Native Americans that preceded Dartmouth College were raised primarily by the efforts of a Native American named Samson Occom, and at least some of those funds were used to help found the college.

The college graduated only 19 Native Americans during its first two hundred years. In 1970, the college established Native American academic and social programs as part of a "new dedication to increasing Native American enrollment." Since then, Dartmouth has graduated over 1,000 Native American students from over 200 different tribes, more than the other seven Ivy League universities combined.

Dartmouth is well known for its fierce school spirit and many traditions. The college functions on a quarter system, and one weekend each term is set aside as a traditional celebratory event, known on campus as "big weekends" or "party weekends". In the fall term, Homecoming (officially called Dartmouth Night) is marked by a bonfire on the Green constructed by the freshman class. Winter term is celebrated by Winter Carnival, a tradition started in 1911 by the Dartmouth Outing Club to promote winter sports. This tradition is the oldest in the United States, and subsequently went on to catch on at other New England colleges. In the spring, Green Key is a weekend mostly devoted to campus parties and celebration.

The summer term was formerly marked by Tubestock, an unofficial tradition in which the students used wooden rafts and inner tubes to float on the Connecticut River. Begun in 1986, Tubestock was ended in 2006 by town ordinance. The Class of 2008, during their summer term on campus in 2006, replaced the defunct Tubestock with Fieldstock. This new celebration includes a barbecue, live music, and the revival of the 1970s and 1980s tradition of racing homemade chariots around the Green. Unlike Tubestock, Fieldstock is funded and supported by the College.

Another longstanding tradition is four-day, student-run Dartmouth Outing Club trips for incoming freshmen, begun in 1935. Each trip concludes at the Moosilauke Ravine Lodge. In 2011, over 96% of freshmen elected to participate.

Dartmouth's motto, chosen by Eleazar Wheelock, is "Vox clamantis in deserto". The Latin motto is literally translated as "A calling voice in the wilderness", but is more often rendered as "A voice crying out in the wilderness". The phrase appears five times in the Bible and is a reference to the college's location on what was once the frontier of European settlement. Richard Hovey's "Men of Dartmouth" was elected as the best of Dartmouth's songs in 1896, and became the school's official song in 1926. The song was retitled to "Alma Mater" in the 1980s when its lyrics were changed to refer to women as well as men.

Dartmouth's 1769 royal charter required the creation of a seal for use on official documents and diplomas. The college's founder Eleazar Wheelock designed a seal for his college bearing a striking resemblance to the seal of the Society for the Propagation of the Gospel, a missionary society founded in London in 1701, in order to maintain the illusion that his college was more for mission work than for higher education. Engraved by a Boston silversmith, the seal was ready by commencement of 1773. The trustees officially accepted the seal on August 25, 1773, describing it as:

On October 28, 1926, the trustees affirmed the charter's reservation of the seal for official corporate documents alone. The College Publications Committee commissioned noted typographer William Addison Dwiggins to create a line drawing version of the seal in 1940 that saw widespread use. Dwiggins' design was modified during 1957 to change the date from "1770" to "1769", to accord with the date of the college charter. The trustees commissioned a new set of dies with a date of "1769" to replace the old dies, now badly worn after almost two hundred years of use. The 1957 design continues to be used under trademark number 2305032.

On October 28, 1926, the trustees approved a "Dartmouth College Shield" for general use. Artist and engraver W. Parke Johnson designed this emblem on the basis of the shield that is depicted at the center of the original seal. This design does not survive. On June 9, 1944, the trustees approved another coat of arms based on the shield part of the seal, this one by Canadian artist and designer Thoreau MacDonald. That design was used widely and, like Dwiggins' seal, had its date changed from "1770" to "1769" around 1958. That version continues to be used under trademark registration number 3112676 and others.

College designer John Scotford made a stylized version of the shield during the 1960s, but it did not see the success of MacDonald's design. The shield appears to have been used as the basis of the shield of Dartmouth Medical School, and it has been reproduced in sizes as small as 20 micrometers across. The design has appeared on Rudolph Ruzicka's Bicentennial Medal (Philadelphia Mint, 1969) and elsewhere.

Dartmouth has never had an official mascot. The nickname "The Big Green," originating in the 1860s, is based on students' adoption of a shade of forest green ("Dartmouth Green") as the school's official color in 1866. Beginning in the 1920s, the Dartmouth College athletic teams were known by their unofficial nickname "the Indians", a moniker that probably originated among sports journalists. This unofficial mascot and team name was used until the early 1970s, when its use came under criticism. In 1974, the Trustees declared the "use of the [Indian] symbol in any form to be inconsistent with present institutional and academic objectives of the College in advancing Native American education." Some alumni and students, as well as the conservative student newspaper, "The Dartmouth Review", have sought to return the Indian symbol to prominence, but never succeeded in doing so.

Various student initiatives have been undertaken to adopt a mascot, but none has become "official." One proposal devised by the college humor magazine the "Dartmouth Jack-O-Lantern" was Keggy the Keg, an anthropomorphic beer keg who makes occasional appearances at college sporting events. Despite student enthusiasm for Keggy, the mascot has received approval from only the student government. In November 2006, student government attempted to revive the "Dartmoose" as a potential replacement amid renewed controversy surrounding the former unofficial Indian mascot.

Dartmouth's alumni are known for their devotion to the college. Most start by giving to the Senior Class Gift. According to a 2008 article in "The Wall Street Journal" based on data from payscale.com, Dartmouth graduates also earn higher median salaries at least 10 years after graduation than alumni of any other American university surveyed.

By 2008, Dartmouth had graduated 238 classes of students and has over 60,000 living alumni in a variety of fields.

Nelson A. Rockefeller, 41st Vice President of the United States and 49th Governor of New York, graduated "cum laude" from Dartmouth with a degree in economics in 1930. Over 164 Dartmouth graduates have served in the United States Senate and United States House of Representatives, such as Massachusetts statesman Daniel Webster. Cabinet members of American presidents include Attorney General Amos T. Akerman, Secretary of Defense James V. Forrestal, Secretary of Labor Robert Reich, former Secretary of the Treasury Henry Paulson, and former Secretary of the Treasury Timothy Geithner. C. Everett Koop was the Surgeon General of the United States under President Ronald Reagan. Two Dartmouth alumni have served as justices on the Supreme Court of the United States: Salmon P. Chase and Levi Woodbury. Eugene Norman Veasey (class of 1954) served as the Chief Justice of Delaware. The 46th and current Governor of Pennsylvania Tom Wolf, and the 42nd and current Governor of Illinois, businessman Bruce Rauner, are also Dartmouth alumni.

In literature and journalism, Dartmouth has produced thirteen Pulitzer Prize winners: Thomas M. Burton, Richard Eberhart, Dan Fagin, Paul Gigot, Frank Gilroy, Jake Hooker, Nigel Jaquiss, Joseph Rago, Martin J. Sherwin, David K. Shipler, David Shribman, and Justin Harvey Smith.

Other authors and media personalities include ABC Senior White House correspondent Jake Tapper, novelist and founding editor of "The Believer" Heidi Julavits, "Dean of rock critics" Robert Christgau, National Book Award winners Louise Erdrich and Phil Klay, novelist/screenwriter Budd Schulberg, political analyst Dinesh D'Souza, radio talk show host Laura Ingraham, commentator Mort Kondracke, and journalist James Panero. Norman Maclean, a former professor at the University of Chicago and author of "A River Runs Through It and Other Stories", graduated from Dartmouth in 1924. Theodor Geisel, better known as children's author Dr. Seuss, was a member of the class of 1925.

In the area of religion and theology, Dartmouth alumni include priests and ministers Ebenezer Porter, Jonathan Clarkson Gibbs, Caleb Sprague Henry, Arthur Whipple Jenks, Solomon Spalding, and Joseph Tracy; and rabbis Marshall Meyer, Arnold Resnicoff, and David E. Stern. Hyrum Smith, brother of Mormon Prophet Joseph Smith, attended the college in his teens. He was Patriarch of the LDS Church.

Dartmouth alumni in academia include Stuart Kauffman and Jeffrey Weeks, both recipients of MacArthur Fellowships (commonly called "genius grants"). Dartmouth has also graduated three Nobel Prize winners: Owen Chamberlain (Physics, 1959), K. Barry Sharpless (Chemistry, 2001), and George Davis Snell (Physiology or Medicine, 1980). Educators include founder and first president of Bates College, Oren Burbank Cheney (1839), the current chancellor of the University of California, San Diego, Marye Anne Fox (PhD. in Chemistry, 1974), founding president of Vassar College Milo Parker Jewett, founder and first president of Kenyon College Philander Chase, first professor of Wabash College Caleb Mills, and former president of Union College Charles Augustus Aiken. Nine of Dartmouth's 17 presidents were alumni of the College.

Dartmouth alumni serving as CEOs or company presidents and executives include Charles Alfred Pillsbury, founder of the Pillsbury Company and patriarch of the Pillsbury family, Sandy Alderson (San Diego Padres), John Donahoe (eBay), Louis V. Gerstner, Jr. (IBM), Charles E. Haldeman (Putnam Investments), Donald J. Hall, Sr. (Hallmark Cards), Jeffrey R. Immelt (General Electric), Gail Koziara Boudreaux (United Health Care), Grant Tinker (NBC), and Brian Goldner (Hasbro).

In film, entertainment, and television, Dartmouth is represented by Budd Schulberg, Academy Award-winning screenwriter of "On the Waterfront", Michael Phillips, who won the Academy Award for best picture as co-producer of "The Sting", Rachel Dratch, a cast member of "Saturday Night Live", Shonda Rhimes creator of "Grey's Anatomy, Private Practice" and "Scandal", Chris Meledandri Executive Producer of "Ice Age", "Horton Hears a Who!", and "Despicable Me", and the title character of "Mister Rogers' Neighborhood", Fred Rogers. Other notable film and television figures include Sarah Wayne Callies ("Prison Break"), Emmy Award winner Michael Moriarty, Andrew Shue of "Melrose Place", Aisha Tyler of "Friends" and "24", Connie Britton of "Spin City", "The West Wing" and "Friday Night Lights", Mindy Kaling of "The Office" and "The Mindy Project", and David Harbour of "Stranger Things".

A number of Dartmouth alumni have found success in professional sports. In baseball, Dartmouth alumni include All-Star and three-time Gold Glove winner and manager Brad Ausmus, All-Star reliever Mike Remlinger, and pitcher Kyle Hendricks. Professional football players include former Miami Dolphins quarterback Jay Fiedler, linebacker Reggie Williams, three-time Pro Bowler Nick Lowery, quarterback Jeff Kemp, and Tennessee Titans tight end Casey Cramer, plus Miami Dolphins defensive coordinator Matt Burke. Dartmouth has also produced a number of Olympic competitors. Adam Nelson won the silver medal in the shot put in the 2000 Sydney Olympics and the gold medal at the 2004 Athens Olympics to go along with his gold medal in the 2005 World Championships in Athletics in Helsinki. Kristin King and Sarah Parsons were members of the United States' 2006 bronze medal-winning ice hockey team. Cherie Piper, Gillian Apps, and Katie Weatherston were among Canada's ice hockey gold medalists in 2006.

Dick Durrance and Tim Caldwell competed for the United States in skiing in the 1936 and 1976 Winter Olympics, respectively. Arthur Shaw, Earl Thomson, Edwin Myers, Marc Wright, Adam Nelson, Gerry Ashworth, and Vilhjálmur Einarsson have all won medals in track and field events. Former heavyweight rower Dominic Seiterle is a member of the Canadian national rowing team and won a gold medal at the 2008 Summer Olympics in the men's 8+ event.

Dartmouth College has appeared in or been referenced by a number of popular media. Most notably, the 1978 comedy film "National Lampoon's Animal House" was co-written by Chris Miller '63, and is based loosely on a series of stories he wrote about his fraternity days at Dartmouth. In a CNN interview, John Landis said the movie was "based on Chris Miller's real fraternity at Dartmouth", Alpha Delta Phi. Dartmouth's Winter Carnival tradition was the subject of the 1939 film "Winter Carnival" starring Ann Sheridan and written by Budd Schulberg '36 and F. Scott Fitzgerald.



</doc>
<doc id="8419" url="https://en.wikipedia.org/wiki?curid=8419" title="Dartmouth, Devon">
Dartmouth, Devon

Dartmouth is a town and civil parish in the English county of Devon. It is a tourist destination set on the western bank of the estuary of the River Dart, which is a long narrow tidal ria that runs inland as far as Totnes. It lies within the South Devon Area of Outstanding Natural Beauty and South Hams District, and had a population of 5,512 in 2001, reducing to 5,064 at the 2011 census There are two electoral wards in the "Dartmouth" area (Townstal & Kingswear). Their combined population at the above census was 6,822.

In 1086, the Domesday Book lists "Dunestal" as the only settlement in the area which now makes up the parish of Dartmouth. It was held by Walter of Douai. It paid tax on half a hide, and had two plough teams, two slaves, five villagers and four smallholders. There were six cattle, 40 sheep and 15 goats. At this time Townstal (as the name became) was apparently a purely agricultural settlement, centred around the church. Walter of Douai rebelled against William II, and his lands were confiscated and added to the honour of Marshwood (Dorset), which sublet Townstal and Dartmouth to the FitzStephens. It was probably during the early part of their proprietorship that Dartmouth began to grow as a port, as it was of strategic importance as a deep-water port for sailing vessels. The port was used as the sailing point for the Crusades of 1147 and 1190, and Warfleet Creek, close to Dartmouth Castle is supposed by some to be named for the vast fleets which assembled there. Dartmouth was a home of the Royal Navy from the reign of Edward III and was twice surprised and sacked during the Hundred Years' War, after which the mouth of the estuary was closed every night with a great chain. The narrow mouth of the Dart is protected by two fortified castles, Dartmouth Castle and Kingswear Castle. Originally Dartmouth's only wharf was Bayard's Cove, a relatively small area protected by a fort at the southern end of the town.

In 1373 Geoffrey Chaucer visited and among the pilgrims in his Canterbury Tales

Notwithstanding Dartmouth's connections with the crown and respectable society, it was a major base for privateering in medieval times. John Hawley or Hauley, a licensed privateer and sometime mayor of Dartmouth is reputed to be a model for Chaucer's "schipman".

The earliest street in Dartmouth to be recorded by name (in the 13th century) is Smith Street. Several of the houses on the street are originally late 16th century or early 17th century and probably rebuilt on the site of earlier medieval dwellings. The street name undoubtedly derives from the smiths and shipwrights who built and repaired ships here when the tidal waters reached as far as this point. Smith Street was also the site of the town pillory in medieval times.

The first church in the parish was St Clement's, Townstal, which may have existed in some form before the 1190s. It was granted by the FitzStephens to Torre Abbey in about 1198, the Abbey having been founded in 1196, and the present stone-built church was probably started shortly after this.

Manorial transactions are first recorded in 1220, when the manor house was at Norton, about half a mile west of Townstal. Names of occupations also started to appear, including taverner, tailor, coggar, korker, goldsmith, glover, skinner and baker. The "Fosse", now Foss Street, a dam across the creek known later as The Mill Pool, was first mentioned in 1243. The flow of water out of the pool through the Mill Gullet powered a tidal mill. The dam was used as an unofficial footpath linking Clifton, to the south, with Hardness, to the north. Before this it was necessary to go westwards to the head of the creek at Ford to travel between the two settlements. The lord of the manor was given the rights to hold a weekly market and an annual fair in 1231. In 1281, a legal case proved that the Lord of Totnes had the right to charge tolls on ships using the river, and this right was bought by Nicholas of Tewkesbury in 1306, who conveyed the town, river and port to the king in 1327, so making Dartmouth a Royal Borough. The king gave the river to the Duchy of Cornwall in 1333, who still own the "fundus" or bed of the river. In 1335 Edward III granted Dartmouth to Joan of Carew, whose husband was Lord of Stoke Fleming, and almost immediately she obediently passed the lordship to Guy de Bryan, one of the king's leading ministers. In 1341, the town was granted a Royal Charter, which allowed for the election of a mayor. The borough was required to provide two ships for forty days per year. After 1390, no more is heard of lordship rights, and the borough became effectively independent of any lord.

St Saviour's Church was constructed in 1335 and consecrated in 1372. It contains a pre-Reformation oak rood screen built in 1480 and several monuments including the tomb of John Hawley (d. 1408) and his two wives, covered with a large brass plate effigy of all three. A large medieval ironwork door is decorated with two leopards of the Plantagenets and is possibly the original portal. Although it is dated "1631", this is thought to be the date of a subsequent refurbishment coincidental with major renovations of the church in the 17th century. The gallery of the church is decorated with the heraldic crests of prominent local families and is reputed to be constructed of timbers from ships captured during the defeat of the Spanish Armada, although this has not been categorically substantiated. An engraving of the interior of the church and showing the screen provided the inspiration for Letitia Elizabeth Landon's poetical illustration "Dartmouth Church" in Fisher's Drawing Room scrap Book, 1833.
In mediaeval times, land access from the Totnes direction passed the manor at Norton and the parish church at Townstal before falling steeply along what are now Church Road, Mount Boone and Ridge Hill to the river at Hardness. There were steeper routes via Townstal Hill and Clarence Street and also via Brown's Hill. These were all too steep for vehicles, so the only land access was by packhorse. In 1671 there is the first mention of the building of the "New Ground". A previously existing sandbank was built up using ships' ballast, and a quay wall was built around it to provide more mooring space. The area proved too unstable to be built on, and is now the Royal Avenue Gardens. It was originally linked to the corner of the Quay by a bridge, opposite Duke Street. At the other end of The Quay, Spithead extended into the river for a few yards. 
In 1592 the "Madre de Deus", a Portuguese treasure ship captured by the English in the Azores, docked at Dartmouth Harbour. It attracted all manner of traders, dealers, cutpurses and thieves and by the time Sir Walter Raleigh arrived to reclaim the Crown's share of the loot, a cargo estimated at half a million pounds had been reduced to £140,000. Still, ten freighters were needed to carry the treasure to London.

Henry Hudson put into Dartmouth on his return from North America, and was arrested for sailing under a foreign flag. The Pilgrim Fathers put into Dartmouth's Bayard's Cove, en route from Southampton to America. They rested a while before setting off on their journey in the "Mayflower" and the "Speedwell" on 20 August 1620. About 300 miles west of Land's End, upon realising that the "Speedwell" was unseaworthy, it returned to Plymouth. The "Mayflower" departed alone to complete the crossing to Cape Cod. Dartmouth's sister city is Dartmouth, Massachusetts.

The town contains many medieval and Elizabethan streetscapes and is a patchwork of narrow lanes and stone stairways. A significant number of the historic buildings are listed. One of the most obvious is the Butterwalk, built 1635 to 1640. Its intricately carved wooden fascia is supported on granite columns. Charles II held court in the Butterwalk whilst sheltering from storms in 1671 in a room which now forms part of Dartmouth Museum. Much of the interior survives from that time.

The Royal Castle Hotel was built in 1639 on the then new quay. The building was re-fronted in the 19th century, and as the new frontage is itself listed, it is not possible to see the original which lies beneath. A claimant for the oldest building is a former merchant's house in Higher Street, now a Good Beer Guide listed public house called "the Cherub", built circa 1380. Agincourt House (next to the Lower Ferry) is also 14th century.

Dartmouth sent numerous ships to join the English fleet that attacked the Spanish Armada, including the Roebuck, Crescent and Hart. The Nuestra Señora del Rosario, the Spanish Armada's "payship" commanded by Admiral Pedro de Valdés, was captured along with all its crew by Sir Francis Drake. It was reportedly anchored in the River Dart for more than a year and the crew were used as labourers on the nearby Greenway Estate which was the home of Sir Humphrey Gilbert and his half-brother Sir Walter Raleigh. Greenway was later the home of Dame Agatha Christie.

The remains of a fort at Gallants Bower just outside the town are some of the best preserved remains of a Civil War defensive structure. The fort was built by Royalist occupation forces in c. 1643 to the south east of the town, with a similar fort at Mount Ridley on the opposite slopes of what is now Kingswear. The Parliamentarian General Fairfax attacked from the north in 1646, taking the town and forcing the Royalists to surrender, after which Gallants Bower was demolished.

Before 1671, what is now the town centre was almost entirely tidal mud flats. The New Road (now Victoria Road) was constructed across the bed of the (silted up) Mill Pool and up the Ford valley after 1823. Spithead was extended in 1864 when the Dartmouth and Torbay Railway arrived in Kingswear and a pontoon was constructed, linked to Spithead by a bridge. The railway directors and others formed the Dartmouth Harbour Commissioners. 
At this time, all the roads in those parts of Dartmouth which were not land reclamations were very narrow. In 1864-7 Higher Street was widened into Southtown and linked to Lower Street, which was also widened, with the northern part renamed Fairfax Place. Some of the buildings were rebuilt further back with decorative frontages.
In 1881 the Harbour Commissioners produced a scheme for an embankment or esplanade from near the Lower Ferry to Hardness, across the remains of The Pool, to provide an attraction for tourists and further mooring space. It was completed in 1885 after much disagreement between the Borough, the Commissioners and the Railway (now the Great Western Railway). A new station was also built at this time. The building of the Embankment left a section of river isolated between Spithead and the New Ground, which is known as The Boatfloat, and is linked to the river by a bridge for small vessels under the road.

The coming of steam ships led to Dartmouth being used as a bunkering port, with coal being brought in by ship or train. Coal lumpers were members of gangs, who competed to bunker the ships by racing to be first to a ship. This led to the men living as close as possible to the river, and their tenements became grossly overcrowded, with the families living in slum conditions, with up to 15 families in one house, one family to a room.

The Royal National Lifeboat Institution opened the Dart Lifeboat Station at the Sand Quay in 1878, but it was closed in 1896. In all this time only one effective rescue was made by the lifeboat.

The area to the north of Ridge Hill was a shallow and muddy bay ("Coombe Mud") with a narrow road running along the shore linking with the Higher Ferry. The mud was a dumping ground for vessels, including a submarine. The reclamation was completed in 1937 by the extension of the Embankment and the reclamation of the mud behind it, which became Coronation Park. 

In the 1920s, aided by government grants, the council made a start on clearing the slums. This was aided by the decline in the use of coal as a fuel for ships. The slums were demolished, and the inhabitants were rehoused in new houses in the Britannia Avenue area, to the west of the old village or hamlet of Townstal. The process was interrupted by the second world war, but was resumed with the construction of many prefabs, and later more houses. Community facilities were minimal at first, but a central area was reserved for a church, which was used by the Baptists and opened in 1954, together with a speedway track. The latter was later used for housing, but a new community centre was opened nearby, together with a leisure centre, an outdoor swimming pool, and later an indoor pool, and supermarkets. There are also light industrial units.

In the latter part of the Second World War the town was a base for American forces and one of the departure points for Utah Beach in the D Day landings. Slipways and harbour improvements were also constructed. Much of the surrounding countryside and notably Slapton Sands was closed to the public while it was used by US troops for practise landings and manoeuvres. 
Between 1985 and 1990 the Embankment was widened by 6 metres and raised to prevent flooding at spring tides. A tidal lock gate was provided at the Boatfloat bridge, which could be closed at such times.

Dart Lifeboat Station was reopened in 2007, the first time that a lifeboat had been stationed in the town since 1896. It has initially been kept in a temporary building in Coronation Park.

In 2010, a fire seriously damaged numerous historical properties in Fairfax Place and Higher Street. Several were Tudor and Grade I or Grade II listed buildings.

The town was an ancient borough, incorporated by Edward III, known formally as Clifton-Dartmouth-Hardness, and consisting of the three parishes of "St Petrox", "St Saviour" and "Townstal", and incorporating the hamlets of Ford, Old Mill and Norton. It was reformed under the Municipal Corporations Act 1835. The town returned two members of parliament from the 13th century until 1835, after which one MP was elected until the town was disenfranchised in 1868. It remained a municipal borough until 1974, when it was merged into the South Hams district, and became a successor parish of Dartmouth with a town council.

Dartmouth Town Council is the lowest of three tiers of local government. It consists of 16 councillors representing the two wards of Clifton and Townstal. At the second tier, Dartmouth forms part of the Dartmouth and Kingswear ward of South Hams District Council, which returns three councillors. At the upper tier of local government Dartmouth and Kingswear Electoral Division elects one member to Devon County Council.

The Port of Dartmouth Royal Regatta takes place annually over three days at the end of August. The event sees the traditional regatta boat races along with markets, fun fairs, community games, musical performances, air displays including the Red Arrows and fireworks. A Royal Navy guard ship is often present at the event.
Other cultural events include beer festivals in February and July (the latter in Kingswear), a music festival and an art and craft weekend in June, a food festival in October and a Christmas candlelit event.

The Flavel Centre incorporates the public library and performance spaces, featuring films, live music and comedy and exhibitions.

Bayard's Cove has been used in several television productions, including "The Onedin Line" a popular BBC television drama series that ran from 1971 to 1980. Many of the scenes from the BBC's popular series 'Down to Earth', starring Ricky Tomlinson, were filmed at various locations around the town.

Notable tourist attractions include the Dartmouth Royal Naval College, Dartmouth Castle and the Dartmouth Steam Railway which terminates at Kingswear on the opposite bank of the river.

Boat cruises to nearby places along the coast (such as Torbay and Start Bay) and up the river (to Totnes, Dittisham and the Greenway Estate) are provided by several companies. The paddlesteamer PS Kingswear Castle returned to the town in 2013. The South West Coast Path National Trail passes through the town, and also through extensive National Trust coastal properties at Little Dartmouth and Brownstone (Kingswear). The Dart Valley Trail starts in Dartmouth, with routes either side of the River Dart as far as Dittisham, and continuing to Totnes via Cornworthy, Tuckenhay and Ashprington. The area has long been well regarded for yachting, and there are extensive marinas at Sandquay, Kingswear and Noss (approximately one mile north of Kingswear).

The nearest Met Office weather station is Slapton, about 5 miles south-south west of Dartmouth and a similar distance from the coast. As with the rest of the British Isles and South West England, the area experiences a maritime climate with warm summers and mild winters - this is particularly pronounced due to its position near the coast - extremes range from a record low of just in January 1987 up to a record high of during June 1976.

Dartmouth is linked to Kingswear, on the other side of the River Dart, by three ferries. The Higher Ferry and the Lower Ferry are both vehicular ferries. The Passenger Ferry, as its name suggests, carries only passengers, principally to connect with the Dartmouth Steam Railway at Kingswear railway station. The nearest bridge across the Dart is in Totnes, some away by road.

The A379 road runs through Dartmouth, linking the town to Slapton and Kingsbridge to the southwest and to Torbay to the east across the Higher Ferry. The A3122 connects Dartmouth to a junction with the A381, and hence to both Totnes and a more direct route to Kingsbridge.
Stagecoach Devon provides local town bus services and links to Plymouth, Totnes and Exeter, and Kingsbridge. In addition Stagecoach Devon provides links to the Torbay resorts of Brixham, Paignton and Torquay from Kingswear via the ferry.

No railway has ever run to Dartmouth, but the town does have a railway station, opened on 31st March 1890 to replace the original facility on the pontoon, although it is now a restaurant. The railway line to Kingswear was opened in 1864. As a result of shortage of capital, a deviation from the original scheme to run the line from Churston to Greenway with a steamer service to Dartmouth was proposed, but defeated in Parliament. It had been suggested that this could, at a later date, be used as a jumping off point for a bridge to the west bank of the Dart and a line direct to Dartmouth.In 1900, a Light Railway scheme was proposed for a crossing of the Dart near Maypool to join another line from Totnes and then proceed to Kingsbridge and Yealmpton, with a branch to Salcombe. This was also defeated by lack of funds. The railway terminated at a station called "Kingswear for Dartmouth" (now on the Dartmouth Steam Railway) and a ferry took passengers across the river to the station at Dartmouth railway station, which had a dedicated pontoon. British Railways formally closed the line to mainline passenger trains in 1973, but it immediately re-opened as a heritage line and has run as one ever since.

The town is home to the Royal Navy's officer training college (Britannia Royal Naval College), where all officers of the Royal Navy and many foreign naval officers are trained.

Dartmouth has one secondary school — formerly (Dartmouth Community College) now Dartmouth Academy — an all-through school for those aged 3–16, and two primary schools: (Dartmouth Primary school (now part of Dartmouth Academy) and St John the Baptist R.C. Primary School). Dartmouth Community College and Dartmouth Primary School are part of the Dartmouth Learning Campus; as from September 2007, Dartmouth Community College is part of a federation with Dartmouth Primary School and Nursery, meaning that the two schools share one governing body for pupils aged 1 to 16. Dartmouth also has a pre-school in the centre of town, established for over 40 years and based in the old Victorian school rooms at South Ford Road. It provides care for 2- to 5-year-olds and is run as a charitable organisation.

Dartmouth has a Non-League football club Dartmouth A.F.C. who play at Long Cross.

Dartmouth also hosts the annual "World Indoor Rally Championship", based on slot car racing in the late summer.

At the end of August and early September there is the annual Port of Dartmouth Royal Regatta.

Since 1905 Dartmouth has had a greenhouse as part of the Royal Avenue Gardens. In May 2013 this building, used for the previous 10 years by Dartmouth in Bloom, a not-for-profit organisation affiliated with Britain in Bloom, was closed as structurally unsound. There are proposals to restore the greenhouse to its prior Edwardian style.

Thomas Newcomen, the inventor of the atmospheric engine – the first successful steam-powered pumping engine – was born in Dartmouth in 1663. The location of his house in Lower Street is marked with a plaque, although the building itself was demolished (and elements incorporated into local architect Thomas Lidstone's house on Ridge Hill) in the 19th century to make way for a new road which was named after Newcomen. An 18th-century working Newcomen steam engine is on display in the town.

The town was home to the civil engineer and calculating prodigy George Parker Bidder (1806–1878), who is notable for his work on railways over much of the world, as well as the docks of the East End in the Port of London. Bidder served on the town council, and his expertise was instrumental in draining the area which is now the centre of the town. He also undertook pioneering work with Samuel Lake on steam trawling whilst living in the town. Bidder died at his home at Paradise Point near Warfleet Creek and is buried at nearby Stoke Fleming.

Flora Thompson lived in Above Town between 1928 and 1940, writing "Lark Rise" and "Over to Candleford" during this time. The books were later combined into a single volume with "Candleford Green" and published as "Lark Rise to Candleford". She is buried at Longcross Cemetery.

The stage and film actress Rachel Kempson (1910–2003) was born in Dartmouth. She was the wife of Sir Michael Redgrave and mother of Vanessa, Lynn and Corin, and published her autobiography, "Life Among the Redgraves", in 1988.

Gordon Onslow Ford (1912–2003), a leading British surrealist painter, attended the Royal Naval College.

Sir John Harvey Jones (1924-2008), Businessman and television presenter, attended the Royal Naval College.

Christopher Robin Milne, son of A. A. Milne, after whom the character Christopher Robin in the Winnie-the-Pooh books was named, used to own the Harbour Bookshop. The bookshop was reported as facing closure in September 2011 and the report was fulfilled.

Many local businesses were commemorated in a special edition of the card game Happy Families produced locally in 1987, created to raise funds locally. A copy is held in Dartmouth Museum.

Theodore Veale, recipient of the Victoria Cross during the First World War.



</doc>
<doc id="8420" url="https://en.wikipedia.org/wiki?curid=8420" title="Dodo">
Dodo

The dodo ("Raphus cucullatus") is an extinct flightless bird that was endemic to the island of Mauritius, east of Madagascar in the Indian Ocean. The dodo's closest genetic relative was the also extinct Rodrigues solitaire, the two forming the subfamily Raphinae of the family of pigeons and doves. The closest living relative of the dodo is the Nicobar pigeon. A white dodo was once thought to have existed on the nearby island of Réunion, but this is now thought to have been confusion based on the Réunion ibis and paintings of white dodos.

Subfossil remains show the dodo was about tall and may have weighed in the wild. The dodo's appearance in life is evidenced only by drawings, paintings, and written accounts from the 17th century. Because these vary considerably, and because only some illustrations are known to have been drawn from live specimens, its exact appearance in life remains unresolved, and little is known about its behaviour. Though the dodo has historically been considered fat and clumsy, it is now thought to have been well-adapted for its ecosystem. It has been depicted with brownish-grey plumage, yellow feet, a tuft of tail feathers, a grey, naked head, and a black, yellow, and green beak. It used gizzard stones to help digest its food, which is thought to have included fruits, and its main habitat is believed to have been the woods in the drier coastal areas of Mauritius. One account states its clutch consisted of a single egg. It is presumed that the dodo became flightless because of the ready availability of abundant food sources and a relative absence of predators on Mauritius.

The first recorded mention of the dodo was by Dutch sailors in 1598. In the following years, the bird was hunted by sailors and invasive species, while its habitat was being destroyed. The last widely accepted sighting of a dodo was in 1662. Its extinction was not immediately noticed, and some considered it to be a mythical creature. In the 19th century, research was conducted on a small quantity of remains of four specimens that had been brought to Europe in the early 17th century. Among these is a dried head, the only soft tissue of the dodo that remains today. Since then, a large amount of subfossil material has been collected on Mauritius, mostly from the Mare aux Songes swamp. The extinction of the dodo within less than a century of its discovery called attention to the previously unrecognised problem of human involvement in the disappearance of entire species. The dodo achieved widespread recognition from its role in the story of "Alice's Adventures in Wonderland", and it has since become a fixture in popular culture, often as a symbol of extinction and obsolescence.

The dodo was variously declared a small ostrich, a rail, an albatross, or a vulture, by early scientists. In 1842, Danish zoologist Johannes Theodor Reinhardt proposed that dodos were ground pigeons, based on studies of a dodo skull he had discovered in the collection of the Natural History Museum of Denmark. This view was met with ridicule, but was later supported by English naturalists Hugh Edwin Strickland and Alexander Gordon Melville in their 1848 monograph "The Dodo and Its Kindred", which attempted to separate myth from reality. After dissecting the preserved head and foot of the specimen at the Oxford University Museum and comparing it with the few remains then available of the extinct Rodrigues solitaire ("Pezophaps solitaria") they concluded that the two were closely related. Strickland stated that although not identical, these birds shared many distinguishing features of the leg bones, otherwise known only in pigeons.

Strickland and Melville established that the dodo was anatomically similar to pigeons in many features. They pointed to the very short keratinous portion of the beak, with its long, slender, naked basal part. Other pigeons also have bare skin around their eyes, almost reaching their beak, as in dodos. The forehead was high in relation to the beak, and the nostril was located low on the middle of the beak and surrounded by skin, a combination of features shared only with pigeons. The legs of the dodo were generally more similar to those of terrestrial pigeons than of other birds, both in their scales and in their skeletal features. Depictions of the large crop hinted at a relationship with pigeons, in which this feature is more developed than in other birds. Pigeons generally have very small clutches, and the dodo is said to have laid a single egg. Like pigeons, the dodo lacked the vomer and septum of the nostrils, and it shared details in the mandible, the zygomatic bone, the palate, and the hallux. The dodo differed from other pigeons mainly in the small size of the wings and the large size of the beak in proportion to the rest of the cranium.

Throughout the 19th century, several species were classified as congeneric with the dodo, including the Rodrigues solitaire and the Réunion solitaire, as "Didus solitarius" and "Raphus solitarius", respectively ("Didus" and "Raphus" being names for the dodo genus used by different authors of the time). An atypical 17th-century description of a dodo and bones found on Rodrigues, now known to have belonged to the Rodrigues solitaire, led Abraham Dee Bartlett to name a new species, "Didus nazarenus", in 1852. Based on solitaire remains, it is now a synonym of that species. Crude drawings of the red rail of Mauritius were also misinterpreted as dodo species; "Didus broeckii" and "Didus herberti".

For many years the dodo and the Rodrigues solitaire were placed in a family of their own, the Raphidae (formerly Dididae), because their exact relationships with other pigeons were unresolved. Each was also placed in its own monotypic family (Raphidae and Pezophapidae, respectively), as it was thought that they had evolved their similarities independently. Osteological and DNA analysis has since led to the dissolution of the family Raphidae, and the dodo and solitaire are now placed in their own subfamily, Raphinae, within the family Columbidae.

In 2002, American geneticist Beth Shapiro and colleagues analysed the DNA of the dodo for the first time. Comparison of mitochondrial cytochrome "b" and 12S rRNA sequences isolated from a tarsal of the Oxford specimen and a femur of a Rodrigues solitaire confirmed their close relationship and their placement within the Columbidae. The genetic evidence was interpreted as showing the Southeast Asian Nicobar pigeon ("Caloenas nicobarica") to be their closest living relative, followed by the crowned pigeons ("Goura") of New Guinea, and the superficially dodo-like tooth-billed pigeon ("Didunculus strigirostris") from Samoa (its scientific name refers to its dodo-like beak). This clade consists of generally ground-dwelling island endemic pigeons. The following cladogram shows the dodo's closest relationships within the Columbidae, based on Shapiro et al., 2002:
A similar cladogram was published in 2007, inverting the placement of "Goura" and "Dicunculus" and including the pheasant pigeon ("Otidiphaps nobilis") and the thick-billed ground pigeon ("Trugon terrestris") at the base of the clade. The DNA used in these studies was obtained from the Oxford specimen, and since this material is degraded, and no usable DNA has been extracted from subfossil remains, these findings still need to be independently verified. Based on behavioural and morphological evidence, Jolyon C. Parish proposed that the dodo and Rodrigues solitaire should be placed in the subfamily Gourinae along with the "Groura" pigeons and others, in agreement with the genetic evidence. In 2014, DNA of the only known specimen of the recently extinct spotted green pigeon ("Caloenas maculata") was analysed, and it was found to be a close relative of the Nicobar pigeon, and thus also the dodo and Rodrigues solitaire.

The 2002 study indicated that the ancestors of the dodo and the solitaire diverged around the Paleogene-Neogene boundary. The Mascarene Islands (Mauritius, Réunion, and Rodrigues), are of volcanic origin and are less than 10 million years old. Therefore, the ancestors of both birds probably remained capable of flight for a considerable time after the separation of their lineage. The Nicobar and spotted green pigeon were placed at the base of a lineage leading to the Raphinae, which indicates the flightless raphines had ancestors that were able to fly, were semi-terrestrial, and inhabited islands. This in turn supports the hypothesis that the ancestors of those birds reached the Mascarene islands by island hopping from South Asia. The lack of mammalian herbivores competing for resources on these islands allowed the solitaire and the dodo to attain very large sizes and flightlessness. Despite its divergent skull morphology and adaptations for larger size, many features of its skeleton remained similar to those of smaller, flying pigeons. Another large, flightless pigeon, the Viti Levu giant pigeon ("Natunaornis gigoura"), was described in 2001 from subfossil material from Fiji. It was only slightly smaller than the dodo and the solitaire, and it too is thought to have been related to the crowned pigeons.

One of the original names for the dodo was the Dutch ""Walghvogel"", first used in the journal of Vice Admiral Wybrand van Warwijck, who visited Mauritius during the Second Dutch Expedition to Indonesia in 1598. "Walghe" means "tasteless", "insipid", or "sickly", and "vogel" means "bird". The name was translated into German as "Walchstök" or "Walchvögel", by Jakob Friedlib. The original Dutch report titled "Waarachtige Beschryving" was lost, but the English translation survived:
Another account from that voyage, perhaps the first to mention the dodo, states that the Portuguese referred to them as penguins. The meaning may not have been derived from "penguin" (the Portuguese referred to them as ""fotilicaios"" at the time), but from "pinion", a reference to the small wings. The crew of the Dutch ship "Gelderland" referred to the bird as "Dronte" (meaning "swollen") in 1602, a name that is still used in some languages. This crew also called them "griff-eendt" and "kermisgans", in reference to fowl fattened for the Kermesse festival in Amsterdam, which was held the day after they anchored on Mauritius.

The etymology of the word "dodo" is unclear. Some ascribe it to the Dutch word "dodoor" for "sluggard", but it is more probably related to "Dodaars", which means either "fat-arse" or "knot-arse", referring to the knot of feathers on the hind end. The first record of the word "Dodaars" is in Captain Willem Van West-Zanen's journal in 1602. The English writer Sir Thomas Herbert was the first to use the word "dodo" in print in his 1634 travelogue, claiming it was referred to as such by the Portuguese, who had visited Mauritius in 1507. Another Englishman, Emmanuel Altham, had used the word in a 1628 letter, in which he also claimed the origin was Portuguese. The name "dodar" was introduced into English at the same time as dodo, but was only used until the 18th century. As far as is known, the Portuguese never mentioned the bird. Nevertheless, some sources still state that the word "dodo" derives from the Portuguese word "doudo" (currently "doido"), meaning "fool" or "crazy". It has also been suggested that "dodo" was an onomatopoeic approximation of the bird's call, a two-note pigeon-like sound resembling "doo-doo".

The Latin name "cucullatus" ("hooded") was first used by Juan Eusebio Nieremberg in 1635 as "Cygnus cucullatus", in reference to Carolus Clusius's 1605 depiction of a dodo. In his 18th-century classic work "Systema Naturae", Carl Linnaeus used "cucullatus" as the specific name, but combined it with the genus name "Struthio" (ostrich). Mathurin Jacques Brisson coined the genus name "Raphus" (referring to the bustards) in 1760, resulting in the current name "Raphus cucullatus". In 1766, Linnaeus coined the new binomial "Didus ineptus" (meaning "inept dodo"). This has become a synonym of the earlier name because of nomenclatural priority.

As no complete dodo specimens exist, its external appearance, such as plumage and colouration, is hard to determine. Illustrations and written accounts of encounters with the dodo between its discovery and its extinction (1598–1662) are the primary evidence for its external appearance. According to most representations, the dodo had greyish or brownish plumage, with lighter primary feathers and a tuft of curly light feathers high on its rear end. The head was grey and naked, the beak green, black and yellow, and the legs were stout and yellowish, with black claws. A study of the few remaining feathers on the Oxford specimen head showed that they were pennaceous rather than plumaceous (downy) and most similar to those of other pigeons.

Subfossil remains and remnants of the birds that were brought to Europe in the 17th century show that dodos were very large birds, up to tall. 
The bird was sexually dimorphic; males were larger and had proportionally longer beaks. Weight estimates have varied from study to study. In 1993, Bradley C. Livezey proposed that males would have weighed and females . Also in 1993, Andrew C. Kitchener attributed a high contemporary weight estimate and the roundness of dodos depicted in Europe to these birds having been overfed in captivity; weights in the wild were estimated to have been in the range of , and fattened birds could have weighed . A 2011 estimate by Angst and colleagues gave an average weight as low as . This has also been questioned, and there is still controversy over weight estimates. A 2016 study estimated the weight at , based on CT scans of composite skeletons. It has also been suggested that the weight depended on the season, and that individuals were fat during cool seasons, but less so during hot.

The skull of the dodo differed much from those of other pigeons, especially in being more robust, the bill having a hooked tip, and in having a short cranium compared to the jaws. The upper bill was nearly twice as long as the cranium, which was short compared to those of its closest pigeon relatives. The openings of the bony nostrils were elongated along the length of the beak, and they contained no bony septum. The cranium (excluding the beak) was wider than it was long, and the frontal bone formed a dome-shape, with the highest point above the hind part of the eye sockets. The skull sloped downwards at the back. The eye sockets occupied much of the hind part of the skull. The sclerotic rings inside the eye were formed by eleven ossicles (small bones), similar to the amount in other pigeons. The mandible was slightly curved, and each half had a single fenestra (opening), as in other pigeons.

The dodo had about nineteen presynsacral vertebrae (those of the neck and thorax, including three fused into a notarium), sixteen synsacral vertebrae (those of the lumbar region and sacrum), six free tail (caudal) vertebrae, and a pygostyle. The neck had well-developed areas for muscle and ligament attachment, probably to support the heavy skull and beak. On each side, it had six ribs, four of which articulated with the sternum through sternal ribs. The sternum was large, but small in relation to the body compared to those of much smaller pigeons that are able to fly. The sternum was highly pneumatic, broad, and relatively thick in cross-section. The bones of the pectoral girdle, shoulder blades, and wing bones were reduced in size compared to those of flighted pigeon, and were more gracile compared to those of the Rodrigues solitaire, but none of the individual skeletal components had disappeared. The carpometacarpus of the dodo was more robust than that of the solitaire, however. The pelvis was wider than that of the solitaire and other relatives, yet was comparable to the proportions in some smaller, flighted pigeons. Most of the leg bones were more robust than those of extant pigeons and the solitaire, but the length proportions were little different.

Many of the skeletal features that distinguish the dodo and the Rodrigues solitaire, its closest relative, from pigeons have been attributed to their flightlessness. The pelvic elements were thicker than those of flighted pigeons to support the higher weight, and the pectoral region and the small wings were paedomorphic, meaning that they were underdeveloped and retained juvenile features. The skull, trunk and pelvic limbs were peramorphic, meaning that they changed considerably with age. The dodo shared several other traits with the Rodrigues solitaire, such as features of the skull, pelvis, and sternum, as well as their large size. It differed in other aspects, such as being more robust and shorter than the solitaire, having a larger skull and beak, a rounded skull roof, and smaller orbits. The dodo's neck and legs were proportionally shorter, and it did not possess an equivalent to the knob present on the solitaire's wrists.

Most contemporary descriptions of the dodo are found in ship's logs and journals of the Dutch East India Company vessels that docked in Mauritius when the Dutch Empire ruled the island. These records were used as guides for future voyages. Few contemporary accounts are reliable, as many seem to be based on earlier accounts, and none were written by scientists. One of the earliest accounts, from van Warwijck's 1598 journal, describes the bird as follows:

One of the most detailed descriptions is by Sir Thomas Herbert in "A Relation of Some Yeares Travaille into Afrique and the Greater Asia" from 1634:

The travel journal of the Dutch ship "Gelderland" (1601–1603), rediscovered in the 1860s, contains the only known sketches of living or recently killed specimens drawn on Mauritius. They have been attributed to the professional artist Joris Joostensz Laerle, who also drew other now-extinct Mauritian birds, and to a second, less refined artist. Apart from these sketches, it is unknown how many of the twenty or so 17th-century illustrations of the dodos were drawn from life or from stuffed specimens, which affects their reliability.

All post-1638 depictions appear to be based on earlier images, around the time reports mentioning dodos became rarer. Differences in the depictions led authors such as Anthonie Cornelis Oudemans and Masauji Hachisuka to speculate about sexual dimorphism, ontogenic traits, seasonal variation, and even the existence of different species, but these theories are not accepted today. Because details such as markings of the beak, the form of the tail feathers, and colouration vary from account to account, it is impossible to determine the exact morphology of these features, whether they signal age or sex, or if they even reflect reality. Dodo specialist Julian Hume argued that the nostrils of the living dodo would have been slits, as seen in the "Gelderland", Cornelis Saftleven, Crocker Art Gallery, and Ustad Mansur images. According to this claim, the gaping nostrils often seen in paintings indicate that taxidermy specimens were used as models. Most depictions show that the wings were held in an extended position, unlike flighted pigeons, but similar to ratites such as the ostrich and kiwi.

The traditional image of the dodo is of a very fat and clumsy bird, but this view may be exaggerated. The general opinion of scientists today is that many old European depictions were based on overfed captive birds or crudely stuffed specimens. It has also been suggested that the images might show dodos with puffed feathers, as part of display behaviour. The Dutch painter Roelant Savery was the most prolific and influential illustrator of the dodo, having made at least ten depictions, often showing it in the lower corners. A famous painting of his from 1626, now called "Edwards's Dodo" as it was once owned by the ornithologist George Edwards, has since become the standard image of a dodo. It is housed in the Natural History Museum, London. The image shows a particularly fat bird and is the source for many other dodo illustrations.

An Indian Mughal painting rediscovered in St. Petersburg in the 1950s shows a dodo along with native Indian birds. It depicts a slimmer, brownish bird, and its discoverer A. Iwanow and dodo specialist Julian Hume regard it as one of the most accurate depictions of the living dodo; the surrounding birds are clearly identifiable and depicted with appropriate colouring. It is believed to be from the 17th century and has been attributed to artist Ustad Mansur. The bird depicted probably lived in the menagerie of Mughal Emperor Jahangir, located in Surat, where English traveller Peter Mundy also claimed to have seen two dodos sometime between 1628 and 1633. In 2014, another Indian illustration of a dodo was reported, but it was found to be derivative of an 1836 German illustration.

Little is known of the behaviour of the dodo, as most contemporary descriptions are very brief. Based on weight estimates, it has been suggested the male could reach the age of 21, and the female 17. Studies of the cantilever strength of its leg bones indicate that it could run quite fast. The legs were robust and strong to support the bulk of the bird, and also made it agile and manoeuvrable in the dense, pre-human landscape. Though the wings were small, well-developed muscle scars on the bones show that they were not completely vestigial, and may have been used for display behaviour and balance; extant pigeons also use their wings for such purposes. Unlike the Rodrigues solitaire, there is no evidence that the dodo used its wings in intraspecific combat. Though some dodo bones have been found with healed fractures, it had weak pectoral muscles and more reduced wings in comparison. The dodo may instead have used its large, hooked beak in territorial disputes. Since Mauritius receives more rainfall and has less seasonal variation than Rodrigues, which would have affected the availability of resources on the island, the dodo would have less reason to evolve aggressive territorial behaviour. The Rodrigues solitaire was therefore probably the more aggressive of the two.

The preferred habitat of the dodo is unknown, but old descriptions suggest that it inhabited the woods on the drier coastal areas of south and west Mauritius. This view is supported by the fact that the Mare aux Songes swamp, where most dodo remains have been excavated, is close to the sea in south-eastern Mauritius. Such a limited distribution across the island could well have contributed to its extinction. A 1601 map from the "Gelderland" journal shows a small island off the coast of Mauritius where dodos were caught. Julian Hume has suggested this island was l'île aux Benitiers in Tamarin Bay, on the west coast of Mauritius. Subfossil bones have also been found inside caves in highland areas, indicating that it once occurred on mountains. Work at the Mare aux Songes swamp has shown that its habitat was dominated by tambalacoque and "Pandanus" trees and endemic palms. The near-coastal placement and wetness of the Mare aux Songes led to a high diversity of plant species, whereas the surrounding areas were drier.

Many endemic species of Mauritius became extinct after the arrival of humans, so the ecosystem of the island is badly damaged and hard to reconstruct. Before humans arrived, Mauritius was entirely covered in forests, but very little remains of them today, because of deforestation. The surviving endemic fauna is still seriously threatened. The dodo lived alongside other recently extinct Mauritian birds such as the flightless red rail, the broad-billed parrot, the Mascarene grey parakeet, the Mauritius blue pigeon, the Mauritius owl, the Mascarene coot, the Mauritian shelduck, the Mauritian duck, and the Mauritius night heron. Extinct Mauritian reptiles include the saddle-backed Mauritius giant tortoise, the domed Mauritius giant tortoise, the Mauritian giant skink, and the Round Island burrowing boa. The small Mauritian flying fox and the snail "Tropidophora carinata" lived on Mauritius and Réunion, but vanished from both islands. Some plants, such as "Casearia tinifolia" and the palm orchid, have also become extinct.

A 1631 Dutch letter (long thought lost, but rediscovered in 2017) is the only account of the dodo's diet, and also mentions that it used its beak for defence. The document uses word-play to refer to the animals described, with dodos presumably being an allegory for wealthy mayors:

In addition to fallen fruits, the dodo probably subsisted on nuts, seeds, bulbs, and roots. It has also been suggested that the dodo might have eaten crabs and shellfish, like their relatives the crowned pigeons. Its feeding habits must have been versatile, since captive specimens were probably given a wide range of food on the long sea journeys. Oudemans suggested that as Mauritius has marked dry and wet seasons, the dodo probably fattened itself on ripe fruits at the end of the wet season to survive the dry season, when food was scarce; contemporary reports describe the bird's "greedy" appetite. France Staub suggested that they mainly fed on palm fruits, and he attempted to correlate the fat-cycle of the dodo with the fruiting regime of the palms.

Skeletal elements of the upper jaw appear to have been rhynchokinetic (movable in relation to each other), which must have affected its feeding behaviour. In extant birds, such as frugivorous (fruit-eating) pigeons, kinetic premaxillae help with consuming large food items. The beak also appears to have been able to withstand high force loads, which indicates a diet of hard food. In 2016, the first 3D endocast was made from the brain of the dodo; examination found that though the brain was similar to that of other pigeons in most respects, the dodo had a comparatively large olfactory bulb. This gave the dodo a good sense of smell, which may have aided in locating fruit and small prey.

Several contemporary sources state that the dodo used Gastroliths (gizzard stones) to aid digestion. The English writer Sir Hamon L'Estrange witnessed a live bird in London and described it as follows:

It is not known how the young were fed, but related pigeons provide crop milk. Contemporary depictions show a large crop, which was probably used to add space for food storage and to produce crop milk. It has been suggested that the maximum size attained by the dodo and the solitaire was limited by the amount of crop milk they could produce for their young during early growth.

In 1973, the tambalacoque, also known as the dodo tree, was thought to be dying out on Mauritius, to which it is endemic. There were supposedly only 13 specimens left, all estimated to be about 300 years old. Stanley Temple hypothesised that it depended on the dodo for its propagation, and that its seeds would germinate only after passing through the bird's digestive tract. He claimed that the tambalacoque was now nearly coextinct because of the disappearance of the dodo. Temple overlooked reports from the 1940s that found that tambalacoque seeds germinated, albeit very rarely, without being abraded during digestion. Others have contested his hypothesis and suggested that the decline of the tree was exaggerated, or seeds were also distributed by other extinct animals such as "Cylindraspis" tortoises, fruit bats or the broad-billed parrot. According to Wendy Strahm and Anthony Cheke, two experts in the ecology of the Mascarene Islands, the tree, while rare, has germinated since the demise of the dodo and numbers several hundred, not 13 as claimed by Temple, hence discrediting Temple's view as to the dodo and the tree's sole survival relationship.

It has been suggested that the broad-billed parrot may have depended on dodos and "Cylindraspis" tortoises to eat palm fruits and excrete their seeds, which became food for the parrots. "Anodorhynchus" macaws depended on now-extinct South American megafauna in the same way, but now rely on domesticated cattle for this service.

As it was flightless and terrestrial and there were no mammalian predators or other kinds of natural enemy on Mauritius, the dodo probably nested on the ground. The account by François Cauche from 1651 is the only description of the egg and the call:
Cauche's account is problematic, since it also mentions that the bird he was describing had three toes and no tongue, unlike dodos. This led some to believe that Cauche was describing a new species of dodo (""Didus nazarenus""). The description was most probably mingled with that of a cassowary, and Cauche's writings have other inconsistencies. A mention of a "young ostrich" taken on board a ship in 1617 is the only other reference to a possible juvenile dodo. An egg claimed to be that of a dodo is stored in the museum of East London, South Africa. It was donated by Marjorie Courtenay-Latimer, whose great aunt had received it from a captain who claimed to have found it in a swamp on Mauritius. In 2010, the curator of the museum proposed using genetic studies to determine its authenticity. It may instead be an aberrant ostrich egg.

Because of the possible single-egg clutch and the bird's large size, it has been proposed that the dodo was K-selected, meaning that it produced a low number of altricial offspring, which required parental care until they matured. Some evidence, including the large size and the fact that tropical and frugivorous birds have slower growth rates, indicates that the bird may have had a protracted development period. The fact that no juvenile dodos have been found in the Mare aux Songes swamp may indicate that they produced little offspring, that they matured rapidly, that the breeding grounds were far away from the swamp, or that the risk of miring was seasonal.

A 2017 study examined the histology of thin-sectioned dodo bones, modern Mauritian birds, local ecology, and contemporary accounts, to recover information about the life history of the dodo. The study suggested that dodos bred around August, after having potentially fattened themselves, corresponding with the fat and thin cycles of many vertebrates of Mauritius. The chicks grew rapidly, reaching robust, almost adult, sizes, and sexual maturity before Austral summer or the cyclone season. Adult dodos which had just bred moulted after Austral summer, around March. The feathers of the wings and tail were replaced first, and the moulting would have completed at the end of July, in time for the next breeding season. Different stages of moulting may also account for inconsistencies in contemporary descriptions of dodo plumage.

Mauritius had previously been visited by Arab vessels in the Middle Ages and Portuguese ships between 1507 and 1513, but was settled by neither. No records of dodos by these are known, although the Portuguese name for Mauritius, "Cerne (swan) Island", may have been a reference to dodos. The Dutch Empire acquired Mauritius in 1598, renaming it after Maurice of Nassau, and it was used for the provisioning of trade vessels of the Dutch East India Company henceforward. The earliest known accounts of the dodo were provided by Dutch travelers during the Second Dutch Expedition to Indonesia, led by admiral Jacob van Neck in 1598. They appear in reports published in 1601, which also contain the first published illustration of the bird. Since the first sailors to visit Mauritius had been at sea for a long time, their interest in these large birds was mainly culinary. The 1602 journal by Willem Van West-Zanen of the ship "Bruin-Vis" mentions that 24–25 dodos were hunted for food, which were so large that two could scarcely be consumed at mealtime, their remains being preserved by salting. An illustration made for the 1648 published version of this journal, showing the killing of dodos, a dugong, and possibly Mascarene grey parakeets, was captioned with a Dutch poem, here in Hugh Strickland's 1848 translation:
Some early travellers found dodo meat unsavoury, and preferred to eat parrots and pigeons; others described it as tough but good. Some hunted dodos only for their gizzards, as this was considered the most delicious part of the bird. Dodos were easy to catch, but hunters had to be careful not to be bitten by their powerful beaks.

The appearance of the dodo and the red rail led Peter Mundy to speculate, 230 years before Charles Darwin's theory of evolution:

The dodo was found interesting enough that living specimens were sent to Europe and the East. The number of transported dodos that reached their destinations alive is uncertain, and it is unknown how they relate to contemporary depictions and the few non-fossil remains in European museums. Based on a combination of contemporary accounts, paintings, and specimens, Julian Hume has inferred that at least eleven transported dodos reached their destinations alive.

Hamon L'Estrange's description of a dodo that he saw in London in 1638 is the only account that specifically mentions a live specimen in Europe. In 1626 Adriaen van de Venne drew a dodo that he claimed to have seen in Amsterdam, but he did not mention if it were alive, and his depiction is reminiscent of Savery's "Edwards's Dodo". Two live specimens were seen by Peter Mundy in Surat, India, between 1628 and 1634, one of which may have been the individual painted by Ustad Mansur around 1625. In 1628, Emmanuel Altham visited Mauritius and sent a letter to his brother in England:

Whether the dodo survived the journey is unknown, and the letter was destroyed by fire in the 19th century.
The earliest known picture of a dodo specimen in Europe is from a collection of paintings depicting animals in the royal menagerie of Emperor Rudolph II in Prague. This collection includes paintings of other Mauritian animals as well, including a red rail. The dodo, which may be a juvenile, seems to have been dried or embalmed, and had probably lived in the emperor's zoo for a while together with the other animals. That whole stuffed dodos were present in Europe indicates they had been brought alive and died there; it is unlikely that taxidermists were on board the visiting ships, and spirits were not yet used to preserve biological specimens. Most tropical specimens were preserved as dried heads and feet.

One dodo was reportedly sent as far as Nagasaki, Japan in 1647, but it was long unknown whether it arrived. Contemporary documents first published in 2014 proved the story, and showed that it had arrived alive. It was meant as a gift, and, despite its rarity, was considered of equal value to a white deer and a bezoar stone. It is the last recorded live dodo in captivity.

Like many animals that evolved in isolation from significant predators, the dodo was entirely fearless of humans. This fearlessness and its inability to fly made the dodo easy prey for sailors. Although some scattered reports describe mass killings of dodos for ships' provisions, archaeological investigations have found scant evidence of human predation. Bones of at least two dodos were found in caves at Baie du Cap that sheltered fugitive slaves and convicts in the 17th century, which would not have been easily accessible to dodos because of the high, broken terrain. The human population on Mauritius (an area of ) never exceeded 50 people in the 17th century, but they introduced other animals, including dogs, pigs, cats, rats, and crab-eating macaques, which plundered dodo nests and competed for the limited food resources. At the same time, humans destroyed the forest habitat of the dodos. The impact of the introduced animals on the dodo population, especially the pigs and macaques, is today considered more severe than that of hunting. Rats were perhaps not much of a threat to the nests, since dodos would have been used to dealing with local land crabs.

It has been suggested that the dodo may already have been rare or localised before the arrival of humans on Mauritius, since it would have been unlikely to become extinct so rapidly if it had occupied all the remote areas of the island. A 2005 expedition found subfossil remains of dodos and other animals killed by a flash flood. Such mass mortalities would have further jeopardised a species already in danger of becoming extinct. Yet the fact that the dodo survived hundreds of years of volcanic activity and climactic changes shows the bird was resilient within its ecosystem.

Some controversy surrounds the date of their extinction. The last widely accepted record of a dodo sighting is the 1662 report by shipwrecked mariner Volkert Evertsz of the Dutch ship "Arnhem", who described birds caught on a small islet off Mauritius, now suggested to be Amber Island:
The dodos on this islet may not necessarily have been the last members of the species. The last claimed sighting of a dodo was reported in the hunting records of Isaac Johannes Lamotius in 1688. Statistical analysis of these records by Roberts and Solow gives a new estimated extinction date of 1693, with a 95% confidence interval of 1688–1715. The authors also pointed out that because the last sighting before 1662 was in 1638, the dodo was probably already quite rare by the 1660s, and thus a disputed report from 1674 by an escaped slave cannot be dismissed out of hand.

Cheke pointed out that some descriptions after 1662 use the names "Dodo" and "Dodaers" when referring to the red rail, indicating that they had been transferred to it after the disappearance of the dodo itself. Cheke therefore points to the 1662 description as the last credible observation. A 1668 account by English traveller John Marshall, who used the names "Dodo" and "Red Hen" interchangeably for the red rail, mentioned that the meat was "hard", which echoes the description of the meat in the 1681 account. Even the 1662 account has been questioned by the writer Errol Fuller, as the reaction to distress cries matches what was described for the red rail. Until this explanation was proposed, a description of "dodos" from 1681 was thought to be the last account, and that date still has proponents. Recently accessible Dutch manuscripts indicate that no dodos were seen by settlers in 1664–1674. It is unlikely the issue will ever be resolved, unless late reports mentioning the name alongside a physical description are rediscovered. The IUCN Red List accepts Cheke's rationale for choosing the 1662 date, taking all subsequent reports to refer to red rails. In any case, the dodo was probably extinct by 1700, about a century after its discovery in 1598. The Dutch left Mauritius in 1710, but by then the dodo and most of the large terrestrial vertebrates there had become extinct.

Even though the rareness of the dodo was reported already in the 17th century, its extinction was not recognised until the 19th century. This was partly because, for religious reasons, extinction was not believed possible until later proved so by Georges Cuvier, and partly because many scientists doubted that the dodo had ever existed. It seemed altogether too strange a creature, and many believed it a myth. The bird was first used as an example of human-induced extinction in "Penny Magazine" in 1833, and have since been referred to as an "icon" of extinction.

The only extant remains of dodos taken to Europe in the 17th century are a dried head and foot in the Oxford University Museum of Natural History, a foot once housed in the British Museum but now lost, a skull in the University of Copenhagen Zoological Museum, and an upper jaw and leg bones in the National Museum, Prague. The last two were rediscovered and identified as dodo remains in the mid-19th century. Several stuffed dodos were also mentioned in old museum inventories, but none are known to have survived. Apart from these remains, a dried foot, which belonged to the Dutch professor Pieter Pauw, was mentioned by Carolus Clusius in 1605. Its provenance is unknown, and it is now lost, but it may have been collected during the Van Neck voyage.

The only known soft tissue remains, the Oxford head (specimen OUM 11605) and foot, belonged to the last known stuffed dodo, which was first mentioned as part of the Tradescant collection in 1656 and was moved to the Ashmolean Museum in 1659. It has been suggested that this might be the remains of the bird that Hamon L'Estrange saw in London, the bird sent by Emanuel Altham, or a donation by Thomas Herbert. Since the remains do not show signs of having been mounted, the specimen might instead have been preserved as a study skin. In 2018, it was reported that scans of the Oxford dodo's head showed that its skin and bone contained lead shot, pellets which were used to hunt birds in the 17th century. This indicates that the Oxford dodo was shot either before being transported to Britain, or some time after arriving. The circumstances of its killing are unknown, and the pellets are to be examined to identify where the lead was mined from.

Many sources state that the Ashmolean Museum burned the stuffed dodo around 1755 because of severe decay, saving only the head and leg. Statute 8 of the museum states "That as any particular grows old and perishing the keeper may remove it into one of the closets or other repository; and some other to be substituted." The deliberate destruction of the specimen is now believed to be a myth; it was removed from exhibition to preserve what remained of it. This remaining soft tissue has since degraded further; the head was dissected by Strickland and Melville, separating the skin from the skull in two halves. The foot is in a skeletal state, with only scraps of skin and tendons. Very few feathers remain on the head. It is probably a female, as the foot is 11% smaller and more gracile than the London foot, yet appears to be fully grown. The specimen was exhibited at the Oxford museum from at least the 1860s and until 1998, where-after it was mainly kept in storage to prevent damage. Casts of the head can today be found in many museums worldwide.

The dried London foot, first mentioned in 1665, and transferred to the British Museum in the 18th century, was displayed next to Savery's "Edwards's Dodo" painting until the 1840s, and it too was dissected by Strickland and Melville. It was not posed in a standing posture, which suggests that it was severed from a fresh specimen, not a mounted one. By 1896 it was mentioned as being without its integuments, and only the bones are believed to remain today, though its present whereabouts are unknown.

The Copenhagen skull (specimen ZMUC 90-806) is known to have been part of the collection of Bernardus Paludanus in Enkhuizen until 1651, when it was moved to the museum in Gottorf Castle, Schleswig. After the castle was occupied by Danish forces in 1702, the museum collection was assimilated into the Royal Danish collection. The skull was rediscovered by J. T. Reinhardt in 1840. Based on its history, it may be the oldest known surviving remains of a dodo brought to Europe in the 17th century. It is shorter than the Oxford skull, and may have belonged to a female. It was mummified, but the skin has perished.

The front part of a skull (specimen NMP P6V-004389, a syntype of this species) in the National Museum of Prague was found in 1850 among the remains of the Böhmisches Museum. Other elements supposedly belonging to this specimen have been listed in the literature, but it appears only the partial skull was ever present. It may be what remains of one of the stuffed dodos known to have been at the menagerie of Emperor Rudolph II, possibly the specimen painted by Hoefnagel or Savery there.

Until 1860, the only known dodo remains were the four incomplete 17th-century specimens. Philip Burnard Ayres found the first subfossil bones in 1860, which were sent to Richard Owen at the British Museum, who did not publish the findings. In 1863, Owen requested the Mauritian Bishop Vincent Ryan to spread word that he should be informed if any dodo bones were found. In 1865, George Clark, the government schoolmaster at Mahébourg, finally found an abundance of subfossil dodo bones in the swamp of Mare aux Songes in Southern Mauritius, after a 30-year search inspired by Strickland and Melville's monograph. In 1866, Clark explained his procedure to "The Ibis", an ornithology journal: he had sent his coolies to wade through the centre of the swamp, feeling for bones with their feet. At first they found few bones, until they cut away herbage that covered the deepest part of the swamp, where they found many fossils. The swamp yielded the remains of over 300 dodos, but very few skull and wing bones, possibly because the upper bodies were washed away or scavenged while the lower body was trapped. The situation is similar to many finds of moa remains in New Zealand marshes. Most dodo remains from the Mare aux Songes have a medium to dark brown colouration.

Clark's reports about the finds rekindled interest in the bird. Sir Richard Owen and Alfred Newton both wanted to be first to describe the post-cranial anatomy of the dodo, and Owen bought a shipment of dodo bones originally meant for Newton, which led to rivalry between the two. Owen described the bones in "Memoir on the Dodo" in October 1866, but erroneously based his reconstruction on the "Edwards's Dodo" painting by Savery, making it too squat and obese. In 1869 he received more bones and corrected its stance, making it more upright. Newton moved his focus to the Réunion solitaire instead. The remaining bones not sold to Owen or Newton were auctioned off or donated to museums. In 1889, Théodor Sauzier was commissioned to explore the "historical souvenirs" of Mauritius and find more dodo remains in the Mare aux Songes. He was successful, and also found remains of other extinct species.

In 2005, after a hundred years of neglect, a part of the Mare aux Songes swamp was excavated by an international team of researchers (International Dodo Research Project). To prevent malaria, the British had covered the swamp with hard core during their rule over Mauritius, which had to be removed. Many remains were found, including bones of at least 17 dodos in various stages of maturity (though no juveniles), and several bones obviously from the skeleton of one individual bird, which have been preserved in their natural position. These findings were made public in December 2005 in the Naturalis museum in Leiden. 63% of the fossils found in the swamp belonged to turtles of the extinct genus "Cylindraspis", and 7.1% belonged to dodos, which had been deposited within several centuries, 4,000 years ago. Subsequent excavations suggested that dodos and other animals became mired in the Mare aux Songes while trying to reach water during a long period of severe drought about 4,200 years ago. Furthermore, cyanobacteria thrived in the conditions created by the excrements of animals gathered around the swamp, which died of intoxication, dehydration, trampling, and miring. Though many small skeletal elements were found during the recent excavations of the swamp, few were found during the 19th century, probably owing to the employment of less refined methods when collecting.

Louis Etienne Thirioux, an amateur naturalist at Port Louis, also found many dodo remains around 1900 from several locations. They included the first articulated specimen, which is the first subfossil dodo skeleton found outside the Mare aux Songes, and the only remains of a juvenile specimen, a now lost tarsometatarsus. The former specimen was found in 1904 in a cave near Le Pouce mountain, and is the only known complete skeleton of an individual dodo. Thirioux donated the specimen to the Museum Desjardins (now Natural History Museum at Mauritius Institute). Thrioux's heirs sold a second mounted composite skeleton (composed of at least two skeletons, with a mainly reconstructed skull) to the Durban Museum of Natural Science in South Africa in 1918. Together, these two skeletons represent the most completely known dodo remains, including bone elements previously unrecorded (such as knee-caps and various wing bones). Though some contemporary writers noted the importance of Thrioux's specimens, they were not scientifically studied, and were largely forgotten until 2011, when sought out by a group of researchers. The mounted skeletons were laser scanned, from which 3-D models were reconstructed, which became the basis of a 2016 monograph about the osteology of the dodo. In 2006, explorers discovered a complete skeleton of a dodo in a lava cave in Mauritius. This was only the second associated skeleton of an individual specimen everfound, and the only one in recent times.

Worldwide, 26 museums have significant holdings of dodo material, almost all found in the Mare aux Songes. The Natural History Museum, American Museum of Natural History, Cambridge University Museum of Zoology, the Senckenberg Museum, and others have almost complete skeletons, assembled from the dissociated subfossil remains of several individuals. In 2011, a wooden box containing dodo bones from the Edwardian era was rediscovered at the Grant Museum at University College London during preparations for a move. They had been stored with crocodile bones until then.

The supposed "white dodo" (or "solitaire") of Réunion is now considered an erroneous conjecture based on contemporary reports of the Réunion ibis and 17th-century paintings of white, dodo-like birds by Pieter Withoos and Pieter Holsteyn that surfaced in the 19th century. The confusion began when Willem Ysbrandtszoon Bontekoe, who visited Réunion around 1619, mentioned fat, flightless birds that he referred to as "Dod-eersen" in his journal, though without mentioning their colouration. When the journal was published in 1646, it was accompanied by an engraving of a dodo from Savery's "Crocker Art Gallery sketch". A white, stocky, and flightless bird was first mentioned as part of the Réunion fauna by Chief Officer J. Tatton in 1625. Sporadic mentions were subsequently made by Sieur Dubois and other contemporary writers.

Baron Edmond de Sélys Longchamps coined the name "Raphus solitarius" for these birds in 1848, as he believed the accounts referred to a species of dodo. When 17th-century paintings of white dodos were discovered by 19th-century naturalists, it was assumed they depicted these birds. Anthonie Cornelis Oudemans suggested that the discrepancy between the paintings and the old descriptions was that the paintings showed females, and that the species was therefore sexually dimorphic. Some authors also believed the birds described were of a species similar to the Rodrigues solitaire, as it was referred to by the same name, or even that there were white species of both dodo and solitaire on the island.

The Pieter Withoos painting, which was discovered first, appears to be based on an earlier painting by Pieter Holsteyn, three versions of which are known to have existed. According to Hume, Cheke, and Valledor de Lozoya, it appears that all depictions of white dodos were based on Roelant Savery's 1611 painting "Landscape with Orpheus and the animals", or on copies of it. The painting shows a whitish specimen and was apparently based on a stuffed specimen then in Prague; a "walghvogel" described as having a "dirty off-white colouring" was mentioned in an inventory of specimens in the Prague collection of the Holy Roman Emperor Rudolf II, to whom Savery was contracted at the time (1607–1611). Savery's several later images all show greyish birds, possibly because he had by then seen another specimen. Cheke and Hume believe the painted specimen was white, owing to albinism. Valledor de Lozoya has instead suggested that the light plumage was a juvenile trait, a result of bleaching of old taxidermy specimens, or simply artistic license.

In 1987, scientists described fossils of a recently extinct species of ibis from Réunion with a relatively short beak, "Borbonibis latipes", before a connection to the solitaire reports had been made. Cheke suggested to one of the authors, Francois Moutou, that the fossils may have been of the Réunion solitaire, and this suggestion was published in 1995. The ibis was reassigned to the genus "Threskiornis", now combined with the specific epithet "" from the binomial "R. solitarius". Birds of this genus are also white and black with slender beaks, fitting the old descriptions of the Réunion solitaire. No fossil remains of dodo-like birds have ever been found on the island.

The dodo's significance as one of the best-known extinct animals and its singular appearance led to its use in literature and popular culture as a symbol of an outdated concept or object, as in the expression "dead as a dodo," which has come to mean unquestionably dead or obsolete. Similarly, the phrase "to go the way of the dodo" means to become extinct or obsolete, to fall out of common usage or practice, or to become a thing of the past. "Dodo" is also a slang term for a stupid, dull-witted person, as it was supposedly stupid and easily caught.

The dodo appears frequently in works of popular fiction, and even before its extinction, it was featured in European literature, as symbol for exotic lands, and of gluttony, due to its apparent fatness. In 1865, the same year that George Clark started to publish reports about excavated dodo fossils, the newly vindicated bird was featured as a character in Lewis Carroll's "Alice's Adventures in Wonderland". It is thought that he included the dodo because he identified with it and had adopted the name as a nickname for himself because of his stammer, which made him accidentally introduce himself as "Do-do-dodgson", his legal surname. Carroll and the girl who served as inspiration for Alice, Alice Liddell, had enjoyed visiting the Oxford museum to see the dodo remains there. The book's popularity made the dodo a well-known icon of extinction.
The dodo is used as a mascot for many kinds of products, especially in Mauritius. It appears as a supporter on the coat of arms of Mauritius, on Mauritius coins, is used as a watermark on all Mauritian rupee banknotes, and features as the background of the Mauritian immigration form. A smiling dodo is the symbol of the Brasseries de Bourbon, a popular brewer on Réunion, whose emblem displays the white species once thought to have lived there.

The dodo is used to promote the protection of endangered species by environmental organisations, such as the Durrell Wildlife Conservation Trust and the Durrell Wildlife Park. The Center for Biological Diversity gives an annual 'Rubber Dodo Award', to "those who have done the most to destroy wild places, species and biological diversity". In 2011, the nephiline spider "Nephilengys dodo", which inhabits the same woods as the dodo once did, was named after the bird to raise awareness of the urgent need for protection of the Mauritius biota. Two species of ant from Mauritius have been named after the dodo: "Pseudolasius dodo" in 1946 and "Pheidole dodo" in 2013. A species of isopod from a coral reef off Réunion was named "Hansenium dodo" in 1991. The name dodo has been used by scientists naming genetic elements, honoring the dodo's flightless nature. A fruitfly gene within a region of a chromosome required for flying ability was named "dodo". In addition, a defective transposable element family from "Phytophthora infestans" was named "DodoPi" as it contained mutations that eliminated the element's ability to jump to new locations in a chromosome. 

In 2009, a previously unpublished 17th-century Dutch illustration of a dodo went for sale at Christie's and was expected to sell for £6,000. It is unknown whether the illustration was based on a specimen or on a previous image. It sold for £44,450.

The poet Hilaire Belloc included the following poem about the dodo in his "Bad Child's Book of Beasts" from 1896:




</doc>
<doc id="8421" url="https://en.wikipedia.org/wiki?curid=8421" title="Sideroxylon grandiflorum">
Sideroxylon grandiflorum

Sideroxylon grandiflorum, known as tambalacoque or dodo tree, is a long-lived tree in the family Sapotaceae, endemic to Mauritius. It is valued for its timber.

The "Sideroxylon grandiflorum" fruit is analogous to the peach. They are both termed drupes because both have a hard endocarp, or pit, surrounding the seed, with the endocarp naturally splitting along a fracture line during germination.

In 1973, it was thought that this species was dying out. There were supposedly only 13 specimens left, all estimated to be about 300 years old. The true age could not be determined because tambalacoque has no growth rings. Stanley Temple hypothesized that the dodo, which became extinct in the 17th century, ate tambalacoque fruits, and only by passing through the digestive tract of the dodo could the seeds germinate. Temple (1977) force-fed seventeen tambalacoque fruits to wild turkeys. Seven of the fruits were crushed by the bird's gizzard. The remaining ten were either regurgitated or passed with the bird's feces. Temple planted the remaining ten fruits and three germinated. Temple did not try to germinate any seeds from control fruits not fed to turkeys so the effect of feeding fruits to turkeys was unclear. Reports made on tambalacoque seed germination by Hill (1941) and King (1946) found the seeds germinated without abrading.

Temple's hypothesis that the tree required the dodo has been contested. Others have suggested the decline of the tree was exaggerated, or that other extinct animals may also have been distributing the seeds, such as tortoises, fruit bats or the broad-billed parrot. Wendy Strahm and Anthony Cheke, two experts in Mascarene ecology, claim that while a rare tree, it has germinated since the demise of the dodo and numbers a few hundred, not 13. The difference in numbers is because young trees are not distinct in appearance and may easily be confused with similar species. The decline of the tree may possibly be due to introduction of domestic pigs and crab-eating macaques and competition with introduced plants. Catling (2001) in a summary cites Owadally and Temple (1979), and Witmer (1991). Hershey (2004) reviewed the flaws in Temple's dodo-tambalacoque hypothesis.

In 2004, Botanical Society of America's Plant Science Bulletin disputed Dr. Temple's research as flawed which published evidence as to why the dodo's extinction did not directly cause the increasing disappearance of young trees including suggestion that tortoises would have been more likely to disperse the seeds than dodo hence discrediting Temple's view as to the dodo and the tree's sole survival relationship.

This dodo tree is highly valued for its wood in Mauritius, which has led some foresters to scrape the pits by hand to make them sprout and grow.




</doc>
<doc id="8425" url="https://en.wikipedia.org/wiki?curid=8425" title="Dwight Schultz">
Dwight Schultz

William Dwight Schultz (born November 24, 1947) is an American actor and voice artist. He is known for his roles as Captain "Howling Mad" Murdock on the 1980s action series "The A-Team", and as Reginald Barclay in "", "" and the film "". He is also well known in animation as the mad scientist Dr. Animo in the "Ben 10" series, Chef Mung Daal in the children's cartoon "Chowder", and Eddie the Squirrel in "CatDog".

Schultz was born in Baltimore, Maryland, of German descent, and is a Roman Catholic. He attended Calvert Hall College High School and Towson University.

Schultz's breakthrough role was the character of Captain "Howling Mad" Murdock on "The A-Team". He subsequently appeared in several films, including "The Fan" (1981), and starred in "Fat Man and Little Boy" (1989) as J. Robert Oppenheimer. In the early 1990s, he had a recurring role as Lieutenant Reginald Barclay in "", and reprised the role in "" and the film "". 

Schultz played a dramatic change-of-pace role in the 1992 television film "Child of Rage", starring opposite Mel Harris as a compassionate couple who adopt a troubled girl who has been sexually abused. 

In November 2009, Schultz confirmed that he and former "A-Team" co-star Dirk Benedict would make cameo appearances in the feature film "The A-Team". Although their parts were ultimately cut from the film, they were included after the credits as an Easter egg.

Shultz hosted a conservative talk radio podcast called "Howling Mad Radio", which ended in March 2009. He has also guest-hosted on numerous occasions for Michael Savage on "The Savage Nation", Jerry Doyle on "The Jerry Doyle Show", and Rusty Humphries on "The Rusty Humphries Show".

Schultz married actress Wendy Fulton in 1983. They have one daughter, Ava (born 1987), who serves in the Marines.

Schultz is a conservative and in 2012 began regular appearances on "The Glazov Gang", an Internet political talk show hosted by Jamie Glazov, managing editor of FrontPage Magazine. He also posts political commentaries and podcasts on his official fansite.





</doc>
<doc id="8429" url="https://en.wikipedia.org/wiki?curid=8429" title="Density">
Density

The density, or more precisely, the volumetric mass density, of a substance is its mass per unit volume. The symbol most often used for density is "ρ" (the lower case Greek letter rho), although the Latin letter "D" can also be used. Mathematically, density is defined as mass divided by volume:

where "ρ" is the density, "m" is the mass, and "V" is the volume. In some cases (for instance, in the United States oil and gas industry), density is loosely defined as its weight per unit volume, although this is scientifically inaccurate – this quantity is more specifically called specific weight.

For a pure substance the density has the same numerical value as its mass concentration.
Different materials usually have different densities, and density may be relevant to buoyancy, purity and packaging. Osmium and iridium are the densest known elements at standard conditions for temperature and pressure but certain chemical compounds may be denser.

To simplify comparisons of density across different systems of units, it is sometimes replaced by the dimensionless quantity "relative density" or "specific gravity", i.e. the ratio of the density of the material to that of a standard material, usually water. Thus a relative density less than one means that the substance floats in water.

The density of a material varies with temperature and pressure. This variation is typically small for solids and liquids but much greater for gases. Increasing the pressure on an object decreases the volume of the object and thus increases its density. Increasing the temperature of a substance (with a few exceptions) decreases its density by increasing its volume. In most materials, heating the bottom of a fluid results in convection of the heat from the bottom to the top, due to the decrease in the density of the heated fluid. This causes it to rise relative to more dense unheated material.

The reciprocal of the density of a substance is occasionally called its specific volume, a term sometimes used in thermodynamics. Density is an intensive property in that increasing the amount of a substance does not increase its density; rather it increases its mass.

In a well-known but probably apocryphal tale, Archimedes was given the task of determining whether King Hiero's goldsmith was embezzling gold during the manufacture of a golden wreath dedicated to the gods and replacing it with another, cheaper alloy. Archimedes knew that the irregularly shaped wreath could be crushed into a cube whose volume could be calculated easily and compared with the mass; but the king did not approve of this. Baffled, Archimedes is said to have taken an immersion bath and observed from the rise of the water upon entering that he could calculate the volume of the gold wreath through the displacement of the water. Upon this discovery, he leapt from his bath and ran naked through the streets shouting, "Eureka! Eureka!" (Εύρηκα! Greek "I have found it"). As a result, the term "eureka" entered common parlance and is used today to indicate a moment of enlightenment.

The story first appeared in written form in Vitruvius' "books of architecture", two centuries after it supposedly took place. Some scholars have doubted the accuracy of this tale, saying among other things that the method would have required precise measurements that would have been difficult to make at the time.

From the equation for density ("ρ" = "m"/"V"), mass density has units of mass divided by volume. As there are many units of mass and volume covering many different magnitudes there are a large number of units for mass density in use. The SI unit of kilogram per cubic metre (kg/m) and the cgs unit of gram per cubic centimetre (g/cm) are probably the most commonly used units for density. One g/cm is equal to one thousand kg/m. One cubic centimetre (abbreviation cc) is equal to one millilitre. In industry, other larger or smaller units of mass and or volume are often more practical and US customary units may be used. See below for a list of some of the most common units of density.

The density at all points of a homogeneous object equals its total mass divided by its total volume. The mass is normally measured with a scale or balance; the volume may be measured directly (from the geometry of the object) or by the displacement of a fluid. To determine the density of a liquid or a gas, a hydrometer, a dasymeter or a Coriolis flow meter may be used, respectively. Similarly, hydrostatic weighing uses the displacement of water due to a submerged object to determine the density of the object.

If the body is not homogeneous, then its density varies between different regions of the object. In that case the density around any given location is determined by calculating the density of a small volume around that location. In the limit of an infinitesimal volume the density of an inhomogeneous object at a point becomes: formula_2, where formula_3 is an elementary volume at position formula_4. The mass of the body then can be expressed as

In practice, bulk materials such as sugar, sand, or snow contain voids. Many materials exist in nature as flakes, pellets, or granules.

Voids are regions which contain something other than the considered material. Commonly the void is air, but it could also be vacuum, liquid, solid, or a different gas or gaseous mixture.

The bulk volume of a material—inclusive of the void fraction—is often obtained by a simple measurement (e.g. with a calibrated measuring cup) or geometrically from known dimensions.

Mass divided by "bulk" volume determines bulk density. This is not the same thing as volumetric mass density.

To determine volumetric mass density, one must first discount the volume of the void fraction. Sometimes this can be determined by geometrical reasoning. For the close-packing of equal spheres the non-void fraction can be at most about 74%. It can also be determined empirically. Some bulk materials, however, such as sand, have a "variable" void fraction which depends on how the material is agitated or poured. It might be loose or compact, with more or less air space depending on handling.

In practice, the void fraction is not necessarily air, or even gaseous. In the case of sand, it could be water, which can be advantageous for measurement as the void fraction for sand saturated in water—once any air bubbles are thoroughly driven out—is potentially more consistent than dry sand measured with an air void.

In the case of non-compact materials, one must also take care in determining the mass of the material sample. If the material is under pressure (commonly ambient air pressure at the earth's surface) the determination of mass from a measured sample weight might need to account for buoyancy effects due to the density of the void constituent, depending on how the measurement was conducted. In the case of dry sand, sand is so much denser than air that the buoyancy effect is commonly neglected (less than one part in one thousand).

Mass change upon displacing one void material with another while maintaining constant volume can be used to estimate the void fraction, if the difference in density of the two voids materials is reliably known.

In general, density can be changed by changing either the pressure or the temperature. Increasing the pressure always increases the density of a material. Increasing the temperature generally decreases the density, but there are notable exceptions to this generalization. For example, the density of water increases between its melting point at 0 °C and 4 °C; similar behavior is observed in silicon at low temperatures.

The effect of pressure and temperature on the densities of liquids and solids is small. The compressibility for a typical liquid or solid is 10 bar (1 bar = 0.1 MPa) and a typical thermal expansivity is 10 K. This roughly translates into needing around ten thousand times atmospheric pressure to reduce the volume of a substance by one percent. (Although the pressures needed may be around a thousand times smaller for sandy soil and some clays.) A one percent expansion of volume typically requires a temperature increase on the order of thousands of degrees Celsius.

In contrast, the density of gases is strongly affected by pressure. The density of an ideal gas is

where is the molar mass, is the pressure, is the universal gas constant, and is the absolute temperature. This means that the density of an ideal gas can be doubled by doubling the pressure, or by halving the absolute temperature.

In the case of volumic thermal expansion at constant pressure and small intervals of temperature the temperature dependence of density is :

where formula_8 is the density at a reference temperature, formula_9 is the thermal expansion coefficient of the material at temperatures close to formula_10.

The density of a solution is the sum of mass (massic) concentrations of the components of that solution.

Mass (massic) concentration of each given component ρ in a solution sums to density of the solution.

Expressed as a function of the densities of pure components of the mixture and their volume participation, it allows the determination of excess molar volumes:
provided that there is no interaction between the components.

Knowing the relation between excess volumes and activity coefficients of the components, one can determine the activity coefficients.

The SI unit for density is:

The litre and metric tons are not part of the SI, but are acceptable for use with it, leading to the following units:

Densities using the following metric units all have exactly the same numerical value, one thousandth of the value in (kg/m). Liquid water has a density of about 1 kg/dm, making any of these SI units numerically convenient to use as most solids and liquids have densities between 0.1 and 20 kg/dm.

In US customary units density can be stated in:

Imperial units differing from the above (as the Imperial gallon and bushel differ from the US units) in practice are rarely used, though found in older documents. The Imperial gallon was based on the concept that an Imperial fluid ounce of water would have a mass of one Avoirdupois ounce, and indeed 1 g/cc ≈ 1.00224129 ounces per Imperial fluid ounce = 10.0224129 pounds per Imperial gallon. The density of precious metals could conceivably be based on Troy ounces and pounds, a possible cause of confusion.



</doc>
<doc id="8432" url="https://en.wikipedia.org/wiki?curid=8432" title="Dave Barry">
Dave Barry

David McAlister Barry (born July 3, 1947) is a Pulitzer Prize-winning American author and columnist who wrote a nationally syndicated humor column for the "Miami Herald" from 1983 to 2005. He has also written numerous books of humor and parody, as well as comic novels.

Barry was born in Armonk, New York, where his father, David, was a Presbyterian minister. He was educated at Wampus Elementary School, Harold C. Crittenden Junior High School (both in Armonk), and Pleasantville High School, where he was elected "Class Clown" in 1965. He earned a Bachelor of Arts degree in English from Haverford College in 1969.

As an alumnus of a Quaker-affiliated college, he avoided military service during the Vietnam War by registering as a religious conscientious objector. Notwithstanding his father's vocation, Barry decided "early on" that he was an atheist. He said, "The problem with writing about religion is that you run the risk of offending sincerely religious people, and then they come after you with machetes."

Barry began his journalism career in 1971, working as a general-assignment reporter for the "Daily Local News" in West Chester, Pennsylvania, near his alma mater, Haverford College. He covered local government and civic events and was promoted to City Editor after about two years. He also started writing a weekly humor column for the paper and began to develop his unique style. He remained at the newspaper through 1974. He then worked briefly as a copy editor at the Associated Press's Philadelphia bureau before joining Burger Associates, a consulting firm.

At Burger, he taught effective writing to business people. In his own words, he "spent nearly eight years trying to get various businesspersons to...stop writing things like 'Enclosed please find the enclosed enclosures,' but...eventually realized that it was hopeless."

In 1981 he wrote a humorous guest column, about watching the birth of his son, in the "Philadelphia Inquirer", which attracted the attention of Gene Weingarten, then an editor of the "Miami Herald"'s Sunday magazine "Tropic". Weingarten hired Barry as a humor columnist in 1983. Barry's column was syndicated nationally. Barry won a Pulitzer Prize for Commentary in 1988 for "his consistently effective use of humor as a device for presenting fresh insights into serious concerns."

Barry's first novel, "Big Trouble", was published in 1999. The book was adapted into a motion picture directed by Barry Sonnenfeld and starring Tim Allen, Rene Russo, and Patrick Warburton, with a cameo by Barry (deleted in post-production). The movie was originally due for release in September 2001 but was postponed following the September 11, 2001, attacks because the story involved smuggling a nuclear weapon onto an airplane. The film was released in April 2002.

In response to a column in which Barry mocked the cities of Grand Forks, North Dakota, and East Grand Forks, Minnesota, for calling themselves the "Grand Cities", Grand Forks named a sewage pumping station after Barry in January 2002. Barry traveled to Grand Forks for the dedication ceremony.

Articles written by Barry have appeared in publications such as "Boating", "Home Office Computing", and "Reader's Digest", in addition to the "Chicken Soup for the Soul" inspirational book series. Two of his articles have been included in the "Best American Sportswriting" series. One of his columns was used as the introduction to the book "Pirattitude!: So You Wanna Be a Pirate? Here's How!" (), a follow-up to Barry's role in publicizing International Talk Like a Pirate Day. His books have frequently appeared on the New York Times Best Seller List.

On October 31, 2004, Barry announced that he would be taking an indefinite leave of absence of at least a year from his weekly column in order to spend more time with his family. In December 2005, Barry said in an interview with "Editor and Publisher" that he would not resume his weekly column, although he would continue such features as his yearly gift guide, his year-in-review feature, and his blog, as well as an occasional article or column.

In 2005, Barry won the Walter Cronkite Award for Excellence in Journalism.

On Sunday, September 22, 2013, the opening night of the 15th annual Fall for the Book festival in Fairfax, Virginia, Barry was awarded the event's highest honor, the Fairfax Prize, honoring outstanding literary achievement, presented by the Fairfax Library Foundation.

From 1993 to 1997, CBS broadcast the sitcom "Dave's World" based on the books "Dave Barry Turns 40" and "Dave Barry's Greatest Hits". The show starred Harry Anderson as Barry and DeLane Matthews as his wife Beth. In an early episode, Barry appeared in a cameo role. After four seasons, the program was canceled shortly after being moved from Monday to the "Friday night death slot".

During college, Barry was in a band called the Federal Duck. While at the "Miami Herald", he and several of his colleagues created a band called the Urban Professionals, with Barry on lead guitar and vocals. They performed an original song called "The Tupperware Song" at the Tupperware headquarters in Orlando, Florida.

Beginning in 1992, Barry played lead guitar in the Rock Bottom Remainders, a rock band made up of published authors. (Remainder is a publishing term for a book that doesn't sell.) The band was founded by Barry's sister-in-law, Kathi Kamen Goldmark, for an American Booksellers Association convention, and has also included Stephen King, Amy Tan, Ridley Pearson, Scott Turow, Mitch Albom, Roy Blount, Jr., Barbara Kingsolver, Matt Groening, and Barry's brother Sam, among others. The band's members "are not musically skilled, but they are extremely loud," according to Barry. Several high-profile musicians, including Al Kooper, Warren Zevon, and Roger McGuinn, have performed with the band, and Bruce Springsteen sat in at least once. The band's road tour resulted in the book "Mid-Life Confidential: The Rock Bottom Remainders Tour America with Three Chords and an Attitude". The Rock Bottom Remainders disbanded in 2012 following Goldmark's death from breast cancer. They have reunited at least several times, performing at the Tucson Festival of books in 2016 and 2018.

Beginning in 1984, Barry and "Tropic" editors Gene Weingarten and Tom Shroder have organized the Tropic Hunt (now the Herald Hunt), an annual puzzlehunt in Miami. A Washington, D.C., spinoff, the Post Hunt, began in 2008.

Barry has run several mock campaigns for President of the United States, running on a libertarian platform. He has also written for the Libertarian Party's national newsletter.

The screen adaptation of Barry's book "Dave Barry's Complete Guide to Guys" was released in 2005; it premiered at several film festivals and is available on DVD.

Barry has defined a sense of humor as "a measurement of the extent to which we realize that we are trapped in a world almost totally devoid of reason. Laughter is how we express the anxiety we feel at this knowledge."

He married Lois Ann Shelnutt, his first wife, in 1969. Barry married his second wife, Beth Lenox, in 1976. Barry and Lenox worked together at the "Daily Local News", where they began their journalism careers on the same day in September 1971; they had one child, Robert, born October 8, 1980. Barry and Lenox divorced in 1993. Barry experienced tragedy in his family; his father David W and his youngest brother suffered alcoholism, and his father died in 1984, his sister Mary Katherine was institutionalized for schizophrenia, and his mother committed suicide in 1987. In 1996, Barry married "Miami Herald" sportswriter Michelle Kaufman; they had a daughter, Sophie, in 2000. Barry has had dogs named Earnest, Zippy, and now Lucy. All have been mentioned regularly in Barry's columns.










</doc>
<doc id="8436" url="https://en.wikipedia.org/wiki?curid=8436" title="David Angell">
David Angell

David Lawrence Angell (April 10, 1946September 11, 2001) was an American producer of sitcoms. Angell won multiple Emmy Awards as the creator and executive producer, along with Peter Casey and David Lee, of the comedy series "Frasier". Angell and his wife Lynn both died heading home from their vacation on Cape Cod aboard American Airlines Flight 11. This was the first plane to hit the World Trade Center during the September 11 attacks.

Angell was born in Providence, Rhode Island, to Henry and Mae (née Cooney) Angell. He received a bachelor's degree in English Literature from Providence College. He married Lynn Edwards on August 14, 1971. Soon after Angell entered the U.S. Army upon graduation and served at the Pentagon until 1972. He then moved to Boston and worked as a methods analyst at an engineering company and later at an insurance firm in Rhode Island. His brother, the late Most Rev. Kenneth Angell, was a Roman Catholic prelate and former Bishop of Burlington, Vermont.

Angell moved to Los Angeles in 1977. His first script was sold to the producers of the "Annie Flynn" series. Five years later, he sold his second script to "Archie Bunker's Place". In 1983, he joined "Cheers" as a staff writer. In 1985, Angell joined forces with Peter Casey and David Lee as "Cheers" supervising producers/writers. The trio received 37 Emmy Award nominations and won 24 Emmy Awards, including the above-mentioned for "Frasier", as well as an Outstanding Comedy Series Emmy for "Cheers", in 1989, which Angell, Casey, Lee and the series' other producers shared, and Outstanding Writing/Comedy Emmy for "Cheers", which Angell received in 1984. After working together as producers on "Cheers", Angell, Casey and Lee formed Grub Street Productions. In 1990, they created and executive-produced the comedy series "Wings".

Angell and his wife, Lynn, were among the passengers of American Airlines Flight 11 killed in the September 11 attacks on the World Trade Center in New York City in 2001.

The American Screenwriters Association awards the annual David Angell Humanitarian Award to any individual in the entertainment industry who contributes to global well-being through donations of time, expertise or other support to improve the human condition. 

In 2004, The Angell Foundation of Los Angeles, California awarded Providence College a gift of $2 million for the Smith Center for the Arts. 

The second episode of "Frasier" to air after the attacks, "Don Juan in Hell: Part 2", airing on September 25, 2001, ended with the memorial tribute, "In loving memory of our friends Lynn and David Angell". "Goodnight, Seattle", the series finale which aired May 13, 2004, featured the birth of Niles and Daphne's son who is named David in tribute.

At the National 9/11 Memorial, Angell and his wife are memorialized at the North Pool, on Panel N-1, along with other passengers from Flight 11.



</doc>
<doc id="8437" url="https://en.wikipedia.org/wiki?curid=8437" title="Diedrich Hermann Westermann">
Diedrich Hermann Westermann

Diedrich Hermann Westermann (June 24, 1875–May 31, 1956) was a German missionary, Africanist, and linguist. He substantially extended and revised the work of Carl Meinhof, his teacher, although he rejected some of Meinhof's theories only implicitly. Westermann is seen as one of the founders of modern African linguistics. 

He carried out extensive linguistic and anthropological research in the area ranging from Senegal eastwards to the Upper Nile. His linguistic publications cover a wide range of African languages, including the Gbe languages, Nuer, Kpelle, Shilluk, Hausa, and Guang. 

Westermann's comparative work, begun in 1911, initially brought together much of today's Niger–Congo and Nilo-Saharan language phyla under the name Sudanic languages. His most important later publication "Die westlichen Sudansprachen" 1927a divided these into East and West Sudanic languages and laid the basis for what would become Niger–Congo. In this book and a series of associated articles between 1925 and 1928, Westermann both identified a large number of roots that form the basis of our understanding of Niger–Congo and set out the evidence for the coherence of many of the families that constitute it. Much of the classification of African languages associated with Joseph Greenberg actually derives from the work of Westermann.
In 1927 Westermann published a "Practical Orthography of African Languages" which became later known as the "Westermann script". Subsequently he published the influential and oft-reprinted "Practical Phonetics for Students of African Languages" in collaboration with Ida C. Ward (1933).

He was born in Baden near Bremen and also died there.





</doc>
<doc id="8439" url="https://en.wikipedia.org/wiki?curid=8439" title="Diacritic">
Diacritic

A diacritic – also diacritical mark, diacritical point, diacritical sign, or an accent – is a glyph added to a letter, or basic glyph. The term derives from the Ancient Greek ("diakritikós", "distinguishing"), from ("diakrī́nō", "to distinguish"). "Diacritic" is primarily an adjective, though sometimes used as a noun, whereas "diacritical" is only ever an adjective. Some diacritical marks, such as the acute ( ´ ) and grave ( ` ), are often called "accents". Diacritical marks may appear above or below a letter, or in some other position such as within the letter or between two letters.

The main use of diacritical marks in the Latin script is to change the sound-values of the letters to which they are added. Examples are the diaereses in the borrowed French words "naïve" and "Noël", which show that the vowel with the diaeresis mark is pronounced separately from the preceding vowel; the acute and grave accents, which can indicate that a final vowel is to be pronounced, as in "saké" and poetic "breathèd"; and the cedilla under the "c" in the borrowed French word "façade", which shows it is pronounced rather than . In other Latin-script alphabets, they may distinguish between homonyms, such as the French "là" ("there") versus "la" ("the") that are both pronounced . In Gaelic type, a dot over a consonant indicates lenition of the consonant in question.

In other alphabetic systems, diacritical marks may perform other functions. Vowel pointing systems, namely the Arabic harakat (  etc.) and the Hebrew niqqud ( etc.) systems, indicate vowels that are not conveyed by the basic alphabet. The Indic virama ( ् etc.) and the Arabic sukūn (  ) mark the absence of vowel. Cantillation marks indicate prosody. Other uses include the Early Cyrillic titlo stroke ( ◌҃ ) and the Hebrew gershayim (  ), which, respectively, mark abbreviations or acronyms, and Greek diacritical marks, which showed that letters of the alphabet were being used as numerals. In the Hanyu Pinyin official romanization system for Chinese, diacritics are used to mark the tones of the syllables in which the marked vowels occur.

In orthography and collation, a letter modified by a diacritic may be treated either as a new, distinct letter or as a letter–diacritic combination. This varies from language to language, and may vary from case to case within a language. English is the only major modern European language requiring no diacritics for native words (although a diaeresis may be used in words such as "coöperation").

In some cases, letters are used as "in-line diacritics", with the same function as ancillary glyphs, in that they modify the sound of the letter preceding them, as in the case of the "h" in the English pronunciation of "sh" and "th".

Among the types of diacritic used in alphabets based on the Latin script are:

The tilde, dot, comma, titlo, apostrophe, bar, and colon are sometimes diacritical marks, but also have other uses.

Not all diacritics occur adjacent to the letter they modify. In the Wali language of Ghana, for example, an apostrophe indicates a change of vowel quality, but occurs at the beginning of the word, as in the dialects "’Bulengee" and "’Dolimi". Because of vowel harmony, all vowels in a word are affected, so the scope of the diacritic is the entire word. In abugida scripts, like those used to write Hindi and Thai, diacritics indicate vowels, and may occur above, below, before, after, or around the consonant letter they modify.

The tittle (dot) on the letter "i" of the Latin alphabet originated as a diacritic to clearly distinguish "i" from the minims (downstrokes) of adjacent letters. It first appeared in the 11th century in the sequence "ii" (as in "ingeníí)", then spread to "i" adjacent to "m, n, u", and finally to all lowercase "i"'s. The "j", originally a variant of "i", inherited the tittle. The shape of the diacritic developed from initially resembling today's acute accent to a long flourish by the 15th century. With the advent of Roman type it was reduced to the round dot we have today.


These diacritics are used in addition to the acute, grave, and circumflex accents and the diaeresis:


The diacritics >〮 and 〯  , known as Bangjeom (), were used to mark pitch accents in Hangul for Middle Korean. They were written to the left of a syllable in vertical writing and above a syllable in horizontal writing. 

The South Korean government officially revised the romanization of the Korean language in July 2000 to eliminate diacritics.


In addition to the above vowel marks, transliteration of Syriac sometimes includes "ə", "e̊" or superscript "" (or often nothing at all) to represent an original Aramaic schwa that became lost later on at some point in the development of Syriac. Some transliteration schemes find its inclusion necessary for showing spirantization or for historical reasons.

Some non-alphabetic scripts also employ symbols that function essentially as diacritics.

Different languages use different rules to put diacritic characters in alphabetical order. French treats letters with diacritical marks the same as the underlying letter for purposes of ordering and dictionaries.

The Scandinavian languages, by contrast, treat the characters with diacritics "ä", "ö" and "å" as new and separate letters of the alphabet, and sort them after "z". Usually "ä" is sorted as equal to "æ" (ash) and "ö" is sorted as equal to "ø" (o-slash). Also, "aa", when used as an alternative spelling to "å", is sorted as such. Other letters modified by diacritics are treated as variants of the underlying letter, with the exception that "ü" is frequently sorted as "y".

Languages that treat accented letters as variants of the underlying letter usually alphabetize words with such symbols immediately after similar unmarked words. For instance, in German where two words differ only by an umlaut, the word without it is sorted first in German dictionaries (e.g. "schon" and then "schön", or "fallen" and then "fällen"). However, when names are concerned (e.g. in phone books or in author catalogues in libraries), umlauts are often treated as combinations of the vowel with a suffixed "e"; Austrian phone books now treat characters with umlauts as separate letters (immediately following the underlying vowel).

In Spanish, the grapheme "ñ" is considered a new letter different from "n" and collated between "n" and "o", as it denotes a different sound from that of a plain "n". But the accented vowels "á", "é", "í", "ó", "ú" are not separated from the unaccented vowels "a", "e", "i", "o", "u", as the acute accent in Spanish only modifies stress within the word or denotes a distinction between homonyms, and does not modify the sound of a letter.

For a comprehensive list of the collating orders in various languages, see Collating sequence.

Modern computer technology was developed mostly in English-speaking countries, so data formats, keyboard layouts, etc. were developed with a bias favoring English, a language with an alphabet without diacritical marks. This has led to fears internationally that the marks and accents may be made obsolete to facilitate the worldwide exchange of data. Efforts have been made to create internationalized domain names that further extend the English alphabet (e.g., "pokémon.com").

Depending on the keyboard layout, which differs amongst countries, it is more or less easy to enter letters with diacritics on computers and typewriters. Some have their own keys; some are created by first pressing the key with the diacritic mark followed by the letter to place it on. Such a key is sometimes referred to as a dead key, as it produces no output of its own but modifies the output of the key pressed after it.

In modern Microsoft Windows and Linux operating systems, the keyboard layouts "US International" and "UK International" feature dead keys that allow one to type Latin letters with the acute, grave, circumflex, diæresis, tilde, and cedilla found in Western European languages (specifically, those combinations found in the ISO Latin-1 character set) directly: "¨+e" gives "ë", "~+o" gives "õ", etc. On Apple Macintosh computers, there are keyboard shortcuts for the most common diacritics; Option-"e" followed by a vowel places an acute accent, Option-"u" followed by a vowel gives an umlaut, option-"c" gives a cedilla, etc. Diacritics can be composed in most X Window System keyboard layouts, as well as other operating systems, such as Microsoft Windows, using additional software.

On computers, the availability of code pages determines whether one can use certain diacritics. Unicode solves this problem by assigning every known character its own code; if this code is known, most modern computer systems provide a method to input it. With Unicode, it is also possible to combine diacritical marks with most characters.

The following languages have letters that contain diacritics that are considered independent letters distinct from those without diacritics.



English is one of the few European languages that does not have many words that contain diacritical marks. Exceptions are unassimilated foreign loanwords, including borrowings from French and, increasingly, Spanish; however, the diacritic is also sometimes omitted from such words. Loanwords that frequently appear with the diacritic in English include "café", "résumé" or "resumé" (a usage that helps distinguish it from the verb "resume"), "soufflé", and "naïveté" (see "English terms with diacritical marks"). In older practice (and even among some orthographically conservative modern writers) one may see examples such as "élite", "mêlée" and "rôle."

English speakers and writers once used the diaeresis more often than now in words such as "coöperation" (from Fr. "coopération"), "zoölogy" (from Grk. "zoologia"), and "seeër" (now more commonly "see-er "or simply" seer"), but this practice has become far less common. "The New Yorker" magazine is a major publication that continues to use the diaresis in place of a dash for clarity and economy of space.

A few English words, out of context, can only be distinguished from others by a diacritic or modified letter, including exposé, lamé, maté, öre, øre, pâté, and rosé'. The same is true of "résumé," alternately "" but nevertheless it is regularly spelled "resume". In a few words, diacritics that did not exist in the original have been added for disambiguation, as in maté (from Sp. and Port. "mate"), saké (the standard Romanization of the Japanese has no accent mark), and Malé (from Dhivehi މާލެ), to clearly distinguish them from the English words "mate", "sake", and "male".

The acute and grave accents are occasionally used in poetry and lyrics: the acute to indicate stress overtly where it might be ambiguous ("rébel" vs. "rebél") or nonstandard for metrical reasons ("caléndar"), the grave to indicate that an ordinarily silent or elided syllable is pronounced ("warnèd," "parlìament").

In certain personal names such as "Renée" and "Zoë", often two spellings exist, and the preference will be known only to those close to the person themselves. Even when the name of a person is spelled with a diacritic, like Charlotte Brontë, this may be dropped in less careful sources such as webpages, and may not appear even in official documents such as passports. They also appear in some worldwide company names and/or trademarks such as Nestlé or Citroën.

The following languages have letter-diacritic combinations that are not considered independent letters.

Several languages that are not written with the Roman alphabet are transliterated, or romanized, using diacritics. Examples:




</doc>
<doc id="8442" url="https://en.wikipedia.org/wiki?curid=8442" title="Digraph">
Digraph

Digraph may refer to:




</doc>
<doc id="8443" url="https://en.wikipedia.org/wiki?curid=8443" title="Didgeridoo">
Didgeridoo

The didgeridoo (; also known as a didjeridu) is a wind instrument developed by Indigenous Australians of northern Australia potentially within the last 1,500 years and still in widespread use today both in Australia and around the world. It is sometimes described as a natural wooden trumpet or "drone pipe". Musicologists classify it as a brass aerophone.

There are no reliable sources stating the didgeridoo's exact age. Archaeological studies of rock art in Northern Australia suggest that the people of the Kakadu region of the Northern Territory have been using the didgeridoo for less than 1,000 years, based on the dating of paintings on cave walls and shelters from this period. A clear rock painting in Ginga Wardelirrhmeng, on the northern edge of the Arnhem Land plateau, from the freshwater period (that had begun 1500 years ago) shows a didgeridoo player and two songmen participating in an Ubarr Ceremony.

A modern didgeridoo is usually cylindrical or conical, and can measure anywhere from long. Most are around long. Generally, the longer the instrument, the lower its pitch or key. However, flared instruments play a higher pitch than unflared instruments of the same length.

There are numerous names for the instrument among the Aboriginal peoples of northern Australia, none of which closely resemble the word "didgeridoo" (see below). Many didgeridoo enthusiasts and some scholars advocate reserving local names for traditional instruments, and this practice has been endorsed by some Aboriginal community organisations. However, in everyday conversation, bilingual Aboriginal people will often use the word "didgeridoo" interchangeably with the instrument's name in their own language.

"Didgeridoo" is considered to be an onomatopoetic word of Western invention. The earliest occurrences of the word in print include a 1908 edition of the "Hamilton Spectator", a 1914 edition of "The Northern Territory Times and Gazette", and a 1919 issue of "Smith's Weekly" where it was referred to as an "infernal didjerry" which "produced but one sound – (phonic) didjerry, didjerry, didjerry and so on ad infinitum".

A rival explanation, that didgeridoo is a corruption of the Irish language (Gaelic) phrase "dúdaire dubh" or "dúidire dúth", is controversial. "Dúdaire"/"dúidire" is a noun that may mean, depending on the context, "trumpeter", "hummer", "crooner", "long-necked person", "puffer", "eavesdropper", or "chain smoker", while "dubh" means "black" and "dúth" means "native".

"Yiḏaki" (sometimes spelt "yirdaki") is one of the most commonly used names, although – strictly speaking – it refers to a specific type of instrument made and used by the Yolngu people of north-east Arnhem Land. However, since the passing, in early 2011, of a Manggalili-clan man whose name sounds similar to "yiḏaki", Yolngu themselves now use the synonym "mandapul" to refer to the instrument, out of respect for the deceased.

There are numerous other, regional names for the didgeridoo. The following are some of the more common of these.
Authentic Aboriginal didgeridoos are produced in traditionally oriented communities in Northern Australia or by makers who travel to Central and Northern Australia to collect the raw materials. They are usually made from hardwoods, especially the various eucalyptus species that are endemic to the region. Generally the main trunk of the tree is harvested, though a substantial branch may be used instead. Aboriginal didgeridoo craftsmen hunt for suitably hollow live trees in areas with obvious termite activity. Termites attack these living eucalyptus trees, removing only the dead heartwood of the tree, as the living sapwood contains a chemical that repels the insects. Various techniques are employed to find trees with a suitable hollow, including knowledge of landscape and termite activity patterns, and a kind of tap or knock test, in which the bark of the tree is peeled back, and a fingernail or the blunt end of a tool, such as an axe is knocked against the wood to determine if the hollow produces the right resonance.

Once a suitably hollow tree is found, it is cut down and cleaned out, the bark is taken off, the ends trimmed, and the exterior is shaped; this results in a finished instrument. This instrument may be painted or left undecorated. A rim of beeswax may be applied to the mouthpiece end. Traditional instruments made by Aboriginal craftsmen in Arnhem Land are sometimes fitted with a "sugarbag" mouthpiece. This black beeswax comes from wild bees and has a distinctive aroma.

Non-traditional didgeridoos can also be made from PVC piping, non-native hard woods (typically split, hollowed and rejoined), glass, fiberglass, metal, agave, clay, hemp (in the form of a bioplastic named zelfo), and even carbon fibre. These didges typically have an upper inside diameter of around 1.25" down to a bell end of anywhere between two and eight inches and have a length corresponding to the desired key. The mouthpiece can be constructed of beeswax, hardwood or simply sanded and sized by the craftsman. In PVC, an appropriately sized rubber stopper with a hole cut into it is equally acceptable, or to finely sand and buff the end of the pipe to create a comfortable mouthpiece.

Modern didgeridoo designs are distinct from the traditional Australian Aboriginal didgeridoo, and are innovations recognized by musicologists. Didgeridoo design innovation started in the late 20th century using non-traditional materials and non-traditional shapes.

Many didgeridoos are painted using traditional or modern paints by either their maker or a dedicated artist; however, it is not essential that the instrument be decorated. It is also common to retain the natural wood grain with minimal or no decoration. Some modern makers deliberately avoid decoration if they are not of Indigenous Australian descent, or leave the instrument blank for an Indigenous Australian artist to decorate it at a later stage.

The didgeridoo is played with continuously vibrating lips to produce the drone while using a special breathing technique called circular breathing. This requires breathing in through the nose whilst simultaneously expelling stored air out of the mouth using the tongue and cheeks. By use of this technique, a skilled player can replenish the air in their lungs, and with practice can sustain a note for as long as desired. Recordings exist of modern didgeridoo players playing continuously for more than 40 minutes; Mark Atkins on "Didgeridoo Concerto" (1994) plays for over 50 minutes continuously.

Fellow of the British Society Anthony Baines wrote that the didgeridoo functions "...as an aural kaleidoscope of timbres" and that "the extremely difficult virtuoso techniques developed by expert performers find no parallel elsewhere."

More modern approaches to playing the didgeridoo are starting to show up in performances and lessons around the World. One of these techniques involves combining beatboxing with playing the didgeridoo. It was featured on the British children's TV series "Blue Peter".

A termite-bored didgeridoo has an irregular shape that, overall, usually increases in diameter towards the lower end. This shape means that its resonances occur at frequencies that are not harmonically spaced in frequency. This contrasts with the harmonic spacing of the resonances in a cylindrical plastic pipe, whose resonant frequencies fall in the ratio 1:3:5 etc. The second resonance of a didgeridoo (the note sounded by overblowing) is usually around an 11th higher than the fundamental frequency (a frequency ratio somewhat less than 3:1).

The vibration produced by the player's lips has harmonics, i.e., it has frequency components falling exactly in the ratio 1:2:3 etc. However, the non-harmonic spacing of the instrument's resonances means that the harmonics of the fundamental note are not systematically assisted by instrument resonances, as is usually the case for Western wind instruments (e.g., in a clarinet, the 1st 3rd and 5th harmonics of the reed are assisted by resonances of the bore, at least for notes in the low range).

Sufficiently strong resonances of the vocal tract can strongly influence the timbre of the instrument.
At some frequencies, whose values depend on the position of the player's tongue, resonances of the vocal tract inhibit the oscillatory flow of air into the instrument.
Bands of frequencies that are not thus inhibited produce formants in the output sound.
These formants, and especially their variation during the inhalation and exhalation phases of circular breathing, give the instrument its readily recognizable sound.

Other variations in the didgeridoo's sound can be made by adding vocalizations to the drone. Most of the vocalizations are related to sounds emitted by Australian animals, such as the dingo or the kookaburra. To produce these sounds, the players simply have to use their vocal folds to produce the sounds of the animals whilst continuing to blow air through the instrument. The results range from very high-pitched sounds to much lower guttural vibrations. Adding vocalizations increases the complexity of the playing.

Traditionally and originally, the didgeridoo was primarily played as an accompaniment to ceremonial dancing and singing. However, it was also common for didgeridoos to be played for solo or recreational purposes outside of ceremonial gatherings. For surviving Aboriginal groups of northern Australia, the didgeridoo is still an integral part of ceremonial life, as it accompanies singers and dancers in cultural ceremonies that continue. Today, the majority of didgeridoo playing is for recreational purposes in both Indigenous Australian communities and elsewhere around the world.

Pair sticks, sometimes called "clapsticks" or "bilma", establish the beat for the songs during ceremonies. The rhythm of the didgeridoo and the beat of the clapsticks are precise, and these patterns have been handed down for many generations. In the Wangga genre, the song-man starts with vocals and then introduces "blima" to the accompaniment of didgeridoo.

Traditionally, only men play the didgeridoo and sing during ceremonial occasions, although both men and women may dance. Female didgeridoo players do exist, but their playing takes place in an informal context and is not specifically encouraged by Aboriginal elders. Linda Barwick, an ethnomusicologist, says that though traditionally women have not played the didgeridoo in ceremony, in informal situations there is no prohibition in the Dreaming Law. For example, Jemima Wimalu, a Mara woman from the Roper River is very proficient at playing the didgeridoo and is featured on the record "Aboriginal Sound Instruments" released in 1978. In 1995, musicologist Steve Knopoff observed Yirrkala women performing "djatpangarri" songs that are traditionally performed by men and in 1996, ethnomusicologist Elizabeth MacKinley reported women of the Yanyuwa group giving public performances. In 2008, however, publisher Harper Collins apologized for its book "The Daring Book for Girls", which openly encouraged girls to play the instrument after Aboriginal academics described such encouragement as "extreme cultural insensitivity" and "an extreme faux pas... part of a general ignorance that mainstream Australia has about Aboriginal culture."

While there is no prohibition in the area of the didgeridoo's origin, such restrictions have been applied by other Indigenous communities. The didgeridoo was introduced to the Kimberleys almost a century ago but it is only in the last decade that Aboriginal men have shown adverse reactions to women playing the instrument and prohibitions are especially evident in the South East of Australia. The belief that women are prohibited from playing is widespread among non-Aboriginal people and is also common among Aboriginal communities in Southern Australia; some ethnomusicologists believe that the dissemination of the "Taboo" belief and other misconceptions is a result of commercial agendas and marketing. Tourists generally rely on shop employees for information when purchasing a didgeridoo. Additionally, the majority of commercial didgeridoo recordings available are distributed by multinational recording companies and feature non-Aboriginals playing a New Age style of music with liner notes promoting the instrument's spirituality which misleads consumers about the didgeridoo's secular role in traditional Aboriginal culture.

The Taboo belief is particularly strong among many Indigenous groups in the South East of Australia, where it is forbidden and considered "cultural theft" for non-Indigenous women, and especially performers of "New Age" music regardless of sex, to play or even touch a didgeridoo.

The didgeridoo also became a role playing instrument in the experimental and avant-garde music scene. Industrial music bands like Test Department generated sounds from this instrument and used them in their industrial performances, linking ecology to industry, influenced by ethnic music and culture.

It is very often used in the music project Naakhum which combines Extreme Metal and Ethnic music.

The acid jazz band Jamiroquai were known for their didgeridoo player Wallis Buchanan. In the early days of the band, many songs explored the theme of ecology and those of native cultures marginalized by colonisation. A notable song featuring a didgeridoo is the band's first single "When You Gonna Learn", which features prominent didgeridoo playing in both the introduction and solo sections. When Wallis Buchanan left the band in 1999, the band chose not to replace him, and simply abandoned the use of the instrument in their music.

The instrument is commonly used by ambient artist Steve Roach as a complement to his produced soundscapes, in both live and recorded formats. It features prominently in his collaborative work "" (with Australian Aboriginal artist David Hudson and cellist Sarah Hopkins) as well as "Dreamtime Return".

It is used in the Indian song "Jaane Kyon" from the film "Dil Chahta Hai".

Chris Brooks, lead singer of the New Zealand hard rock band Like a Storm uses the didgeridoo in some of the band's songs including "Love the Way You Hate Me" from their album "".

Kate Bush made extensive use of the didgeridoo (played by Australian musician Rolf Harris) on her album "The Dreaming", which was written and recorded after a holiday in Australia.

A 2005 study in the "British Medical Journal" found that learning and practising the didgeridoo helped reduce snoring and obstructive sleep apnea by strengthening muscles in the upper airway, thus reducing their tendency to collapse during sleep. In the study, intervention subjects were trained in and practiced didgeridoo playing, including circular breathing and other techniques. Control subjects were asked not to play the instrument. Subjects were surveyed before and after the study period to assess the effects of intervention. A small 2010 study noted improvements in the asthma management of Aboriginal teens when incorporating didgeridoo playing.




</doc>
<doc id="8449" url="https://en.wikipedia.org/wiki?curid=8449" title="Developmental biology">
Developmental biology

Developmental biology is the study of the process by which animals and plants grow and develop. Developmental biology also encompasses the biology of regeneration, asexual reproduction, metamorphosis, and the growth and differentiation of stem cells in the adult organism.

In the late 20th century, the discipline has largely transformed into evolutionary developmental biology.

The main processes involved in the embryonic development of animals are: regional specification, morphogenesis, cell differentiation, growth, and the overall control of timing explored in evolutionary developmental biology.

Regional specification refers to the processes that create spatial pattern in a ball or sheet of initially similar cells. This generally involves the action of cytoplasmic determinants, located within parts of the fertilized egg, and of inductive signals emitted from signaling centers in the embryo. The early stages of regional specification do not generate functional differentiated cells, but cell populations committed to develop to a specific region or part of the organism. These are defined by the expression of specific combinations of transcription factors. Morphogenesis relates to the formation of three-dimensional shape. It mainly involves the orchestrated movements of cell sheets and of individual cells. Morphogenesis is important for creating the three germ layers of the early embryo (ectoderm, mesoderm and endoderm) and for building up complex structures during organ development. Cell differentiation relates specifically to the formation of functional cell types such as nerve, muscle, secretory epithelia etc. Differentiated cells contain large amounts of specific proteins associated with the cell function. Growth involves both an overall increase in size, and also the differential growth of parts (allometry) which contributes to morphogenesis. Growth mostly occurs through cell division but also through changes of cell size and the deposition of extracellular materials. The control of timing of events and the integration of the various processes with one another is the least well understood area of the subject. It remains unclear whether animal embryos contain a master clock mechanism or not.

The development of plants involves similar processes to that of animals. However plant cells are mostly immotile so morphogenesis is achieved by differential growth, without cell movements. Also, the inductive signals and the genes involved are different from those that control animal development.

Cell differentiation is the process whereby different functional cell types arise in development. For example, neurons, muscle fibers and hepatocytes (liver cells) are well known types of differentiated cell. Differentiated cells usually produce large amounts of a few proteins that are required for their specific function and this gives them the characteristic appearance that enables them to be recognized under the light microscope. The genes encoding these proteins are highly active. Typically their chromatin structure is very open, allowing access for the transcription enzymes, and specific transcription factors bind to regulatory sequences in the DNA in order to activate gene expression. For example, NeuroD is a key transcription factor for neuronal differentiation, myogenin for muscle differentiation, and HNF4 for hepatocyte differentiation.
Cell differentiation is usually the final stage of development, preceded by several states of commitment which are not visibly differentiated. A single tissue, formed from a single type of progenitor cell or stem cell, often consists of several differentiated cell types. Control of their formation involves a process of lateral inhibition, based on the properties of the Notch signaling pathway. For example, in the neural plate of the embryo this system operates to generate a population of neuronal precursor cells in which NeuroD is highly expressed.

Regeneration indicates the ability to regrow a missing part. This is very prevalent amongst plants, which show continuous growth, and also among colonial animals such as hydroids and ascidians. But most interest by developmental biologists has been shown in the regeneration of parts in free living animals. In particular four models have been the subject of much investigation. Two of these have the ability to regenerate whole bodies: "Hydra", which can regenerate any part of the polyp from a small fragment, and planarian worms, which can usually regenerate both heads and tails. Both of these examples have continuous cell turnover fed by stem cells and, at least in planaria, at least some of the stem cells have been shown to be pluripotent. The other two models show only distal regeneration of appendages. These are the insect appendages, usually the legs of hemimetabolous insects such as the cricket, and the limbs of urodele amphibians. Considerable information is now available about amphibian limb regeneration and it is known that each cell type regenerates itself, except for connective tissues where there is considerable interconversion between cartilage, dermis and tendons. In terms of the pattern of structures, this is controlled by a re-activation of signals active in the embryo.
There is still debate about the old question of whether regeneration is a "pristine" or an "adaptive" property. If the former is the case, with improved knowledge, we might expect to be able to improve regenerative ability in humans. If the latter, then each instance of regeneration is presumed to have arisen by natural selection in circumstances particular to the species, so no general rules would be expected.

The sperm and egg fuse in the process of fertilization to form a fertilized egg, or zygote. This undergoes a period of divisions to form a ball or sheet of similar cells called a blastula or blastoderm. These cell divisions are usually rapid with no growth so the daughter cells are half the size of the mother cell and the whole embryo stays about the same size. They are called cleavage divisions. Morphogenetic movements convert the cell mass into a three layered structure consisting of multicellular sheets called ectoderm, mesoderm and endoderm, which are known as germ layers. This is the process of gastrulation. During cleavage and gastrulation the first regional specification events occur. In addition to the formation of the three germ layers themselves, these often generate extraembryonic structures, such as the mammalian placenta, needed for support and nutrition of the embryo, and also establish differences of commitment along the anteroposterior axis (head, trunk and tail).

Regional specification is initiated by the presence of cytoplasmic determinants in one part of the zygote. The cells that contain the determinant become a signaling center and emit an inducing factor. Because the inducing factor is produced in one place, diffuses away, and decays, it forms a concentration gradient, high near the source cells and low further away. The remaining cells of the embryo, which do not contain the determinant, are competent to respond to different concentrations by upregulating specific developmental control genes. This results in a series of zones becoming set up, arranged at progressively greater distance from the signaling center. In each zone a different combination of developmental control genes is upregulated. These genes encode transcription factors which upregulate new combinations of gene activity in each region. Among other functions, these transcription factors control expression of genes conferring specific adhesive and motility properties on the cells in which they are active. Because of these different morphogenetic properties, the cells of each germ layer move to form sheets such that the ectoderm ends up on the outside, mesoderm in the middle, and endoderm on the inside. Morphogenetic movements not only change the shape and structure of the embryo, but by bringing cell sheets into new spatial relationships they also make possible new phases of signaling and response between them.

Growth in embryos is mostly autonomous. For each territory of cells the growth rate is controlled by the combination of genes that are active. Free living embryos do not grow in mass as they have no external food supply. But embryos fed by a placenta or extraembryonic yolk supply can grow very fast, and changes to relative growth rate between parts in these organisms help to produce the final overall anatomy.

The whole process needs to be coordinated in time and how this is controlled is not understood. There may be a master clock able to communicate with all parts of the embryo that controls the course of events, or timing may depend simply on local causal sequences of events.

Developmental processes are very evident during the process of metamorphosis. This occurs in various types of animal. Well known are the examples of the frog, which usually hatches as a tadpole and metamorphoses to an adult frog, and certain insects which hatch as a larva and then become remodeled to the adult form during a pupal stage.

All the developmental processes listed above occur during metamorphosis. Examples that have been especially well studied include tail loss and other changes in the tadpole of the frog "Xenopus", and the biology of the imaginal discs, which generate the adult body parts of the fly "Drosophila melanogaster".

Plant development is the process by which structures originate and mature as a plant grows. It is studied in plant anatomy and plant physiology as well as plant morphology.

Plants constantly produce new tissues and structures throughout their life from meristems located at the tips of organs, or between mature tissues. Thus, a living plant always has embryonic tissues. By contrast, an animal embryo will very early produce all of the body parts that it will ever have in its life. When the animal is born (or hatches from its egg), it has all its body parts and from that point will only grow larger and more mature.

The properties of organization seen in a plant are emergent properties which are more than the sum of the individual parts. "The assembly of these tissues and functions into an integrated multicellular organism yields not only the characteristics of the separate parts and processes but also quite a new set of characteristics which would not have been predictable on the basis of examination of the separate parts."

A vascular plant begins from a single celled zygote, formed by fertilisation of an egg cell by a sperm cell. From that point, it begins to divide to form a plant embryo through the process of embryogenesis. As this happens, the resulting cells will organize so that one end becomes the first root, while the other end forms the tip of the shoot. In seed plants, the embryo will develop one or more "seed leaves" (cotyledons). By the end of embryogenesis, the young plant will have all the parts necessary to begin in its life.

Once the embryo germinates from its seed or parent plant, it begins to produce additional organs (leaves, stems, and roots) through the process of organogenesis. New roots grow from root meristems located at the tip of the root, and new stems and leaves grow from shoot meristems located at the tip of the shoot. Branching occurs when small clumps of cells left behind by the meristem, and which have not yet undergone cellular differentiation to form a specialized tissue, begin to grow as the tip of a new root or shoot. Growth from any such meristem at the tip of a root or shoot is termed primary growth and results in the lengthening of that root or shoot. Secondary growth results in widening of a root or shoot from divisions of cells in a cambium.

In addition to growth by cell division, a plant may grow through cell elongation. This occurs when individual cells or groups of cells grow longer. Not all plant cells will grow to the same length. When cells on one side of a stem grow longer and faster than cells on the other side, the stem will bend to the side of the slower growing cells as a result. This directional growth can occur via a plant's response to a particular stimulus, such as light (phototropism), gravity (gravitropism), water, (hydrotropism), and physical contact (thigmotropism).

Plant growth and development are mediated by specific plant hormones and plant growth regulators (PGRs) (Ross et al. 1983). Endogenous hormone levels are influenced by plant age, cold hardiness, dormancy, and other metabolic conditions; photoperiod, drought, temperature, and other external environmental conditions; and exogenous sources of PGRs, e.g., externally applied and of rhizospheric origin.

Plants exhibit natural variation in their form and structure. While all organisms vary from individual to individual, plants exhibit an additional type of variation. Within a single individual, parts are repeated which may differ in form and structure from other similar parts. This variation is most easily seen in the leaves of a plant, though other organs such as stems and flowers may show similar variation. There are three primary causes of this variation: positional effects, environmental effects, and juvenility.

Transcription factors and transcriptional regulatory networks play key roles in plant morphogenesis and their evolution. During plant landing, many novel transcription factor families emerged and are preferentially wired into the networks of multicellular development, reproduction, and organ development, contributing to more complex morphogenesis of land plants.

Much of developmental biology research in recent decades has focused on the use of a small number of model organisms. It has turned out that there is much conservation of developmental mechanisms across the animal kingdom. In early development different vertebrate species all use essentially the same inductive signals and the same genes encoding regional identity. Even invertebrates use a similar repertoire of signals and genes although the body parts formed are significantly different. Model organisms each have some particular experimental advantages which have enabled them to become popular among researchers. In one sense they are "models" for the whole animal kingdom, and in another sense they are "models" for human development, which is difficult to study directly for both ethical and practical reasons. Model organisms have been most useful for elucidating the broad nature of developmental mechanisms. The more detail is sought, the more they differ from each other and from humans.

Plants:

Vertebrates:

Invertebrates:


Also popular for some purposes have been sea urchins and ascidians. For studies of regeneration urodele amphibians such as the axolotl "Ambystoma mexicanum" are used, and also planarian worms such as "Schmidtea mediterranea". Organoids have also been demonstrated as an efficient model for development. Plant development has focused on the thale cress "Arabidopsis thaliana" as a model organism.




</doc>
<doc id="8452" url="https://en.wikipedia.org/wiki?curid=8452" title="December 27">
December 27





</doc>
<doc id="8454" url="https://en.wikipedia.org/wiki?curid=8454" title="Double planet">
Double planet

In astronomy, a double planet (also binary planet) is a binary system where both objects are of planetary mass. The term is not recognized by the International Astronomical Union (IAU) and is therefore not an official classification. At its 2006 General Assembly, the International Astronomical Union considered a proposal that Pluto and Charon be reclassified as a double planet, but the proposal was abandoned in favor of the current definition of planet. In promotional materials advertising the SMART-1 mission and pre-dating the IAU planet definition, the European Space Agency once referred to the Earth–Moon system as a double planet.

Some binary asteroids with components of roughly equal mass are sometimes informally referred to as double minor planets. These include binary asteroids 69230 Hermes and 90 Antiope and binary Kuiper belt objects (KBOs) 79360 Sila–Nunam and .

There is debate as to what criteria should be used to distinguish "double planet" from a "planet–moon system". The following are considerations.

A definition proposed in the Astronomical Journal calls for both bodies to individually satisfy an orbit-clearing criterion in order to be called a double planet.

One important consideration in defining "double planet" is the ratio of the masses of the two bodies. A mass ratio of 1 would indicate bodies of equal mass, and bodies with mass ratios closer to 1 are more attractive to label as "doubles". Using this definition, the satellites of Mars, Jupiter, Saturn, Uranus, and Neptune can all easily be excluded; they all have masses less than 0.00025 () of the planets around which they revolve. Some dwarf planets, too, have satellites substantially less massive than the dwarf planets themselves.

The most notable exception is the Pluto–Charon system. The Charon-to-Pluto mass ratio of 0.117 (≈ ) is close enough to 1 that Pluto and Charon have frequently been described by many scientists as "double dwarf planets" ("double planets" prior to the 2006 definition of "planet"). The International Astronomical Union (IAU) currently calls Charon a satellite of Pluto, but has explicitly expressed a willingness to reconsider the bodies double dwarf planets at a future time.

The Moon-to-Earth mass ratio of 0.01230 (≈ ) is also notably close to 1 when compared to all other satellite-to-planet ratios. Consequently, some scientists view the Earth-Moon system as a double planet as well, though this is a minority view. Eris's lone satellite, Dysnomia, has a radius somewhere around that of Eris; assuming similar densities (Dysnomia's compositional make-up may or may not differ substantially from Eris's), the mass ratio would be near , a value intermediate to the Moon–Earth and Charon–Pluto ratios.

The next criteria both attempt to answer the question "How close to 1 must the mass ratio be?"

Currently, the most commonly proposed definition for a double-planet system is one in which the barycenter, around which both bodies orbit, lies outside both bodies. Under this definition, Pluto and Charon are double (dwarf) planets, since they orbit a point clearly outside of Pluto, as visible in animations created from images of the "New Horizons" space probe in June 2015.

Under this definition, the Earth–Moon system is not currently a double planet; although the Moon is massive enough to cause the Earth to make a noticeable revolution around this center of mass, this point nevertheless lies well within Earth. However, the Moon migrates outward from Earth at a rate of approximately per year; in a few hundred million years, the Earth–Moon system's center of mass will lie outside Earth, which would make it a double-planet system.

It is interesting to note that the center of mass of the Jupiter–Sun system lies outside the surface of the Sun, though arguing that Jupiter is a double star is "not" analogous to arguing Charon is a double planet; the problem is that one cannot argue that Jupiter is even a star—even a brown dwarf—due to its low mass and associated inability to support any type of fusion.

Isaac Asimov suggested a distinction between planet–moon and double-planet structures based in part on what he called a "tug-of-war" value, which does not consider their relative sizes. This quantity is simply the ratio of the force exerted on the smaller body by the larger (primary) body to the force exerted on the smaller body by the Sun. This can be shown to equal

where m is the mass of the primary (the larger body), m is the mass of the Sun, d is the distance between the smaller body and the Sun, and d is the distance between the smaller body and the primary. Note that the tug-of-war value does not rely on the mass of the satellite (the smaller body).

This formula actually reflects the relation of the gravitational effects on the smaller body from the larger body and from the Sun. The tug-of-war figure for Saturn's moon Titan is 380, which means that Saturn's hold on Titan is 380 times as strong as the Sun's hold on Titan. Titan's tug-of-war value may be compared with that of Saturn's moon Phoebe, which has a tug-of-war value of just 3.5. So Saturn's hold on Phoebe is only 3.5 times as strong as the Sun's hold on Phoebe.

Asimov calculated tug-of-war values for several satellites of the planets. He showed that even the largest gas giant, Jupiter, had only a slightly better hold than the Sun on its outer captured satellites, some with tug-of-war values not much higher than one. In nearly every one of Asimov's calculations the tug-of-war value was found to be greater than one, so in those cases the Sun loses the tug-of-war with the planets. The one exception was Earth's Moon, where the Sun wins the tug-of-war with a value of 0.46, which means that Earth's hold on the Moon is less than half that of the Sun's. Asimov included this with his other arguments that Earth and the Moon should be considered a binary planet.
See the Path of Earth and Moon around Sun section in the "Orbit of the Moon" article for a more detailed explanation.

Note that this definition of double planet depends on the pair's distance from the Sun. If the Earth–Moon system happened to orbit farther away from the Sun than it does now, then Earth would win the tug of war. For example, at the orbit of Mars, the Moon's tug-of-war value would be 1.05. Also, several tiny moons discovered since Asimov's proposal would qualify as double planets by this argument. Neptune's small outer moons Neso and Psamathe, for example, have tug-of-war values of 0.42 and 0.44, less than that of Earth's Moon. Yet their masses are tiny compared to Neptune's, with an estimated ratio of 1.5 () and 0.4 ().

A final consideration is the way in which the two bodies came to form a system. Both the Earth-Moon and Pluto-Charon systems are thought to have been formed as a result of giant impacts: one body was impacted by a second body, resulting in a debris disk, and through accretion, either two new bodies formed or one new body formed, with the larger body remaining (but changed). However, a giant impact is not a sufficient condition for two bodies being "double planets" because such impacts can also produce tiny satellites, such as the four, small, outer satellites of Pluto.

A now-abandoned hypothesis for the origin of the Moon was actually called the "double-planet hypothesis"; the idea was that the Earth and the Moon formed in the same region of the solar system's proto-planetary disk, forming a system under gravitational interaction. This idea, too, is a problematic condition for defining two bodies as "double planets" because planets can "capture" moons through gravitational interaction. For example, the moons of Mars (Phobos and Deimos) are thought to be asteroids captured long ago by Mars. Such a weak definition would also deem Neptune-Triton a double planet, since Triton was a Kuiper belt body the same size and of similar composition to Pluto, later captured by Neptune.




</doc>
<doc id="8456" url="https://en.wikipedia.org/wiki?curid=8456" title="Denaturation (biochemistry)">
Denaturation (biochemistry)

Denaturation is a process in which proteins or nucleic acids lose the quaternary structure, tertiary structure, and secondary structure which is present in their native state, by application of some external stress or compound such as a strong acid or base, a concentrated inorganic salt, an organic solvent (e.g., alcohol or chloroform), radiation or heat. If proteins in a living cell are denatured, this results in disruption of cell activity and possibly cell death. Protein denaturation is also a consequence of cell death. Denatured proteins can exhibit a wide range of characteristics, from conformational change and loss of solubility to aggregation due to the exposure of hydrophobic groups. Denatured proteins lose their 3D structure and therefore cannot function.

Protein folding is key to whether a globular protein or a membrane protein can do its job correctly. It must be folded into the right shape to function. But hydrogen bonds, which play a big part in folding, are rather weak, and it doesn't take much heat, acidity, varying salt concentrations, or other stress to break some and form others, denaturing the protein. This is one reason why tight homeostasis is physiologically necessary in many life forms.

This concept is unrelated to denatured alcohol, which is alcohol that has been mixed with additives to make it unsuitable for human consumption.

When food is cooked, some of its proteins become denatured. This is why boiled eggs become hard and cooked meat becomes firm.

A classic example of denaturing in proteins comes from egg whites, which are typically largely egg albumins in water. Fresh from the eggs, egg whites are transparent and liquid. Cooking the thermally unstable whites turns them opaque, forming an interconnected solid mass. The same transformation can be effected with a denaturing chemical. Pouring egg whites into a beaker of acetone will also turn egg whites translucent and solid. The skin that forms on curdled milk is another common example of denatured protein. The cold appetizer known as ceviche is prepared by chemically "cooking" raw fish and shellfish in an acidic citrus marinade, without heat.

Denatured proteins can exhibit a wide range of characteristics, from loss of solubility to protein aggregation.

Proteins or Polypeptides are polymers of amino acids. A protein is created by ribosomes that "read" RNA that is encoded by codons in the gene and assemble the requisite amino acid combination from the genetic instruction, in a process known as translation. The newly created protein strand then undergoes posttranslational modification, in which additional atoms or molecules are added, for example copper, zinc, or iron. Once this post-translational modification process has been completed, the protein begins to fold (sometimes spontaneously and sometimes with enzymatic assistance), curling up on itself so that hydrophobic elements of the protein are buried deep inside the structure and hydrophilic elements end up on the outside. The final shape of a protein determines how it interacts with its environment.

Protein folding consists of a balance between a substantial amount of weak intra-molecular interactions within a protein (Hydrophobic, electrostatic, and Van Der Waals Interactions) and protein-solvent interactions. As a result, this process is heavily reliant on environmental state that the protein resides in. These environmental conditions include, and are not limited to, temperature, salinity, pressure, and the solvents that happen to be involved. Consequently, any exposure to extreme stresses (e.g. heat or radiation, high inorganic salt concentrations, strong acids and bases) can disrupt a protein's interaction and inevitably lead to denaturation.

When a protein is denatured, secondary and tertiary structures are altered but the peptide bonds of the primary structure between the amino acids are left intact. Since all structural levels of the protein determine its function, the protein can no longer perform its function once it has been denatured. This is in contrast to intrinsically unstructured proteins, which are unfolded in their native state, but still functionally active and tend to fold upon binding to their biological target.


Most biological substrates lose their biological function when denatured. For example, enzymes lose their activity, because the substrates can no longer bind to the active site, and because amino acid residues involved in stabilizing substrates' transition states are no longer positioned to be able to do so. The denaturing process and the associated loss of activity can be measured using techniques such as dual polarization interferometry, CD, QCM-D and MP-SPR.

By targeting proteins, heavy metals have been known to disrupt the function and activity carried out by proteins. It is important to note that heavy metals fall into categories consisting of transition metals as well as a select amount of metalloid. These metals, when interacting with naive, folded proteins, tend to play a role in obstructing their biological activity. This interference can be carried out in a different amount of ways. These heavy metals can form a complex with the functional side chain groups present in a protein or form bonds to free thiols. Heavy metals also play a role in oxidizing amino acid side chains present in protein. Along with this, when interacting with metalloproteins, heavy metals can dislocate and replace key metal ions. As a result, heavy metals can interfere with folded proteins, which can strongly deter protein stability and activity.

In many cases, denaturation is reversible (the proteins can regain their native state when the denaturing influence is removed). This process can be called renaturation. This understanding has led to the notion that all the information needed for proteins to assume their native state was encoded in the primary structure of the protein, and hence in the DNA that codes for the protein, the so-called "Anfinsen's thermodynamic hypothesis".

However, denaturation can also be irreversible. However, this irreversibility is typically a kinetic, not thermodynamic irreversibility, as generally when a protein is folded it has lower free energy. But, through kinetic irreversibility, the fact that the protein is stuck in a local minimum can stop it from ever refolding after it has been irreversibly denatured.

Denaturation can also be caused by changes in the pH which can affect the chemistry of the amino acids and their residues. The ionizable groups in amino acids are able to become ionized when changes in pH occur. A pH change to more acidic or more basic conditions can induce unfolding. Acid-induced unfolding often occurs between pH 2 and 5, base-induced unfolding usually requires pH 10 or higher.

Nucleic acids (including RNA and DNA) are nucleotide polymers synthesized by polymerase enzymes during either transcription or DNA replication. Following 5'-3' synthesis of the backbone, individual nitrogenous bases are capable of interacting with one another via hydrogen bonding, thus allowing for the formation of higher-order structures. Nucleic acid denaturation occurs when hydrogen bonding between nucleotides is disrupted, and results in the separation of previously annealed strands. For example, denaturation of DNA due to high temperatures results in the disruption of base pairs and the separation of the double stranded helix into two single strands. Nucleic acid strands are capable of re-annealling when "normal" conditions are restored, but if restoration occurs too quickly, the nucleic acid strands may re-anneal imperfectly resulting in the improper pairing of bases.

The non-covalent interactions between antiparallel strands in DNA can be broken in order to "open" the double helix when biologically important mechanisms such as DNA replication, transcription, DNA repair or protein binding are set to occur. The area of partially separated DNA is known as the denaturation bubble, which can be more specifically defined as the opening of a DNA double helix through the coordinated separation of base pairs.

The first model that attempted to describe the thermodynamics of the denaturation bubble was introduced in 1966 and called the Poland-Scheraga Model. This model describes the denaturation of DNA strands as a function of temperature. As the temperature increases, the hydrogen bonds between the Watson and Crick base pairs are increasingly disturbed and "denatured loops" begin to form. However, the Poland-Scheraga Model is now considered elementary because it fails to account for the confounding implications of DNA sequence, chemical composition, stiffness and torsion.

Recent thermodynamic studies have inferred that the lifetime of a singular denaturation bubble ranges from 1 microsecond to 1 millisecond. This information is based on established timescales of DNA replication and transcription. Currently, biophysical and biochemical research studies are being performed to more fully elucidate the thermodynamic details of the denaturation bubble.

With polymerase chain reaction (PCR) being among the most popular contexts in which DNA denaturation is desired, heating is the most frequent method of denaturation. Other than denaturation by heat, nucleic acids can undergo the denaturation process through various chemical agents such as formamide, guanidine, sodium salicylate, dimethyl sulfoxide (DMSO), propylene glycol, and urea. These chemical denaturing agents lower the melting temperature (T) by competing for hydrogen bond donors and acceptors with pre-existing nitrogenous base pairs. Some agents are even able to induce denaturation at room temperature. For example, alkaline agents (e.g. NaOH) have been shown to denature DNA by changing pH and removing hydrogen-bond contributing protons. These denaturants have been employed to make Denaturing Gradient Gel Electrophoresis gel (DGGE), which promotes denaturation of nucleic acids in order to eliminate the influence of nucleic acid shape on their electrophoretic mobility.

The optical activity (absorption and scattering of light) and hydrodynamic properties (translational diffusion, sedimentation coefficients, and rotational correlation times) of formamide denatured nucleic acids are similar to those of heat-denatured nucleic acids. Therefore, depending on the desired effect, chemically denaturing DNA can provide a gentler procedure for denaturing nucleic acids than denaturation induced by heat. Studies comparing different denaturation methods such as heating, beads mill of different bead sizes, probe sonification, and chemical denaturation show that chemical denaturation can provide quicker denaturation compared to the other physical denaturation methods described. Particularly in cases where rapid renaturation is desired, chemical denaturation agents can provide an ideal alternative to heating. For example, DNA strands denatured with alkaline agents such as NaOH renature as soon as phosphate buffer is added.

Small, electronegative molecules such as nitrogen and oxygen, which are the primary gases in air, significantly impact the ability of surrounding molecules to participate in hydrogen bonding. These molecules compete with surrounding hydrogen bond acceptors for hydrogen bond donors, therefore acting as "hydrogen bond breakers" and weakening interactions between surrounding molecules in the environment. Antiparellel strands in DNA double helices are non-covalently bound by hydrogen bonding between Watson and Crick base pairs; nitrogen and oxygen therefore maintain the potential to weaken the integrity of DNA when exposed to air. As a result, DNA strands exposed to air require less force to separate and exemplify lower melting temperatures.

Many laboratory techniques rely on the ability of nucleic acid strands to separate. By understanding the properties of nucleic acid denaturation, the following methods were created:

Acidic protein denaturants include:

Bases work similarly to acids in denaturation. They include:

Most organic solvents are denaturing, including:

Cross-linking agents for proteins include:

Chaotropic agents include:

Agents that break disulfide bonds by reduction include:


Acidic nucleic acid denaturants include:
Basic nucleic acid denaturants include:
Other nucleic acid denaturants include:





</doc>
<doc id="8459" url="https://en.wikipedia.org/wiki?curid=8459" title="Dwight L. Moody">
Dwight L. Moody

Dwight Lyman Moody (February 5, 1837 – December 22, 1899), also known as D. L. Moody, was an American evangelist and publisher connected with the Holiness Movement, who founded the Moody Church, Northfield School and Mount Hermon School in Massachusetts (now Northfield Mount Hermon School), Moody Bible Institute and Moody Publishers.

Dwight Moody was born in Northfield Massachusetts , to a large family. His father, Edwin J. Moody (1800–1841), a small farmer and stonemason, died at the age of 41, when Dwight was only four years old; his mother was Betsey Moody (née Holton; 1805–1896). They had five sons and a daughter before Dwight's birth, with twins, a boy and a girl, born one month after Edwin's death. His mother struggled to support the family, but even with her best effort, some of her children had to be sent off to work for their room and board. Dwight too was sent off, where he received cornmeal, porridge, and milk three times a day. He complained to his mother, but when she found out that he got all that he wanted to eat, she sent him back. Even during that time she continued to send them to church. Together with his eight siblings he was raised in the Unitarian church. His oldest brother ran away and was not heard from by the family until many years later.
When Moody turned 17, he moved to Boston to work (after many job rejections) in an uncle's shoe store. One of the uncle's requirements was that Moody attend the Congregational Church of Mount Vernon where Dr. Edward Norris Kirk served as the pastor. In April 1855 Moody was then converted to evangelical Christianity when his Sunday school teacher, Edward Kimball, talked to him about how much God loved him. His conversion sparked the start of his career as an evangelist. However, his first application for church membership, in May 1855, was rejected. He was not received as a church member until May 4, 1856. As his teacher, Edward Kimball, stated:

D. L. Moody "could not conscientiously enlist" in the Union Army during the Civil War, later describing himself as "a Quaker" in this respect. After the Civil War started, he became involved with the United States Christian Commission of the YMCA, and paid nine visits to the battlefront, being present among the Union soldiers after the Battle of Shiloh (a.k.a. Pittsburg Landing) and the Battle of Stones River; he also entered Richmond, Virginia, with the troops of General Grant. On August 28, 1862, he married Emma C. Revell, with whom he had a daughter, Emma Reynolds Moody, and two sons, William Revell Moody and Paul Dwight Moody.

The growing Sunday School congregation needed a permanent home, so Moody started a church in Chicago, the Illinois Street Church.

In June 1871 at an International Sunday School Convention in Indianapolis, Dwight Moody met Ira D. Sankey, up to then a single-gospel-singer, with whom he soon began to cooperate and collaborate.
Four months later in October 1871 the Great Chicago Fire destroyed Dwight's church building, as well as his family dwelling and the homes of most of his churchmembers. Many had to flee the flames, saving only their lives, and ending up completely destitute. Moody, reporting on the disaster, said about his own situation that: "...he saved nothing but his reputation and his Bible."

In the years after the fire, Moody's wealthy Chicago supporter John V. Farwell tried to persuade him to make his permanent home in Chicago, offering to build a new house for Moody and his family. But the newly famous Moody, also sought by supporters in New York, Philadelphia, and elsewhere, chose the tranquil farm he had purchased next door to his birthplace in Northfield, Massachusetts. He felt he could better recover from his lengthy and exhausting preaching trips in a rural setting. Northfield became an important location in evangelical Christian history in the late 19th century as Moody organized summer conferences which were led and attended by prominent Christian preachers and evangelists from around the world. It was also in Northfield where Moody founded two schools (Northfield School for Girls, founded in 1879, and the Mount Hermon School for Boys, founded in 1881) which later merged into today's co-educational, nondenominational Northfield Mount Hermon School. Western Massachusetts has had a rich evangelical tradition including Jonathan Edwards preaching in Northampton as well as C.I. Scofield's preaching in Northfield. A protégé of Moody founded Moores Corner Church, in Leverett, Massachusetts, which remains evangelical to this day.

During a trip to United Kingdom in the spring of 1872, he became well known as an evangelist. Literary works published by the Moody Bible Institute have claimed that he was the greatest evangelist of the 19th century. He preached almost a hundred times and came into communion with the Plymouth Brethren. On several occasions he filled stadia of a capacity of 2,000 to 4,000. In the Botanic Gardens Palace a meeting had an audience between 15,000 and 30,000.

That turnout continued throughout 1874 and 1875, with crowds of thousands at all of his meetings. During his visit to Scotland he was helped and encouraged by Andrew A. Bonar. The famous London Baptist preacher, Charles Spurgeon, invited him to speak, and he promoted him as well. When he returned to the US, crowds of 12,000 to 20,000 were as common as they had been in England. President Grant and some of his cabinet officials attended a meeting on January 19, 1876. His evangelistic meetings took place from Boston to New York, throughout New England, and as far as San Francisco, along with other West Coast towns from Vancouver to San Diego.

Moody aided in the work of cross-cultural evangelism by promoting "The Wordless Book," a teaching tool that had been invented by Charles Spurgeon in 1866. In 1875, he added a fourth color to the design of the three-color evangelistic device: gold—to "represent heaven." This "book" has been and is still used to teach uncounted thousands of illiterate people, young and old, around the globe about the gospel message.
Dwight L. Moody visited Britain with Ira D. Sankey, with Moody preaching and Sankey singing. Together they published books of Christian hymns. In 1883 they visited Edinburgh and raised £10,000 for the building of a new home for the Carrubbers Close Mission. Moody later preached at the laying of the foundation stone for what is one of the few buildings on the Royal Mile which continues to be used for its original purpose and is now called the Carrubbers Christian Centre.

Moody greatly influenced the cause of cross-cultural Christian missions after he met Hudson Taylor, a pioneer missionary to China. He actively supported the China Inland Mission and encouraged many of his congregation to volunteer for service overseas.

His influence was felt among Swedes despite that he was of English heritage, that he never visited Sweden or any other Scandinavian country, and that he never spoke a word of Swedish. Nonetheless he became a hero revivalist among Swedish Mission Friends in Sweden and America.

News of Moody’s large revival campaigns in Great Britain from 1873 through 1875 traveled quickly to Sweden, making "Mr. Moody" a household name in homes of many Mission Friends. Moody’s sermons published in Sweden were distributed in books, newspapers, and colporteur tracts, and they led to the spread of Sweden’s "Moody fever" from 1875 through 1880.

He preached his last sermon on November 16, 1899, in Kansas City, Missouri. Becoming ill, he returned home by train to Northfield. During the preceding several months, friends had observed he had added some to his already ample frame. Although his illness was never diagnosed, it has been speculated that he suffered from congestive heart failure. He died on December 22, 1899, surrounded by his family. Already installed as the leader of his Chicago Bible Institute, R. A. Torrey succeeded Moody as its president.


Ten years after Moody's death the Chicago Avenue Church was renamed the Moody Church in his honor, and the Chicago Bible Institute was likewise renamed the Moody Bible Institute.

During World War II the Liberty ship was built in Panama City, Florida, and named in his honor.





</doc>
<doc id="8460" url="https://en.wikipedia.org/wiki?curid=8460" title="Dieting">
Dieting

Dieting is the practice of eating food in a regulated and supervised fashion to decrease, maintain, or increase body weight, or to prevent and treat diseases, such as diabetes. A restricted diet is often used by those who are overweight or obese, sometimes in combination with physical exercise, to reduce body weight. Some people follow a diet to gain weight (usually in the form of muscle). Diets can also be used to maintain a stable body weight and improve health.

Diets to promote weight loss can be categorized as: low-fat, low-carbohydrate, low-calorie, very low calorie and more recently flexible dieting. A meta-analysis of six randomized controlled trials found no difference between low-calorie, low-carbohydrate, and low-fat diets, with a 2–4 kilogram weight loss over 12–18 months in all studies. At two years, all calorie-reduced diet types cause equal weight loss irrespective of the macronutrients emphasized. In general, the most effective diet is any which reduces calorie consumption.

A study published in "American Psychologist" found that short-term dieting involving "severe restriction of calorie intake" does not lead to "sustained improvements in weight and health for the majority of individuals". Other studies have found that the average individual maintains some weight loss after dieting. Weight loss by dieting, while of benefit to those classified as unhealthy, may slightly increase the mortality rate for individuals who are otherwise healthy.

The first popular diet was "Banting", named after William Banting. In his 1863 pamphlet, "Letter on Corpulence, Addressed to the Public", he outlined the details of a particular low-carbohydrate, low-calorie diet that had led to his own dramatic weight loss.

One of the first dietitians was the English doctor George Cheyne. He himself was tremendously overweight and would constantly eat large quantities of rich food and drink. He began a meatless diet, taking only milk and vegetables, and soon regained his health. He began publicly recommending his diet for everyone suffering from obesity. In 1724, he wrote "An Essay of Health and Long Life", in which he advises exercise and fresh air and avoiding luxury foods.

The Scottish military surgeon, John Rollo, published "Notes of a Diabetic Case" in 1797. It described the benefits of a meat diet for those suffering from diabetes, basing this recommendation on Matthew Dobson's discovery of glycosuria in diabetes mellitus. By means of Dobson's testing procedure (for glucose in the urine) Rollo worked out a diet that had success for what is now called type 2 diabetes.

The first popular diet was "Banting", named after the English undertaker William Banting. In 1863, he wrote a booklet called "Letter on Corpulence, Addressed to the Public", which contained the particular plan for the diet he had successfully followed. His own diet was four meals per day, consisting of meat, greens, fruits, and dry wine. The emphasis was on avoiding sugar, sweet foods, starch, beer, milk and butter. Banting’s pamphlet was popular for years to come, and would be used as a model for modern diets. The pamphlet's popularity was such that the question "Do you bant?" referred to his method, and eventually to dieting in general. His booklet remains in print as of 2007.

The first weight-loss book to promote calorie counting, and the first weight-loss book to become a bestseller, was the 1918 "Diet and Health: With Key to the Calories" by American physician and columnist Lulu Hunt Peters.

Low-fat diets involve the reduction of the percentage of fat in one's diet. Calorie consumption is reduced because less fat is consumed. Diets of this type include NCEP Step I and II. A meta-analysis of 16 trials of 2–12 months' duration found that low-fat diets (without intentional restriction of caloric intake) resulted in average weight loss of over habitual eating.

Low-carbohydrate diets such as Atkins and Protein Power are relatively high in protein and fats. Low-carbohydrate diets are sometimes "ketogenic" (i.e., they restrict carbohydrate intake sufficiently to cause ketosis).

Low-calorie diets usually produce an energy deficit of 500–1,000 calories per day, which can result in a weight loss per week. One of the most commonly used low-calorie diets is Weight Watchers. The National Institutes of Health reviewed 34 randomized controlled trials to determine the effectiveness of low-calorie diets. They found that these diets lowered total body mass by 8% in the short term, over 3–12 months. Women doing low-calorie diets should have at least 1,200 calories per day. Men should have at least 1,800 calories per day.

Very low calorie diets provide 200–800 calories per day, maintaining protein intake but limiting calories from both fat and carbohydrates. They subject the body to starvation and produce an average loss of per week. "2-4-6-8", a popular diet of this variety, follows a four-day cycle in which only 200 calories are consumed the first day, 400 the second day, 600 the third day, 800 the fourth day, and then totally fasting, after which the cycle repeats. These diets are not recommended for general use as they are associated with adverse side effects such as loss of lean muscle mass, increased risks of gout, and electrolyte imbalances. People attempting these diets must be monitored closely by a physician to prevent complications.

Detox diets claim to eliminate "toxins" from the human body rather than claiming to cause weight loss. Many of these use herbs or celery and other juicy low-calorie vegetables.

Religious prescription may be a factor in motivating people to adopt a specific restrictive diet. For example, the Biblical Book of Daniel (1:2-20, and 10:2-3) refers to a 10- or 21-day avoidance of foods (Daniel Fast) declared unclean by God in the laws of Moses. In modern versions of the Daniel Fast, food choices may be limited to whole grains, fruits, vegetables, pulses, nuts, seeds and oil. The Daniel Fast resembles the vegan diet in that it excludes foods of animal origin. The passages strongly suggest that the Daniel Fast will promote good health and mental performance.

Fasting is practiced in various religions. Examples include Lent in Christianity; Yom Kippur, Tisha B'av, Fast of Esther, Tzom Gedalia, the Seventeenth of Tamuz, and the Tenth of Tevet in Judaism. Muslims refrain from eating during the hours of daytime for one entire month, Ramadan, every year.

Details of fasting practices differ. Eastern Orthodox Christians fast during specified fasting seasons of the year, which include not only the better-known Great Lent, but also fasts on every Wednesday and Friday (except on special holidays), together with extended fasting periods before Christmas (the Nativity Fast), after Easter (the Apostles Fast) and in early August (the Dormition Fast). Members of The Church of Jesus Christ of Latter-day Saints (Mormons) generally fast for 24 hours on the first Sunday of each month. Like Muslims, they refrain from all drinking and eating unless they are children or are physically unable to fast. Fasting is also a feature of ascetic traditions in religions such as Hinduism and Buddhism. Mahayana traditions that follow the Brahma's Net Sutra may recommend that the laity fast "during the six days of fasting each month and the three months of fasting each year" [Brahma's Net Sutra, minor precept 30]. Members of the Baha'i Faith observe a Nineteen Day Fast from sunrise to sunset during March each year.

Weight loss diets that manipulate the proportion of macronutrients (low-fat, low-carbohydrate, etc.) have been shown to be more effective than diets that maintain a typical mix of foods with smaller portions and perhaps some substitutions (e.g. low-fat milk, or less salad dressing). Extreme diets may, in some cases, lead to malnutrition.

Nutritionists also agree on the importance of avoiding fats, especially saturated fats, to reduce weight and to be healthier. They also agree on the importance of reducing salt intake because foods including snacks, biscuits, and bread already contain ocean-salt, contributing to an excess of salt daily intake.

The Dietary Guidelines for Americans is a quintannually-revised set of recommendations about a healthy diet written for policy makers, nutrition scientists, and dieticians and other clinicians. The current guidelines are written for the period 2015 - 2020 and were used to produce the MyPlate recommendations on a healthy diet for the general public.

One of the most important things to take into consideration when either trying to lose or put on weight is output versus input. It is important to know the amount of energy your body is using every day, so that your intake fits the needs of one's personal weight goal. Someone wanting to lose weight would want a smaller energy intake than what they put out. There is increasing research-based evidence that low-fat vegetarian diets consistently lead to healthy weight loss and management, a decrease in diabetic symptoms as well as improved cardiac health.

When the body is expending more energy than it is consuming (e.g. when exercising), the body's cells rely on internally stored energy sources, such as complex carbohydrates and fats, for energy. The first source to which the body turns is glycogen (by glycogenolysis). Glycogen is a complex carbohydrate, 65% of which is stored in skeletal muscles and the remainder in the liver (totaling about 2,000 kcal in the whole body). It is created from the excess of ingested macronutrients, mainly carbohydrates. When glycogen is nearly depleted, the body begins lipolysis, the mobilization and catabolism of fat stores for energy. In this process, fats, obtained from adipose tissue, or fat cells, are broken down into glycerol and fatty acids, which can be used to generate energy. The primary by-products of metabolism are carbon dioxide and water; carbon dioxide is expelled through the respiratory system.

Some weight loss groups aim to make money, others work as charities. The former include Weight Watchers and Peertrainer. The latter include Overeaters Anonymous and groups run by local organizations.

These organizations' customs and practices differ widely. Some groups are modelled on twelve-step programs, while others are quite informal. Some groups advocate certain prepared foods or special menus, while others train dieters to make healthy choices from restaurant menus and while grocery-shopping and cooking.

A 2008 study published in the American Journal of Preventive Medicine showed that dieters who kept a daily food diary (or diet journal), lost twice as much weight as those who did not keep a food log, suggesting that if you record your eating, you wouldn't eat as many calories.

A 2009 review found that existing limited evidence suggested that encouraging water consumption and substituting energy-free beverages for energy-containing beverages (i.e., reducing caloric intake) may facilitate weight management. A 2009 article found that drinking 500 ml of water prior to meals for a 12-week period resulted in increased long-term weight reduction. (References given in main article.)

Fasting is when there is a long time interval between the meals. In dieting, fasting is not recommended, instead, having small portions of food after small intervals is encouraged. Lengthy fasting can also be dangerous due to the risk of malnutrition and should be carried out only under medical supervision. During prolonged fasting or very low calorie diets the reduction of blood glucose, the preferred energy source of the brain, causes the body to deplete its glycogen stores. Once glycogen is depleted the body begins to fuel the brain using ketones, while also metabolizing body protein (including but not limited to skeletal muscle) to be used to synthesize sugars for use as energy by the rest of the body. Most experts believe that a prolonged fast can lead to muscle wasting, although some dispute this. The use of short-term fasting, or various forms of intermittent fasting have been used as a form of dieting to circumvent this issue.

While there are studies that show the health and medical benefits of weight loss, a study in 2005 of around 3000 Finns over an 18-year period showed that weight loss from dieting can result in increased mortality, while those who maintained their weight fared the best. Similar conclusion is drawn by other studies, and although other studies suggest that intentional weight loss has a small benefit for individuals classified as unhealthy, it is associated with slightly increased mortality for healthy individuals and the slightly overweight but not obese. This may reflect the loss of subcutaneous fat and beneficial mass from organs and muscle in addition to visceral fat when there is a sudden and dramatic weight loss.

Many studies have focused on diets that reduce calories via a low-carbohydrate (Atkins diet, Scarsdale diet, Zone diet) diet versus a low-fat diet (LEARN diet, Ornish diet). The Nurses' Health Study, an observational cohort study, found that low carbohydrate diets based on vegetable sources of fat and protein are associated with less coronary heart disease. The same study also found no correlation (with multivariate adjustment) between animal fat intake and coronary heart disease (table 4). A long term study that monitored 43,396 Swedish women however suggests that a low carbohydrate-high protein diet, used on a regular basis and without consideration of the nature of carbohydrates or the source of proteins, is associated with increased risk of cardiovascular disease.

A meta-analysis of randomized controlled trials by the international Cochrane Collaboration in 2002 concluded that fat-restricted diets are no better than calorie-restricted diets in achieving long term weight loss in overweight or obese people. A more recent meta-analysis that included randomized controlled trials published after the Cochrane review found that low-carbohydrate, non-energy-restricted diets appear to be at least as effective as low-fat, energy-restricted diets in inducing weight loss for up to 1 year. These results can be understood because weight loss is mainly governed by daily caloric deficit and not by the particular foods eaten. However, when low-carbohydrate diets to induce weight loss are considered, potential favorable changes in triglyceride and high-density lipoprotein cholesterol values should be weighed against potential unfavorable changes in low-density lipoprotein cholesterol values."

The Women's Health Initiative Randomized Controlled Dietary Modification Trial found that a diet of total fat to 20% of energy and increasing consumption of vegetables and fruit to at least 5 servings daily and grains to at least 6 servings daily resulted in:

Additional randomized controlled trials found that:

The American Diabetes Association recommended a low carbohydrate diet to reduce weight for those with or at risk of Type 2 diabetes in its January 2008 Clinical Practice Recommendations.

"The glycemic index (GI) factor is a ranking of foods based on their overall effect on blood sugar levels. The diet based around this research is called the Low GI diet. Low glycemic index foods, such as lentils, provide a slower, more consistent source of glucose to the bloodstream, thereby stimulating less insulin release than high glycemic index foods, such as white bread."

The glycemic load is "the mathematical product of the glycemic index and the carbohydrate amount".

In a randomized controlled trial that compared four diets that varied in carbohydrate amount and glycemic index found complicated results:

Diets 2 and 3 lost the most weight and fat mass; however, low density lipoprotein fell in Diet 2 and rose in Diet 3. Thus the authors concluded that the high-carbohydrate, low-glycemic index diet was the most favorable.

A meta-analysis by the Cochrane Collaboration concluded that low glycemic index or low glycemic load diets led to more weight loss and better lipid profiles. "However", the Cochrane Collaboration grouped low glycemic index and low glycemic load diets together and did not try to separate the effects of the load versus the index.




</doc>
<doc id="8461" url="https://en.wikipedia.org/wiki?curid=8461" title="Diet">
Diet

Diet may refer to:








</doc>
<doc id="8463" url="https://en.wikipedia.org/wiki?curid=8463" title="Dubnium">
Dubnium

Dubnium is a synthetic chemical element with symbol Db and atomic number 105. Dubnium is highly radioactive: the most stable known isotope, dubnium-268, has a half-life of about 28 hours. This greatly limits the extent of research on dubnium.

Dubnium does not occur naturally on Earth and is produced artificially. The Soviet Joint Institute for Nuclear Research (JINR) claimed the first discovery of the element in 1968, followed by the American Lawrence Berkeley Laboratory in 1970. Both teams proposed their names for the new element and used them without formal approval. The long-standing dispute was resolved in 1993 by an official investigation of the discovery claims by the IUPAC/IUPAP Joint Working Party, resulting in credit for the discovery being officially shared between both teams. The element was formally named "dubnium" in 1997 after the town of Dubna, the site of the JINR.

Theoretical research establishes dubnium as a member of group 5 in the 6d series of transition metals, placing it under vanadium, niobium, and tantalum. Dubnium should share most properties, such as its valence electron configuration and having a dominant +5 oxidation state, with the other group 5 elements, with a few anomalies due to relativistic effects. A limited investigation of dubnium chemistry has confirmed this. Solution chemistry experiments have revealed that dubnium often behaves more like niobium rather than tantalum, breaking periodic trends.

Uranium, element 92, is the heaviest element to occur in significant quantity in nature; heavier elements can only be produced practically by synthesis. The first synthesis of a new element—neptunium, element 93—was achieved in 1940 by a team of researchers in the United States. In the following years, American scientists synthesized the elements up to mendelevium, element 101, which was synthesized in 1955. From element 102, the priority of discoveries was contested between American and Soviet physicists. Their rivalry resulted in a race for new elements and credit for their discoveries, later named the Transfermium Wars.

The first report of the discovery of element 105 came from the Joint Institute for Nuclear Research (JINR) in Dubna, Moscow Oblast, Russian SFSR, Soviet Union, in April 1968. The scientists bombarded Am with a beam of Ne ions, and reported 9.4 MeV (with a half-life of 0.1–3 seconds) and 9.7 MeV ("t" > 0.05 s) alpha activities followed by alpha activities similar to those of either 103 or 103. Based on prior theoretical predictions, the two activity lines were assigned to 105 and 105, respectively.

After observing the alpha decays of element 105, the researchers aimed to observe spontaneous fission (SF) of the element and study the resulting fission fragments. They published a paper in February 1970, reporting multiple examples of two such activities, with half-lives of 14 ms and . They assigned the former activity to Am and ascribed the latter activity to an isotope of element 105. They suggested that it was unlikely that this activity could come from a transfer reaction instead of element 105, because the yield ratio for this reaction was significantly lower than that of the Am-producing transfer reaction, in accordance with theoretical predictions. To establish that this activity was not from a (Ne,"x"n) reaction, the researchers bombarded a Am target with O ions; reactions producing 103 and 103 showed very little SF activity (matching the established data), and the reaction producing heavier 103 and 103 produced no SF activity at all, in line with theoretical data. The researchers concluded that the activities observed came from SF of element 105.

In April 1970, a team at Lawrence Berkeley Laboratory (LBL), in Berkeley, California, United States, claimed to have synthesized element 105 by bombarding californium-249 with nitrogen-15 ions, with an alpha activity of 9.1 MeV. To ensure this activity was not from a different reaction, the team attempted other reactions: bombarding Cf with N, Pb with N, and Hg with N. They stated no such activity was found in those reactions. The characteristics of the daughter nuclei matched those of 103, implying that the parent nuclei were of 105.

These results did not confirm the JINR findings regarding the 9.4 MeV or 9.7 MeV alpha decay of 105, leaving only 105 as a possibly produced isotope.

JINR then attempted another experiment to create element 105, published in a report in May 1970. They claimed that they had synthesized more nuclei of element 105 and that the experiment confirmed their previous work. According to the paper, the isotope produced by JINR was probably 105, or possibly 105. This report included an initial chemical examination: the thermal gradient version of the gas-chromatography method was applied to demonstrate that the chloride of what had formed from the SF activity nearly matched that of niobium pentachloride, rather than hafnium tetrachloride. The team identified a 2.2-second SF activity in a volatile chloride portraying eka-tantalum properties, and inferred that the source of the SF activity must have been element 105.

In June 1970, JINR made improvements on their first experiment, using a purer target and reducing the intensity of transfer reactions by installing a collimator before the catcher. This time, they were able to find 9.1 MeV alpha activities with daughter isotopes identifiable as either 103 or 103, implying that the original isotope was either 105 or 105.

JINR did not propose a name after their first report claiming synthesis of element 105, which would have been the usual practice. This led LBL to believe that JINR did not have enough experimental data to back their claim. After collecting more data, JINR proposed the name "nielsbohrium" (Ns) in honor of the Danish nuclear physicist Niels Bohr, a founder of the theories of atomic structure and quantum theory. When LBL first announced their synthesis of element 105, they proposed that the new element be named "hahnium" (Ha) after the German chemist Otto Hahn, the "father of nuclear chemistry", thus creating an element naming controversy.

In the early 1970s, both teams reported synthesis of the next element, element 106, but did not suggest names. JINR suggested establishing an international committee to clarify the discovery criteria. This proposal was accepted in 1974 and a neutral joint group formed. Neither team showed interest in resolving the conflict through a third party, so the leading scientists of LBL—Albert Ghiorso and Glenn Seaborg—traveled to Dubna in 1975 and met with the leading scientists of JINR—Georgy Flerov, Yuri Oganessian, and others— to try to resolve the conflict internally and render the neutral joint group unnecessary; after two hours of discussions, this failed. The joint neutral group never assembled to assess the claims and the conflict remained unsolved. In 1979, IUPAC suggested systematic element names to be used as placeholders until permanent names were established; under it, element 105 would be "unnilpentium", from the Latin roots "un-" and "nil-" and the Greek root "pent-" (meaning "one", "zero", and "five", respectively, the digits of the atomic number). Both teams ignored it as they did not wish to weaken their outstanding claims.

In 1981, the Gesellschaft für Schwerionenforschung (GSI; "Society for Heavy Ion Research") in Darmstadt, West Germany, claimed synthesis of element 107; their report came out five years after the first report from JINR but with greater precision, making a more solid claim on discovery. GSI acknowledged JINR's efforts by suggesting the name "nielsbohrium" for the new element. JINR did not suggest a new name for element 105, stating it was more important to determine its discoverers first.

In 1985, the International Union of Pure and Applied Chemistry (IUPAC) and the International Union of Pure and Applied Physics (IUPAP) formed a Joint Working Party (JWP) to assess discoveries and establish final names for the controversial elements. The party held meetings with delegates from the three competing institutes; in 1990, they established criteria on recognition of an element, and in 1991, they finished the work on assessing discoveries and disbanded. These results were published in 1993. According to the report, the first definitely successful experiment was the April 1970 LBL experiment, closely followed by the June 1970 JINR experiment, so credit for the discovery of the element should be shared between the two teams.

LBL said that the input from JINR was overrated in the review. They claimed JINR was only able to unambiguously demonstrate the synthesis of element 105 a year after they did. JINR and GSI endorsed the report.

In 1994, IUPAC published a recommendation on naming the disputed elements. For element 105, they proposed "joliotium" (Jl) after the French physicist Frédéric Joliot-Curie, a contributor to the development of nuclear physics and chemistry; this name was originally proposed by the Soviet team for element 102, which by then had long been called nobelium. This recommendation was criticized by the American scientists for several reasons. Firstly, their suggestions were scrambled: the names "rutherfordium" and "hahnium", originally suggested by Berkeley for elements 104 and 105, were respectively reassigned to elements 106 and 108. Secondly, elements 104 and 105 were given names favored by JINR, despite earlier recognition of LBL as an equal co-discoverer for both of them. Thirdly and most importantly, IUPAC rejected the name "seaborgium" for element 106, having just approved a rule that an element could not be named after a living person, even though the 1993 report had given the LBL team the sole credit for its discovery.

In 1995, IUPAC abandoned the controversial rule and established a committee of national representatives aimed at finding a compromise. They suggested "seaborgium" for element 106 in exchange for the removal of all the other American proposals, except for the established name "lawrencium" for element 103. The equally entrenched name "nobelium" for element 102 was replaced by "flerovium" after Georgy Flerov, following the recognition by the 1993 report that that element had been first synthesized in Dubna. This was rejected by American scientists and the decision was retracted. The name "flerovium" was later used for element 114.

In 1996, IUPAC held another meeting, reconsidered all names in hand, and accepted another set of recommendations; it was approved and published in 1997. Element 105 was named "dubnium" (Db), after Dubna in Russia, the location of the JINR; the American suggestions were used for elements 102, 103, 104, and 106. The name "dubnium" had been used for element 104 in the previous IUPAC recommendation. The American scientists "reluctantly" approved this decision. IUPAC pointed out that the Berkeley laboratory had already been recognized several times, in the naming of berkelium, californium, and americium, and that the acceptance of the names "rutherfordium" and "seaborgium" for elements 104 and 106 should be offset by recognizing JINR's contributions to the discovery of elements 104, 105, and 106.

Dubnium, having an atomic number of 105, is a superheavy element; like all elements with such high atomic numbers, it is very unstable. The longest-lasting known isotope of dubnium, Db, has a half-life of around a day. No stable isotopes have been seen, and a 2012 calculation by JINR suggested that the half-lives of all dubnium isotopes would not significantly exceed a day. Dubnium can only be obtained by artificial production.

The short half-life of dubnium limits experimentation. This is exacerbated by the fact that the most stable isotopes are the hardest to synthesize. Elements with a lower atomic number have stable isotopes with a lower neutron-to-proton ratio than those with higher atomic number, meaning that the target and beam nuclei that could be employed to create the superheavy element have fewer neutrons than needed to form these most stable isotopes. (Different techniques based on rapid neutron capture and transfer reactions are being considered as of the 2010s, but those based on the collision of a large and small nucleus still dominate research in the area.)

Only a few atoms of Db can be produced in each experiment, and thus the measured lifetimes vary significantly during the process. During three experiments, 23 atoms were created in total, with a resulting half-life of . The second most stable isotope, Db, has been produced in even smaller quantities: three atoms in total, with lifetimes of 33.4 h, 1.3 h, and 1.6 h. These two are the heaviest isotopes of dubnium to date, and both were produced as a result of decay of the heavier nuclei Mc and Ts rather than directly, because the experiments that yielded them were originally designed in Dubna for Ca beams. For its mass, Ca has by far the greatest neutron excess of all practically stable nuclei, both quantitative and relative, which correspondingly helps synthesize superheavy nuclei with more neutrons, but this gain is compensated by the decreased likelihood of fusion for high atomic numbers.

According to the periodic law, dubnium should belong to group 5, with vanadium, niobium, and tantalum. Several studies have investigated the properties of element 105 and found that they generally agreed with the predictions of periodic law. Significant deviations may nevertheless occur, due to relativistic effects, which dramatically change physical properties on both atomic and macroscopic scales. These properties have remained challenging to measure for several reasons: the difficulties of production of superheavy atoms, the low rates of production, which only allows for microscopic scales, requirements for a radiochemistry laboratory to test the atoms, short half-lives of those atoms, and the presence of many unwanted activities apart from those of synthesis of superheavy atoms. So far, studies have only been performed on single atoms.

A direct relativistic effect is that as the atomic numbers of elements increase, the innermost electrons begin to revolve faster around the nucleus as a result of an increase of electromagnetic attraction between an electron and a nucleus. Similar effects have been found for the outermost s orbitals (and p ones, though in dubnium they are not occupied): for example, the 7s orbital contracts by 25% in size and is stabilized by 2.6 eV.

A more indirect effect is that the contracted s and p orbitals shield the charge of the nucleus more effectively, leaving less for the outer d and f electrons, which therefore move in larger orbitals. Dubnium is greatly affected by this: unlike the previous group 5 members, its 7s electrons are slightly more difficult to extract than its 6d electrons.
Another effect is the spin–orbit interaction, particularly spin–orbit splitting, which splits the 6d subshell—the azimuthal quantum number ℓ of a d shell is 2—into two subshells, with four of the ten orbitals having their ℓ lowered to 3/2 and six raised to 5/2. All ten energy levels are raised; four of them are lower than the other six. (The three 6d electrons normally occupy the lowest energy levels, 6d.)

A singly ionized atom of dubnium (Db) should lose a 6d electron compared to a neutral atom; the doubly (Db) or triply (Db) ionized atoms of dubnium should eliminate 7s electrons, unlike its lighter homologs. Despite the changes, dubnium is still expected to have five valence electrons; 7p energy levels have not been shown to influence dubnium and its properties. As the 6d orbitals of dubnium are more destabilized than the 5d ones of tantalum, and Db is expected to have two 6d, rather than 7s, electrons remaining, the resulting +3 oxidation state is expected to be unstable and even rarer than that of tantalum. The ionization potential of dubnium in its maximum +5 oxidation state should be slightly lower than that of tantalum and the ionic radius of dubnium should increase compared to tantalum; this has a significant effect on dubnium's chemistry.

Atoms of dubnium in the solid state should arrange themselves in a body-centered cubic configuration, like the previous group 5 elements. The predicted density of dubnium is 29 g/cm.

Computational chemistry is simplest in gas-phase chemistry, in which interactions between molecules may be ignored as negligible. Multiple authors have researched dubnium pentachloride; calculations show it to be consistent with the periodic laws by exhibiting the properties of a compound of a group 5 element. For example, the molecular orbital levels indicate that dubnium uses three 6d electron levels as expected. Compared to its tantalum analog, dubnium pentachloride is expected to show increased covalent character: a decrease in the effective charge on an atom and an increase in the overlap population (between orbitals of dubnium and chlorine).

Calculations of solution chemistry indicate that the maximum oxidation state of dubnium, +5, will be more stable than those of niobium and tantalum and the +3 and +4 states will be less stable. The tendency towards hydrolysis of cations with the highest oxidation state should continue to decrease within group 5 but is still expected to be quite rapid. Complexation of dubnium is expected to follow group 5 trends in its richness. Calculations for hydroxo-chlorido- complexes have shown a reversal in the trends of complex formation and extraction of group 5 elements, with dubnium being more prone to do so than tantalum.

Experimental results of the chemistry of dubnium date back to 1974 and 1976. JINR researchers used a thermochromatographic system and concluded that the volatility of dubnium bromide was less than that of niobium bromide and about the same as that of hafnium bromide. It is not certain that the detected fission products confirmed that the parent was indeed element 105. These results may imply that dubnium behaves more like hafnium than niobium.

The next studies on the chemistry of dubnium were conducted in 1988, in Berkeley. They examined whether the most stable oxidation state of dubnium in aqueous solution was +5. Dubnium was fumed twice and washed with concentrated nitric acid; sorption of dubnium on glass cover slips was then compared with that of the group 5 elements niobium and tantalum and the group 4 elements zirconium and hafnium produced under similar conditions. The group 5 elements are known to sorb on glass surfaces; the group 4 elements do not. Dubnium was confirmed as a group 5 member. Surprisingly, the behavior on extraction from mixed nitric and hydrofluoric acid solution into methyl isobutyl ketone differed between dubnium, tantalum, and niobium. Dubnium did not extract and its behavior resembled niobium more closely than tantalum, indicating that complexing behavior could not be predicted purely from simple extrapolations of trends within a group in the periodic table.

This prompted further exploration of the chemical behavior of complexes of dubnium. Various labs jointly conducted thousands of repetitive chromatographic experiments between 1988 and 1993. All group 5 elements and protactinium were extracted from concentrated hydrochloric acid; after mixing with lower concentrations of hydrogen chloride, small amounts of hydrogen fluoride were added to start selective re-extraction. Dubnium showed behavior different from that of tantalum but similar to that of niobium and its pseudohomolog protactinium at concentrations of hydrogen chloride below 12 moles per liter. This similarity to the two elements suggested that the formed complex was either or . After extraction experiments of dubnium from hydrogen bromide into diisobutyl carbinol (2,6-dimethylheptan-4-ol), a specific extractant for protactinium, with subsequent elutions with the hydrogen chloride/hydrogen fluoride mix as well as hydrogen chloride, dubnium was found to be less prone to extraction than either protactinium or niobium. This was explained as an increasing tendency to form non‐extractable complexes of multiple negative charges. Further experiments in 1992 confirmed the stability of the +5 state: Db(V) was shown to be extractable from cation‐exchange columns with α‐hydroxyisobutyrate, like the group 5 elements and protactinium; Db(III) and Db(IV) were not. In 1998 and 1999, new predictions suggested that dubnium would extract nearly as well as niobium and better than tantalum from halide solutions, which was later confirmed.

The first isothermal gas chromatography experiments were performed in 1992 with Db (half-life 35 seconds). The volatilities for niobium and tantalum were similar within error limits, but dubnium appeared to be significantly less volatile. It was postulated that traces of oxygen in the system might have led to formation of , which was predicted to be less volatile than . Later experiments in 1996 showed that group 5 chlorides were more volatile than the corresponding bromides, with the exception of tantalum, presumably due to formation of . Later volatility studies of chlorides of dubnium and niobium as a function of controlled partial pressures of oxygen showed that formation of oxychlorides and general volatility are dependent on concentrations of oxygen. The oxychlorides were shown to be less volatile than the chlorides.

In 2004–05, researchers from Dubna and Livermore identified a new dubnium isotope, Db, as a fivefold alpha decay product of the newly created element 115. This new isotope proved to be long-lived enough to allow further chemical experimentation, with a half-life of over a day. In the 2004 experiment, a thin layer with dubnium was removed from the surface of the target and dissolved in aqua regia with tracers and a lanthanum carrier, from which various +3, +4, and +5 species were precipitated on adding ammonium hydroxide. The precipitate was washed and dissolved in hydrochloric acid, where it converted to nitrate form and was then dried on a film and counted. Mostly containing a +5 species, which was immediately assigned to dubnium, it also had a +4 species; based on that result, the team decided that additional chemical separation was needed. In 2005, the experiment was repeated, with the final product being hydroxide rather than nitrate precipitate, which was processed further in both Livermore (based on reverse phase chromatography) and Dubna (based on anion exchange chromatography). The +5 species was effectively isolated; dubnium appeared three times in tantalum-only fractions and never in niobium-only fractions. It was noted that these experiments were insufficient to draw conclusions about the general chemical profile of dubnium.

In 2009, at the JAEA tandem accelerator in Japan, dubnium was processed in nitric and hydrofluoric acid solution, at concentrations where niobium forms and tantalum forms . Dubnium's behavior was close to that of niobium but not tantalum; it was thus deduced that dubnium formed . From the available information, it was concluded that dubnium often behaved like niobium, sometimes like protactinium, but rarely like tantalum.


</doc>
<doc id="8464" url="https://en.wikipedia.org/wiki?curid=8464" title="Disaccharide">
Disaccharide

A disaccharide (also called a double sugar or bivose) is the sugar formed when two monosaccharides (simple sugars) are joined by glycosidic linkage. Like monosaccharides, disaccharides are soluble in water. Three common examples are sucrose, lactose, and maltose.

Disaccharides are one of the four chemical groupings of carbohydrates (monosaccharides, disaccharides, oligosaccharides, and polysaccharides). The most common types of disaccharides—sucrose, lactose, and maltose—have twelve carbon atoms, with the general formula CHO. The differences in these disaccharides are due to atomic arrangements within the molecule.

The joining of simple sugars into a double sugar happens by a condensation reaction, which involves the elimination of a water molecule from the functional groups only. Breaking apart a double sugar into its two simple sugars is accomplished by hydrolysis with the help of a type of enzyme called a disaccharidase. As building the larger sugar ejects a water molecule, breaking it down consumes a water molecule. These reactions are vital in metabolism. Each disaccharide is broken down with the help of a corresponding disaccharidase (sucrase, lactase, and maltase).

There are two functionally different classes of disaccharides: 

The formation of a disaccharide molecule from two monosaccharide molecules proceeds by displacing a hydroxyl radical from one molecule and a hydrogen nucleus (a proton) from the other, so that the now vacant bonds on the monosaccharides join the two monomers together. The vacant bonds on the hydroxyl radical and the proton unite in their turn, forming a molecule of water, that then goes free. Because of the removal of the water molecule from the product, the term of convenience for such a process is "dehydration reaction" (also "condensation reaction" or "dehydration synthesis"). For example, milk sugar (lactose) is a disaccharide made by condensation of one molecule of each of the monosaccharides glucose and galactose, whereas the disaccharide sucrose in sugar cane and sugar beet, is a condensation product of glucose and fructose. Maltose, another common disaccharide, is condensed from two glucose molecules. 

The dehydration reaction that bonds monosaccharides into disaccharides (and also bonds monosaccharides into more complex polysaccharides) forms what are called glycosidic bonds.

The glycosidic bond can be formed between any hydroxyl group on the component monosaccharide. So, even if both component sugars are the same (e.g., glucose), different bond combinations (regiochemistry) and stereochemistry ("alpha-" or "beta-") result in disaccharides that are diastereoisomers with different chemical and physical properties.

Depending on the monosaccharide constituents, disaccharides are sometimes crystalline, sometimes water-soluble, and sometimes sweet-tasting and sticky-feeling.

Digestion involves breakdown to the monosaccharides.

Maltose, cellobiose, and chitobiose are hydrolysis products of the polysaccharides starch, cellulose, and chitin, respectively.

Less common disaccharides include:


</doc>
<doc id="8465" url="https://en.wikipedia.org/wiki?curid=8465" title="Dactylic hexameter">
Dactylic hexameter

Dactylic hexameter (also known as "heroic hexameter" and "the meter of epic") is a form of meter or rhythmic scheme in poetry. It is traditionally associated with the quantitative meter of classical epic poetry in both Greek and Latin and was consequently considered to be "the" grand style of Western classical poetry. Some premier examples of its use are Homer's "Iliad" and "Odyssey", Virgil's "Aeneid", and Ovid's "Metamorphoses". Hexameters also form part of elegiac poetry in both languages, alternating with dactylic pentameters.

A dactylic hexameter has six (in Greek ἕξ, "hex") feet. In strict dactylic hexameter, each foot would be a dactyl (a long and two short syllables), but classical meter allows for the substitution of a spondee (two long syllables) in place of a dactyl in most positions. Specifically, the first four feet can either be dactyls or spondees more or less freely. The fifth foot is usually a dactyl (around 95% of the time in Homer).

The sixth foot can be filled by either a trochee (a long then short syllable) or a spondee. Thus the dactylic line most normally looks as follows:

Hexameters also have a primary caesura — a break between words, sometimes (but not always) coinciding with a break in sense — at one of several normal positions: After the first syllable of the second foot; after the first syllable in the third foot (the "masculine" caesura); after the second syllable in the third foot if the third foot is a dactyl (the "feminine" caesura); after the first syllable of the fourth foot (the hephthemimeral caesura). 

Hexameters are frequently enjambed — the meaning runs over from one line to the next, without terminal punctuation — which helps to create the long, flowing narrative of epic. They are generally considered the most grandiose and formal meter.

An English-language example of the dactylic hexameter, in quantitative meter:

Quantitative meter is extremely difficult to use for most English speakers. Here is an example in normal stress meter (the first line of Longfellow's "Evangeline"):

The "foot" is often compared to a musical measure and the long and short syllables to half notes (minims) and quarter notes (crotchets), respectively.

The hexameter was first used by early Greek poets of the oral tradition, and the most complete extant examples of their works are the "Iliad" and the "Odyssey", which influenced the authors of all later classical epics that survive today. Early epic poetry was also accompanied by music, and pitch changes associated with the accented Greek must have highlighted the melody, though the exact mechanism is still a topic of discussion.

The Homeric poems arrange words so as to create an interplay between the metrical ictus—the first syllable of each foot—and the natural, spoken accent of words. If the ictus and accent coincide too frequently the hexameter becomes "sing-songy". Thus in general, word breaks occur in the middle of metrical feet, while ictus and accent coincide more often near the end of the line.
The first line of Homer’s "Iliad"—"Sing, goddess, the anger of Peleus’ son Achilles"—provides an example:

Dividing the line into metrical units:

Note how the word endings do not coincide with the end of a metrical foot; for the early part of the line this forces the accent of each word to lie in the middle of a foot, playing against the ictus.

This line also includes a masculine caesura after , a break that separates the line into two parts. Homer employs a feminine caesura more commonly than later writers: an example occurs in "Iliad" I.5 "...and every bird; thus the plan of Zeus came to fulfillment":

Homer’s hexameters contain a higher proportion of dactyls than later hexameter poetry. They are also characterised by a laxer following of verse principles than later epicists almost invariably adhered to. For example, Homer allows spondaic fifth feet (albeit not often), whereas many later authors virtually never did. 

Homer also altered the forms of words to allow them to fit the hexameter, typically by using a dialectal form: "ptolis" is an epic form used instead of the Attic "polis" as necessary for the meter. Proper names sometimes take forms to fit the meter, for example "Pouludamas" instead of the metrically unviable "Poludamas".
Note also that some lines require a knowledge of the digamma for their scansion, e.g. "Iliad" I.108 "you have not yet spoken a good word nor brought one to pass":

Here the word was originally in Ionian; the digamma, later lost, lengthened the last syllable of the preceding and removed the apparent defect in the meter. A digamma also saved the hiatus in the third foot. This example demonstrates the oral tradition of the Homeric epics that flourished before they were written down sometime in the 7th century BC.

In spite of the occasional exceptions in early epic, most of the later rules of hexameter composition have their origins in the methods and practices of Homer.

The hexameter came into Latin as an adaptation from Greek long after the practice of singing the epics had faded. Consequentially, the properties of the meter were learned as specific "rules" rather than as a natural result of musical expression. Also, because the Latin language generally has a higher proportion of long syllables than Greek, it is by nature more spondaic. Thus the Latin hexameter took on characteristics of its own.

The earliest example of hexameter in Latin poetry is the "Annales" of Ennius, which established it as the standard for later Latin epics. Later Republican writers, such as Lucretius, Catullus and even Cicero, wrote hexameter compositions, and it was at this time that many of the principles of Latin hexameter were firmly established, and followed by later writers such as Virgil, Ovid, Lucan, and Juvenal. Virgil's opening line for the "Aeneid" is a classic example::

As in Greek, lines were arranged so that the metrically long syllables—those occurring at the beginning of a foot— often avoided the natural stress of a word.In the earlier feet of a line, meter and stress were expected to clash, while in the later feet they were expected to resolve and coincide—an effect that gives each line a natural "dum-ditty-dum-dum" ("shave and a haircut") rhythm to close. Such an arrangement is a balance between an exaggerated emphasis on the metre—which would cause the verse to be sing-songy—and the need to provide some repeated rhythmic guide for skilled recitation.

In the following example of Ennius's early Latin hexameter composition, metrical weight (') falls on the first and last syllables of '; the ictus is therefore opposed to the natural stress on the second syllable when the word is pronounced. Similarly, the second syllable of the words ' and ' carry the metrical ictus even though the first is naturally stressed in typical pronunciation. In the closing feet of the line, the natural stress that falls on the third syllable of ' and the second syllable of ' coincide with the metrical ictus and produce the characteristic "shave and a haircut" ending:

Like their Greek predecessors, classical Latin poets avoided a large number of word breaks at the ends of foot divisions except between the fourth and fifth, where it was encouraged. In order to preserve the rhythmic close, Latin poets avoided the placement of a single syllable or four-syllable word at the end of a line. The caesura is also handled far more strictly, with Homer's feminine caesura becoming exceedingly rare, and the second-foot caesura always paired with one in the fourth.

One example of the evolution of the Latin verse form can be seen in a comparative analysis of the use of spondees in Ennius' time vs. the Augustan age. The repeated use of the heavily spondaic line came to be frowned upon, as well as the use of a high proportion of spondees in both of the first two feet. The following lines of Ennius would not have been felt admissible by later authors since they both contain repeated spondees at the beginning of consecutive lines:

However, it is from Virgil that the following famous, heavily spondaic line comes:

By the age of Augustus, poets like Virgil closely followed the rules of the meter and approached it in a highly rhetorical way, looking for effects that can be exploited in skilled recitation. For example, the following line from the "Aeneid" (VIII.596) describes the movement of rushing horses and how "a hoof shakes the crumbling field with a galloping sound":

This line is made up of five dactyls and a closing spondee, an unusual rhythmic arrangement that imitates the described action. A similar effect is found in VIII.452, where Virgil describes how the blacksmith sons of Vulcan "lift their arms with great strength one to another" in forging Aeneas' shield:

The line consists of all spondees except for the usual dactyl in the fifth foot, and is meant to mimic the pounding sound of the work. A third example that mixes the two effects comes from I.42, where Juno pouts that Athena was allowed to use Jove's thunderbolts to destroy Ajax ("she hurled Jove's quick fire from the clouds"):

This line is nearly all dactyls except for the spondee at "-lata e". This change in rhythm paired with the harsh elision is intended to emphasize the crash of Athena's thunderbolt.

Virgil will occasionally deviate from the strict rules of the meter to produce a special effect. One example from I.105 describing a ship at sea during a storm has Virgil violating metrical standards to place a single-syllable word at the end of the line:

The boat "gives its side to the waves; there comes next in a heap a steep mountain of water." By placing the monosyllable "mons" at the end of the line, Virgil interrupts the usual "shave and a haircut" pattern to produce a jarring rhythm, an effect that echoes the crash of a large wave against the side of a ship. The Roman poet Horace uses a similar trick to highlight the comedic irony that "Mountains will be in labor, and bring forth a ridiculous mouse" in this famous line from his "Ars Poetica" (line 139):

Another amusing example that comments on the importance of these verse rules comes later in the same poem (line 263):

This line, which lacks a proper caesura, is translated "Not every critic sees an inharmonious verse."

The verse innovations of the Augustan writers were carefully imitated by their successors in the Silver Age of Latin literature. The verse form itself then was little changed, as the quality of a poet's hexameter was judged against the standard set by Virgil and the other Augustan poets, a respect for literary precedent encompassed by the Latin word '. Deviations were generally regarded as idiosyncrasies or hallmarks of personal style, and were not imitated by later poets. Juvenal, for example, was fond of occasionally creating verses that placed a sense break between the fourth and fifth foot (instead of in the usual caesura positions), but this technique—known as the bucolic diaeresis—did not catch on with other poets.

In the late empire, writers experimented again by adding unusual restrictions to the standard hexameter. The rhopalic verse of Ausonius is a good example; besides following the standard hexameter pattern, each word in the line is one syllable longer than the previous, e.g.:

Also notable is the tendency among late grammarians to thoroughly dissect the hexameters of Virgil and earlier poets. A treatise on poetry by Diomedes Grammaticus is a good example, as this work (among other things) categorizes dactylic hexameter verses in ways that were later interpreted under the golden line rubric. Independently, these two trends show the form becoming highly artificial—more like a puzzle to solve than a medium for personal poetic expression.

By the Middle Ages, some writers adopted more relaxed versions of the meter. Bernard of Cluny, for example, employs it in his "De Contemptu Mundi", but ignores classical conventions in favor of accentual effects and predictable rhyme both within and between verses, e.g.:

Not all medieval writers are so at odds with the Virgilian standard, and with the rediscovery of classical literature, later Medieval and Renaissance writers are far more orthodox, but by then the form had become an academic exercise. Petrarch, for example, devoted much time to his "Africa", a dactylic hexameter epic on Scipio Africanus, but this work was unappreciated in his time and remains little read today. In contrast, Dante decided to write his epic, the "Divine Comedy" in Italian—a choice that defied the traditional epic choice of Latin dactylic hexameters—and produced a masterpiece beloved both then and now.

With the New Latin period, the language itself came to be regarded as a medium only for "serious" and learned expression, a view that left little room for Latin poetry. The emergence of Recent Latin in the 20th century restored classical orthodoxy among Latinists and sparked a general (if still academic) interest in the beauty of Latin poetry. Today, the modern Latin poets who use the dactylic hexameter are generally as faithful to Virgil as Rome's Silver Age poets.

In addition to modern Latin poets, examples of dactylic hexameter in modern use can frequently be found in hip-hop and rap lyrics, though it is not definitively researched enough to declare whether it is derived from the ephemeral notion of "flow" (such as in the music of Jay-Z) or more intentionally employed by major artists in the poetic creation of their lyrics. The relationship between dactylic hexameter and hip-hop/rap has been notably used in teaching classic poetry to young students. Dactylic hexameter in rap/hip-hop is most frequently mentioned in discussions of the song "Bring the Noise" by the musical artists Public Enemy. "Bring the Noise" has been sampled and remixed by other artists, and both the original song and cover versions have performed well on industry trackers such as the Billboard charts – across musical genres and different countries/linguistic groups – which may anecdotally indicate the strength of dactylic hexameter in conveying lyrical quality to the human ear, particularly when it is considered that the meter has had enduring success for artists from the time of Homer through the modern day.

"The Seasons" ("Metai") by Kristijonas Donelaitis is a famous Lithuanian poem in quantitative dactylic hexameters. Because of the nature of Lithuanian, more than half of the lines of the poem consist entirely of spondees save for the mandatory dactyl in the fifth foot.

"Der Messias" by Friedrich Gottlieb Klopstock is a German poem in accentual dactylic hexameters.



</doc>
<doc id="8466" url="https://en.wikipedia.org/wiki?curid=8466" title="Dorado">
Dorado

Dorado (English pronunciation: ) is a constellation in the southern sky. It was named in the late 16th century and is now one of the 88 modern constellations. Its name refers to the dolphinfish ("Coryphaena hippurus"), which is known as "dorado" in Portuguese, although it has also been depicted as a swordfish. Dorado contains most of the Large Magellanic Cloud, the remainder being in the constellation Mensa. The South Ecliptic pole also lies within this constellation.

Even though the name Dorado is not Latin but Portuguese, astronomers give it the Latin genitive form "Doradus" when naming its stars; it is treated (like the adjacent asterism Argo Navis) as a feminine proper name of Greek origin ending in -ō (like "Io" or "Callisto" or "Argo"), which have a genitive ending "-ūs".

Dorado was one of twelve constellations named by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman. It appeared:
Dorado has been represented historically as a dolphinfish and a swordfish; the latter depiction is inaccurate. It has also been represented as a goldfish. The constellation was also known in the 17th and 18th century as Xiphias. The name "Dorado" ultimately become dominant and was adopted by the IAU.

Alpha Doradus is a blue-white star of magnitude 3.3, 176 light-years from Earth. It is the brightest star in Dorado. Beta Doradus is a notably bright Cepheid variable star. It is a yellow-tinged supergiant star that has a minimum magnitude of 4.1 and a maximum magnitude of 3.5. One thousand and forty light-years from Earth, Beta Doradus has a period of 9 days and 20 hours.

R Doradus is one of the many variable stars in Dorado. S Dor, 9.721 hypergiant in the Large Magellanic Cloud, is the prototype of S Doradus variable stars. The variable star R Doradus 5.73 has the largest known apparent size of any star other than the Sun. Gamma Doradus is the prototype of the Gamma Doradus variable stars.

Supernova 1987A was the closest supernova to occur since the invention of the telescope. SNR 0509-67.5 is the remnant of an unusually energetic Type 1a supernova from about 400 years ago.

HE 0437-5439 is a hypervelocity star escaping from the Milky Way/Magellanic Cloud system.

Dorado is also the location of the South Ecliptic pole, which lies near the fish's head. The pole was called "Polus Doradinalis" by Willem Jansson Blaeu.

Because Dorado contains part of the Large Magellanic Cloud, it is rich in deep sky objects. The Large Magellanic Cloud, 25,000 light-years in diameter, is a satellite galaxy of the Milky Way Galaxy, located at a distance of 179,000 light-years. It has been deformed by its gravitational interactions with the larger Milky Way. In 1987, it became host to SN 1987A, the first supernova of 1987 and the closest since 1604. This 25,000-light-year-wide galaxy contains over 10,000 million stars. All coordinates given are for Epoch J2000.0.




In Chinese astronomy, the stars of Dorado are in two of Xu Guangqi's Southern Asterisms (近南極星區, "Jìnnánjíxīngōu"): the White Patches Attached (夾白, "Jiābái") and the Goldfish (金魚, "Jīnyú").







</doc>
<doc id="8467" url="https://en.wikipedia.org/wiki?curid=8467" title="Draco (lawgiver)">
Draco (lawgiver)

Draco (; , "Drakōn"; fl. c. 7th century BC) was the first recorded legislator of Athens in Ancient Greece. He replaced the prevailing system of oral law and blood feud by a written code to be enforced only by a court of law. Draco was the first democratic legislator, he was requested by the Athenian citizens to be a lawgiver for the city-state, but the citizens were fully unaware that Draco would establish harsh laws. Draco's written law was characterized by its harshness. To this day, the adjective "draconian" refers to similarly unforgiving rules or laws, in English and other European languages.

During the 39th Olympiad, in 622 or 621 BC, Draco established the legal code with which he is identified.

Little is known about his life. He may have belonged to the Greek nobility of Attica, with which the 10th-century [Suda] text records him as contemporaneous, prior to the period of the Seven Sages of Greece. It also relates a folkloric story of his death in the Aeginetan theatre. In a traditional ancient Greek show of approval, his supporters "threw so many hats and shirts and cloaks on his head that he suffocated, and was buried in that same theatre". The truth about his death is still unclear, but we do know that Draco was driven out of Athens by the Athenians to the neighbouring island of Aegina, where he spent the remainder of his life.

The laws ( - "thesmoi") that he laid were the first written constitution of Athens. So that no one would be unaware of them, they were posted on wooden tablets ( - "axones"), where they were preserved for almost two centuries on steles of the shape of three-sided pyramids ( - "kyrbeis"). The tablets were called "axones", perhaps because they could be pivoted along the pyramid's axis to read any side.

The constitution featured several major innovations:

The laws were particularly harsh. For example, any debtor whose status was lower than that of his creditor was forced into slavery. The punishment was more lenient for those owing a debt to a member of a lower class. The death penalty was the punishment for even minor offences, such as stealing a cabbage. Concerning the liberal use of the death penalty in the Draconic code, Plutarch states: "It is said that Drakon himself, when asked why he had fixed the punishment of death for most offences, answered that he considered these lesser crimes to deserve it, and he had no greater punishment for more important ones".

All his laws were repealed by Solon in the early 6th century BC, with the exception of the homicide law.

After much debate, the Athenians decided to revise the laws, including the homicide law, in 409 BC. The homicide law is a highly fragmented inscription but states that it is up to the victim's relatives to prosecute a killer. According to the preserved part of the inscription, unintentional homicides received a sentence of exile.

It is not clear whether Draco's law specified the punishment for intentional homicide. In 409 BC, intentional homicide was punished by death, but Draco's law begins, 'καὶ ἐὰμ μὲ ‘κ [π]ρονοί[α]ς [κ]τ[ένει τίς τινα, φεύγ]ε[ν]', which is ambiguous and difficult to translate. One possible translation offers, "Even if a man not intentionally kills another, he is exiled".

Draco introduced the lot-chosen Council of Four Hundred, distinct from the Areopagus, which evolved in later constitutions to play a large role in Athenian democracy. Aristotle notes that Draco, while having the laws written, merely legislated for an existing unwritten Athenian constitution such as setting exact qualifications for eligibility for office.

Draco extended the franchise to all free men who could furnish themselves with a set of military equipment. They elected the Council of Four Hundred from among their number; nine archons and the treasurers were drawn from persons possessing an unencumbered property of not less than ten "minas", the generals ("strategoi") and commanders of cavalry ("hipparchoi") from those who could show an unencumbered property of not less than a hundred "minas" and had children born in lawful wedlock over ten years of age. Thus, in the event of their death, their estate could pass to a competent heir. These officers were required to hold to account the "prytanes" (councillors), "strategoi" (generals) and "hipparchoi" (cavalry officers) of the preceding year until their accounts had been audited. "The Council of Areopagus was guardian of the laws, and kept watch over the magistrates to see that they executed their offices in accordance with the laws. Any person who felt himself wronged might lay an information before the Council of Areopagus, on declaring what law was broken by the wrong done to him. But, as has been said before, loans were secured upon the persons of the debtors, and the land was in the hands of a few."




Translation of original inscription


</doc>
<doc id="8468" url="https://en.wikipedia.org/wiki?curid=8468" title="Determinant">
Determinant

In linear algebra, the determinant is a value that can be computed from the elements of a square matrix. The determinant of a matrix is denoted , , or . Geometrically, it can be viewed as the scaling factor of the linear transformation described by the matrix.

In the case of a matrix the determinant may be defined as:

Similarly, for a 3 × 3 matrix "A", its determinant is:
Each determinant of a matrix in this equation is called a "minor" of the matrix . This procedure can be extended to give a recursive definition for the determinant of an matrix, the "minor expansion formula".

Determinants occur throughout mathematics. For example, a matrix is often used to represent the coefficients in a system of linear equations, and the determinant can be used to solve those equations, although other methods of solution are much more computationally efficient. In linear algebra, a matrix (with entries in a field) is invertible if and only if its determinant is non-zero, and correspondingly the matrix is singular if and only if its determinant is zero. This leads to the use of determinants in defining the characteristic polynomial of a matrix, whose roots are the eigenvalues. In analytic geometry, determinants express the signed "n"-dimensional volumes of "n"-dimensional parallelepipeds. This leads to the use of determinants in calculus, the Jacobian determinant in the change of variables rule for integrals of functions of several variables. Determinants appear frequently in algebraic identities such as the Vandermonde identity.

Determinants possess many algebraic properties, including that the determinant of a product of matrices is equal to the product of determinants. Special types of matrices have special determinants; for example, the determinant of an orthogonal matrix is always plus or minus one, and the determinant of a complex Hermitian matrix is always real.

If an real matrix "A" is written in terms of its column vectors formula_3 then 

This means that formula_5 maps the unit n-cube to the "n"-dimensional parallelotope defined by the vectors formula_6, the region formula_7
The determinant gives the signed n-dimensional volume of this parallelotope, formula_8, and hence describes more generally the "n"-dimensional volume scaling factor of the linear transformation produced by "A". (The sign shows whether the transformation preserves or reverses orientation.) In particular, if the determinant is zero, then this parallelotope has volume zero and is not fully "n"-dimensional, which indicates that the dimension of the image of "A" is less than "n". This means that "A" produces a linear transformation which is neither onto nor one-to-one, and so is not invertible.

There are various equivalent ways to define the determinant of a square matrix "A", i.e. one with the same number of rows and columns. Perhaps the simplest way to express the determinant is by considering the elements in the top row and the respective minors; starting at the left, multiply the element by the minor, then subtract the product of the next element and its minor, and alternate adding and subtracting such products until all elements in the top row have been exhausted. For example, here is the result for a 4 × 4 matrix:

Another way to define the determinant is expressed in terms of the columns of the matrix. If we write an matrix "A" in terms of its column vectors

where the formula_11 are vectors of size "n", then the determinant of "A" is defined so that

where "b" and "c" are scalars, "v" is any vector of size "n" and "I" is the identity matrix of size "n". These equations say that the determinant is a linear function of each column, that interchanging adjacent columns reverses the sign of the determinant, and that the determinant of the identity matrix is 1. These properties mean that the determinant is an alternating multilinear function of the columns that maps the identity matrix to the underlying unit scalar. These suffice to uniquely calculate the determinant of any square matrix. Provided the underlying scalars form a field (more generally, a commutative ring with unity), the definition below shows that such a function exists, and it can be shown to be unique.

Equivalently, the determinant can be expressed as a sum of products of entries of the matrix where each product has "n" terms and the coefficient of each product is −1 or 1 or 0 according to a given rule: it is a polynomial expression of the matrix entries. This expression grows rapidly with the size of the matrix (an matrix contributes "n"! terms), so it will first be given explicitly for the case of matrices and matrices, followed by the rule for arbitrary size matrices, which subsumes these two cases.

Assume "A" is a square matrix with "n" rows and "n" columns, so that it can be written as
The entries can be numbers or expressions (as happens when the determinant is used to define a characteristic polynomial); the definition of the determinant depends only on the fact that they can be added and multiplied together in a commutative manner.

The determinant of "A" is denoted by det("A"), or it can be denoted directly in terms of the matrix entries by writing enclosing bars instead of brackets:

The Leibniz formula for the determinant of a matrix is

If the matrix entries are real numbers, the matrix "A" can be used to represent two linear maps: one that maps the standard basis vectors to the rows of "A", and one that maps them to the columns of "A". In either case, the images of the basis vectors form a parallelogram that represents the image of the unit square under the mapping. The parallelogram defined by the rows of the above matrix is the one with vertices at , , , and , as shown in the accompanying diagram.

The absolute value of is the area of the parallelogram, and thus represents the scale factor by which areas are transformed by "A". (The parallelogram formed by the columns of "A" is in general a different parallelogram, but since the determinant is symmetric with respect to rows and columns, the area will be the same.)

The absolute value of the determinant together with the sign becomes the "oriented area" of the parallelogram. The oriented area is the same as the usual area, except that it is negative when the angle from the first to the second vector defining the parallelogram turns in a clockwise direction (which is opposite to the direction one would get for the identity matrix).

To show that is the signed area, one may consider a matrix containing two vectors and representing the parallelogram's sides. The signed area can be expressed as for the angle "θ" between the vectors, which is simply base times height, the length of one vector times the perpendicular component of the other. Due to the sine this already is the signed area, yet it may be expressed more conveniently using the cosine of the complementary angle to a perpendicular vector, e.g. , such that , which can be determined by the pattern of the scalar product to be equal to :

Thus the determinant gives the scaling factor and the orientation induced by the mapping represented by "A". When the determinant is equal to one, the linear mapping defined by the matrix is equi-areal and orientation-preserving.

The object known as the "bivector" is related to these ideas. In 2D, it can be interpreted as an "oriented plane segment" formed by imagining two vectors each with origin , and coordinates and . The bivector magnitude (denoted by ) is the "signed area", which is also the determinant .

The Laplace formula for the determinant of a matrix is

this can be expanded out to give

which is the Leibniz formula for the determinant of a matrix.

The rule of Sarrus is a mnemonic for the matrix determinant: the sum of the products of three diagonal north-west to south-east lines of matrix elements, minus the sum of the products of three diagonal south-west to north-east lines of elements, when the copies of the first two columns of the matrix are written beside it as in the illustration. This scheme for calculating the determinant of a matrix does not carry over into higher dimensions.

The determinant of a matrix of arbitrary size can be defined by the Leibniz formula or the Laplace formula.

The Leibniz formula for the determinant of an matrix "A" is

Here the sum is computed over all permutations σ of the set A permutation is a function that reorders this set of integers. The value in the "i"th position after the reordering σ is denoted by σ. For example, for , the original sequence 1, 2, 3 might be reordered to , with , , and . The set of all such permutations (also known as the symmetric group on "n" elements) is denoted by S. For each permutation σ, sgn(σ) denotes the signature of σ, a value that is +1 whenever the reordering given by σ can be achieved by successively interchanging two entries an even number of times, and −1 whenever it can be achieved by an odd number of such interchanges.

In any of the formula_20 summands, the term

is notation for the product of the entries at positions , where "i" ranges from 1 to "n":

For example, the determinant of a matrix "A" () is

It is sometimes useful to extend the Leibniz formula to a summation in which not only permutations, but all sequences of "n" indices in the range occur, ensuring that the contribution of a sequence will be zero unless it denotes a permutation. Thus the totally antisymmetric Levi-Civita symbol formula_24 extends the signature of a permutation, by setting formula_25 for any permutation σ of "n", and formula_26 when no permutation σ exists such that formula_27 for formula_28 (or equivalently, whenever some pair of indices are equal). The determinant for an matrix can then be expressed using an "n"-fold summation as
or using two epsilon symbols as
where now each "i" and each "j" should be summed over .

The determinant has many properties. Some basic properties of determinants are


Property 5 says that the determinant on matrices is homogeneous of degree "n". These properties can be used to facilitate the computation of determinants by simplifying the matrix to the point where the determinant can be determined immediately. Specifically, for matrices with coefficients in a field, properties 13 and 14 can be used to transform any matrix into a triangular matrix, whose determinant is given by property 6; this is essentially the method of Gaussian elimination.

For example, the determinant of

can be computed using the following matrices:

Here, "B" is obtained from "A" by adding −1/2×the first row to the second, so that . "C" is obtained from "B" by adding the first to the third row, so that . Finally, "D" is obtained from "C" by exchanging the second and third row, so that . The determinant of the (upper) triangular matrix "D" is the product of its entries on the main diagonal: . Therefore, .

The determinant of a matrix product of square matrices equals the product of their determinants:

Thus the determinant is a "multiplicative map". This property is a consequence of the characterization given above of the determinant as the unique "n"-linear alternating function of the columns with value 1 on the identity matrix, since the function that maps can easily be seen to be "n"-linear and alternating in the columns of "M", and takes the value det("A") at the identity. The formula can be generalized to (square) products of rectangular matrices, giving the Cauchy–Binet formula, which also provides an independent proof of the multiplicative property.

The determinant det("A") of a matrix "A" is non-zero if and only if "A" is invertible or, yet another equivalent statement, if its rank equals the size of the matrix. If so, the determinant of the inverse matrix is given by

In particular, products and inverses of matrices with determinant one still have this property. Thus, the set of such matrices (of fixed size "n") form a group known as the special linear group. More generally, the word "special" indicates the subgroup of another matrix group of matrices of determinant one. Examples include the special orthogonal group (which if "n" is 2 or 3 consists of all rotation matrices), and the special unitary group.

Laplace's formula expresses the determinant of a matrix in terms of its minors. The minor "M" is defined to be the determinant of the -matrix that results from "A" by removing the "i"-th row and the "j"-th column. The expression is known as a cofactor. The determinant of "A" is given by

Calculating det("A") by means of this formula is referred to as expanding the determinant along a row, the "i"-th row using the first form with fixed "i", or expanding along a column, using the second form with fixed "j". For example, the Laplace expansion of the matrix
along the second column ( and the sum runs over "i") is given by,

However, Laplace expansion is efficient for small matrices only.

The adjugate matrix adj("A") is the transpose of the matrix consisting of the cofactors, i.e.,
In terms of the adjugate matrix, Laplace's expansion can be written as

Sylvester's determinant theorem states that for "A", an matrix, and "B", an matrix (so that "A" and "B" have dimensions allowing them to be multiplied in either order forming a square matrix):

where "I" and "I" are the and identity matrices, respectively.

From this general result several consequences follow.

Let be an arbitrary matrix of complex numbers with eigenvalues formula_52, formula_53, … formula_54. (Here it is understood that an eigenvalue with algebraic multiplicity occurs times in this list.) Then the determinant of is the product of all eigenvalues,
The product of all non-zero eigenvalues is referred to as pseudo-determinant.

Conversely, determinants can be used to find the eigenvalues of the matrix : they are the solutions of the characteristic equation
where "I" is the identity matrix of the same dimension as and is a (scalar) number which solves the equation (there are no more than solutions, where is the dimension of ).

A Hermitian matrix is positive definite if all its eigenvalues are positive. Sylvester's criterion asserts that this is equivalent to the determinants of the submatrices
being positive, for all between 1 and .

The trace tr("A") is by definition the sum of the diagonal entries of and also equals the sum of the eigenvalues. Thus, for complex matrices ,
or, for real matrices ,
Here exp() denotes the matrix exponential of , because every eigenvalue of corresponds to the eigenvalue exp() of exp(). In particular, given any logarithm of , that is, any matrix satisfying
the determinant of is given by

For example, for , , and , respectively,
cf. Cayley-Hamilton theorem. Such expressions are deducible from combinatorial arguments, Newton's identities, or the Faddeev–LeVerrier algorithm. That is, for generic ,

In the general case, this may also be obtained from
where the sum is taken over the set of all integers "k" ≥ 0 satisfying the equation

The formula can be expressed in terms of the complete exponential Bell polynomial of "n" arguments "s" = - ("l" – 1)! tr("A") as

This formula can also be used to find the determinant of a matrix with multidimensional indices and . The product and trace of such matrices are defined in a natural way as

An important arbitrary dimension identity can be obtained from the Mercator series expansion of the logarithm when the expansion converges. If every eigenvalue of "A" is less than 1 in absolute value,
where is the identity matrix. More generally, if 
is expanded as a formal power series in then all coefficients of for are zero and the remaining polynomial is .

For a positive definite matrix , the trace operator gives the following tight lower and upper bounds on the log determinant
with equality if and only if . This relationship can be derived via the formula for the KL-divergence between two multivariate normal distributions.

Also,
These inequalities can be proved by bringing the matrix "A" to the diagonal form. As such, they represent the well-known fact that the harmonic mean is less than the geometric mean, which is less than the arithmetic mean, which is, in turn, less than the root mean square.

For a matrix equation

the solution is given by Cramer's rule:
where "A" is the matrix formed by replacing the "i"th column of "A" by the column vector "b". This follows immediately by column expansion of the determinant, i.e.
where the vectors formula_11 are the columns of "A". The rule is also implied by the identity

It has recently been shown that Cramer's rule can be implemented in O("n") time, which is comparable to more common methods of solving systems of linear equations, such as LU, QR, or singular value decomposition.

Suppose "A", "B", "C", and "D" are matrices of dimension , , , and , respectively. Then

This can be seen from the Leibniz formula, or from a decomposition like (for the former case)

When "A" is invertible, one has

as can be seen by employing the decomposition

When "D" is invertible, a similar identity with formula_83 factored out can be derived analogously, that is,

When the blocks are square matrices of the same order further formulas hold. For example, if "C" and "D" commute (i.e., ), then the following formula comparable to the determinant of a matrix holds:

Generally, if all pairs of matrices of the block matrix commute, then the determinant of the block matrix is equal to the determinant of the matrix obtained by computing the determinant of the block matrix considering its entries as the entries of a matrix. As the previous formula shows, for "p" = 2, this criterion is sufficient, but not necessary.

When "A" = "D" and "B" = "C", the blocks are square matrices of the same order and the following formula holds (even if "A" and "B" do not commute)

When "D" is a 1×1 matrix, "B" is a column vector, and "C" is a row vector then

Let formula_88 be a scalar complex number. If a block matrix is square, its characteristic polynomial can be factored with

By definition, e.g., using the Leibniz formula, the determinant of real (or analogously for complex) square matrices is a polynomial function from to R. As such it is everywhere differentiable. Its derivative can be expressed using Jacobi's formula:

where adj("A") denotes the adjugate of "A". In particular, if "A" is invertible, we have

Expressed in terms of the entries of "A", these are

Yet another equivalent formulation is

using big O notation. The special case where formula_94, the identity matrix, yields

This identity is used in describing the tangent space of certain matrix Lie groups.

If the matrix A is written as formula_96 where a, b, c are column vectors of length 3, then the gradient over one of the three vectors may be written as the cross product of the other two:

The above identities concerning the determinant of products and inverses of matrices imply that similar matrices have the same determinant: two matrices "A" and "B" are similar, if there exists an invertible matrix "X" such that . Indeed, repeatedly applying the above identities yields

The determinant is therefore also called a similarity invariant. The determinant of a linear transformation
for some finite-dimensional vector space "V" is defined to be the determinant of the matrix describing it, with respect to an arbitrary choice of basis in "V". By the similarity invariance, this determinant is independent of the choice of the basis for "V" and therefore only depends on the endomorphism "T".

The determinant of a linear transformation of an "n"-dimensional vector space "V" can be formulated in a coordinate-free manner by considering the "n"th exterior power Λ"V" of "V". "A" induces a linear map

As Λ"V" is one-dimensional, the map ΛA is given by multiplying with some scalar. This scalar coincides with the determinant of "A", that is to say
This definition agrees with the more concrete coordinate-dependent definition. This follows from the characterization of the determinant given above. For example, switching two columns changes the sign of the determinant; likewise, permuting the vectors in the exterior product to , say, also changes its sign.

For this reason, the highest non-zero exterior power Λ("V") is sometimes also called the determinant of "V" and similarly for more involved objects such as vector bundles or chain complexes of vector spaces. Minors of a matrix can also be cast in this setting, by considering lower alternating forms Λ"V" with .

The vector space "W" of all alternating multilinear "n"-forms on an "n"-dimensional vector space "V" has dimension one. To each linear transformation "T" on "V" we associate a linear transformation "T"′ on "W", where for each "w" in "W" we define . As a linear transformation on a one-dimensional space, "T"′ is equivalent to a scalar multiple. We call this scalar the determinant of "T".

The determinant can also be characterized as the unique function
from the set of all matrices with entries in a field "K" to this field satisfying the following three properties: first, "D" is an "n"-linear function: considering all but one column of "A" fixed, the determinant is linear in the remaining column, that is
for any column vectors "v", ..., "v", and "w" and any scalars (elements of "K") "a" and "b". Second, "D" is an alternating function: for any matrix "A" with two identical columns, . Finally, , where "I" is the identity matrix.

This fact also implies that every other "n"-linear alternating function satisfies

This definition can also be extended where "K" is a commutative ring "R", in which case a matrix is invertible if and only if its determinant is an invertible element in "R". For example, a matrix "A" with entries in Z, the integers, is invertible (in the sense that there exists an inverse matrix with integer entries) if the determinant is +1 or −1. Such a matrix is called unimodular.

The determinant defines a mapping
between the group of invertible matrices with entries in "R" and the multiplicative group of units in "R". Since it respects the multiplication in both groups, this map is a group homomorphism. Secondly, given a ring homomorphism , there is a map given by replacing all entries in "R" by their images under "f". The determinant respects these maps, i.e., given a matrix with entries in "R", the identity
holds. In other words, the following diagram commutes:

For example, the determinant of the complex conjugate of a complex matrix (which is also the determinant of its conjugate transpose) is the complex conjugate of its determinant, and for integer matrices: the reduction modulo "m" of the determinant of such a matrix is equal to the determinant of the matrix reduced modulo "m" (the latter determinant being computed using modular arithmetic). In the language of category theory, the determinant is a natural transformation between the two functors GL and (⋅) (see also Natural transformation#Determinant). Adding yet another layer of abstraction, this is captured by saying that the determinant is a morphism of algebraic groups, from the general linear group to the multiplicative group,

For matrices with an infinite number of rows and columns, the above definitions of the determinant do not carry over directly. For example, in the Leibniz formula, an infinite sum (all of whose terms are infinite products) would have to be calculated. Functional analysis provides different extensions of the determinant for such infinite-dimensional situations, which however only work for particular kinds of operators.

The Fredholm determinant defines the determinant for operators known as trace class operators by an appropriate generalization of the formula

Another infinite-dimensional notion of determinant is the functional determinant.

For square matrices with entries in a non-commutative ring, there are various difficulties in defining determinants analogously to that for commutative rings. A meaning can be given to the Leibniz formula provided that the order for the product is specified, and similarly for other ways to define the determinant, but non-commutativity then leads to the loss of many fundamental properties of the determinant, for instance the multiplicative property or the fact that the determinant is unchanged under transposition of the matrix. Over non-commutative rings, there is no reasonable notion of a multilinear form (existence of a nonzero with a regular element of "R" as value on some pair of arguments implies that "R" is commutative). Nevertheless, various notions of non-commutative determinant have been formulated, which preserve some of the properties of determinants, notably quasideterminants and the Dieudonné determinant. It may be noted that if one considers certain specific classes of matrices with non-commutative elements, then there are examples where one can define the determinant and prove linear algebra theorems that are very similar to their commutative analogs. Examples include quantum groups and "q"-determinant, Capelli matrix and Capelli determinant, super-matrices and Berezinian; Manin matrices is the class of matrices which is most close to matrices with commutative elements.

Determinants of matrices in superrings (that is, Z-graded rings) are known as Berezinians or superdeterminants.

The permanent of a matrix is defined as the determinant, except that the factors sgn("σ") occurring in Leibniz's rule are omitted. The immanant generalizes both by introducing a character of the symmetric group S in Leibniz's rule.

Determinants are mainly used as a theoretical tool. They are rarely calculated explicitly in numerical linear algebra, where for applications like checking invertibility and finding eigenvalues the determinant has largely been supplanted by other techniques. Computational geometry, however, does frequently use calculations related to determinants.

Naive methods of implementing an algorithm to compute the determinant include using the Leibniz formula or Laplace's formula. Both these approaches are extremely inefficient for large matrices, though, since the number of required operations grows very quickly: it is of order "n"! ("n" factorial) for an matrix "M". For example, Leibniz's formula requires calculating "n"! products. Therefore, more involved techniques have been developed for calculating determinants.

Given a matrix "A", some methods compute its determinant by writing "A" as a product of matrices whose determinants can be more easily computed. Such techniques are referred to as decomposition methods. Examples include the LU decomposition, the QR decomposition or the Cholesky decomposition (for positive definite matrices). These methods are of order O("n"), which is a significant improvement over O("n"!)

The LU decomposition expresses "A" in terms of a lower triangular matrix "L", an upper triangular matrix "U" and a permutation matrix "P":
The determinants of "L" and "U" can be quickly calculated, since they are the products of the respective diagonal entries. The determinant of "P" is just the sign formula_111 of the corresponding permutation (which is +1 for an even number of permutations and is −1 for an uneven number of permutations). The determinant of "A" is then

(See determinant identities.) Moreover, the decomposition can be chosen such that "L" is a unitriangular matrix and therefore has determinant 1, in which case the formula further simplifies to

If the determinant of "A" and the inverse of "A" have already been computed, the matrix determinant lemma allows rapid calculation of the determinant of , where "u" and "v" are column vectors.

Since the definition of the determinant does not need divisions, a question arises: do fast algorithms exist that do not need divisions? This is especially interesting for matrices over rings. Indeed, algorithms with run-time proportional to "n" exist. An algorithm of Mahajan and Vinay, and Berkowitz is based on closed ordered walks (short "clow"). It computes more products than the determinant definition requires, but some of these products cancel and the sum of these products can be computed more efficiently. The final algorithm looks very much like an iterated product of triangular matrices.

If two matrices of order "n" can be multiplied in time "M"("n"), where for some , then the determinant can be computed in time O("M"("n")). This means, for example, that an O("n") algorithm exists based on the Coppersmith–Winograd algorithm.

Charles Dodgson (i.e. Lewis Carroll of Alice's Adventures in Wonderland fame) invented a method for computing determinants called Dodgson condensation. Unfortunately this interesting method does not always work in its original form.

Algorithms can also be assessed according to their bit complexity, i.e., how many bits of accuracy are needed to store intermediate values occurring in the computation. For example, the Gaussian elimination (or LU decomposition) method is of order O("n"), but the bit length of intermediate values can become exponentially long. The Bareiss Algorithm, on the other hand, is an exact-division method based on Sylvester's identity is also of order "n", but the bit complexity is roughly the bit size of the original entries in the matrix times "n".

Historically, determinants were used long before matrices: originally, a determinant was defined as a property of a system of linear equations. 
The determinant "determines" whether the system has a unique solution (which occurs precisely if the determinant is non-zero). 
In this sense, determinants were first used in the Chinese mathematics textbook "The Nine Chapters on the Mathematical Art" (九章算術, Chinese scholars, around the 3rd century BCE). 
In Europe, determinants were considered by Cardano at the end of the 16th century and larger ones by Leibniz.

In Japan, Seki Takakazu (関 孝和) is credited with the discovery of the resultant and the determinant (at first in 1683, the complete version no later than 1710). 
In Europe, Cramer (1750) added to the theory, treating the subject in relation to sets of equations. 
The recurrence law was first announced by Bézout (1764).

It was Vandermonde (1771) who first recognized determinants as independent functions. Laplace (1772) gave the general method of expanding a determinant in terms of its complementary minors: Vandermonde had already given a special case. Immediately following, Lagrange (1773) treated determinants of the second and third order and applied it to questions of elimination theory; he proved many special cases of general identities.

Gauss (1801) made the next advance. Like Lagrange, he made much use of determinants in the theory of numbers. He introduced the word determinant (Laplace had used "resultant"), though not in the present signification, but rather as applied to the discriminant of a quantic. Gauss also arrived at the notion of reciprocal (inverse) determinants, and came very near the multiplication theorem.

The next contributor of importance is Binet (1811, 1812), who formally stated the theorem relating to the product of two matrices of "m" columns and "n" rows, which for the special case of reduces to the multiplication theorem. On the same day (November 30, 1812) that Binet presented his paper to the Academy, Cauchy also presented one on the subject. (See Cauchy–Binet formula.) In this he used the word determinant in its present sense, summarized and simplified what was then known on the subject, improved the notation, and gave the multiplication theorem with a proof more satisfactory than Binet's. With him begins the theory in its generality.

The next important figure was Jacobi (from 1827). He early used the functional determinant which Sylvester later called the Jacobian, and in his memoirs in "Crelle's Journal" for 1841 he specially treats this subject, as well as the class of alternating functions which Sylvester has called "alternants". About the time of Jacobi's last memoirs, Sylvester (1839) and Cayley began their work.

The study of special forms of determinants has been the natural result of the completion of the general theory. Axisymmetric determinants have been studied by Lebesgue, Hesse, and Sylvester; persymmetric determinants by Sylvester and Hankel; circulants by Catalan, Spottiswoode, Glaisher, and Scott; skew determinants and Pfaffians, in connection with the theory of orthogonal transformation, by Cayley; continuants by Sylvester; Wronskians (so called by Muir) by Christoffel and Frobenius; compound determinants by Sylvester, Reiss, and Picquet; Jacobians and Hessians by Sylvester; and symmetric gauche determinants by Trudi. Of the textbooks on the subject Spottiswoode's was the first. In America, Hanus (1886), Weld (1893), and Muir/Metzler (1933) published treatises.

As mentioned above, the determinant of a matrix (with real or complex entries, say) is zero if and only if the column vectors (or the row vectors) of the matrix are linearly dependent. Thus, determinants can be used to characterize linearly dependent vectors. For example, given two linearly independent vectors "v", "v" in R, a third vector "v" lies in the plane spanned by the former two vectors exactly if the determinant of the matrix consisting of the three vectors is zero. The same idea is also used in the theory of differential equations: given "n" functions "f"("x"), …, "f"("x") (supposed to be times differentiable), the Wronskian is defined to be
It is non-zero (for some "x") in a specified interval if and only if the given functions and all their derivatives up to order "n"−1 are linearly independent. If it can be shown that the Wronskian is zero everywhere on an interval then, in the case of analytic functions, this implies the given functions are linearly dependent. See the Wronskian and linear independence.

The determinant can be thought of as assigning a number to every sequence of "n" vectors in R, by using the square matrix whose columns are the given vectors. For instance, an orthogonal matrix with entries in R represents an orthonormal basis in Euclidean space. The determinant of such a matrix determines whether the orientation of the basis is consistent with or opposite to the orientation of the standard basis. If the determinant is +1, the basis has the same orientation. If it is −1, the basis has the opposite orientation.

More generally, if the determinant of "A" is positive, "A" represents an orientation-preserving linear transformation (if "A" is an orthogonal or matrix, this is a rotation), while if it is negative, "A" switches the orientation of the basis.

As pointed out above, the absolute value of the determinant of real vectors is equal to the volume of the parallelepiped spanned by those vectors. As a consequence, if is the linear map represented by the matrix "A", and "S" is any measurable subset of R, then the volume of "f"("S") is given by |det("A")| times the volume of "S". More generally, if the linear map is represented by the matrix "A", then the "n"-dimensional volume of "f"("S") is given by:

By calculating the volume of the tetrahedron bounded by four points, they can be used to identify skew lines. The volume of any tetrahedron, given its vertices a, b, c, and d, is , or any other combination of pairs of vertices that would form a spanning tree over the vertices.

For a general differentiable function, much of the above carries over by considering the Jacobian matrix of "f". For
the Jacobian matrix is the matrix whose entries are given by
Its determinant, the Jacobian determinant, appears in the higher-dimensional version of integration by substitution: for suitable functions "f" and an open subset "U" of R (the domain of "f"), the integral over "f"("U") of some other function is given by
The Jacobian also occurs in the inverse function theorem.

The third order Vandermonde determinant is
In general, the "n"th-order Vandermonde determinant is
where the right-hand side is the continued product of all the differences that can be formed from the "n"("n"−1)/2 pairs of numbers taken from "x", "x", …, "x", with the order of the differences taken in the reversed order of the suffixes that are involved.

Second order
Third order
where ω and ω are the complex cube roots of 1. In general, the "n"th-order circulant determinant is
where ω is an "n"th root of 1.




</doc>
<doc id="8470" url="https://en.wikipedia.org/wiki?curid=8470" title="David Ricardo">
David Ricardo

David Ricardo (18 April 1772 – 11 September 1823) was a British political economist, one of the most influential of the classical economists along with Thomas Malthus, Adam Smith and James Mill.

Born in London, England, Ricardo was the third of 17 children of a Sephardic Jewish family of Portuguese origin who had recently relocated from the Dutch Republic. His father, Abraham Ricardo, was a successful stockbroker. He began working with his father at the age of 14. At age 21, Ricardo eloped with a Quaker, Priscilla Anne Wilkinson, and, against his father's wishes, converted to the Unitarian faith. This religious difference resulted in estrangement from his family, and he was led to adopt a position of independence. His father disowned him and his mother apparently never spoke to him again.

Following this estrangement he went into business for himself with the support of Lubbocks and Forster, an eminent banking house. He made the bulk of his fortune as a result of speculation on the outcome of the Battle of Waterloo. "The Sunday Times" reported in Ricardo’s obituary, published on 14 September 1823, that during the Battle of Waterloo Ricardo "netted upwards of a million sterling", a huge sum at the time. He immediately retired, his position on the floor no longer tenable, and subsequently purchased Gatcombe Park, an estate in Gloucestershire, now owned by Princess Anne, the Princess Royal and retired to the country. He was appointed High Sheriff of Gloucestershire for 1818–19.

In August 1818 he bought Lord Portarlington’s seat in Parliament for £4,000, as part of the terms of a loan of £25,000. His record in Parliament was that of an earnest reformer. He held the seat until his death five years later.

Ricardo was a close friend of James Mill. Other notable friends included Jeremy Bentham and Thomas Malthus, with whom Ricardo had a considerable debate (in correspondence) over such things as the role of landowners in a society. He also was a member of Malthus' Political Economy Club, and a member of the King of Clubs. He was one of the original members of The Geological Society. His youngest sister was author Sarah Ricardo-Porter (e.g., "Conversations in Arithmetic").

He voted with opposition in support of the liberal movements in Naples, 21 Feb., and Sicily, 21 June, and for inquiry into the administration of justice in Tobago, 6 June. He divided for repeal of the Blasphemous and Seditious Libels Act, 8 May, inquiry into the Peterloo massacre, 16 May, and abolition of the death penalty for forgery, 25 May, 4 June 1821.

He adamantly supported the implementation of free trade. He voted against renewal of the sugar duties, 9 Feb., and objected to the higher duty on East as opposed to West Indian produce, 4 May 1821. He opposed the timber duties. He voted silently for parliamentary reform, 25 Apr., 3 June, and spoke in its favour at the Westminster anniversary reform dinner, 23 May 1822. He again voted for criminal law reform, 4 June.

His friend John Louis Mallett commented: " … he meets you upon every subject that he has studied with a mind made up, and opinions in the nature of mathematical truths. He spoke of parliamentary reform and ballot as a man who would bring such things about, and destroy the existing system tomorrow, if it were in his power, and without the slightest doubt on the result … It is this very quality of the man’s mind, his entire disregard of experience and practice, which makes me doubtful of his opinions on political economy."

Ten years after retiring and four years after entering Parliament Ricardo died from an infection of the middle ear that spread into the brain and induced septicaemia. He was 51.

He had eight children, including three sons, of whom Osman Ricardo (1795–1881; MP for Worcester 1847–1865) and another David Ricardo (1803–1864, MP for Stroud 1832–1833), became Members of Parliament, while the third, Mortimer Ricardo, served as an officer in the Life Guards and was a deputy lieutenant for Oxfordshire.

Ricardo is buried in an ornate grave in the churchyard of Saint Nicholas in Hardenhuish, now a suburb of Chippenham, Wiltshire. At the time of his death his fortune was estimated at about £600,000.

Ricardo became interested in economics after reading Adam Smith's "The Wealth of Nations" in 1799. He wrote his first economics article at age 37, firstly in The Morning Chronicle advocating reduction in the note-issuing of the Bank of England and then publishing ""The High Price of Bullion, a Proof of the Depreciation of Bank Notes"" in 1810.

He was also an abolitionist, speaking at a meeting of the Court of the East India Company in March 1823, where he said he regarded slavery as a stain on the character of the nation. His sister, Hanna, had married David Samuda (1776–1824) who came from a slave-owning family with a substantial number of slaves in Jamaica.

Ricardo's most famous work is his "Principles of Political Economy and Taxation" (1817). He advanced a labor theory of value:

The value of a commodity, or the quantity of any other commodity for which it will exchange, depends on the relative quantity of labour which is necessary for its production, and not on the greater or less compensation which is paid for that labour.

Ricardo's note to Section VI:

Mr. Malthus appears to think that it is a part of my doctrine, that the cost and value of a thing be the same;—it is, if he means by cost, "cost of production" including profit.

Ricardo contributed to the development of theories of rent, wages, and profits. He defined rent as "the difference between the produce obtained by the employment of two equal quantities of capital and labor." Ricardo believed that the process of economic development, which increased land utilization and eventually led to the cultivation of poorer land, principally benefited landowners. According to Ricardo, such premium over "real social value" that is reaped due to ownership constitutes value to an individual but is at best a paper monetary return to "society". The portion of such purely individual benefit that accrues to scarce resources Ricardo labels "rent".

In his "Theory of Profit", Ricardo stated that as real wages increase, real profits decrease because the revenue from the sale of manufactured goods is split between profits and wages. He said in his "Essay on Profits", "Profits depend on high or low wages, wages on the price of necessaries, and the price of necessaries chiefly on the price of food."

Between 1500 and 1750 most economists advocated Mercantilism which promoted the idea of international trade for the purpose of earning bullion by running a trade surplus with other countries. Ricardo challenged the idea that the purpose of trade was merely to accumulate gold or silver. With "comparative advantage" Ricardo argued in favour of industry specialisation and free trade. He suggested that industry specialization combined with free international trade always produces positive results. This theory expanded on the concept of absolute advantage.

Ricardo suggested that there is mutual national benefit from trade even if one country is more competitive in every area than its trading counterpart and that a nation should concentrate resources only in industries where it has a comparative advantage, that is in those industries in which it has the greatest competitive edge. Ricardo suggested that national industries which were, in fact, profitable and internationally competitive should be jettisoned in favour of the most competitive industries, the assumption being that subsequent economic growth would more than offset any economic dislocation which would result from closing profitable and competitive national industries.

Ricardo attempted to prove theoretically that international trade is always beneficial. Paul Samuelson called the numbers used in Ricardo's example dealing with trade between England and Portugal the "four magic numbers". "In spite of the fact that the Portuguese could produce both cloth and wine with less amount of labor, Ricardo suggested that both countries would benefit from trade with each other".

As Joan Robinson pointed out, following the opening of free trade with England, Portugal endured centuries of economic underdevelopment: "the imposition of free trade on Portugal killed off a promising textile industry and left her with a slow-growing export market for wine, while for England, exports of cotton cloth led to accumulation, mechanisation and the whole spiralling growth of the industrial revolution". Robinson argued that Ricardo's example required that economies were in static equilibrium positions with full employment and that there could not be a trade deficit or a trade surplus. These conditions, she wrote, were not relevant to the real world. She also argued that Ricardo's math did not take into account that some countries may be at different levels of development and that this raised the prospect of 'unequal exchange' which might hamper a country's development, as we saw in the case of Portugal.

Like Adam Smith, Ricardo was an opponent of protectionism for national economies, especially for agriculture. He believed that the British "Corn Laws"—tariffs on agricultural products—ensured that less-productive domestic land would be harvested and rents would be driven up . Thus, profits would be directed toward landlords and away from the emerging industrial capitalists. Ricardo believed landlords tended to squander their wealth on luxuries, rather than invest. He believed the Corn Laws were leading to the stagnation of the British economy. In 1846, his nephew John Lewis Ricardo, MP for Stoke-upon-Trent, advocated free trade and the repeal of the Corn Laws.

Modern empirical analysis of the Corn Laws yield mixed results. Parliament repealed the Corn Laws in 1846.

Ricardo himself was the first to recognize that comparative advantage is a domain-specific theory, meaning that it only applies when certain conditions are met. Ricardo noted that the theory only applies in situations where capital is immobile. Regarding his famous example, he wrote:"it would undoubtedly be advantageous to the capitalists [and consumers] of England… [that] the wine and cloth should both be made in Portugal [and that] the capital and labour of England employed in making cloth should be removed to Portugal for that purpose."Ricardo recognized that applying his theory in situations where capital was mobile would result in offshoring, and therefore economic decline and job loss. To correct for this, he argued that (i) "most men of property [will be] satisfied with a low rate of profits in their own country, rather than seek[ing] a more advantageous employment for their wealth in foreign nations," and (ii) that capital was functionally immobile.

Ricardo's argument in favour of free trade has also been attacked by those who believe trade restriction can be necessary for the economic development of a nation. Utsa Patnaik claims that Ricardian theory of international trade contains a logical fallacy. Ricardo assumed that in both countries two goods are producible and actually are produced, but developed and underdeveloped countries often trade those goods which are not producible in their own country. In these cases, one cannot define which country has comparative advantage.

Critics also argue that Ricardo's theory of comparative advantage is flawed in that it assumes production is continuous and absolute. In the real world, events outside the realm of human control (e.g. natural disasters) can disrupt production. In this case, specialisation could cripple a country that depends on imports from foreign, naturally disrupted countries. For example, if an industrially based country trades its manufactured goods with an agrarian country in exchange for agricultural products, a natural disaster in the agricultural country (e.g. drought) may cause an industrially based country to starve.

The development economist Ha-Joon Chang challenges the argument that free trade benefits every country:
Another idea associated with Ricardo is Ricardian equivalence, an argument suggesting that in some circumstances a government's choice of how to pay for its spending ("i.e.," whether to use tax revenue or issue debt and run a deficit) might have no effect on the economy. This is due to the fact the public saves its excess money to pay for expected future tax increases that will be used to pay off the debt. Ricardo notes that the proposition is theoretically implied in the presence of intertemporal optimisation by rational tax-payers: but that since tax-payers do not act so rationally, the proposition fails to be true in practice. Thus, while the proposition bears his name, he does not seem to have believed it. Economist Robert Barro is responsible for its modern prominence.

David Ricardo's ideas had a tremendous influence on later developments in economics. US economists rank Ricardo as the second most influential economic thinker, behind Adam Smith, prior to the twentieth century.

Ricardo became the theoretical father of classical political economy. However, Schumpeter coined an expression "Ricardian vice", which indicates that rigorous logic does not provide a good economic theory. This criticism applies also to most neoclassical theories, which make heavy use of mathematics, but are, according to him, theoretically unsound, because the conclusion being drawn does not logically follow from the theories used to defend it.

Ricardo's writings fascinated a number of early socialists in the 1820s, who thought his value theory had radical implications. They argued that, in view of labor theory of value, labor produces the entire product, and the profits capitalists get are a result of exploitations of workers. These include Thomas Hodgskin, William Thompson, John Francis Bray, and Percy Ravenstone.

Georgists believe that rent, in the sense that Ricardo used, belongs to the community as a whole. Henry George was greatly influenced by Ricardo, and often cited him, including in his most famous work, Progress and Poverty from 1879. In the preface to the fourth edition, he wrote: ""What I have done in this book, if I have correctly solved the great problem I have sought to investigate, is, to unite the truth perceived by the school of Smith and Ricardo to the truth perceived by the school of Proudhon and Lasalle; to show that laissez faire (in its full true meaning) opens the way to a realization of the noble dreams of socialism; to identify social law with moral law, and to disprove ideas which in the minds of many cloud grand and elevating perceptions.""

After the rise of the 'neoclassical' school, Ricardo's influence declined temporarily. It was Piero Sraffa, the editor of the Collected Works of David Ricardo and the author of seminal "Production of Commodities by Means of Commodities", who resurrected Ricardo as the originator of another strand of economics thought, which was effaced with the arrival of the neoclassical school. The new interpretation of Ricardo and Sraffa's criticism against the marginal theory of value gave rise to a new school, now named neo-Ricardian or Sraffian school. Major contributors to this school includes Luigi Pasinetti (1930–), Pierangelo Garegnani (1930–2011), Ian Steedman (1941–), Geoffrey Harcourt (1931–), Heinz Kurz (1946–), Neri Salvadori (1951–), Pier Paolo Saviotti (–) among others. See also Neo-Ricardianism. The Neo-Ricardian school is sometimes seen to be a component of Post-Keynesian economics.

Inspired by Piero Sraffa, a new strand of trade theory emerged and was named neo-Ricardian trade theory. The main contributors include Ian Steedman and Stanley Metcalfe. They have criticised neoclassical international trade theory, namely the Heckscher–Ohlin model on the basis that the notion of capital as primary factor has no method of measuring it before the determination of profit rate (thus trapped in a logical vicious circle). This was a second round of the Cambridge capital controversy, this time in the field of international trade. Depoortère and Ravix judge that neo-Ricardian contribution failed without giving effective impact on neoclassical trade theory, because it could not offer “a genuine alternative approach from a classical point of view.”

Several distinctive groups have sprung out of the neo-Ricardian school. One is the evolutionary growth theory, developed notably by Luigi Pasinetti, J.S. Metcalfe, Pier Paolo Saviotti, and Koen Frenken and others.

Pasinetti argued that the demand for any commodity came to stagnate and frequently decline, demand saturation occurs. Introduction of new commodities (goods and services) is necessary to avoid economic stagnation.

Ricardo's idea was even expanded to the case of continuum of goods by Dornbusch, Fischer, and Samuelson This formulation is employed for example by Matsuyama and others.

Ricardian trade theory ordinarily assumes that the labour is the unique input. This is a deficiency as intermediate goods are a great part of international trade. The situation changed after the appearance of Yoshinori Shiozawa's work of 2007. He has succeeded to incorporate traded input goods in his model.

Yeats found that 30% of world trade in manufacturing is intermediate inputs. Bardhan and Jafee found that intermediate inputs occupy 37 to 38% in the imports to the US for the years from 1992 to 1997, whereas the percentage of intrafirm trade grew from 43% in 1992 to 52% in 1997.

Chris Edward includes Emmanuel's unequal exchange theory among variations of neo-Ricardian trade theory. Arghiri Emmanuel argued that the Third World is poor because of the international exploitation of labour.

The unequal exchange theory of trade has been influential to the (new) dependency theory.

Ricardo's publications included:

His works and writings were collected in:




</doc>
<doc id="8471" url="https://en.wikipedia.org/wiki?curid=8471" title="Delphinus">
Delphinus

Delphinus (Eng. U.S. ) Eng. oth: ) is a constellation in the northern sky, close to the celestial equator. Its name is Latin for dolphin. Delphinus was one of the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains among the 88 modern constellations recognized by the International Astronomical Union. It is one of the smaller constellations, ranked 69th in size.

Delphinus' brightest stars form a distinctive asterism that can easily be recognized. It is bordered (clockwise from north) by Vulpecula the fox, Sagitta the arrow, Aquila the eagle, Aquarius the water-carrier, Equuleus the foal and Pegasus the flying horse.

Delphinus lacks stars above fourth (apparent) magnitude; its brightest star is of magnitude 3.8. The main asterism in Delphinus is Job's Coffin, nearly a 45°-apex lozenge diamond of the four brightest stars: Alpha, Beta, Gamma, and Delta Delphini. Delphinus is in a rich Milky Way star field. Alpha and Beta Delphini have 19th century names Sualocin and Rotanev, read backwards: Nicolaus Venator, the Latinized name of a Palermo Observatory director, Niccolò Cacciatore (d. 1841).

Alpha Delphini is a blue-white hued main sequence star of magnitude 3.8, 241 light-years from Earth. 

Beta Delphini, called Rotanev. The gap between its close binary stars is visible from large amateur telescopes. To the unaided eye, it appears to be a white star of magnitude 3.6. It has a period of 27 years and is 97 light-years from Earth. 

Gamma Delphini is a celebrated binary star among amateur astronomers. The primary is orange-gold of magnitude 4.3; the secondary is a light yellow star of magnitude 5.1. The pair form a true binary with an estimated orbital period of over 3,000 years. 125 light-years away, the two components are visible in a small amateur telescope. The secondary, also described as green, is 10 arcseconds from the primary. Struve 2725, called the "Ghost Double", is a pair that appears similar but dimmer. Its components of magnitudes 7.6 and 8.4 are separated by 6 arcseconds and are 15 arcminutes from Gamma Delphini itself.

Delta Delphini is a type A7 IIIp star of magnitude 4.43. 

Epsilon Delphini, Deneb Dulfim (lit. "tail [of the] Dolphin"), or Aldulfin, is a star of stellar class B6 III and magnitude 4, at 330 ly.

In Delphinus, in extremes of distance, Gliese 795 is the closest known star at 54.95 ly and rapidly moves east over a period of centuries (863±3 arcseconds per year); whereas the giant of blue colour, W Delphini is at 2203.81 ly at 9.76 magnitude. Its brightness ranges from a magnitude of 12.3 to a magnitude of 9.7 over its variable period as it is a Beta Persei star-type semi-detached system. Other variable stars of large amateur telescopic visibility include R Delphini, a Mira-type variable star with a period of 285.5 days. Its magnitude ranges between a maximum 7.6 and a minimum 13.8. 

Rho Aquilae at magnitude 4.94 is at about 150 light years. Due to its proper motion it has been in the (round-figure parameter) bounds of the constellation since 1992.

HR Delphini was a nova that brightened to magnitude 3.5 in December 1967. A nova was discovered by amateur astronomer Koichi Itagaki, Nova Delphini 2013.

Giants within our galaxy in Delphinus aside from Delta, Gamma and Epsilon include:
Its rich Milky Way star field means many modestly deep-sky objects. NGC 6891 is a planetary nebula of magnitude 10.5; another is NGC 6905 or the Blue Flash nebula. NGC 6934 is a globular cluster of magnitude 9.75. At a distance of about 185,000 light-years, the globular cluster NGC 7006 is at the outer reaches of the galaxy. It is also fairly dim at magnitude 11.5.

Delphinus is associated with two stories from Greek mythology.

According to the first Greek god Poseidon wanted to marry Amphitrite, a beautiful nereid. However, wanting to protect her virginity, she fled to the Atlas mountains. Her suitor then sent out several searchers, among them a certain Delphinus. Delphinus accidentally stumbled upon her and was able to persuade Amphitrite to accept Poseidon's wooing. Out of gratitude the god placed the image of a dolphin among the stars.

The second story tells of the Greek poet Arion of Lesbos (7th century BC), who was saved by a dolphin. He was a court musician at the palace of Periander, ruler of Corinth. Arion had amassed a fortune during his travels to Sicily and Italy. On his way home from Tarentum his wealth caused the crew of his ship to conspire against him. Threatened with death, Arion asked to be granted a last wish which the crew granted: he wanted to sing a dirge. This he did, and while doing so, flung himself into the sea. There, he was rescued by a dolphin which had been charmed by Arion's music. The dolphin carried Arion to the coast of Greece and left.

In Chinese astronomy, the stars of Delphinus are located within "the Black Tortoise of the North" (北方玄武, "Běi Fāng Xuán Wǔ").

In Polynesia, two cultures recognized Delphinus as a constellation. In Pukapuka, it was called "Te Toloa" and in the Tuamotus, it was called "Te Uru-o-tiki".

USS Delphinus (AF-24) and USS Delphinus (PHM-1), two United States Navy ships, are named after the constellation.

A house at Sutton Girls is named Delphinus

Delphinus (Chinese astronomy)




</doc>
<doc id="8472" url="https://en.wikipedia.org/wiki?curid=8472" title="Disk storage">
Disk storage

Disk storage (also sometimes called drive storage) is a general category of storage mechanisms where data is recorded by various electronic, magnetic, optical, or mechanical changes to a surface layer of one or more rotating disks. A disk drive is a device implementing such a storage mechanism. Notable types are the hard disk drive (HDD) containing a non-removable disk, the floppy disk drive (FDD) and its removable floppy disk, and various optical disc drives (ODD) and associated optical disc media.

(The spelling disk and disc are used interchangeably except where trademarks preclude one usage, e.g. the Compact Disc logo. The choice of a particular form is frequently historical, as in IBM's usage of the "disk" form beginning in 1956 with the "IBM 350 disk storage unit").

Audio information was originally recorded by analog methods (see Sound recording and reproduction). Similarly the first video disc used an analog recording method. In the music industry, analog recording has been mostly replaced by digital optical technology where the data is recorded in a digital format with optical information.

The first commercial digital disk storage device was the IBM 350 which shipped in 1956 as a part of the IBM 305 RAMAC computing system. The random-access, low-density storage of disks was developed to complement the already used sequential-access, high-density storage provided by tape drives using magnetic tape. Vigorous innovation in disk storage technology, coupled with less vigorous innovation in tape storage, has reduced the difference in acquisition cost per terabyte between disk storage and tape storage; however, the total cost of ownership of data on disk including power and management remains larger than that of tape.

Disk storage is now used in both computer storage and consumer electronic storage, e.g., audio CDs and video discs (standard DVD and Blu-ray).

Data on modern disks is stored in fixed length blocks, usually called sectors and varying in length from a few hundred to many thousands of bytes. Gross disk drive capacity is simply the number of disk surfaces times the number of blocks/surface times the number of bytes/block. In certain legacy IBM CKD drives the data was stored on magnetic disks with variable length blocks, called records; record length could vary on and between disks. Capacity decreased as record length decreased due to the necessary gaps between blocks.

Digital disk drives are block storage devices. Each disk is divided into logical blocks (collection of sectors). Blocks are addressed using their logical block addresses (LBA). Read from or writing to disk happens at the granularity of blocks.

Originally the disk capacity was quite low and has been improved in one of several ways. Improvements in mechanical design and manufacture allowed smaller and more precise heads, meaning that more tracks could be stored on each of the disks. Advancements in data compression methods permitted more information to be stored in each of the individual sectors.

The drive stores data onto cylinders, heads, and sectors. The sectors unit is the smallest size of data to be stored in a hard disk drive and each file will have many sectors units assigned to it. The smallest entity in a CD is called a frame, which consists of 33 bytes and contains six complete 16-bit stereo samples (two bytes × two channels × six samples = 24 bytes). The other nine bytes consist of eight CIRC error-correction bytes and one subcode byte used for control and display.

The information is sent from the computer processor to the BIOS into a chip controlling the data transfer. This is then sent out to the hard drive via a multi-wire connector. Once the data is received onto the circuit board of the drive, they are translated and compressed into a format that the individual drive can use to store onto the disk itself. The data is then passed to a chip on the circuit board that controls the access to the drive. The drive is divided into sectors of data stored onto one of the sides of one of the internal disks. An HDD with two disks internally will typically store data on all four surfaces.

The hardware on the drive tells the actuator arm where it is to go for the relevant track and the compressed information is then sent down to the head which changes the physical properties, optically or magnetically for example, of each byte on the drive, thus storing the information. A file is not stored in a linear manner, rather, it is held in the best way for quickest retrieval.

Mechanically there are two different motions occurring inside the drive. One is the rotation of the disks inside the device. The other is the side-to-side motion of the head across the disk as it moves between tracks.

There are two types of disk rotation methods:

Track positioning also follows two different methods across disk storage devices. Storage devices focused on holding computer data, e.g., HDDs, FDDs, Iomega zip drives, use concentric tracks to store data. During a sequential read or write operation, after the drive accesses all the sectors in a track it repositions the head(s) to the next track. This will cause a momentary delay in the flow of data between the device and the computer. In contrast, optical audio and video discs use a single spiral track that starts at the inner most point on the disc and flows continuously to the outer edge. When reading or writing data there is no need to stop the flow of data to switch tracks. This is similar to vinyl records except vinyl records started at the outer edge and spiraled in toward the center.

The disk drive interface is the mechanism/protocol of communication between the rest of the system and the disk drive itself. Storage devices intended for desktop and mobile computers typically use ATA (PATA) and SATA interfaces. Enterprise systems and high-end storage devices will typically use SCSI, SAS, and FC interfaces in addition to some use of SATA.





</doc>
<doc id="8474" url="https://en.wikipedia.org/wiki?curid=8474" title="Arthur Wellesley, 1st Duke of Wellington">
Arthur Wellesley, 1st Duke of Wellington

Arthur Wellesley, 1st Duke of Wellington, (1 May 1769 – 14 September 1852) was an Anglo-Irish soldier and statesman who was one of the leading military and political figures of 19th-century Britain, serving twice as Prime Minister. His victory against Napoleon at the Battle of Waterloo in 1815 puts him in the first rank of Britain's military heroes.

Wellesley was born in Dublin, into the Protestant Ascendancy in Ireland. He was commissioned as an ensign in the British Army in 1787, serving in Ireland as aide-de-camp to two successive Lords Lieutenant of Ireland. He was also elected as a Member of Parliament in the Irish House of Commons. He was a colonel by 1796, and saw action in the Netherlands and in India, where he fought in the Fourth Anglo-Mysore War at the Battle of Seringapatam. He was appointed governor of Seringapatam and Mysore in 1799 and, as a newly appointed major-general (since 1802), won a decisive victory over the Maratha Confederacy at the Battle of Assaye in 1803.

Wellesley rose to prominence as a general during the Peninsular campaign of the Napoleonic Wars, and was promoted to the rank of field marshal after leading the allied forces to victory against the French Empire at the Battle of Vitoria in 1813. Following Napoleon's exile in 1814, he served as the ambassador to France and was granted a dukedom. During the Hundred Days in 1815, he commanded the allied army which, together with a Prussian army under Blücher, defeated Napoleon at Waterloo. Wellington's battle record is exemplary; he ultimately participated in some 60 battles during the course of his military career.

Wellington is famous for his adaptive defensive style of warfare, resulting in several victories against numerically superior forces while minimising his own losses. He is regarded as one of the greatest defensive commanders of all time, and many of his tactics and battle plans are still studied in military academies around the world.

After the end of his active military career, Wellington returned to politics. He was twice British prime minister as part of the Tory party: from 1828 to 1830, and for a little less than a month in 1834. He oversaw the passage of the Catholic Relief Act 1829, but opposed the Reform Act 1832. He continued as one of the leading figures in the House of Lords until his retirement and remained Commander-in-Chief of the British Army until his death.
Wellesley was born into an aristocratic Anglo-Irish family in Ireland as The Hon. Arthur Wesley, the third of five surviving sons (fourth otherwise) to Anne and Garret Wesley, 1st Earl of Mornington. His mother was the eldest daughter of The 1st Viscount Dungannon. As such, he belonged to the Protestant Ascendancy. His biographers mostly follow the same contemporary newspaper evidence in saying that he was born on 1 May 1769, the day before he was baptised. His birthplace is uncertain. He was most likely born at his parents' townhouse, 24 Upper Merrion Street, Dublin, now the Merrion Hotel. But his mother Anne, Countess of Mornington, recalled in 1815 that he had been born at 6 Merrion Street, Dublin. Other places have been put forward as the location of his birth, including Mornington House (the house next door on Upper Merrion), as his father had asserted; the Dublin packet boat; and the mansion in the family estate of Athy (consumed in the fires of 1916), as the Duke apparently put on his 1851 census return.

He spent most of his childhood at his family's two homes, the first a large house in Dublin and the second Dangan Castle, north of Summerhill on the Trim Road (now the R158) in County Meath. In 1781, Arthur's father died and his eldest brother Richard inherited his father's earldom.

He went to the diocesan school in Trim when at Dangan, Mr Whyte's Academy when in Dublin, and Brown's School in Chelsea when in London. He then enrolled at Eton College, where he studied from 1781 to 1784. His loneliness there caused him to hate it, and makes it highly unlikely that he actually said "The Battle of Waterloo was won on the playing fields of Eton", a quotation which is often attributed to him. Moreover, Eton had no playing fields at the time. In 1785, a lack of success at Eton, combined with a shortage of family funds due to his father's death, forced the young Wellesley and his mother to move to Brussels. Until his early twenties, Arthur showed little sign of distinction and his mother grew increasingly concerned at his idleness, stating, "I don't know what I shall do with my awkward son Arthur."

A year later, Arthur enrolled in the French Royal Academy of Equitation in Angers, where he progressed significantly, becoming a good horseman and learning French, which later proved very useful. Upon returning to England in late 1786, he astonished his mother with his improvement.

Despite his new promise, he had yet to find a job and his family was still short of money, so upon the advice of his mother, his brother Richard asked his friend the Duke of Rutland (then Lord Lieutenant of Ireland) to consider Arthur for a commission in the Army. Soon afterward, on 7 March 1787, he was gazetted ensign in the 73rd Regiment of Foot. In October, with the assistance of his brother, he was assigned as "aide-de-camp", on ten shillings a day (twice his pay as an ensign), to the new Lord Lieutenant of Ireland, Lord Buckingham. He was also transferred to the new 76th Regiment forming in Ireland and on Christmas Day, 1787, was promoted to lieutenant. During his time in Dublin his duties were mainly social; attending balls, entertaining guests and providing advice to Buckingham. While in Ireland, he overextended himself in borrowing due to his occasional gambling, but in his defence stated that "I have often known what it was to be in want of money, but I have never got helplessly into debt".

On 23 January 1788, he transferred into the 41st Regiment of Foot, then again on 25 June 1789, still a lieutenant, he transferred to the 12th (Prince of Wales's) Regiment of (Light) Dragoons and, according to military historian Richard Holmes, he also dipped a reluctant toe into politics. Shortly before the general election of 1789, he went to the rotten borough of Trim to speak against the granting of the title "Freeman" of Dublin to the parliamentary leader of the Irish Patriot Party, Henry Grattan. Succeeding, he was later nominated and duly elected as a Member of Parliament (MP) for Trim in the Irish House of Commons. Because of the limited suffrage at the time, he sat in a parliament where at least two-thirds of the members owed their election to the landowners of fewer than a hundred boroughs. Wellesley continued to serve at Dublin Castle, voting with the government in the Irish parliament over the next two years. He became a captain on 30 January 1791, and was transferred to the 58th Regiment of Foot.

On 31 October, he transferred to the 18th Light Dragoons and it was during this period that he grew increasingly attracted to Kitty Pakenham, the daughter of Edward Pakenham, 2nd Baron Longford. She was described as being full of 'gaiety and charm'. In 1793, he sought her hand, but was turned down by her brother Thomas, Earl of Longford, who considered Wellesley to be a young man, in debt, with very poor prospects. An aspiring amateur musician, Wellesley, devastated by the rejection, burnt his violins in anger, and resolved to pursue a military career in earnest. He became a major by purchase in the 33rd Regiment in 1793. A few months later, in September, his brother lent him more money and with it he purchased a lieutenant-colonelcy in the 33rd.

In 1793, the Duke of York was sent to Flanders in command of the British contingent of an allied force destined for the invasion of France. In June 1794, Wellesley with the 33rd regiment set sail from Cork bound for Ostend as part of an expedition bringing reinforcements for the army in Flanders. They arrived too late and joined the Duke of York as he was pulling back towards the Netherlands. On 15 September 1794, at the Battle of Boxtel, east of Breda, Wellington, in temporary command of his brigade, had his first experience of battle. During General Abercromby’s withdrawal in the face of superior French forces, the 33rd held off enemy cavalry, allowing neighbouring units to retreat safely. During the extremely harsh winter that followed, Wellesley and his regiment formed part of an allied force holding the defence line along the Waal River. The 33rd, along with the rest of the army, suffered heavy losses from sickness and exposure. Wellesley’s health was also affected by the damp environment. Though the campaign was to end disastrously, with the British army driven out of the United Provinces into Germany, Wellesley was to learn several valuable lessons, including the use of steady lines of infantry against advancing columns and of the merits of supporting sea-power. He understood that the failure of the campaign was due in part to the faults of the leaders and the poor organisation at headquarters. He remarked later of his time in the Netherlands that "At least I learned what not to do, and that is always a valuable lesson".

Returning to England in March 1795, he was returned as a Member of Parliament for Trim for a second time. He hoped to be given the position of secretary of war in the new Irish government but the new lord-lieutenant, Lord Camden, was only able to offer him the post of Surveyor-General of the Ordnance. Declining the post, he returned to his regiment, now at Southampton preparing to set sail for the West Indies. After seven weeks at sea, a storm forced the fleet back to Poole. The 33rd was given time to recuperate and a few months later, Whitehall decided to send the regiment to India. Wellesley was promoted full colonel by seniority on 3 May 1796 and a few weeks later set sail for Calcutta with his regiment.

Arriving in Calcutta in February 1797 he spent several months there, before being sent on a brief expedition to the Philippines, where he established a list of new hygiene precautions for his men to deal with the unfamiliar climate. Returning in November to India, he learnt that his elder brother Richard, now known as Lord Mornington, had been appointed as the new Governor-General of India.

In 1798, he changed the spelling of his surname to "Wellesley"; up to this time he was still known as Wesley, which his eldest brother considered the ancient and proper spelling.

As part of the campaign to extend the rule of the British East India Company, the Fourth Anglo-Mysore War broke out in 1798 against the Sultan of Mysore, Tipu Sultan. Arthur's brother Richard ordered that an armed force be sent to capture Seringapatam and defeat Tipu. Under the command of General Harris, some 24,000 troops were dispatched to Madras (to join an equal force being sent from Bombay in the west). Arthur and the 33rd sailed to join them in August.

After extensive and careful logistic preparation (which would become one of Wellesley's main attributes) the 33rd left with the main force in December and travelled across of jungle from Madras to Mysore. On account of his brother, during the journey, Wellesley was given an additional command, that of chief advisor to the Nizam of Hyderabad's army (sent to accompany the British force). This position was to cause friction among many of the senior officers (some of whom were senior to Wellesley). Much of this friction was put to rest after the Battle of Mallavelly, some from Seringapatam, in which Harris's army attacked a large part of the sultan's army. During the battle, Wellesley led his men, in a line of battle of two ranks, against the enemy to a gentle ridge and gave the order to fire. After an extensive repetition of volleys, followed by a bayonet charge, the 33rd, in conjunction with the rest of Harris's force, forced Tipu's infantry to retreat.

Immediately after their arrival at Seringapatam on 5 April 1799, the Battle of Seringapatam began and Wellesley was ordered to lead a night attack on the village of Sultanpettah, adjacent to the fortress to clear the way for the artillery. Because of the enemy's strong defensive preparations, and the darkness, with the resulting confusion, the attack failed with 25 casualties. Wellesley suffered a minor injury to his knee from a spent musket-ball. Although they would re-attack successfully the next day, after time to scout ahead the enemy's positions, the affair affected Wellesley. He resolved "never to attack an enemy who is preparing and strongly posted, and whose posts have not been reconnoitered by daylight".

Lewin Bentham Bowring gives this alternative account:

A few weeks later, after extensive artillery bombardment, a breach was opened in the main walls of the fortress of Seringapatam. An attack led by Major-General Baird secured the fortress. Wellesley secured the rear of the advance, posting guards at the breach and then stationed his regiment at the main palace. After hearing news of the death of the Tipu Sultan, Wellesley was the first at the scene to confirm his death, checking his pulse. Over the coming day, Wellesley grew increasingly concerned over the lack of discipline among his men, who drank and pillaged the fortress and city. To restore order, several soldiers were flogged and four hanged.

After battle and the resulting end of the war, the main force under General Harris left Seringapatam and Wellesley, aged 30, stayed behind to command the area as the new Governor of Seringapatam and Mysore. While in India, Wellesley was ill for a considerable time, first with severe diarrhoea from the water and then with fever, followed by a serious skin infection caused by trichophyton.

Wellesley was in charge of raising an Anglo-Indian expeditionary force in Trincomali in early 1801 for the capture of Batavia and Mauritius from the French. However, on the eve of its departure, orders arrived from England that it was to be sent to Egypt to co-operate with Sir Ralph Abercromby in the expulsion of the French from Egypt. Wellesley had been appointed second in command to Baird, but owing to ill-health did not accompany the expedition on 9 April 1801. This turned out fortunately for Wellesley, since the very vessel on which he was to have sailed foundered with all hands in the Red Sea.

He was promoted to brigadier-general on 17 July 1801. He took residence within the Sultan's summer palace and reformed the tax and justice systems in his province to maintain order and prevent bribery. He also hunted down the mercenary and self-proclaimed 'King' Dhoondiah Waugh, who had escaped from prison in Seringapatam during the battle. Wellesley, with command of four regiments, defeated Dhoondiah's larger rebel force, along with Dhoondiah himself who was killed in the battle. He paid for the future upkeep of Dhoondiah's orphaned son.

He received good news when in September 1802 he learnt that he had been promoted to the rank of major-general. Wellesley had been gazetted on 29 April 1802, but the news took several months to reach him by sea. He remained at Mysore until November when he was sent to command an army in the Second Anglo-Maratha War.

In 1800, whilst serving as Governor of Mysore, Wellesley was tasked with putting down an insurgency led by Dhoondiah Waugh, formerly a Patan trooper for Tipu Sultan. After the fall of Seringapatam he became a powerful brigand, raiding villages along the Maratha–Mysore border region. Despite initial setbacks, the East India Company having pursued and destroyed his forces once already, forcing him into retreat in August 1799, he raised a sizeable force composed of disbanded Mysore soldiers, captured small outposts and forts in Mysore, and was receiving the support of several Maratha "killedars" opposed to British occupation. This drew the attention of the British administration, who were beginning to recognise him as more than just a bandit, as his raids, expansion and threats to destabilise British authority suddenly increased in 1800. The death of Tipu Sultan had created a power vacuum and Waugh was seeking to fill it.

Given independent command of a combined East India Company and British Army force, Wellesley ventured north to confront Waugh in June 1800, with an army of 8,000 infantry and cavalry, having learned that Waugh's forces numbered over 50,000, although the majority (around 30,000) were irregular light cavalry and unlikely to pose a serious threat to British infantry and artillery.

Throughout June–August 1800, Wellesley advanced through Waugh's territory, his troops escalading forts in turn and capturing each one with "trifling loss". The forts generally offered little resistance due to their poor construction and design. Wellesley did not have sufficient troops to garrison each fort, and had to clear the surrounding area of insurgents before advancing to the next fort. On 31 July, he had "taken and destroyed Dhoondiah's baggage and six guns, and driven into the Malpoorba (where they were drowned) about five thousand people". Dhoondiah continued to retreat, but his forces were rapidly deserting, he had no infantry and due to the monsoon weather flooding river crossings he could no longer outpace the British advance. On 10 September, at the Battle of Conaghul, Wellesley personally led a charge of 1,400 British dragoons and Indian cavalry, in single line with no reserve, against Dhoondiah and his remaining 5,000 cavalry. Dhoondiah was killed during the clash, his body was discovered and taken to the British camp tied to a cannon. With this victory Wellesley's campaign was concluded, British authority had been restored.

When he determined that a long defensive war would ruin his army, Wellesley decided to act boldly to defeat the numerically larger force of the Maratha Empire. With the logistic assembly of his army complete (24,000 men in total) he gave the order to break camp and attack the nearest Maratha fort on 8 August 1803. The fort surrendered on 12 August after an infantry attack had exploited an artillery-made breach in the wall. With the fort now in British control Wellesley was able to extend control southwards to the river Godavari.

Splitting his army into two forces, to pursue and locate the main Marathas army, (the second force, commanded by Colonel Stevenson was far smaller) Wellesley was preparing to rejoin his forces on 24 September. His intelligence, however, reported the location of the Marathas' main army, between two rivers near Assaye. If he waited for the arrival of his second force, the Marathas would be able to mount a retreat, so Wellesley decided to launch an attack immediately.

On 23 September, Wellesley led his forces over a ford in the river Kaitna and the Battle of Assaye commenced. After crossing the ford the infantry was reorganised into several lines and advanced against the Maratha infantry. Wellesley ordered his cavalry to exploit the flank of the Maratha army just near the village. During the battle Wellesley himself came under fire; two of his horses were shot from under him and he had to mount a third. At a crucial moment, Wellesley regrouped his forces and ordered Colonel Maxwell (later killed in the attack) to attack the eastern end of the Maratha position while Wellesley himself directed a renewed infantry attack against the centre.

An officer in the attack wrote of the importance of Wellesley's personal leadership: "The General was in the thick of the action the whole time ... I never saw a man so cool and collected as he was ... though I can assure you, 'til our troops got the order to advance the fate of the day seemed doubtful ..." With some 6,000 Marathas killed or wounded, the enemy was routed, though Wellesley's force was in no condition to pursue. British casualties were heavy: the British losses were counted as 409 soldiers being killed out of which 164 were Europeans and the remaining 245 were Indian; a further 1,622 British soldiers were wounded and 26 soldiers were reported missing (the British casualty figures were taken from Wellesley's own despatch). Wellesley was troubled by the loss of men and remarked that he hoped "I should not like to see again such loss as I sustained on 23 September, even if attended by such gain". Years later, however, he remarked that Assaye and not Waterloo, was the best battle he ever fought.

Despite the damage done to the Maratha army, the battle did not end the war. A few months later in November, Wellesley attacked a larger force near Argaum, leading his army to victory again, with an astonishing 5,000 enemy dead at the cost of only 361 British casualties. A further successful attack at the fortress at Gawilghur, combined with the victory of General Lake at Delhi forced the Maratha to sign a peace settlement at Anjangaon (not concluded until a year later) called the Treaty of Surji-Anjangaon.

Military historian Richard Holmes remarked that Wellesley's experiences in India had an important influence on his personality and military tactics, teaching him much about military matters that would prove vital to his success in the Peninsular War. These included a strong sense of discipline through drill and order, the use of diplomacy to gain allies, and the vital necessity for a secure supply line. He also established a high regard for the acquisition of intelligence through scouts and spies. His personal tastes also developed, including dressing himself in white trousers, a dark tunic, with Hessian boots and black cocked hat (that later became synonymous as his style).

Wellesley had grown tired of his time in India, remarking "I have served as long in India as any man ought who can serve anywhere else". In June 1804 he applied for permission to return home and as a reward for his service in India he was made a Knight of the Bath in September. While in India, Wellesley had amassed a fortune of £42,000 (considerable at the time), consisting mainly of prize money from his campaign. When his brother's term as Governor-General of India ended in March 1805, the brothers returned together to England on HMS "Howe". Arthur, coincidentally, stopped on his voyage at the little island of Saint Helena and stayed in the same building to which Napoleon I would later be exiled.

In September 1805, Major-General Wellesley was newly returned from his campaigns in India and was not yet particularly well-known to the public. He reported to the office of the Secretary for War to request a new assignment. In the waiting room he met Vice-Admiral Horatio Nelson, already a legendary figure after his victories at the Nile and Copenhagen, who was briefly in England after months chasing the French Toulon fleet to the West Indies and back. Some 30 years later, Wellington recalled a conversation that Nelson began with him which Wellesley found "almost all on his side in a style so vain and silly as to surprise and almost disgust me". Nelson left the room to inquire who the young general was and, on his return, switched to a very different tone, discussing the war, the state of the colonies, and the geopolitical situation as between equals. On this second discussion, Wellington recalled, "I don't know that I ever had a conversation that interested me more". This was the only time that the two men met; Nelson was killed at his great victory at Trafalgar just seven weeks later.

Wellesley then served in the abortive Anglo-Russian expedition to north Germany in 1805, taking a brigade to Elbe.

He then took a period of extended leave from the army and was elected as a Tory member of the British parliament for Rye in January 1806. A year later, he was elected MP for Newport on the Isle of Wight and was then appointed to serve as Chief Secretary for Ireland, under the Duke of Richmond. At the same time, he was made a privy counsellor. While in Ireland, he gave a verbal promise that the remaining Penal Laws would be enforced with great moderation, perhaps an indication of his later willingness to support Catholic Emancipation.

Wellesley was in Ireland in May 1807 when he heard of the British expedition to Denmark. He decided to go, stepping down from his political appointments and was appointed to command an infantry brigade in the Second Battle of Copenhagen which took place in August. He fought at the Køge, during which the men under his command took 1,500 prisoners, with Wellesley later present during the surrender.

By 30 September, he had returned to England and was raised to the rank of lieutenant general on 25 April 1808. In June 1808 he accepted the command of an expedition of 9,000 men. Preparing to sail for an attack on the Spanish colonies in South America (to assist the Latin American patriot Francisco de Miranda) his force was instead ordered to sail for Portugal, to take part in the Peninsular Campaign and rendezvous with 5,000 troops from Gibraltar.

Ready for battle, Wellesley left Cork on 12 July 1808 to participate in the war against French forces in the Iberian Peninsula, with his skills as a commander tested and developed. According to the historian Robin Neillands, "Wellesley had by now acquired the experience on which his later successes were founded. He knew about command from the ground up, about the importance of logistics, about campaigning in a hostile environment. He enjoyed political influence and realised the need to maintain support at home. Above all, he had gained a clear idea of how, by setting attainable objectives and relying on his own force and abilities, a campaign could be fought and won."

Wellesley defeated the French at the Battle of Roliça and the Battle of Vimeiro in 1808 but was superseded in command immediately after the latter battle. General Dalrymple then signed the controversial Convention of Sintra, which stipulated that the Royal Navy transport the French army out of Lisbon with all their loot, and insisted on the association of the only available government minister, Wellesley.
Dalrymple and Wellesley were recalled to Britain to face a Court of Enquiry. Wellesley had agreed to sign the preliminary armistice, but had not signed the convention, and was cleared.

Meanwhile, Napoleon himself entered Spain with his veteran troops to put down the revolt; the new commander of the British forces in the Peninsula, Sir John Moore, died during the Battle of Corunna in January 1809.

Although overall the land war with France was not going well from a British perspective, the Peninsula was the one theatre where they, with the Portuguese, had provided strong resistance against France and her allies. This contrasted with the disastrous Walcheren expedition, which was typical of the mismanaged British operations of the time. Wellesley submitted a memorandum to Lord Castlereagh on the defence of Portugal. He stressed its mountainous frontiers and advocated Lisbon as the main base because the Royal Navy could help to defend it. Castlereagh and the cabinet approved the memo, appointed him head of all British forces in Portugal.

Wellesley arrived in Lisbon on 22 April 1809 on board HMS "Surveillante", after narrowly escaping shipwreck. Reinforced, he took to the offensive. In the Second Battle of Porto he crossed the Douro river in a daylight "coup de main", and routed Marshal Soult's French troops in Porto.

With Portugal secured, Wellesley advanced into Spain to unite with General Cuesta's forces. The combined allied force prepared for an assault on Marshal Victor's I Corps at Talavera, 23 July. Cuesta, however, was reluctant to agree, and was only persuaded to advance on the following day. The delay allowed the French to withdraw, but Cuesta sent his army headlong after Victor, and found himself faced by almost the entire French army in New Castile—Victor had been reinforced by the Toledo and Madrid garrisons. The Spanish retreated precipitously, necessitating the advance of two British divisions to cover their retreat.

The next day, 27 July, at the Battle of Talavera the French advanced in three columns and were repulsed several times throughout the day by Wellesley, but at a heavy cost to the British force. In the aftermath Marshal Soult's army was discovered to be advancing south, threatening to cut Wellesley off from Portugal. Wellesley moved east on 3 August to block it, leaving 1,500 wounded in the care of the Spanish, intending to confront Soult before finding out that the French were in fact 30,000 strong. The British commander sent the Light Brigade on a dash to hold the bridge over the Tagus River at Almaraz. With communications and supply from Lisbon secured for now, Wellesley considered joining with Cuesta again but found out that his Spanish ally had abandoned the British wounded to the French and was thoroughly uncooperative, promising and then refusing to supply the British forces, aggravating Wellesley and causing considerable friction between the British and their Spanish allies. The lack of supplies, coupled with the threat of French reinforcement (including the possible inclusion of Napoleon himself) in the spring, led to the British deciding to retreat into Portugal.

Following his victory at Talavera, Wellesley was elevated to the Peerage of the United Kingdom on 26 August 1809 as Viscount Wellington of Talavera and of Wellington, in the County of Somerset, with the subsidiary title of Baron Douro of Wellesley, in the said County.

In 1810, a newly enlarged French army under Marshal André Masséna invaded Portugal. British opinion both at home and in the army was negative and there were suggestions that they must evacuate Portugal. Instead, Lord Wellington first slowed the French down at Buçaco; he then prevented them from taking the Lisbon Peninsula by the construction of his massive earthworks, the Lines of Torres Vedras, which had been assembled in complete secrecy and had flanks guarded by the Royal Navy. The baffled and starving French invasion forces retreated after six months. Wellington's pursuit was frustrated by a series of reverses inflicted by Marshal Ney in a much-lauded rear guard campaign.

In 1811, Masséna returned toward Portugal to relieve Almeida; Wellington narrowly checked the French at the Battle of Fuentes de Onoro. Simultaneously, his subordinate, Viscount Beresford, fought Soult's 'Army of the South' to a mutual bloody standstill at the Battle of Albuera in May. Wellington was promoted to full General on 31 July for his services. The French abandoned Almeida, slipping away from British pursuit, but retained the twin Spanish fortresses of Ciudad Rodrigo and Badajoz, the 'Keys' guarding the roads through the mountain passes into Portugal.

In 1812, Wellington finally captured Ciudad Rodrigo by a rapid movement as the French went into winter quarters, storming it before they could react. He then moved south quickly, besieged the fortress of Badajoz for a month and captured it during one bloody night. On viewing the aftermath of the Storming of Badajoz, Wellington lost his composure and cried at the sight of the bloody carnage in the breaches.

His army now was a veteran British force reinforced by units of the retrained Portuguese army. Campaigning in Spain, he routed the French at the Battle of Salamanca, taking advantage of a minor French mispositioning. The victory liberated the Spanish capital of Madrid. As a reward, he was created Earl of Wellington, in the county of Somerset on 22 February 1812, and then Marquess of Wellington, in the said county on 18 August 1812, and given command of all Allied armies in Spain.

Wellington attempted to take the vital fortress of Burgos, which linked Madrid to France. But failure, due in part to a lack of siege guns, forced him into a headlong retreat with the loss of over 2,000 casualties.

The French abandoned Andalusia, and combined the troops of Soult and Marmont. Thus combined, the French outnumbered the British, putting the British forces in a precarious position. Wellington withdrew his army and, joined with the smaller corps commanded by Rowland Hill, began to retreat to Portugal. Marshal Soult declined to attack.

In 1813, Wellington led a new offensive, this time against the French line of communications. He struck through the hills north of Burgos, the Tras os Montes, and switched his supply line from Portugal to Santander on Spain's north coast; this led to the French abandoning Madrid and Burgos. Continuing to outflank the French lines, Wellington caught up with and smashed the army of King Joseph Bonaparte in the Battle of Vitoria, for which he was promoted to field marshal on 21 June. He personally led a column against the French centre, while other columns commanded by Sir Thomas Graham, Rowland Hill and the Earl of Dalhousie looped around the French right and left (this battle became the subject of Beethoven's opus 91, "Wellington's Victory"). The British troops broke ranks to loot the abandoned French wagons instead of pursuing the beaten foe. This gross abandonment of discipline caused an enraged Wellington to write in a famous dispatch to Earl Bathurst, "We have in the service the scum of the earth as common soldiers".

Although later, when his temper had cooled, he extended his comment to praise the men under his command saying that though many of the men were, "the scum of the earth; it is really wonderful that we should have made them to the fine fellows they are".

After taking the small fortresses of Pamplona, Wellington invested San Sebastián but was frustrated by the obstinate French garrison, losing 693 dead and 316 captured in a failed assault and suspending the siege at the end of July. Soult's relief attempt was blocked by the Spanish Army of Galicia at San Marcial, allowing the Allies to consolidate their position and tighten the ring around the city, which fell in September after a second spirited defence. Wellington then forced Soult's demoralised and battered army into a fighting retreat into France, punctuated by battles at the Pyrenees, Bidassoa and Nivelle. Wellington invaded southern France, winning at the Nive and Orthez. Wellington's final battle against his rival Soult occurred at Toulouse, where the Allied divisions were badly mauled storming the French redoubts, losing some 4,600 men. Despite this momentary victory, news arrived of Napoleon's defeat and abdication and Soult, seeing no reason to continue the fighting, agreed on a ceasefire with Wellington, allowing Soult to evacuate the city.

Hailed as the conquering hero by the British, on 3 May 1814 Wellington was made Duke of Wellington, in the county of Somerset, together with the subsidiary title of Marquess Douro, in the said County.

As he did not return to England until the Peninsular War was over, he was awarded all his patents of nobility in a unique ceremony lasting a full day. He received some recognition during his lifetime (the title of "Duque de Ciudad Rodrigo" and "Grandee of Spain") and the Spanish King Ferdinand VII allowed him to keep part of the works of art from the Royal Collection which he had recovered from the French. His equestrian portrait features prominently in the Monument to the Battle of Vitoria, in present-day Vitoria-Gasteiz.

His popularity in Britain was due to his image and his appearance as well as to his military triumphs. His victory fitted well with the passion and intensity of the Romantic movement, with its emphasis on individuality. His personal style influenced the fashions on Britain at the time: his tall, lean figure and his plumed black hat and grand yet classic uniform and white trousers became very popular.

In late 1814, the Prime Minister wanted him to take command in Canada and with the assignment of winning the War of 1812 against the United States. Wellesley replied that he would go to America, but he believed that he was needed more in Europe. He stated:

He was appointed Ambassador to France, then took Lord Castlereagh's place as first plenipotentiary to the Congress of Vienna, where he strongly advocated allowing France to keep its place in the European balance of power. On 2 January 1815 the title of his Knighthood of the Bath was converted to Knight Grand Cross upon the expansion of that order.

On 26 February 1815, Napoleon escaped from Elba and returned to France. He regained control of the country by May and faced a renewed alliance against him. Wellington left Vienna for what became known as the Waterloo Campaign. He arrived in Belgium to take command of the British-German army and their allied Dutch-Belgians, all stationed alongside the Prussian forces of Gebhard Leberecht von Blücher.

Napoleon's strategy was to isolate the Allied and Prussian armies, and annihilate each one separately before the Austrians and Russians arrived. In doing so the vast superiority in numbers of the Coalition would be greatly diminished. He would then seek the possibility of a peace with Austria and Russia.

The French invaded Belgium, with Napoleon defeating the Prussians at Ligny, and Marshal Ney engaging indecisively with Wellington, at the Battle of Quatre Bras. The Prussians retreated 18 miles north to Wavre whilst Wellington’s Anglo-Allied army withdrew 15 miles north to a site he had noted the previous year as favourable for a battle: the north ridge of a shallow valley on the Brussels road, just south of the small town of Waterloo. On 17 June there was torrential rain, which severely hampered movement and had a considerable effect the next day, 18 June, when the Battle of Waterloo was fought. This was the first time Wellington had encountered Napoleon; he commanded an Anglo-Dutch-German army that consisted of approximately 73,000 troops, 26,000 of whom were British, approximately 30 percent of that 26,000 were Irish.

The Battle of Waterloo commenced with a diversionary attack on Hougoumont by a division of French soldiers. After a barrage of 80 cannons the first French infantry attack was launched by Comte D'Erlon's I Corps. D'Erlon's troops advanced through the Allied centre, resulting in Allied troops in front of the ridge retreating in disorder through the main position. D'Erlon's corps stormed the most fortified Allied position, La Haye Sainte, but failed to take it. An Allied division under Thomas Picton met the remainder of D'Erlon's corps head to head, engaging them in an infantry duel in which Picton fell. During this struggle Lord Uxbridge launched two of his cavalry brigades at the enemy, catching the French infantry off guard, driving them to the bottom of the slope, and capturing two French Imperial Eagles. The charge, however, over-reached itself, and the British cavalry, crushed by fresh French horsemen hurled at them by Napoleon, were driven back, suffering tremendous losses.

A little before 16:00, Marshal Ney noted an apparent exodus from Wellington's centre. He mistook the movement of casualties to the rear for the beginnings of a retreat, and sought to exploit it. Ney at this time had few infantry reserves left, as most of the infantry had been committed either to the futile Hougoumont attack or to the defence of the French right. Ney therefore tried to break Wellington's centre with a cavalry charge alone.

At about 16:30, the first Prussian corps arrived. Commanded by Freiherr von Bülow, IV Corps arrived as the French cavalry attack was in full spate. Bülow sent the 15th Brigade to link up with Wellington's left flank in the Frichermont–La Haie area while the brigade's horse artillery battery and additional brigade artillery deployed to its left in support. Napoleon sent Lobau's corps to intercept the rest of Bülow's IV Corps proceeding to Plancenoit. The 15th Brigade sent Lobau's corps into retreat to the Plancenoit area. Von Hiller's 16th Brigade also pushed forward with six battalions against Plancenoit. Napoleon had dispatched all eight battalions of the Young Guard to reinforce Lobau, who was now seriously pressed by the enemy. Napoleon's Young Guard counter-attacked and, after very hard fighting, secured Plancenoit, but were themselves counter-attacked and driven out. Napoleon then resorted to sending two battalions of the Middle and Old Guard into Plancenoit and after ferocious fighting they recaptured the village.
The French cavalry attacked the British infantry squares many times, each at heavy cost to the French but with few British casualties. Ney himself was displaced from his horse four times. Eventually it became obvious, even to Ney, that cavalry alone were achieving little. Belatedly, he organised a combined-arms attack, using Bachelu's division and Tissot's regiment of Foy's division from Reille's II Corps plus those French cavalry that remained in a fit state to fight. This assault was directed along much the same route as the previous heavy cavalry attacks.
Meanwhile, at approximately the same time as Ney's combined-arms assault on the centre-right of Wellington's line, Napoleon ordered Ney to capture La Haye Sainte at whatever the cost. Ney accomplished this with what was left of D'Erlon's corps soon after 18:00. Ney then moved horse artillery up towards Wellington's centre and began to destroy the infantry squares at short-range with canister. This all but destroyed the 27th (Inniskilling) Regiment, and the 30th and 73rd Regiments suffered such heavy losses that they had to combine to form a viable square. Wellington's centre was now on the verge of collapse and wide open to an attack from the French. Luckily for Wellington, Pirch I's and Zieten's corps of the Prussian Army were now at hand. Zieten's corps permitted the two fresh cavalry brigades of Vivian and Vandeleur on Wellington's extreme left to be moved and posted behind the depleted centre. Pirch I Corps then proceeded to support Bülow and together they regained possession of Plancenoit, and once more the Charleroi road was swept by Prussian round shot. The value of this reinforcement at this particular moment can hardly be overestimated.
The French army now fiercely attacked the Coalition all along the line with the culminating point being reached when Napoleon sent forward the Imperial Guard at 19:30. The attack of the Imperial Guards was mounted by five battalions of the Middle Guard, and not by the Grenadiers or Chasseurs of the Old Guard. Marching through a hail of canister and skirmisher fire and severely outnumbered, the 3,000 or so Middle Guardsmen advanced to the west of La Haye Sainte and proceeded to separate into three distinct attack forces. One, consisting of two battalions of Grenadiers, defeated the Coalition's first line and marched on. Chassé's relatively fresh Dutch division was sent against them and Allied artillery fired into the victorious Grenadiers' flank. This still could not stop the Guard's advance, so Chassé ordered his first brigade to charge the outnumbered French, who faltered and broke.

Further to the west, 1,500 British Foot Guards under Maitland were lying down to protect themselves from the French artillery. As two battalions of Chasseurs approached, the second prong of the Imperial Guard's attack, Maitland's guardsmen rose and devastated them with point-blank volleys. The Chasseurs deployed to counter-attack, but began to waver. A bayonet charge by the Foot Guards then broke them. The third prong, a fresh Chasseur battalion, now came up in support. The British guardsmen retreated with these Chasseurs in pursuit, but the latter were halted as the 52nd Light Infantry wheeled in line onto their flank and poured a devastating fire into them and then charged. Under this onslaught they too broke.

The last of the Guard retreated headlong. A ripple of panic passed through the French lines as the astounding news spread: ""La Garde recule. Sauve qui peut!"" ("The Guard retreats. Save yourself if you can!"). Wellington then stood up in Copenhagen's stirrups, and waved his hat in the air to signal an advance of the Allied line just as the Prussians were overrunning the French positions to the east. What remained of the French army then abandoned the field in disorder. Wellington and Blücher met at the inn of La Belle Alliance, on the north-south road which bisected the battlefield, and it was agreed that the Prussians should pursue the retreating French army back to France. The Treaty of Paris was signed on 20 November 1815.

After the victory, the Duke supported proposals that a medal be awarded to all British soldiers who participated in the Waterloo campaign, and on 28 June 1815 he wrote to the Duke of York suggesting: ... the expediency of giving to the non commissioned officers and soldiers engaged in the Battle of Waterloo a medal. I am convinced it would have the best effect in the army, and if the battle should settle our concerns, they will well deserve it.The Waterloo Medal was duly authorised and distributed to all ranks in 1816.

Much historical discussion has been made about Napoleon's decision to send 33,000 troops under Marshal Grouchy to intercept the Prussians, but—having defeated Blücher at Ligny on 16 June and forced the Allies to retreat in divergent directions—Napoleon may have been strategically astute in a judgement that he would have been unable to beat the combined Allied forces on one battlefield. Wellington's comparable strategic gamble was to leave 17,000 troops and artillery, mostly Dutch and Belgian, away at Halle, north-west of Mont-Saint-Jean, in case of a French advance up the Mons-Hal-Brussels road.
The campaign led to numerous other controversies, especially concerning the Prussians. For example: Were Wellington's troop dispositions prior to Napoleon's invasion of Belgium sound? Did Wellington somehow mislead or betray Blücher by promising, then failing, to come directly to Blücher's aid at Ligny? Who deserved the lion's share of credit for the victory—Wellington or the Prussians? These and other such issues concerning Blücher's, Wellington's, and Napoleon's decisions during the campaign were the subject of a major strategic-level study by the famous Prussian political-military theorist Carl von Clausewitz, "Feldzug von 1815: Strategische Uebersicht des Feldzugs von 1815", English title: "The Campaign of 1815: Strategic Overview of the Campaign". Written c.1827, this study was Clausewitz's last such work and is widely considered to be the best example of Clausewitz's mature theories concerning such analyses. It attracted the attention of Wellington's staff, who prompted the Duke to write his only published essay on the campaign (other than his immediate, official after-action report, "The Waterloo Dispatch"), his 1842 "Memorandum on the Battle of Waterloo". While Wellington disputed Clausewitz on several points, the Prussian writer largely absolved Wellington of accusations levelled against him by nationalistic German axe-grinders. This exchange with Clausewitz was quite famous in Britain in the 19th century (it was heavily discussed in, for example, Chesney's "Waterloo Lectures" (1868).) It seems, however, to have been systematically ignored by British historians writing since 1914, which is odd considering that it was one of only two discussions of the battle that Wellington wrote. The explanation, unfortunately, is probably that it drew too much attention to the decisive German role in Wellington's victory—which Wellington himself was perfectly happy to acknowledge, but which became an awkward subject given Anglo-German hostilities in the 20th century.

Wellington entered politics again when he was appointed Master-General of the Ordnance in the Tory government of Lord Liverpool on 26 December 1818. He also became Governor of Plymouth on 9 October 1819. He was appointed Commander-in-Chief of the British Army on 22 January 1827 and Constable of the Tower of London on 5 February 1827.

Along with Robert Peel, Wellington became an increasingly influential member of the Tory party, and in 1828 he resigned as Commander-in-Chief and became Prime Minister.

During his first seven months as prime minister he chose not to live in the official residence at 10 Downing Street, finding it too small. He moved in only because his own home, Apsley House, required extensive renovations. During this time he was largely instrumental in the foundation of King's College London. On 20 January 1829 Wellington was appointed Lord Warden of the Cinque Ports.

His term was marked by Catholic emancipation: the granting of almost full civil rights to Catholics in Great Britain and Ireland. The change was prompted by the landslide by-election win of Daniel O'Connell, an Irish Catholic proponent of emancipation, who was elected despite not being legally allowed to sit in Parliament. In the House of Lords, facing stiff opposition, Wellington spoke for Catholic Emancipation, and according to some sources, gave one of the best speeches of his career. He was born in Ireland and so had some understanding of the grievances of the Catholic communities there; as Chief Secretary, he had given an undertaking that the remaining Penal Laws would only be enforced as "mildly" as possible. In 1811 Catholic soldiers were given freedom of worship and 18 years later the Catholic Relief Act 1829 was passed with a majority of 105. Many Tories voted against the Act, and it passed only with the help of the Whigs. Wellington had threatened to resign as Prime Minister if the King (George IV) did not give his Royal Assent.

The Earl of Winchilsea accused the Duke of "an insidious design for the infringement of our liberties and the introduction of Popery into every department of the State". Wellington responded by immediately challenging Winchilsea to a duel. On 21 March 1829, Wellington and Winchilsea met on Battersea fields. When the time came to fire, the Duke took aim and Winchilsea kept his arm down. The Duke fired wide to the right. Accounts differ as to whether he missed on purpose, an act known in dueling as a "delope". Wellington claimed he did. However, he was noted for his poor aim and reports more sympathetic to Winchilsea claimed he had aimed to kill. Winchilsea did not fire, a plan he and his second had almost certainly decided upon before the duel. Honour was saved and Winchilsea wrote Wellington an apology.

The nickname "Iron Duke" originates from this period, when he experienced a high degree of personal and political unpopularity. Its repeated use in "Freeman's Journal" throughout June 1830 appears to bear reference to his resolute political will, with taints of disapproval from its Irish editors. His residence at Apsley House was targeted by a mob of demonstrators on 27 April 1831 and again on 12 October, leaving his windows smashed. Iron shutters were installed in June 1832 to prevent further damage by crowds angry over rejection of the Reform Bill, which he strongly opposed.

Wellington's government fell in 1830. In the summer and autumn of that year, a wave of riots swept the country. The Whigs had been out of power for most years since the 1770s, and saw political reform in response to the unrest as the key to their return. Wellington stuck to the Tory policy of no reform and no expansion of suffrage, and as a result lost a vote of no confidence on 15 November 1830.

The Whigs introduced the first Reform Bill while Wellington and the Tories worked to prevent its passage. The Whigs could not get the bill past its second reading in the British House of Commons, and the bill failed. An election followed in direct response, and the Whigs were returned with a landslide majority. A second Reform Act was introduced and passed in the House of Commons, but was defeated in the Tory-controlled House of Lords. Another wave of near insurrection swept the country. During this time, Wellington was greeted by a hostile reaction from the crowds at the opening of the Liverpool and Manchester Railway. The Whig Government fell in 1832 and Wellington was unable to form a Tory Government partly because of a run on the Bank of England. This left King William IV no choice but to restore Earl Grey to the premiership. Eventually the bill passed the House of Lords after the King threatened to fill that House with newly created Whig peers if it were not. Wellington was never reconciled to the change; when Parliament first met after the first election under the widened franchise, Wellington is reported to have said "I never saw so many shocking bad hats in my life".

During debate on the Jewish Civil Disabilities Repeal Bill, Wellington, who opposed the Bill, stated in Parliament on 1 August 1833: "... this is a Christian country and a Christian legislature, and that the effect of this measure would be to remove that peculiar character." And "I see no ground whatever for passing the Bill; and shall, therefore, vote against it." The Bill was defeated, 104 votes against, and 54 for.

Wellington was gradually superseded as leader of the Tories by Robert Peel, while the party evolved into the Conservatives. When the Tories were returned to power in 1834, Wellington declined to become Prime Minister because he thought membership in Commons had become essential. The king reluctantly approved Peel, who was in Italy. So for three weeks in November and December 1834, Wellington acted as interim leader, taking the responsibilities of Prime Minister and most of the other ministries. In Peel's first cabinet (1834–1835), Wellington became Foreign Secretary, while in the second (1841–1846) he was a Minister without Portfolio and Leader of the House of Lords. Wellington was also re-appointed Commander-in-Chief of the British Army on 15 August 1842 following the resignation of Lord Hill.

Wellington served as the leader of the Conservative party in the House of Lords, 1828–1846. Some historians have belittled him as a befuddled reactionary, but a consensus in the late 20th century depicts him as a shrewd operator who hid his cleverness behind the facade of a poorly informed old soldier. Wellington worked to transform the Lords from unstinting support of the Crown to an active player in political maneuvering, with a commitment to the landed aristocracy. He used his London residence as a venue for intimate dinners and private consultations, together with extensive correspondence that kept him in close touch with party leaders in the Commons, and the main persona in the Lords. He gave public rhetorical support to Ultra-Tory anti-reform positions, but then deftly changed positions toward the party's center, especially when Peel needed support from the upper house. Wellington's success was based on the 44 Elected peers from Scotland and Ireland, whose election he controlled.

Upon his return from the Hanover Expedition in 1805, Wellesley received good news; owing to his new title and status, Kitty Pakenham's family had consented to his marrying her. Wellesley and Kitty were married in Dublin on 10 April 1806. The marriage would prove to be unsatisfactory and the two would spend years apart while Wellesley was campaigning. Kitty grew depressed, while Wellesley pursued other sexual and romantic partners. 
However the marriage produced two sons, Arthur, in 1807, and Charles, in 1808. They lived apart for most of the time and occupied separate rooms in the house when they were together. Her brother, Edward "Ned" Pakenham, served under Wellesley throughout the Peninsular War and Wellesley's regard for him helped to smooth his relations with Kitty, until Ned Pakenham's death at the Battle of New Orleans in 1815.

Wellington retired from political life in 1846, although he remained Commander-in-Chief, and returned briefly to the spotlight in 1848 when he helped organise a military force to protect London during that year of European revolution.

The Conservative Party had split over the Repeal of the Corn Laws in 1846, with Wellington and most of the former Cabinet still supporting Peel, but most of the MPs led by Lord Derby supporting a protectionist stance. Early in 1852 Wellington, by then very deaf, gave Derby's first government its nickname by shouting "Who? Who?" as the list of inexperienced Cabinet Ministers was read out in the House of Lords.

He became Chief Ranger and Keeper of Hyde Park and St. James's Park on 31 August 1850. He was also colonel of the 33rd Regiment of Foot from 1 February 1806 and colonel of the Grenadier Guards from 22 January 1827.

Kitty died of cancer in 1831; despite their generally unhappy relations, which had led to an effective separation, Wellington was said to have been greatly saddened by her death, his one comfort being that after "half a lifetime together, they had come to understand each other at the end". He had found consolation for his unhappy marriage in his warm friendship with the diarist Harriet Arbuthnot, wife of his colleague Charles Arbuthnot. Harriet's death in the cholera epidemic of 1834 was almost as great a blow to Wellington as it was to her husband. The two widowers spent their last years together at Apsley House.

Wellington died at Walmer Castle in Deal on 14 September 1852. This was his residence as Lord Warden of the Cinque Ports. Walmer Castle was said to have been his favourite residence. He was found to be unwell on that morning and was aided from his military campaign bed (the same one he used throughout his historic military career) and seated in his chair where he died. His death was recorded as being due to the after-effects of a stroke culminating in a series of seizures. He was aged 83.

Although in life he hated travelling by rail (after witnessing the death of William Huskisson, one of the first railway accident casualties), his body was then taken by train to London, where he was given a state funeral – one of only a handful of British subjects to be honoured in that way (other examples are Lord Nelson and Sir Winston Churchill) – and the last heraldic state funeral to be held in Britain. The funeral took place on 18 November 1852. At his funeral there was hardly any space to stand because of the number of people attending, and the effusive praise given him in Tennyson's "Ode on the Death of the Duke of Wellington" attests to his stature at the time of his death. He was buried in a sarcophagus of luxulyanite in St Paul's Cathedral next to Lord Nelson. A bronze memorial was sculpted by Alfred Stevens, and features two intricate supports: "Truth tearing the tongue out of the mouth of False-hood", and "Valour trampling Cowardice underfoot". Stevens did not live to see it placed in its home under one of the great arches of the Cathedral.

Wellington's casket was decorated with banners which were made for his funeral procession. Originally, there was one from Prussia, which was removed during World War I and never reinstated. In the procession, the "Great Banner" was carried by General Sir James Charles Chatterton of the 4th Dragoon Guards on the orders of Queen Victoria.

Most of the book "A Biographical Sketch of the Military and Political Career of the Late Duke of Wellington" by Weymouth newspaper proprietor Joseph Drew is a detailed contemporary account of his death, lying in state and funeral.

After his death, Irish and English newspapers disputed whether Wellington had been born an Irishman or an Englishman. In 2002, he was number 15 in the BBC's poll of the 100 Greatest Britons.

Owing to its links with Wellington, as the former commanding officer and colonel of the regiment, the title "33rd (The Duke of Wellington's) Regiment" was granted to the 33rd Regiment of Foot, on 18 June 1853 (the 38th anniversary of the Battle of Waterloo) by Queen Victoria. Wellington's battle record is exemplary; he participated in some 60 battles during the course of his military career.

Wellington always rose early; he "couldn't bear to lie awake in bed", even if the army was not on the march. Even when he returned to civilian life after 1815, he slept in a camp bed, reflecting his lack of regard for creature comforts; it remains on display in Walmer Castle. General Miguel de Álava complained that Wellington said so often that the army would march "at daybreak" and dine on "cold meat", that he began to dread those two phrases. While on campaign, he seldom ate anything between breakfast and dinner. During the retreat to Portugal in 1811, he subsisted on "cold meat and bread", to the despair of his staff who dined with him. He was, however, renowned for the quality of the wine which he drank and served, often drinking a bottle with his dinner (not a great quantity by the standards of his day).

He rarely showed emotion in public, and often appeared condescending to those less competent or less well-born than himself (which was nearly everyone). However, Álava was a witness to an incident just before the Battle of Salamanca. Wellington was eating a chicken leg while observing the manoeuvres of the French army through a spyglass. He spotted an overextension in the French left flank, and realised that he could launch a successful attack there. He threw the drumstick in the air and shouted ""Les français sont perdus!"" ("The French are lost!"). After the Battle of Toulouse, an aide brought him the news of Napoleon's abdication, and Wellington broke into an impromptu flamenco dance, spinning around on his heels and clicking his fingers.
Military historian Charles Dalton recorded that, after a hard-fought battle in Spain, a young officer made the comment, "I am going to dine with Wellington tonight", which was overheard by the Duke as he rode by. "Give me at least the prefix of Mr. before my name," Wellington said. "My Lord," replied the officer, "we do not speak of Mr. Caesar or Mr. Alexander, so why should I speak of Mr. Wellington?"

His stern countenance and iron-handed discipline were renowned; he was said to disapprove of soldiers cheering as "too nearly an expression of opinion." Nevertheless, Wellington cared for his men; he refused to pursue the French after the battles of Porto and Salamanca, foreseeing an inevitable cost to his army in chasing a diminished enemy through rough terrain. The only time that he ever showed grief in public was after the storming of Badajoz; he cried at the sight of the British dead in the breaches. In this context, his famous dispatch after the Battle of Vitoria, calling them the "scum of the earth," can be seen to be fuelled as much by disappointment at their breaking ranks as by anger. He expressed his grief openly the night after Waterloo before his personal physician, and later with his family; unwilling to be congratulated for his victory, he broke down in tears, his fighting spirit diminished by the high cost of the battle and great personal loss.

Viva Montgomerie, niece to the third Duke of Wellington, relates an anecdote that Holman, valet to the duke, often recalled how his master never spoke to servants unless he was obliged to, preferring instead to write his orders on a note pad on his dressing-table. (Holman, incidentally, was said to greatly resemble Napoleon.)

Following an incident when, as Master-General of the Ordnance he had been close to a large explosion, Wellington begun to experience deafness and other ear-related problems. In 1822, he had an operation to improve the hearing of the left ear. The result, however, was that he became permanently deaf on that side. It is claimed that he was "never quite well afterwards".

Wellington had a "vigorous sexual appetite" and many amorous liaisons during his marriage to Kitty. He enjoyed the company of intellectual and attractive women for many decades, particularly after the Battle of Waterloo and his subsequent ambassadorial position in Paris. The British press lampooned this side of the national hero. In 1824, one liaison came back to haunt him, when Wellington received a letter from a publisher offering to refrain from issuing an edition of the rather racy memoirs of one of his mistresses Harriette Wilson, in exchange for financial consideration. It is said that the Duke promptly returned the letter, after scrawling across it, "Publish and be damned". However, Hibbert notes in his biography that the letter can be found among the Duke's papers, with nothing written on it. It is certain that Wellington "did" reply, and the tone of a further letter from the publisher, quoted by Longford, suggests that he had refused in the strongest language to submit to blackmail.

He was also a remarkably practical man who spoke concisely. In 1851, it was discovered that there were a great many sparrows flying about in the Crystal Palace just before the Great Exhibition was to open. His advice to Queen Victoria was "Sparrowhawks, ma'am".

Wellington has often been portrayed as a defensive general, even though many, perhaps most, of his battles were offensive (Argaum, Assaye, Oporto, Salamanca, Vitoria, Toulouse). But for most of the Peninsular War, where he earned his fame, his army lacked the numbers for a strategically offensive posture.


This commonly used nickname originally related to his consistent political resolve rather than to any particular incident. In various cases its editorial use appears to be disparaging. It is likely that its use became more widespread after an incident in 1832 in which he installed metal shutters to prevent rioters breaking windows at Apsley House. The term may have been made increasingly popular by "Punch" cartoons published in 1844–45.

Wellington had various other nicknames:

In addition:






</doc>
<doc id="8476" url="https://en.wikipedia.org/wiki?curid=8476" title="Disk operating system">
Disk operating system

A disk operating system (abbreviated DOS) is a computer operating system that can use a disk storage device, such as a floppy disk, hard disk drive, or optical disc. A disk operating system must provide a file system for organizing, reading, and writing files on the storage disk. Strictly speaking, this definition does not apply to current generations of operating systems, such as versions of Microsoft Windows in use, and is more appropriately used only for older generations of operating systems.

Disk operating systems were available for mainframes, microprocessors and home computers and were usually loaded from the disks themselves as part of the boot process.

In the early days of computers, there were no disk drives, floppy disks or modern flash storage devices. Early storage devices such as delay lines, punched cards, paper tape, magnetic tape, and magnetic drums were used instead. And in the early days of microcomputers and home computers, paper tape or audio cassette tape (see Kansas City standard) or nothing were used instead. In the latter case, program and data entry was done at front panel switches directly into memory or through a computer terminal / keyboard, sometimes controlled by a read-only memory (ROM) BASIC interpreter; when power was turned off after running the program, the information so entered vanished.

Both hard disks and floppy disk drives require software to manage rapid access to block storage of sequential and other data. When microcomputers rarely had expensive disk drives of any kind, the need to have software to manage such devices (the disks) carried much status. To have one or the other was a mark of distinction and prestige, and so was having the disk sort of an operating system. As prices for both disk hardware and operating system software decreased, there came to be many such microcomputer systems.

Mature versions of the Commodore, SWTPC, Atari 8-bit, and Apple II home computer systems all featured a disk operating system (actually called "DOS" in the case of the Commodore 64 ("CBM DOS"), Atari 8-bit family ("Atari DOS"), and Apple II machines ("Apple DOS")), as did (at the other end of the hardware spectrum, and much earlier) IBM's System/360, 370 and (later) 390 series of mainframes (e.g., DOS/360: "Disk Operating System / 360" and DOS/VSE: "Disk Operating System / Virtual Storage Extended"). 

In large machines there were other disk operating systems, such as IBM's VM, DEC's RSTS / RT-11 / VMS / TOPS-10 / TWENEX, MIT's ITS / CTSS, Control Data's assorted NOS variants, Harris's Vulcan, Bell Labs' Unix, and so on. In microcomputers, SWTPC's 6800 and 6809 machines used TSC's FLEX disk operating system, Radio Shack's TRS-80 machines used TRSDOS, their Color Computer used OS-9, and most of the Intel 8080 based machines from IMSAI, MITS (makers of the Altair 8800), Cromemco, North Star, etc., used the CP/M-80 disk operating system. See list of operating systems.

Usually, a disk operating system was loaded from a disk. Only a very few comparable DOSes were stored elsewhere than on floppy disks; among these exceptions were Commodore, whose DOS resided on ROM chips in the disk drives themselves (the computer itself had no DOS, just a form of a BIOS for communicating with peripherals). The Lt. Kernal hard disk subsystem for the Commodore 64 and Commodore 128 models stored its DOS on the disk, as is the case with modern systems, and loaded the DOS into RAM at boot time; the British BBC Micro's optional Disc Filing System, DFS, offered as a kit with a disk controller chip, a ROM chip, and a handful of logic chips, to be installed inside the computer.


Some disk operating systems were the operating system for the entire computer system.



</doc>
<doc id="8477" url="https://en.wikipedia.org/wiki?curid=8477" title="Dual">
Dual

Dual or Duals may refer to:




</doc>
<doc id="8478" url="https://en.wikipedia.org/wiki?curid=8478" title="Doublespeak">
Doublespeak

Doublespeak is language that deliberately obscures, disguises, distorts, or reverses the meaning of words. Doublespeak may take the form of euphemisms (e.g. "downsizing" for layoffs, "servicing the target" for bombing), in which case it is primarily meant to make the truth sound more palatable. It may also refer to intentional ambiguity in language or to actual inversions of meaning. In such cases, doublespeak disguises the nature of the truth. Doublespeak is most closely associated with political language.

The term "doublespeak" originates in George Orwell's book "Nineteen Eighty-Four". Although the term is not used in the book, it is a close relative of two of the book's central concepts, "doublethink" and "Newspeak". Another variant, "doubletalk", also referring to deliberately ambiguous speech, did exist at the time Orwell wrote his book, but the usage of "doublespeak", as well as of "doubletalk", in the sense emphasizing ambiguity clearly postdates the publication of "Nineteen Eighty-Four". Parallels have also been drawn between doublespeak and Orwell's classic essay "Politics and the English Language", which discusses the distortion of language for political purposes.

Edward S. Herman, political economist and media analyst, has highlighted some examples of doublespeak and doublethink in modern society. Herman describes in his book "Beyond Hypocrisy" the principal characteristics of doublespeak:
In his essay "Politics and the English Language", George Orwell observes that political language serves to distort and obfuscate reality. Orwell’s description of political speech is extremely similar to the contemporary definition of doublespeak:
Although the theories that premise doublespeak are still indefinite, there are some theories that have parallels with the theory of doublespeak and Orwell's ideology in "Nineteen Eighty-Four" and might possibly provide a better understanding of where doublespeak's theories could have come from.

Due to the inherently deceptive nature of doublespeak as well as its prominent use in politics, doublespeak has been linked to the sociological perspective known as conflict theories. Conflict theories detract from ideas of society being naturally in harmony, instead placing emphasis on political and material inequality as its structural features. Antonio Gramsci's concepts on cultural hegemony, in particular, suggest that the culture and values of the economic elite – the bourgeoisie – become indoctrinated as "common sense" to the working-class, allowing for the maintenance of the status quo through misplaced belief. Being himself one of the leaders of the Communist Party of Italy, his theories had, in turn, been strongly influenced by the German social thinker Karl Marx, and have their ideological roots grounded in Marxist theory of false consciousness and capitalist exploitation. While Gramsci's views argue that culture (beliefs, perceptions and values) allows the ruling class to maintain domination, Marx's explanation is along more economic lines, with concepts such as commodity fetishism demonstrating how the ideology of the bourgeoisie (in this case, the existence of property as a social creation rather than an "eternal entity") dominate over that of the working classes. 
In both cases, both philosophers argue that one view – that of the bourgeoisie – dominates over others, hence the term conflict theories.

On the other hand, Terrence P. Moran of the US National Council of Teachers of English has compared the use of doublespeak in the mass media to laboratory experiments conducted on rats, where a batch of rats were deprived of food, before one half was fed sugar and water and the other half a saccharin solution. Both groups exhibited behavior indicating that their hunger was satisfied, but rats in the second group (which were fed saccharin solution) died from malnutrition. Moran highlights the structural nature of doublespeak, and notes that social institutions such as the mass media adopt an active, top-down approach in managing opinion. Therefore, Moran parallels doublespeak to producing an illusionary effect:

Doublespeak might also have some connections with contemporary theories.
Edward S. Herman and Noam Chomsky note in their book that Orwellian doublespeak is an important component of the manipulation of the English language in American media, through a process called "dichotomization"; a component of media propaganda involving "deeply embedded double standards in the reporting of news". For example, the use of state funds by the poor and financially needy is commonly referred to as "social welfare" or "handouts", which the "coddled" poor "take advantage of". These terms, however, do not apply to other beneficiaries of government spending such as military spending.

Examples of the structural nature of the use of Doublespeak have been made by modern scholars. Noam Chomsky argues in "" that people in modern society consist of decision-makers and social participants who have to be made to agree. According to Chomsky, the media and public relations industry actively shape public opinion, working to present messages in line with their economic agenda for the purposes of controlling of the "public mind". Contrary to the popular belief that indoctrination is inconsistent with democracy, Chomsky goes so far as to argue that "it's the essence of democracy":
Edward Herman's book "Beyond Hypocrisy" also includes a doublespeak dictionary of commonly employed media terms and phrases into plain English.

Henceforth, conflict theories demonstrate the dominating ideology of the bourgeoisie and Moran's theory highlights that doublespeak produces an illusionary effect, both theories having parallels to Orwell's ideology in "Nineteen Eighty-Four". Similarly, Herman's theory of doublespeak having an inherent nature to be manipulative and Chomsky's theory of "dichotomization" relates directly to the practice of doublespeak and how doublespeak is deliberately deceptive in nature.

William D. Lutz has served as the third chairman of the Doublespeak Committee since 1975. In 1989, both his own book "Doublespeak" and, under his editorship, the committee's third book, "Beyond Nineteen Eighty-Four", were published. Lutz was also the former editor of the now defunct "Quarterly Review of Doublespeak", which examines ways that jargon has polluted the public vocabulary with phrases, words and usages of words designed to obscure the meaning of plain English. His book, "Beyond Nineteen Eighty-Four", consists of 220 pages and eighteen articles contributed by long-time Committee members and others whose body of work has made important contributions to understandings about language, as well as a bibliography of 103 sources on doublespeak.

Lutz is one of the main contributors to the committee as well as promoting the term "doublespeak" to a mass audience so as to inform them of the deceptive qualities that doublespeak contains. He mentions:
He also mentions that the NCTE Committee on Public Doublespeak and their works with regards to educating the public on doublespeak is responsible for "the rather awesome task of combating the advertisers, the politicians, and the major manipulators of public language in our society".

Lutz states that it is important to highlight doublespeak to the public because "language isn't the invention of human beings to lie, deceive, mislead, and manipulate" and the "purpose of language is to communicate the truth and to facilitate social groups getting together". Thus, according to Lutz, doublespeak is a form of language that defeats the purpose of inventing language because doublespeak does not communicate the truth but seeks to do the opposite and the doublespeak committee is tasked with correcting this problem that doublespeak has created in the world of language.

The National Council of Teachers of English (NCTE) Committee on Public Doublespeak was formed in 1971, in the midst of the Watergate scandal, at a point when there was widespread skepticism about the degree of truth which characterized relationships between the public and the worlds of politics, the military, and business. NCTE passed two resolutions. One called for the Council to find means to study dishonest and inhumane uses of language and literature by advertisers, to bring offenses to public attention, and to propose classroom techniques for preparing children to cope with commercial propaganda. The other called for the Council to find means to study the relations of language to public policy, to keep track of, publicize, and combat semantic distortion by public officials, candidates for office, political commentators, and all those who transmit through the mass media. Bringing the charges of the two resolutions to life was accomplished by forming NCTE's Committee on Public Doublespeak, a body which has made significant contributions in describing the need for reform where clarity in communication has been deliberately distorted. Such structures can be applied to the field of education, where they could conceivably initiate an anti-pollution bandwagon in educational communication and educate people on how to counter doublespeak.

William Lutz stated that "the doublespeak committee was formed to combat the use of public language by increasing people's awareness of what is good, clear, solid use of language and what is not." "The committee does more than help students and the general public recognize what doublespeak is; it dramatizes that clarity of expression reflects clarity of thought."

Hugh Rank formed the Doublespeak committee and was the first chairman of this committee. Under his editorship, the committee produced a book called "Language and Public Policy" (1974), with the aim of informing readers of the extensive scope of doublespeak being used to deliberately mislead and deceive the audience. He highlighted the deliberate public misuses of language and provided strategies for countering doublespeak by focusing on educating people in the English language so as to help them identify when doublespeak is being put into play. He was also the founder of the Intensify/Downplay pattern that has been widely used to identify instances of Doublespeak being used.

Daniel Dieterich served as the second chairman of the Doublespeak committee after Hugh Rank in 1975. He served as editor of its second publication, "Teaching about Doublespeak (1976)", which carried forward the Committee's charge to inform teachers of ways of teaching students how to recognize and combat language designed to mislead and misinform.

A. M. Tibbetts is one of the main critics of the NCTE, claiming that "the Committee's very approach to the misuse of language and what it calls 'doublespeak' may in the long run limit its usefulness". According to him, the "Committee's use of Orwell is both confused and confusing". The NCTE's publications resonate with George Orwell's name, and allusions to him abound in statements on doublespeak; for example, the committee quoted Orwell's remark that "language is often used as an instrument of social control" in "Language and Public Policy". Tibbetts argues that such a relation between NCTE and Orwell's work is contradicting because "the Committee's attitude towards language is liberal, even radical" while "Orwell's attitude was conservative, even reactionary". He also criticizes on the Committee's "continual attack" against linguistic "purism".

Whereas in the early days of the practice it was considered wrong to construct words to disguise meaning, this is now an accepted and established practice. There is a thriving industry in constructing words without explicit meaning but with particular connotations for new products or companies. Doublespeak is also employed in the field of politics. Hence, education is necessary to recognize and combat against doublespeak-use effectively.

Advertisers can use doublespeak to mask their commercial intent from users, as users' defenses against advertising become more well entrenched. Some are attempting to counter this technique, however, with a number of systems which offer diverse views and information which highlights the manipulative and dishonest methods that advertisers employ.

According to Jacques Ellul, "the aim is not to even modify people’s ideas on a given subject, rather, it is to achieve conformity in the way that people act." He demonstrates this view by offering an example from drug advertising. By using doublespeak in advertisements, aspirin production rose by almost 50 percent from over 23 million pounds in 1960 to over 35 million pounds in 1970.

William Lutz's book "The Rule of Parity" illustrates how doublespeak is being employed in the advertising industry.

Lutz uses the example of parity products: products in which most, if not all, brands in a class or category are of similar quality. To highlight the uniqueness of their product, advertisers may choose to market it differently from their competitors. Advertising is used to create the impression of superiority. This is shown in the first rule of parity, which involves the use of the words "better" and "best". In parity claims, "better" means "best", and "best" means "equal to".

Lutz goes on to say that when advertisers state that their product is "good", it is equivalent in meaning to saying that their product is the best. If all the brands are similar, they must all be similarly good. When they claim that their product is the "best", they mean that the product is as good as the other superior products in its category. Using the toothpaste industry as an example, Lutz says that, because there is no dramatic difference among the products of the major toothpaste companies today, they are equal. However, if all of the different toothpastes are good and equal, there is no need to prove their claim. On the contrary, advertisers cannot market their products as "better" as it is a comparative term, and a claim of superiority.

Educating students has been suggested by experts to be one of the ways to counter doublespeak. Educating students in the English language is important to help them identify how doublespeak is being used to mislead and conceal information.

Charles Weingartner, one of the founding members of the NCTE committee on Public Doublespeak mentioned: "people do not know enough about the subject (the reality) to recognize that the language being used conceals, distorts, misleads". There is a crucial need for English language teachers to educate and become experts in teaching about linguistic vulnerability. "Teachers of English should teach our students that words are not things, but verbal tokens or signs of things that should finally be carried back to the things that they stand for to be verified. Students should be taught a healthy skepticism about the potential abuse of language but duly warned about the dangers of an unhealthy cynicism."

According to William Lutz: "Only by teaching respect and love for the language can teachers of English instill in students the sense of outrage they should experience when they encounter doublespeak." "Students must first learn to use the language effectively, to understand its beauty and power." "Only by using language well will we come to appreciate the perversion inherent in doublespeak."

This pattern was formulated by Hugh Rank and is a simple tool designed to teach some basic patterns of persuasion used in political propaganda and commercial advertising. As it was formulated to educate the public on how to counter doublespeak via education, its aim was to reach the widest possible audience of citizens. It was prepared to be incorporated within a wide variety of existing programs and textbooks in English, speech, media, communications, journalism, social studies. The NCTE has endorsed this pattern as a useful way of teaching students to cope with propaganda from any source.

The function of the intensify/downplay pattern is not to dictate what should be discussed but to encourage coherent thought and systematic organization. The pattern works in two ways: intensifying and downplaying. All people intensify and this is done via repetition, association and composition. Downplaying is commonly done via omission, diversion and confusion as they communicate in words, gestures, numbers, et cetera. Individuals can better cope with organized persuasion by recognizing the common ways whereby communication is intensified or downplayed, so as to counter doublespeak.

Doublespeak is often used to avoid answering questions or to avoid the public's questions without directly stating that the specific politician is ignoring or rephrasing the question.

Doublespeak is often used by politicians for the advancement of their agenda. The Doublespeak Award is an "ironic tribute to public speakers who have perpetuated language that is grossly deceptive, evasive, euphemistic, confusing, or self-centered." It has been issued by the National Council of Teachers of English (NCTE) since 1974. The recipients of the Doublespeak Award are usually politicians, national administration or departments. An example of this is the United States Department of Defense, which won the award three times in 1991, 1993, and 2001 respectively. For the 1991 award, the United States Department of Defense "swept the first six places in the Doublespeak top ten" for using euphemisms like "servicing the target" (bombing) and "force packages" (warplanes). Among the other phrases in contention were "difficult exercise in labor relations", meaning a strike, and "meaningful downturn in aggregate output", an attempt to avoid saying the word "recession".

Doublespeak, particularly when exaggerated, can be used as a device in satirical comedy and social commentary to ironically parody political or bureaucratic establishments intent on obfuscation or prevarication. The television series "Yes Minister" is notable for its use of this device. Oscar Wilde was an early proponent of this device and a significant influence on Orwell.





</doc>
<doc id="8481" url="https://en.wikipedia.org/wiki?curid=8481" title="Dressed to Kill (1980 film)">
Dressed to Kill (1980 film)

Dressed to Kill is a 1980 American erotic thriller film written and directed by Brian De Palma and starring Michael Caine, Angie Dickinson, Nancy Allen, and Keith Gordon. It centers on the murder of a housewife and an investigation involving a young prostitute who witnessed the murder, the victim’s teenaged son, and her psychiatrist. The original music score is composed by Pino Donaggio.

Kate Miller (Angie Dickinson) is a sexually frustrated housewife who is in therapy with New York City psychiatrist Dr. Robert Elliott (Michael Caine). During an appointment, Kate attempts to seduce him, but Elliott rejects her advances.

Kate goes to the Metropolitan Museum of Art where she has an unexpected flirtation with a mysterious stranger. Kate and the stranger stalk each other through the museum until they finally wind up outside, where Kate joins him in a taxi. They begin to have sex and continue at his apartment.

Hours later, Kate awakens and decides to discreetly leave while the man, Warren Lockman, is asleep. Kate sits at his desk to leave him a note and finds a document indicating that Warren has contracted a sexually transmitted disease. Mortified, she leaves the apartment. In her haste, she has left her wedding ring on the nightstand, so she returns to retrieve it.

The elevator doors open on the figure of a tall, blond woman in dark sunglasses wielding a straight razor. Kate is violently slashed to death in the elevator. A high-priced call girl, Liz Blake (Nancy Allen), happens upon the body. She catches a glimpse of the killer, therefore becoming both the prime suspect and the killer's next target.

Dr. Elliott receives a bizarre message on his answering machine from "Bobbi", a transsexual patient. Bobbi taunts the psychiatrist for breaking off their therapy sessions, apparently because Elliott refuses to sign the necessary papers for Bobbi to get sex-reassignment surgery. Elliott tries to convince Dr. Levy, the patient's new doctor, that Bobbi is a danger to herself and others.

Police Detective Marino (Dennis Franz) is skeptical about Liz's story, partly because of her profession, so Liz joins forces with Kate's revenge-minded son Peter (Keith Gordon) to find the killer. Peter, an inventor, uses a series of homemade listening devices and time-lapse cameras to track patients leaving Elliott's office. They catch Bobbi on camera, and soon Liz is being stalked by a tall blonde in sunglasses. Several attempts are subsequently made on Liz's life. One, in the New York City Subway, is thwarted by Peter, who sprays Bobbi with homemade Mace.

Liz and Peter scheme to learn Bobbi's birth name by getting inside Dr. Elliott's office. Liz baits the therapist by stripping to lingerie and coming on to him, distracting him long enough to make a brief exit and leaf through his appointment book. Peter is watching through the window when a blonde pulls him away. When Liz returns, a blonde with a razor confronts her; the blonde outside shoots and wounds the blonde inside, the wig falls off, and it is Dr. Elliott, revealing that he is also Bobbi. The blonde who shot Bobbi is actually a female police officer, revealing herself to be the blonde who has been trailing Liz.

Elliott is arrested and placed in an insane asylum. Dr. Levy explains later to Liz that Elliott wanted to be a woman, but his male side would not allow him to go through with the operation. Whenever a woman sexually aroused Elliott, Bobbi, representing the unstable, female side of the doctor's personality, became threatened to the point that it finally became murderous. When Dr. Levy realized this through his last conversation with Elliott, he called the police on the spot, who then, with his help, did their duty.

In a final sequence, Elliott escapes from the asylum and slashes Liz's throat in a bloody act of vengeance. She wakes up screaming, Peter rushing to her side, realizing that it was just a dream.


The nude body in the opening scene, taking place in a shower, was not that of Angie Dickinson, but of 1977 "Penthouse" Pet of the Year model Victoria Lynn Johnson. De Palma originally wanted Norwegian actress Liv Ullmann to play Kate Miller, but she declined because of the violence. The role then went to Angie Dickinson. Sean Connery was offered the role of Robert Elliot and was enthusiastic about it, but declined on account of previous commitments. Connery would later work with De Palma on "The Untouchables". De Palma called the elevator killing the best murder scene he has ever done.

Two versions of the film exist in North America, an R-rated version and an unrated version. The unrated version is around 30 seconds longer and shows more pubic hair in the shower scene, more blood in the elevator scene (including a close-up shot of the killer slitting Kate's throat), and some sexier dialogue from Liz during the scene in Elliott's office. These scenes were trimmed when the MPAA originally gave the film an "X" rating.

"Dressed to Kill" currently holds an 84% "fresh" rating on Rotten Tomatoes based on 43 reviews for an average rating of 6.6 out of 10. Roger Ebert awarded the film three stars out of four, stating "the museum sequence is brilliant" and adding: ""Dressed to Kill" is an exercise in style, not narrative; it would rather look and feel like a thriller than make sense, but DePalma has so much fun with the conventions of the thriller that we forgive him and go along." In his movie guide, Leonard Maltin gave the film 3 1/2 stars out of four, calling it a "High-tension melodrama", and stating "De Palma works on viewers' emotions, not logic, and maintains a fever pitch from start to finish." He also praised Pino Donaggio's "chilling music score." "The performers are excellent, especially Miss Dickinson," wrote Vincent Canby in his July 25, 1980 "The New York Times" review. When Alfred Hitchcock was told that Brian De Palma intended "Dressed to Kill" as an homage to his movies, he responded “You mean fromage.”

Allen earned a Golden Globe nomination for Best New Star, but a Razzie nomination, as well.

The film is recognized by American Film Institute in these lists:




</doc>
<doc id="8483" url="https://en.wikipedia.org/wiki?curid=8483" title="Diesel cycle">
Diesel cycle

The Diesel cycle is a combustion process of a reciprocating internal combustion engine. In it, fuel is ignited by heat generated during the compression of air in the combustion chamber, into which fuel is then injected. This is in contrast to igniting the fuel-air mixture with a spark plug as in the Otto cycle (four-stroke/petrol) engine. Diesel engines are used in aircraft, automobiles, power generation, diesel-electric locomotives, and both surface ships and submarines.

The Diesel cycle is assumed to have constant pressure during the initial part of the combustion phase (formula_1 to formula_2 in the diagram, below). This is an idealized mathematical model: real physical diesels do have an increase in pressure during this period, but it is less pronounced than in the Otto cycle. In contrast, the idealized Otto cycle of a gasoline engine approximates a constant volume process during that phase.

The image on the left shows a p-V diagram for the ideal Diesel cycle; where formula_3 is pressure and V the volume or formula_4 the specific volume if the process is placed on a unit mass basis. The ideal Diesel cycle follows the following four distinct processes:


The Diesel engine is a heat engine: it converts heat into work. During the bottom isentropic processes (blue), energy is transferred into the system in the form of work formula_5, but by definition (isentropic) no energy is transferred into or out of the system in the form of heat. During the constant pressure (red, isobaric) process, energy enters the system as heat formula_6. During the top isentropic processes (yellow), energy is transferred out of the system in the form of formula_7, but by definition (isentropic) no energy is transferred into or out of the system in the form of heat. During the constant volume (green, isochoric) process, some of energy flows out of the system as heat through the right depressurizing process formula_8. The work that leaves the system is equal to the work that enters the system plus the difference between the heat added to the system and the heat that leaves the system; in other words, net gain of work is equal to the difference between the heat added to the system and the heat that leaves the system.


The net work produced is also represented by the area enclosed by the cycle on the P-V diagram. The net work is produced per cycle and is also called the useful work, as it can be turned to other useful types of energy and propel a vehicle (kinetic energy) or produce electrical energy. The summation of many such cycles per unit of time is called the developed power. The formula_7 is also called the gross work, some of which is used in the next cycle of the engine to compress the next charge of air.

The maximum thermal efficiency of a Diesel cycle is dependent on the compression ratio and the cut-off ratio. It has the following formula under cold air standard analysis: 

formula_16

where

The cut-off ratio can be expressed in terms of temperature as shown below:

formula_26 can be approximated to the flame temperature of the fuel used. The flame temperature can be approximated to the adiabatic flame temperature of the fuel with corresponding air-to-fuel ratio and compression pressure, formula_27.
formula_28 can be approximated to the inlet air temperature.

This formula only gives the ideal thermal efficiency. The actual thermal efficiency will be significantly lower due to heat and friction losses. The formula is more complex than the Otto cycle (petrol/gasoline engine) relation that has the following formula;

formula_29

The additional complexity for the Diesel formula comes around since the heat addition is at constant pressure and the heat rejection is at constant volume. The Otto cycle by comparison has both the heat addition and rejection at constant volume.

Comparing the two formulae it can be seen that for a given compression ratio (), the ideal Otto cycle will be more efficient. However, a diesel engine will be more efficient overall since it will have the ability to operate at higher compression ratios. If a petrol engine were to have the same compression ratio, then knocking (self-ignition) would occur and this would severely reduce the efficiency, whereas in a diesel engine, the self ignition is the desired behavior. Additionally, both of these cycles are only idealizations, and the actual behavior does not divide as clearly or sharply. Furthermore, the ideal Otto cycle formula stated above does not include throttling losses, which do not apply to diesel engines.

Diesel engines have the lowest specific fuel consumption of any large internal combustion engine employing a single cycle, 0.26 lb/hp·h (0.16 kg/kWh) for very large marine engines (combined cycle power plants are more efficient, but employ two engines rather than one). Two-stroke diesels with high pressure forced induction, particularly turbocharging, make up a large percentage of the very largest diesel engines.

In North America, diesel engines are primarily used in large trucks, where the low-stress, high-efficiency cycle leads to much longer engine life and lower operational costs. These advantages also make the diesel engine ideal for use in the heavy-haul railroad environment.

Many model airplanes use very simple "glow" and "diesel" engines. Glow engines use glow plugs. "Diesel" model airplane engines have variable compression ratios. Both types depend on special fuels.

Some 19th-century or earlier experimental engines used external flames, exposed by valves, for ignition, but this becomes less attractive with increasing compression. (It was the research of Nicolas Léonard Sadi Carnot that established the thermodynamic value of compression.) A historical implication of this is that the diesel engine could have been invented without the aid of electricity.



</doc>
<doc id="8484" url="https://en.wikipedia.org/wiki?curid=8484" title="Deus Ex (video game)">
Deus Ex (video game)

Deus Ex is a 2000 action role-playing video game developed by Ion Storm and published by Eidos Interactive. Set in a cyberpunk-themed dystopian world in the year 2052, the story follows JC Denton, an agent given superhuman abilities by nanotechnology, as he sets out to combat hostile forces in a world ravaged by inequality and a deadly plague. His missions entangle him in a conspiracy that brings him into conflict with the Triads, Majestic 12, and the Illuminati.

"Deus Ex"s gameplay combines elements of the first-person shooter with stealth elements, adventure, and role-playing genres, allowing for its tasks and missions to be completed in a variety of ways, that in turn lead to differing outcomes. Presented from the first-person perspective, the player can customize Denton's various abilities such as weapon skills or lockpicking, increasing his effectiveness in these areas; this opens up different avenues of exploration and methods of interacting with or manipulating other characters. The player is able to complete side missions away from the primary storyline by moving freely around the available areas, which can reward the player with experience points to upgrade abilities and alternative ways to tackle main missions.

The game was first released for Microsoft Windows in June 2000, with a Mac OS port following the next month. A modified version of the game was released later for the PlayStation 2 in 2002. In the years following its release, "Deus Ex" has received additional improvements and content from its fan community.

The game received critical acclaim, including repeatedly being named "Best PC Game of All Time" in "PC Gamer"s "Top 100 PC Games" in 2011 and in a poll carried out by the UK gaming magazine "PC Zone". It was a frequent candidate for and winner of Game of the Year awards, drawing praise for its pioneering designs in player choice and multiple narrative paths. It has sold more than 1 million copies, as of April 23, 2009. The game has spawned both a sequel, "", released in 2003, and three prequels: "", released in 2011, "", released in 2013, and "", released in 2016.

"Deus Ex" incorporates elements from four video game genres: role-playing, first-person shooter, adventure, and "immersive simulation", the last of which being a game where "nothing reminds you that you're just playing a game". For example, the game uses a first-person camera during gameplay and includes exploration and character interaction as primary features.

The player assumes the role of JC Denton, a nanotech-augmented operative of the United Nations Anti-Terrorist Coalition (UNATCO). This nanotechnology is a central gameplay mechanism and allows players to perform superhuman feats.

As the player accomplishes objectives, the player character is rewarded with "skill points". Skill points are used to enhance a character's abilities in eleven different areas, and were designed to provide players with a way to customize their characters; a player might create a combat-focused character by increasing proficiency with pistols or rifles, while a more furtive character can be created by focusing on lock picking and computer hacking abilities. There are four different levels of proficiency in each skill, with the skill point cost increasing for each successive level.

Weapons may be customized through "weapon modifications", which can be found or purchased throughout the game. The player might add scopes, silencers, or laser sights; increase the weapon's range, accuracy, or magazine size; or decrease its recoil and reload time; as appropriate to the weapon type.

Players are further encouraged to customize their characters through nano-augmentations—cybernetic devices that grant characters superhuman powers. While the game contains eighteen different nano-augmentations, the player can install a maximum of nine, as each must be used on a certain part of the body: one in the arms, legs, eyes, and head; two underneath the skin; and three in the torso. This forces the player to choose carefully between the benefits offered by each augmentation. For example, the arm augmentation requires the player to decide between boosting their character's skill in hand-to-hand combat or his ability to lift heavy objects.

Interaction with non-player characters (NPCs) was a large design focus. When the player interacts with a non-player character, the game will enter a cutscene-like conversation mode where the player advances the conversation by selecting from a list of dialogue options. The player's choices often have a substantial effect on both gameplay and plot, as non-player characters will react in different ways depending on the selected answer (e.g. rudeness makes them less likely to provide assistance).

"Deus Ex" features combat similar to first-person shooters, with real-time action, a first-person perspective, and reflex-based gameplay. As the player will often encounter enemies in groups, combat often tends toward a tactical approach, including the use of cover, strafing, and "hit-and-run". A USA Today reviewer found "At the easiest difficulty setting, your character is puréed again and again by an onslaught of human and robotic terrorists until you learn the value of stealth." However, through the game's role-playing systems, it is possible to develop a character's skills and augmentations to create a tank-like combat specialist with the ability to deal and absorb large amounts of damage. Non-player characters will praise or criticize the main character depending on his use of force, incorporating a moral element into the gameplay.

"Deus Ex" features a head-up display crosshair, whose size dynamically shows where shots will fall based on movement, aim, and the weapon in use; the reticle expands while the player is moving or shifting his or her aim, and slowly shrinks to its original size while no actions are taken. How quickly the reticle shrinks depends on the character's proficiency with the equipped weapon the number of accuracy modifications added to the weapon, and the level of the "Targeting" nano-augmentation.

"Deus Ex" features twenty-four weapons, ranging from crowbars, electroshock weapons, and riot baton, to laser guided anti-tank rockets and assault rifles; both lethal and non-lethal weapons are available. The player can also make use of several weapons of opportunity, such as fire extinguishers.

Gameplay in "Deus Ex" emphasizes player choice. Objectives can be completed in numerous ways, including stealth, sniping, heavy frontal assault, dialogue, or engineering and computer hacking. This level of freedom requires that levels, characters, and puzzles be designed with significant redundancy, as a single play-through of the game will miss large sections of dialogue, areas, and other content. In some missions, the player is encouraged to avoid using deadly force, and certain aspects of the story may change depending on how violent or non-violent the player chooses to be. The game is also unusual in that two of its boss villains can be killed off early in the game, or left alive to be defeated later, and this too affects how other characters interact with the player.

Because of its design focus on player choice, "Deus Ex" has been compared with "System Shock", a game that inspired its design. Together, these factors give the game a great degree of replayability, as the player will have vastly different experiences, depending on which methods he or she uses to accomplish objectives.

"Deus Ex" was designed as a single player game, and the initial releases of the Windows and Macintosh versions of the game did not include multiplayer functionality. Support for multiplayer modes was later incorporated through patches. The component includes three game modes: deathmatch, basic team deathmatch, and advanced team deathmatch. Only five maps, based on levels from the single-player portion of the game, were included with the original multiplayer patch, but many user-created maps now exist. The PlayStation 2 release of "Deus Ex" does not offer a multiplayer mode. In April 2014 it was announced that Gamespy would cease their masterserver services, also affecting Deus Ex. A community-made patch for the multiplayer mode has been created as a response to this.

"Deus Ex" takes place in an unspecified near future in an alternate history where popular real world conspiracy theories are true. These include speculations regarding black helicopters, vaccinations, and FEMA, as well as Area 51, the ECHELON network, Men in Black, chupacabras (in the form of "greasels"), and grey aliens. Mysterious groups such as Majestic 12, the Illuminati, the Knights Templar, the Bilderberg Group, and the Trilateral Commission also either play a central part in the plot or are alluded to during the course of the game.

The plot of "Deus Ex" depicts a society on a slow spiral into chaos. There is a massive division between the rich and the poor, not only socially, but in some cities physically. A lethal pandemic known as the "Gray Death" ravages the world's population, especially within the United States, and has no cure. A synthetic vaccine, "Ambrosia", manufactured by the company VersaLife, nullifies the effects of the virus but is in critically short supply. Because of its scarcity, Ambrosia is available only to those deemed "vital to the social order", and finds its way primarily to government officials, military personnel, the rich and influential, scientists, and the intellectual elite. With no hope for the common people of the world, riots occur worldwide, and a number of terrorist organizations have formed with the professed intent of assisting the downtrodden, among them the National Secessionist Forces of the U.S. and a French group known as Silhouette.

In order to combat these threats to the world order, the United Nations has expanded its influence around the globe to form the United Nations Anti-Terrorist Coalition (UNATCO). It is headquartered near New York City in a bunker beneath Liberty Island, placed there after a terrorist strike on the Statue of Liberty.

The main character of "Deus Ex" is JC Denton (Jay Franke), a UNATCO agent physically altered with advanced nanotechnology to gain superhuman abilities. His UNATCO colleagues include: the mechanically-augmented and ruthlessly efficient field agents, Gunther Hermann and Anna Navarre; JC's brother Paul (Jay Franke), who joined UNATCO to avenge his parents deaths at the hands of Majestic 12; and armory chief General Sam Carter. Alex Jacobson's character model and name are based on Warren Spector's own nephew, Alec Jacobson.

After completing his training, UNATCO agent JC Denton takes several missions given by Director Joseph Manderley to track down members of the National Secessionist Forces (NSF) and their stolen shipments of the "Ambrosia" vaccine, the treatment for the "Gray Death" virus. Through these missions, JC is reunited with his brother, Paul, who is also nano-augmented. JC tracks the Ambrosia shipment to a private terminal at LaGuardia Airport. Paul meets JC outside the plane and explains that he has defected from UNATCO and is now working with the NSF after learning that the Gray Death is a man-made virus, with UNATCO using its power to make sure only the elite receive the vaccine.

JC returns to UNATCO headquarters and is told by Manderley that both he and Paul have been outfitted with a 24-hour kill switch and that Paul's has been activated due to his betrayal. Manderley orders JC to fly to Hong Kong to eliminate Tracer Tong, a hacker whom Paul has contact with, and who can disable the kill switches. Instead, JC returns to Paul's apartment to find Paul hiding inside. Paul further explains his defection and encourages JC to also defect by sending out a distress call to alert the NSF's allies. Upon doing so, JC becomes a wanted man by UNATCO, and his own kill switch is activated by Federal Emergency Management Agency (FEMA) Director Walton Simons. JC is unable to escape UNATCO forces, and both he and Paul (provided he survived the raid on the apartment) are taken to a secret prison below UNATCO headquarters. An entity named "Daedalus" contacts JC and informs him that the prison is part of Majestic 12, and arranges for him and Paul to escape. The two flee to Hong Kong to meet with Tong, who deactivates their kill switches. Tong requests JC infiltrate the VersaLife building. Doing so, JC discovers that the corporation is the source for the Gray Death, and he is able to steal the plans for the virus and destroy the "universal constructor" (UC) that produces it.

Analysis of the virus shows it was manufactured by the Illuminati, prompting Tong to send JC to Paris to try to make contact with the organization and obtain their help fighting Majestic 12. JC eventually meets with Illuminati leader Morgan Everett and learns that the Gray Death virus was intended to be used for augmentation technology, but Majestic 12, led by trillionaire businessman and former Illuminatus Bob Page, was able to steal and repurpose it into its current viral form. Everett recognizes that without VersaLife's universal constructor, Majestic 12 can no longer create the virus, and will likely target Vandenberg Air Force Base, where X-51, a group of former Area 51 scientists, have built another one. After aiding the base personnel in repelling a Majestic 12 attack, JC meets X-51 leader Gary Savage, who reveals that Daedalus is an artificial intelligence (AI) borne out of the ECHELON program. Everett attempts to gain control over Majestic 12's communications network by releasing Daedalus onto the U.S. military networks, but Page counters by releasing his own AI, Icarus, which merges with Daedalus to form a new AI, Helios, with the ability to control all global communications. After this, Savage enlists JC's help in procuring schematics for reconstructing components for the UC that were damaged during Majestic 12's raid of Vandenberg. JC finds the schematics and electronically transmits them to Savage. Page intercepts the transmission and launches a nuclear missile at Vandenberg to ensure that Area 51 (now Majestic 12's headquarters), will be the only location in the world with an operational UC. However, JC is able to reprogram the missile to strike Area 51. JC then travels there himself to confront Page.

When JC locates him, Page reveals that he seeks to merge with Helios and gain full control over all nanotechnology, essentially becoming a god. JC is contacted by Tong, Everett, and the Helios AI simultaneously. All three factions ask for his help in defeating Page while furthering their own objectives, and JC is forced to choose between them. Tong seeks to plunge the world into a Dark Age by destroying the global communications hub and preventing anyone from taking control of the world. Everett offers Denton the chance to bring the Illuminati back to power by killing Bob Page and using the technology of Area 51 to rule the world with an invisible hand. Helios wishes to merge with Denton and rule the world as a benevolent dictator with infinite knowledge and reason. The player's decision determines the course of the future and brings the game to a close.

After Looking Glass Technologies and Origin Systems released "" in January 1993, producer Warren Spector began to plan "Troubleshooter", the game that would become "Deus Ex". Spector found himself burnt out on fantasy and science fiction settings and hoped to make a game set in the real world. In his 1994 proposal, he described the concept as ""Underworld"-style first-person action" in a real world setting with "big-budget, nonstop action". Spector later commented that Origin did not have the interest, nor Looking Glass the funding, to produce the game. He eventually left Origin for Looking Glass and continued to develop the game's concept, but his project "Junction Point", which was inspired by ideas from "Troubleshooter", was canceled. After Spector and his team were laid off from Looking Glass, John Romero of Ion Storm offered him the chance to make his "dream game" without any restrictions. Spector quickly joined the company.

Preproduction for "Deus Ex" began around August 1997 and lasted roughly six months. The six-person team came from Looking Glass's Austin studio. Spector, the team's director and producer, saw their work as improving upon the game design ideas of Origin, Looking Glass, and Valve Corporation by doing what those companies did not. The game's "ironic" working title was "Shooter: Majestic Revelations", and it was scheduled for release on Christmas 1998. The team developed the setting before the game mechanics. Noticing his wife's fascination with "The X-Files", Spector connected the "real world, millennial weirdness, [and] conspiracy" topics on his mind and decided to make a game about them that would appeal to a wide audience. "Shooter"s fiction was based in part on conspiracy theories related to Area 51, CIA drug trafficking, the John F. Kennedy assassination, the Majestic 12, and a Masonic bunker beneath Denver International Airport. The team designed over 200 characters without associated in-game roles, which was both helpful when designing missions and unhelpful as they attempted to reduce their scope. Later in 1997, Spector wrote a "manifesto" on his ideal game and the structure of role-playing video games. His principles included "problems, not puzzles", "no forced failure", "players do; NPCs watch", and "areas with multiple entrance and exit points". In retrospect, Spector believed that "Deus Ex" accomplished the intent of his manifesto.

The "Shooter" design document cast the player as an augmented agent working against an elite cabal in the "dangerous and chaotic" 2050s. It cited "Half-Life", "Fallout", "", and "GoldenEye 007" as game design influences, and used the stories and settings of "", "The Manchurian Candidate", "Robocop", "The X-Files" and "Men in Black" as reference points. According to the document, the game would engage with "the millennial madness that's gripping the world ... and a general fascination with conspiracy theories and the desire to play with high-tech espionage toys". The team designed a skill system that featured "special powers" derived from nanotechnological augmentation and avoided the inclusion of die rolling and skills that required micromanagement. Augmentations were unique to the player character. By March 1998, preproduction had generated 300 pages of documentation. The document grew to 500 pages, with "radically different" content, by the game's April 1999 Alpha 1 deadline. Of Spector's original design document, the marketing section was the only part left unedited.

In early 1998, the "Deus Ex" team grew to 20 people and the game entered a 28-month production phase. Spector hired new staff for his Austin studio and was assigned an art team from Ion Storm's Dallas branch. The development team consisted of three programmers, six designers, seven artists, a writer, an associate producer, a "tech", and Warren Spector, the producer, and director. Two writers and four testers were hired as contractors. Chris Norden was the lead programmer and assistant director, Harvey Smith the lead designer, Jay Lee the lead artist, and Sheldon Pacotti the lead writer. However, Spector's initial management structure, which involved two competing design teams and the matrix management of the Dallas art team, was a failure. According to Spector, the team was interested in multiple video game genres, and it contained both design maximalists who wanted to "do everything" and design minimalists who wanted to do a few things well. Close friends of the team who understood the intentions behind the game were invited to playtest and give feedback. The wide range of input led to debates in the office and changes to the game. Spector later concluded that the team was "blinded by promises of complete creative freedom", and by their belief that the game would have no budget, marketing or time restraints. By mid-1998, the game's title had become "Deus Ex", derived from the Latin literary device "deus ex machina" ("god from the machine") in which a plot is resolved by an unpredictable intervention. Spector acknowledged its grammatical faults as a title, but he liked it because of its relevance to the in-game struggle for power, to the medium's storytelling difficulties, to the game being played on a computer, and to the "self-referential" acceptance of trying one's best to resolve affairs.

Spector felt that the best aspects of "Deus Ex"s development were the "high-level vision" and length of preproduction, flexibility within the project, testable "proto-missions", and Unreal Engine license. The team's pitfalls included the management structure, unrealistic goals, underestimating risks with artificial intelligence, their handling of proto-missions, and weakened morale from bad press. He referred to that period of Ion Storm as "Sturm und Drang", because of the degree of hype and the vitriol following "Daikatana" trash talk marketing, alongside negative press in 1998 and 1999. He said that his Austin team had "frequent" slumps in morale from taking the company's coverage personally and seeing their private emails posted online. Eventually, the "Deus Ex" Austin team developed a we'll show them' mentality" to distinguish their work and reputation from those of the Dallas branch. "Deus Ex" was released on June 23, 2000 and published by Eidos Interactive for Microsoft Windows. The team planned third-party ports for Mac OS 9 and Linux.

The original 1997 design document for "Deus Ex" privileges character development over all other features, including experimental sequences and technology demos. The game was designed to be "genre-busting": in parts simulation, role-playing game, first-person shooter, and adventure. The team wanted players to consider "who they wanted to be" in the game, and for that to alter how they behaved in the game. In this way, the game world was "deeply simulated", or realistic and believable enough that the player would solve problems in creative, emergent ways without noticing distinct puzzles. The developers also wanted to include "choice" and "consequence", which Spector called the team's "two most frequently uttered words". However, the team's simulation ultimately failed to maintain the desired level of openness, and they had to brute force "skill", "action", and "character interaction" paths through each level. Playtesting also revealed that their idea of a role-playing game based in the real world was more interesting in theory than in reality. The team chose two real-world bases for levels: "highly interconnected, multi-level" spaces, and places that most cannot visit (e.g., the White House). In practice, the team found that certain aspects of the real world, such as hotels and office buildings, were not compelling in a game. Ion Storm saw "Deus Ex" as being about "player expression" rather than making the developers appear "clever". They treated the player as a "collaborator", who they sought to empower to "make choices and ... deal with the consequences". Spector credited the 1995 role-playing video game "Suikoden" as an inspiration, stating that the limited choices in "Suikoden" inspired him to expand on the idea with more meaningful choices in "Deux Ex".

One of the things that Spector wanted to achieve in Deus Ex was to make JC Denton a cipher for the player, in order to create a better immersion and gameplay experience. He did not want the character to force any emotion so that whatever feelings the player may be experiencing comes from themselves rather than from JC Denton. To do this, Spector instructed voice actor Jay Anthony Franke to record his dialogue without any emotion but in a monotone voice, which is unusual for a voice acting role.

Once coded, the team's game systems did not work as intended. Prototypes of the systems and of certain missions were built near the beginning of development, which revealed some of the team's planning mistakes. For example, the early tests of the conversation system and user interface were flawed, but the team had time to revise them before the game's release. The team also found augmentations and skills to be less interesting than they had seemed in the design document. Colleagues from other companies—such as Doug Church, Rob Fermier, Marc LeBlanc, and Gabe Newell—noticed and pointed out these deficiencies in game "tension" when they played the prototype. In response, Harvey Smith substantially revised the augmentations and skills. Production milestones served as wake-up calls for the game's direction. A May 1998 milestone that called for a functional demo revealed that the size of the game's maps caused frame rate issues, which was one of the first signs that maps needed to be cut. A year later, the team reached a milestone for finished game systems that Spector nicknamed the "Wow, these missions suck" milestone, which led to better estimates for their future mission work and to the reduction of the 500-page design document to 270 pages. Spector recalled Smith's mantra on this point: "less is more". 

One of the team's biggest blind spots was the AI programming for NPCs. Spector wrote that they considered it in preproduction, but that they did not figure out how to handle it until "relatively late in development". This led to wasted time when the team had to discard their early AI code. The team built atop their game engine's shooter-based AI instead of writing new code that would allow characters to exhibit convincing emotions. As a result, NPC behavior was variable until the very end of development. Spector felt that the team's "sin" was their inconsistent display of a trustable "human AI".

 The game was developed on systems including dual-processor Pentium Pro 200s and Athlon 800s with eight and nine gigabyte hard drives, some using SCSI. The team used "more than 100 video cards" throughout development. "Deus Ex" was built using Visual Studio, Lightwave, and Lotus Notes. They also built a custom dialogue editor, ConEdit. The team used UnrealEd atop the Unreal game engine for map design, which Spector wrote was "superior to anything else available". Their trust in UnrealScript led them to code "special-cases" for their immediate mission needs instead of more generalized multi-case code. Even as concerned team members expressed misgivings, the team only addressed this later in the project. To Spector, this was a lesson to always prefer "general solutions" over "special casing", such that the tool set works predictably.

They waited to license a game engine until after preproduction, expecting the benefits of licensing to be more time for the content and gameplay, which Spector reported to be the case. They chose the Unreal engine as it did 80% of what they needed from an engine and was more economical than building from scratch. Their small programming team allowed for a larger design group. The programmers also found the engine accommodating, though it took about nine months to acclimate to the software. Spector felt that they would have understood the code better had they built it themselves, instead of "treating the engine as a black box" and coding conservatively. He acknowledged that this precipitated into the Direct3D issues in their final release, which slipped through their quality assurance testing. Spector also noted that the artificial intelligence, pathfinding, and sound propagation were designed for shooters and should have been rewritten from scratch instead of relying on the engine. He thought the licensed engine worked well enough that he expected to use the same for and "Thief 3". He added that developers should not attempt to force their technology to perform in ways it was not intended, and should find a balance between perfection and pragmatism.

The soundtrack of "Deus Ex", composed by Alexander Brandon (primary contributor, including main theme), Dan Gardopée ("Naval Base" and "Vandenberg"), Michiel van den Bos ("UNATCO", "Lebedev's Airfield", "Airfield Action", "DuClare Chateau" plus minor contribution to some of Brandon's tracks), and Reeves Gabrels ("NYC Bar"), was praised by critics for complementing the gritty atmosphere predominant throughout the game with melodious and ambient music incorporated from a number of genres, including techno, jazz, and classical. The music sports a basic dynamic element, similar to the iMUSE system used in early 1990s LucasArts games; during play, the music will change to a different iteration of the currently playing song based on the player's actions, such as when the player starts a conversation, engages in combat, or transitions to the next level. All the music in the game is tracked - Gabrels' contribution, "NYC Bar", was converted to a module by Brandon.

A compact disc of the "Deus Ex" soundtrack was included in the "Game of the Year" edition and is not available for separate purchase. Notably, the soundtrack is not a direct audio rip from the game itself, however; it is a "remastering" of the soundtrack with added instruments and audio production. Originally only thirty tracks were included with the re-release, with tracks thirty-one through forty-one considered as extras. The PlayStation 2 port featured live, orchestral renditions of some tracks.

"Deus Ex" has been re-released in several iterations since its original publication and has also been the basis of a number of mods developed by its fan community.

The "Deus Ex: Game of the Year Edition", which was released on May 8, 2001, contains the latest game updates and a software development kit, a separate soundtrack CD and a page from a fictional newspaper featured prominently in "Deus Ex" titled "The Midnight Sun", which recounts recent events in the game's world. However, later releases of said version do not include the soundtrack CD and contain a PDF version of the newspaper on the game's disc.

The Mac OS version of the game released a month after the Windows version, was shipped with the same capabilities and can also be patched to enable multiplayer support. However, publisher Aspyr Media did not release any subsequent editions of the game or any additional patches. As such, the game is only supported in Mac OS 9 and the "Classic" environment in Mac OS X, neither of which are compatible with Intel-based Macs. The Windows version will run on Intel-based Macs using Crossover, Boot Camp, or other software to enable a compatible version of Windows to run on a Mac.

A PlayStation 2 port of the game, retitled "Deus Ex: The Conspiracy" outside of Europe, was released on March 26, 2002. Along with pre-rendered introductory and ending cinematics that replaced the original versions, it features a simplified interface with optional auto-aim and motion captured character models. There are many minor changes in level design, some for the purpose of balancing gameplay, but most to accommodate loading transition areas, due to the memory limitations of the PlayStation 2. The PlayStation 2 version was rereleased in Europe on the PlayStation 3 as a PlayStation 2 Classic on May 16, 2012.

Loki Games worked on a Linux version of the game, but the company went out of business before releasing it. The OpenGL layer they wrote for the port, however, was sent out to Windows gamers through an online patch, which also makes the game far more compatible with Wine on Linux than it would have been with only Direct3D.

Though their quality assurance did not see major Direct3D issues, players noted "dramatic slowdowns" immediately following launch, and the team did not understand the "black box" of the Unreal engine well enough to make it do exactly what they needed. Spector characterized "Deus Ex" reviews into two categories based on how they begin with either how "Warren Spector makes games all by himself" or that ""Deus Ex" couldn't possibly have been made by Ion Storm". He has said that the game won over 30 "best of" awards in 2001, and concluded that their final game was not perfect, but that they were much closer for having tried to "do things right or not at all".

"Deus Ex" was built on the Unreal Engine, in which previous games on the engine saw active community involvement in modding. On September 20, 2000, Eidos Interactive and Ion Storm announced in a press release that they would be releasing the software development kit (SDK), which included all the tools used to create the original game. Several team members, as well as project director Warren Spector, stated that they were "really looking forward to seeing what [the community] does with our tools". The kit was released on September 22, 2000, and soon gathered community interest, followed by the release of tutorials, small mods, up to announcements of large mods and conversions. While Ion Storm did not hugely alter the engine's rendering and core functionality, they introduced role-playing elements.

In 2009, a fan-made mod called "The Nameless Mod" ("TNM") was released by Off Topic Productions. The game's protagonist is a user of an Internet forum, with digital places represented as physical locations. The mod offers roughly the same amount of gameplay as Deus Ex and adds several new features to the game, with a more open world structure than "Deus Ex" and new weapons such as the player character's fists. The mod was developed over 7 years and has thousands of lines of recorded dialogue and two different parallel story arcs. Upon its release, "TNM" earned a 9/10 overall from "PCPowerPlay" magazine. In ModDB's 2009 Mod of the Year awards, "The Nameless Mod" won the Editor's Choice award for Best Singleplayer Mod.

In 2015, during the 15th anniversary of the game's release, Square Enix (who had acquired Eidos earlier) endorsed a free fan-created mod, "Deus Ex: Revision" which was released through Steam. The mod, created by Caustic Creative, is a graphical overhaul of the original game, adding in support for newer versions of DirectX, improving the textures and the soundtrack from the original game, and adding in more world-building aesthetics.

In 2017, a large-scale modification "GMDX" was finalised and released, containing various additions to graphics, and levels. It also introduces drastic changes to gameplay, while implementing new mechanics. GMDX received generally favorable reception.

In the United States, "Deus Ex" sold 138,840 copies and earned $5 million during the year 2000. Another 91,013 copies were sold in the region during 2001. "Deus Ex" later received a "Gold" sales award from the Entertainment and Leisure Software Publishers Association (ELSPA), indicating sales of at least 200,000 copies in the United Kingdom.

"Deus Ex" received critical acclaim, attaining a score of 90 out of 100 from 28 critics on Metacritic. Thierry Nguyen from Computer Gaming World said that the game "delivers moments of brilliance, idiocy, ingenuity, and frustration." Computer Games Magazine praised the title for its deep gameplay and its use of multiple solutions to situations in the game. Similarly, "Edge" highlighted the game's freedom of choice, saying that "Deus Ex" "never tells you what to do. Goals are set, but alter according to your decisions."

Former GameSpot reviewer Greg Kasavin, though awarding the game a score of 8.2 of 10, was disappointed by the security and lockpicking mechanics. "Such instances are essentially noninteractive", he wrote. "You simply stand there and spend a particular quantity of electronic picks or modules until the door opens or the security goes down." Kasavin made similar complaints about the hacking interface, noting that, "Even with basic hacking skills, you'll still be able to bypass the encryption and password protection ... by pressing the 'hack' button and waiting a few seconds."

The game's graphics and sounds were also met with muted enthusiasm. Kasavin complained of "Deus Ex"s relatively sub-par graphics, blaming them on the game's "incessantly dark industrial environments." GamePro reviewer Chris Patterson took the time to note that despite being "solid acoustically," "Deus Ex" had moments of weakness. He poked fun at JC's "Joe Friday, 'just the facts, deadpan," and the "truly cheesy accents" of minor characters in Hong Kong and New York City. IGN called the graphics "blocky", adding that "the animation is stiff, and the dithering is just plain awful in some spots," referring to the limited capabilities of the Unreal Engine used to design the game. The website, later on, stated that "overall Deus Ex certainly looks better than your average game."

Reviewers and players also complained about the size of "Deus Ex"s save files. An Adrenaline Vault reviewer noted that "Playing through the entire adventure, [he] accumulated over 250MB of save game data, with the average file coming in at over 15MB."

The game developed a strong cult following, leading to a core modding and playing community that remained active over 15 years after its release. In an interview with IGN in June 2015, game director Warren Spector said he never expected "Deus Ex" to sell many copies, but he did expect it to become a cult classic among a smaller strong community, and he continues to receive fan mail from players to date regarding their experiences and thoughts about "Deus Ex".

"Deus Ex" received over 30 "best of" awards in 2001, from outlets such as IGN, GameSpy, "PC Gamer", "Computer Gaming World", and The Adrenaline Vault. It won "Excellence in Game Design" and "Game Innovation Spotlight" at the 2001 Game Developers Choice Awards, and it was nominated for "Game of the Year". At the Interactive Achievement Awards, it won in the "Computer Innovation" and "Computer Action/Adventure" categories and received nominations for "Sound Design", "PC Role-Playing", and "Game of the Year" in both the PC and overall categories. The British Academy of Film and Television Arts named it "PC Game of the Year". The game also collected several "Best Story" accolades, including first prize in Gamasutra's 2006 "Quantum Leap" awards for storytelling in a video game.

Since its release, "Deus Ex" has appeared in a number of "Greatest Games of All Time" lists and Hall of Fame features. It was included in IGN's "100 Greatest Games of All Time" (#40, #21 and #34 in 2003, 2005 and 2007, respectively), "Top 25 Modern PC Games" (4th place in 2010) and "Top 25 PC Games of All Time" (#20 and #21 in 2007 and 2009 respectively) lists. GameSpy featured the game in its "Top 50 Games of All Time" (18th place in 2001) and "25 Most Memorable Games of the Past 5 Years" (15th place in 2004) lists, and in the site's "Hall of Fame". "PC Gamer" placed "Deus Ex" on its "Top 100 PC Games of All Time" (#2, #2, #1 by staff and #4 by readers in 2007, 2008, 2010 and 2010 respectively) and "50 Best Games of All Time" (#10 and #27 in 2001 and 2005) lists, and it was awarded 1st place in "PC Zone"s "101 Best PC Games Ever" feature. It was also included in Yahoo! UK Video Games' "100 Greatest Computer Games of All Time" (28th place) list, and in "Edge"s "The 100 Best Videogames" (29th place in 2007) and "100 Best Games to Play Today" (57th place in 2009) lists. "Deus Ex" was named the second-best game of the 2000s by Gamasutra. In 2012, "Time" named it one of the 100 greatest video games of all time, and G4tv ranked it as the 53rd best game of all time for its "complex and well-crafted story that was really the start of players making choices that genuinely affect the outcome." 1UP.com listed it as one of the most important games of all time, calling its influence "too massive to properly gauge."

A film adaptation based on the game was originally announced in May 2002 by Columbia Pictures. The film was being produced by Laura Ziskin, along with Greg Pruss attached with writing the screenplay. Peter Schlessel, president of the production for Columbia Pictures, and Paul Baldwin, president of marketing for Eidos Interactive, stated that they were confident in that the adaptation would be a successful development for both the studios and the franchise. In March 2003, during an interview with Greg Pruss, he informed IGN that the character of JC Denton will be "a little bit filthier than he was in the game." He further stated that the script was shaping up to be darker in tone than the original game. Although a release date was scheduled for 2006, the film never got past the scripting stage.<br>

In 2012, CBS films revived the project, buying the rights and commissioning a film inspired by the "Deux Ex" series; its direct inspiration will be the 2011 game "". C. Robert Cargill and Scott Derrickson are writing the screenplay, and Derrickson will direct the film.

A sequel to the game titled "", was released in the United States on December 2, 2003, and then in Europe in early 2004 for both the PC and the Xbox game console. A second sequel, titled "Deus Ex: Clan Wars", was originally conceived as a multiplayer-focused third game for the series. After the commercial performance and public reception of "Deus Ex: Invisible War" failed to meet expectations, the decision was made to set the game in its own universe, and "Deus Ex: Clan Wars" was eventually published under the title "Project: Snowblind".

On March 29, 2007, Valve Corporation announced "Deus Ex" and its sequel would be available for purchase from their Steam service. Among the games announced are several other Eidos franchise titles, including "" and "Tomb Raider".

Eidos Montréal produced a prequel to "Deus Ex" called "". This was confirmed on November 26, 2007, when Eidos Montréal posted a teaser trailer for the title on their website. The game was released on August 23, 2011 for the PC, PlayStation 3, and Xbox 360 platforms and received critical acclaim.

On April 7, 2015, Eidos announced a sequel to "Deus Ex: Human Revolution" and second prequel to "Deus Ex" titled "". "Deus Ex: Mankind Divided" was released on August 23, 2016.




</doc>
<doc id="8485" url="https://en.wikipedia.org/wiki?curid=8485" title="Diego Maradona">
Diego Maradona

Diego Armando Maradona (, born 30 October 1960) is an Argentine retired professional footballer and manager. Many in the sport, including football writers, players, and fans, regard him as the greatest football player of all time. He was joint FIFA Player of the 20th Century with Pelé.

An advanced playmaker who operated in the classic number 10 position, Maradona was the first player in football history to set the world record transfer fee twice, first when he transferred to Barcelona for a then world record £5 million, and second, when he transferred to Napoli for another record fee £6.9 million. He played for Argentinos Juniors, Boca Juniors, Barcelona, Napoli, Sevilla and Newell's Old Boys during his club career, and is most famous for his time at Napoli and Barcelona where he won numerous accolades. In his international career with Argentina, he earned 91 caps and scored 34 goals.

Maradona's vision, passing, ball control, dribbling skills, speed, reflexes and reaction time was combined with his small size ( tall) giving him a low center of gravity which allowed him to maneuver better than most other football players; he would often dribble past multiple opposing players on a run. His presence and leadership on the field had a great effect on his team's general performance, while he would often be singled out by the opposition. A precocious talent, Maradona was given the nickname ""El Pibe de Oro"" ("The Golden Boy"), a name that stuck with him throughout his career.

Maradona played in four FIFA World Cups, including the 1986 World Cup in Mexico where he captained Argentina and led them to victory over West Germany in the final, and won the Golden Ball as the tournament's best player. In the 1986 World Cup quarter final, he scored both goals in a 2–1 victory over England that entered football history for two different reasons. The first goal was an unpenalized handling foul known as the "Hand of God", while the second goal followed a dribble past five England players, voted "Goal of the Century" by FIFA.com voters in 2002.

Maradona became coach of Argentina in November 2008. He was in charge of the team at the 2010 World Cup in South Africa before leaving at the end of the tournament. He coached Dubai-based club Al Wasl in the UAE Pro-League for the 2011–12 season. In 2017, Maradona became the coach of Fujairah before leaving at the end of the season. In May 2018, Maradona was announced as the new chairman of Belarussian club Dynamo Brest. He arrived in Brest and was presented by the club to start his duties in July.

Diego Armando Maradona was born on 30 October 1960, at the Policlínico (Polyclinic) Evita Hospital in Lanús, Buenos Aires Province, but raised in Villa Fiorito, a shantytown on the southern outskirts of Buenos Aires, Argentina, to a poor family that had moved from Corrientes Province. He was the first son after three daughters. He has two younger brothers, Hugo ("el Turco") and Raúl (Lalo), both of whom were also professional football players. 
He was the fifth child and first son of Diego Maradona "Chitoro" (d. 2015) and Dalma Salvadora Franco 'Doña Tota' (1930–2011). Maradona's parents were both born and brought up in the town of Esquina in the north-east province of Corrientes Province, living only two hundred metres from each other on the banks of the Corriente River. In 1950, they left Esquina and settled in Buenos Aires. At age eight, Maradona was spotted by a talent scout while he was playing in his neighbourhood club Estrella Roja. He became a staple of "Los Cebollitas" (The Little Onions), the junior team of Buenos Aires's Argentinos Juniors. As a 12-year-old ball boy, he amused spectators by showing his wizardry with the ball during the halftime intermissions of first division games. He named Brazilian playmaker Rivelino and Manchester United winger George Best among his inspirations growing up.

On 20 October 1976, Maradona made his professional debut for Argentinos Juniors, 10 days before his 16th birthday. He entered to the pitch wearing the number 16 jersey, and after the game said, "That day I felt I had held the sky in my hands." Maradona scored his first goal in the Primera División against Marplatense team San Lorenzo on 14 November 1976, two weeks after turning 16. Maradona spent five years at Argentinos Juniors, from 1976 to 1981, scoring 115 goals in 167 appearances before his US$ 4 million transfer to Boca Juniors. Maradona received offers to join other clubs, including River Plate who offered to make him the club's best paid player. Nevertheless, Maradona expressed his will to be transferred to Boca Juniors, the team he always wanted to play for.

Maradona signed a contract with Boca Juniors on 20 February 1981. He made his debut two days later against Talleres de Córdoba, scoring twice in the club's 4–1 win. On 10 April, Maradona played his first "Superclásico" against River Plate at La Bombonera stadium. Boca defeated River 3–0 with Maradona scoring a goal after dribbling past Alberto Tarantini and Fillol. Despite the distrustful relationship between Maradona and Boca Juniors manager, Silvio Marzolini, Boca had a successful season, winning the league title after securing a point against Racing Club. That would be the only title won by Maradona in the Argentine domestic league.

After the 1982 World Cup, in June, Maradona was transferred to Barcelona in Spain for a then world record fee of £5 million ($7.6 million). In 1983, under coach César Luis Menotti, Barcelona and Maradona won the Copa del Rey (Spain's annual national cup competition), beating Real Madrid, and the Spanish Super Cup, beating Athletic Bilbao. On 26 June 1983, Barcelona defeated Real Madrid on the road in one of the world's biggest club games, "El Clásico", a match where Maradona scored and became the first Barcelona player to be applauded by archrival Real Madrid fans. Maradona dribbled past Madrid goalkeeper Agustín, and as he approached the empty goal, he stopped just as Madrid defender Juan José came sliding in a desperate attempt to block the shot and ended up crashing into the post, before Maradona slotted the ball into the net. The manner of the goal led to many inside the stadium start applauding; only Ronaldinho (in November 2005) and Andrés Iniesta (in November 2015) have since been granted such an ovation as Barcelona players from Madrid fans at the Santiago Bernabéu. Due to illness and injury as well as controversial incidents on the field, Maradona had a difficult tenure in Barcelona. First a bout of hepatitis, then a broken ankle in a La Liga game at the Camp Nou in September 1983 caused by an ill-timed tackle by Athletic Bilbao's Andoni Goikoetxea, threatened to jeopardize Maradona's career, but with treatment and therapy, it was possible for him to return to the pitch after a three-month recovery period.

The end of the 1983–84 season included a violent and chaotic fight Maradona was directly involved in at the 1984 Copa del Rey final at the Santiago Bernabéu against Athletic Bilbao. After receiving another rough tackle by Goikoetxea which wounded his leg, being taunted with xenophobic insults throughout the match by Bilbao fans, and being provoked by Bilbao's Miguel Sola at full time as Barcelona lost 1–0, Maradona snapped. He aggressively got up, stood inches from Sola's face and the two exchanged words. This started a chain reaction of emotional reactions from both teams. Using expletives, Sola mimicked a gesture from the crowd towards Maradona by using a xenophobic term. Maradona then headbutted Sola, elbowed another Bilbao player in the face and kneed another player in the head, knocking him out cold. The Bilbao squad surrounded Maradona to exact some retribution with Goikoetxea connecting with a high kick to his chest, before the rest of the Barcelona squad joined in to help Maradona. From this point, Barcelona and Bilbao players brawled on the field with Maradona in the centre of the action, kicking and punching anyone in a Bilbao shirt.

The mass brawl was played out in front of the Spanish King Juan Carlos and an audience of 100,000 fans inside the stadium, and more than half of Spain watching on television. Sixty people were injured, with the incident effectively sealing Maradona's transfer out of the club in what was his last game in a Barcelona shirt. One Barcelona executive stated, "When I saw those scenes of Maradona fighting and the chaos that followed I realized we couldn't go any further with him." Maradona got into frequent disputes with FC Barcelona executives, particularly club president Josep Lluís Núñez, culminating with a demand to be transferred out of Camp Nou in 1984. During his two injury-hit seasons at Barcelona, Maradona scored 38 goals in 58 games. Maradona transferred to Napoli in Italy's Serie A for another world record fee, £6.9 million ($10.48M).

Maradona arrived in Naples and was presented to the world media as a Napoli player on 5 July 1984, where he was welcomed by 75,000 fans at his presentation at the Stadio San Paolo. Sports writer David Goldblatt commented, "They [the fans] were convinced that the saviour had arrived." A local newspaper stated that despite the lack of a "mayor, houses, schools, buses, employment and sanitation, none of this matters because we have Maradona". Prior to Maradona's arrival, Italian football was dominated by teams from the north and centre of the country, such as A.C. Milan, Juventus, Inter Milan and Roma, and no team in the south of the Italian Peninsula had ever won a league title.

At Napoli, Maradona reached the peak of his professional career: he soon inherited the captain's armband from Napoli veteran defender Giuseppe Bruscolotti and quickly became an adored star among the club's fans; in his time there he elevated the team to the most successful era in its history. Maradona played for Napoli at a period when North-South tensions in Italy were at a peak due to a variety of issues, notably the economic differences between the two. Led by Maradona, Napoli won their first ever Serie A Italian Championship in 1986–87. Goldblatt wrote, "The celebrations were tumultuous. A rolling series of impromptu street parties and festivities broke out contagiously across the city in a round-the-clock carnival which ran for over a week. The world was turned upside down. The Neapolitans held mock funerals for Juventus and Milan, burning their coffins, their death notices announcing 'May 1987, the other Italy has been defeated. A new empire is born.'" Murals of Maradona were painted on the city's ancient buildings, and newborn children were named in his honor. The following season, the team's prolific attacking trio, formed by Maradona, Bruno Giordano and Careca, was later dubbed the "Ma-Gi-Ca" ("magical") front-line.
Napoli would win their second league title in 1989–90, and finish runners up in the league twice, in 1987–88 and 1988–89. Other honors during the Maradona era at Napoli included the Coppa Italia in 1987, (second place in the Coppa Italia in 1989), the UEFA Cup in 1989 and the Italian Supercup in 1990. Despite primarily playing in a creative role as an attacking midfielder, Maradona was the top scorer in Serie A in 1987–88, with 15 goals, and was the all-time leading goalscorer for Napoli, with 115 goals, until his record was broken by Marek Hamšík in 2017. When asked who was the toughest player he ever faced, A.C. Milan central defender Franco Baresi stated, "Maradona; when he was on form, there was almost no way of stopping him," a view shared by his Milan teammate Paolo Maldini, who stated, "The best ever I played against was Maradona."

While Maradona was successful on the field during his time in Italy, his personal problems increased. His cocaine use continued, and he received US $70,000 in fines from his club for missing games and practices, ostensibly because of "stress". He faced a scandal there regarding an illegitimate son, and he was also the object of some suspicion over an alleged friendship with the Camorra. Later on, in honour of Maradona and his achievements during his career at Napoli, the number 10 jersey of Napoli was officially retired.

After serving a 15-month ban for failing a drug test for cocaine, Maradona left Napoli in disgrace in 1992. Despite interest from Real Madrid and Marseille, he signed for Sevilla, where he stayed for one year. In 1993, he played for Newell's Old Boys and in 1995 returned to Boca Juniors for a two-year stint. Maradona also appeared for Tottenham Hotspur in a friendly match against Internazionale, shortly before the 1986 World Cup. The match was a testimonial for Osvaldo Ardiles, who insisted that his friend Maradona play.

During his time with the Argentina national team, Maradona scored 34 goals in 91 appearances. He made his full international debut at age 16, against Hungary, on 27 February 1977. Maradona was left off the Argentine squad for the 1978 World Cup on home soil by coach César Luis Menotti who felt he was too young at age 17. At age 18, Maradona played the 1979 FIFA World Youth Championship in Japan and emerged as the star of the tournament, shining in Argentina's 3–1 final win over the Soviet Union. On 2 June 1979, Maradona scored his first senior international goal in a 3–1 win against Scotland at Hampden Park. He went on to play for Argentina in two 1979 Copa América ties during August 1979, a 2–1 loss against Brazil and a 3–0 win over Bolivia in which he scored his side's third goal.

Maradona and his compatriot and heir apparent, Lionel Messi, are the only players to win the Golden Ball at both the FIFA U-20 World Cup and FIFA World Cup. Maradona did so in 1979 and 1986, which Messi emulated in 2005 and 2014.

Maradona played his first World Cup tournament in 1982 in his new country of residence, Spain. Argentina played Belgium in the opening game of the 1982 Cup at the Camp Nou in Barcelona. The Catalan crowd was eager to see their new world-record signing Maradona in action, but he did not perform to expectations, as Argentina, the defending champions, lost 1–0. Although the team convincingly beat both Hungary and El Salvador in Alicante to progress to the second round, there were internal tensions within the team, with the younger, less experienced players at odds with the older, more experienced players. In a team that also included such players as Mario Kempes, Osvaldo Ardiles, Ramón Díaz, Daniel Bertoni, Alberto Tarantini, Ubaldo Fillol and Daniel Passarella, the Argentine side was defeated in the second round by Brazil and by eventual winners Italy. The Italian match is renowned for Maradona being aggressively man-marked by Claudio Gentile, as Italy beat Argentina at the Sarrià Stadium in Barcelona, 2–1.

Maradona played in all five matches without being substituted, scoring twice against Hungary. He was fouled repeatedly in all five games and particularly in the last one against Brazil at the Sarrià, a game that was blighted by poor officiating and violent fouls. With Argentina already down 3–0 to Brazil, Maradona's temper eventually got the better of him and he was sent off with five minutes remaining for a serious retaliatory foul against Batista.

Maradona captained the Argentine national team to victory in the 1986 World Cup in Mexico, winning the final in Mexico City against West Germany. Throughout the tournament, Maradona asserted his dominance and was the most dynamic player of the tournament. He played every minute of every Argentina game, scoring five goals and making five assists, three of those in the opening match against South Korea at the Olimpico Universitario Stadium in Mexico City. His first goal of the tournament came against Italy in the second group game in Puebla. Argentina eliminated Uruguay in the first knockout round in Puebla, setting up a match against England at the Azteca Stadium, also in Mexico City. After scoring two contrasting goals in the 2–1 quarter-final win against England, his legend was cemented. The majesty of his second goal and the notoriety of his first led to the French newspaper "L'Equipe" describing Maradona as "half-angel, half-devil". This match was played with the background of the Falklands War between Argentina and the United Kingdom. Replays showed that the first goal was scored by striking the ball with his hand. Maradona was coyly evasive, describing it as "a little with the head of Maradona and a little with the hand of God". It became known as the "Hand of God". Ultimately, on 22 August 2005, Maradona acknowledged on his television show that he had hit the ball with his hand purposely, and no contact with his head was made, and that he immediately knew the goal was illegitimate. This became known as an international fiasco in World Cup history. The goal stood, much to the wrath of the English players.

Maradona's second goal, just four minutes after the hotly disputed hand-goal, was later voted by FIFA as the greatest goal in the history of the World Cup. He received the ball in his own half, swivelled around and with 11 touches ran more than half the length of the field, dribbling past five English outfield players (Peter Beardsley, Steve Hodge, Peter Reid, Terry Butcher and Terry Fenwick) before he left goalkeeper Peter Shilton on his backside with a feint, and slotted the ball into the net. This goal was voted "Goal of the Century" in a 2002 online poll conducted by FIFA.

Maradona followed this with two more goals in a semi-final match against Belgium at the Azteca, including another virtuoso dribbling display for the second goal. In the final match, West Germany attempted to contain him by double-marking, but he nevertheless found the space past the West German player Lothar Matthäus to give the final pass to Jorge Burruchaga for the winning goal. Argentina beat West Germany 3–2 in front of 115,000 fans at the Azteca.

During the course of the tournament, Maradona attempted or created more than half of Argentina's shots, attempted 90 dribbles some three times more than any other player and was fouled 53 times, winning his team twice as many free kicks as any player. Maradona scored or assisted 10 of Argentina's 14 goals, including the assist for the winning goal in the final, ensuring that he would be remembered as one of the greatest names in football history. By the end of the World Cup, Maradona went on to win the Golden Ball as the best player of the tournament by unanimous vote and was widely regarded to have won the World Cup virtually single-handedly, something that he later stated he did not entirely agree with. In a tribute to him, Azteca Stadium authorities built a statue of him scoring the "Goal of the Century" and placed it at the entrance of the stadium.

Maradona captained Argentina again in the 1990 World Cup in Italy to yet another World Cup final. An ankle injury affected his overall performance, and he was much less dominant than four years earlier. After losing their opening game to Cameroon at the San Siro in Milan, Argentina were almost eliminated in the first round, only qualifying in third position from their group. In the round of 16 match against Brazil in Turin, Claudio Caniggia scored the only goal after being set up by Maradona.

In the quarter-final, Argentina faced Yugoslavia in Florence; the match ending 0–0 after 120 minutes, and Argentina advancing on penalty kicks, despite Maradona missing one in the shootout with a weak shot to the goalkeeper's right. The semi-final against the host nation Italy at Maradona's club stadium in Naples, the Stadio San Paolo, was also resolved on penalties after a 1–1 draw. This time, however, Maradona was successful with his effort, daringly rolling the ball into the net with an almost exact replica of his missed shot in the previous round. At the final in Rome, Argentina lost 1–0 to West Germany, the only goal being a penalty by Andreas Brehme in the 85th minute after a controversial foul on Rudi Völler.

At the 1994 World Cup in the United States, Maradona played in only two games (both at the Foxboro Stadium near Boston), scoring one goal against Greece, before being sent home after failing a drug test for ephedrine doping. In his autobiography, Maradona argued that the test result was due to his personal trainer giving him the power drink Rip Fuel. His claim was that the U.S. version, unlike the Argentine one, contained the chemical and that, having run out of his Argentine dosage, his trainer unwittingly bought the U.S. formula. FIFA expelled him from USA '94, and Argentina were subsequently eliminated in the second round by Romania in Los Angeles. Maradona has also separately claimed that he had an agreement with FIFA, on which the organization reneged, to allow him to use the drug for weight loss before the competition in order to be able to play. His failed drugs test at the 1994 World Cup signaled the end of his international career, which had lasted 17 years and yielded 34 goals from 91 games, as well as one winner's medal and one runners-up medal in the World Cup.

A classic number 10, Maradona was renowned for his dribbling ability, vision, close ball control, passing and creativity, and is considered one of the most skillful players in the sport. He had a compact physique, and with his strong legs and low center of gravity he could withstand physical pressure well while running with the ball. Former Dutch player Johan Cruyff saw similarities between Maradona and Lionel Messi with the ball seemingly attached to their body when dribbling. His physical strengths were illustrated by his two goals against Belgium in the 1986 World Cup. He was a strategist and a team player, as well as highly technical with the ball. He could manage himself effectively in limited spaces, and would attract defenders only to quickly dash out of the melee (as in the second 1986-goal against England), or give an assist to a free teammate. Being short, but strong, he could hold the ball long enough with a defender on his back to wait for a teammate making a run or to find a gap for a quick shot. He showed leadership qualities on the field and captained Argentina in their World Cup campaigns of 1986, 1990 and 1994.

The team leader on and off the field – he would speak up on a range of issues on behalf of the players – Maradona’s ability as a player and his overpowering personality had a major positive effect on his team, with his 1986 World Cup teammate Jorge Valdano stating: "Maradona was a technical leader: a guy who resolved all difficulties that may come up on the pitch. Firstly, he was in charge of making the miracles happen, that's something that gives team-mates a lot of confidence. Secondly, the scope of his celebrity was such that he absorbed all the pressures on behalf of his team-mates. What I mean is: one slept soundly the night before a game not just because you knew you were playing next to Diego and Diego did things no other player in the world could do, but also because unconsciously we knew that if it was the case that we lost then Maradona would shoulder more of the burden, would be blamed more, than the rest of us. That was the kind of influence he exercised on the team."

One of Maradona's trademark moves was dribbling full-speed on the right wing, and on reaching the opponent's goal line, delivering accurate passes to his teammates. Another trademark was the "rabona", a reverse-cross pass shot behind the leg that holds all the weight. This maneuver led to several assists, such as the cross for Ramón Díaz's header against Switzerland in 1980. He was also a dangerous free kick and penalty kick taker. His free kick technique, which often saw him raise his knee at a high angle when striking the ball, thus enabling him to lift it high over the wall, allowed him to score free kicks even from close range, within 22 to 17 yards (20 to 16 metres) from the goal, or even just outside the penalty area.

Maradona was famous for his cunning personality. Inherent within his nickname "El Pibe de Oro" ("Golden Boy") is a sense of mischief, with "pibe" being an anti-establishment rogue, street smart and full of guile. Some critics view his controversial "Hand of God" goal at the 1986 World Cup as a clever maneuver, with one of the opposition players, Glenn Hoddle, admitting that Maradona had disguised it by flicking his head at the same time as palming the ball. The goal itself has been viewed as an embodiment of the Buenos Aires shanty town Maradona was brought up in and its concept of "viveza criolla" — "native cunning". Maradona used his hand in the 1990 World Cup, again without punishment, and this time on his own goal line, to prevent the Soviet Union from scoring. A number of publications have referred to Maradona as the Artful Dodger, the urchin pickpocket from Charles Dickens' "Oliver Twist".

Maradona was dominantly left-footed, often using his left foot even when the ball was positioned more suitably for a right-footed connection. His first goal against Belgium in the 1986 World Cup semi-final is a worthy indicator of such; he had run into the inside right channel to receive a pass but let the ball travel across to his left foot, requiring more technical ability. During his run past several England players in the previous round for the "Goal of the Century" he did not use his right foot once, despite spending the whole movement on the right-hand side of the pitch. In the 1990 World Cup second round tie against Brazil, he did use his right foot to set up the winning goal for Claudio Caniggia due to two Brazilian markers forcing him into a position that made use of his left foot less practical.

Hounded for years by the press, Maradona once fired a compressed-air rifle at reporters who he claimed were invading his privacy. This quote from former teammate Jorge Valdano summarizes the feelings of many:
In 1990, the Konex Foundation from Argentina granted him the Diamond Konex Award, one of the most prestigious culture awards in Argentina, as the most important personality in Sports in the last decade in his country. In 2000, Maradona published his autobiography "Yo Soy El Diego" ("I am "The Diego""), which became a bestseller in Argentina. Two years later, Maradona donated the Cuban royalties of his book to "the Cuban people and Fidel".

In 2000, he won FIFA Player of the Century award which was to be decided by votes on their official website, their official magazine and a grand jury. Maradona won the Internet-based poll, garnering 53.6% of the votes against 18.53% for Pelé. In spite of this, and shortly before the ceremony, FIFA added a second award and appointed a "Football Family" committee composed of football journalists that also gave to Pelé the title of best player of the century to make it a draw. Maradona also came fifth in the vote of the IFFHS (International Federation of Football History and Statistics). In 2001, the Argentine Football Association (AFA) asked FIFA for authorization to retire the jersey number 10 for Maradona. FIFA did not grant the request, even though Argentine officials have maintained that FIFA hinted that it would.

Maradona has topped a number of fan polls, including a 2002 FIFA poll in which his second goal against England was chosen as the best goal ever scored in a World Cup; he also won the most votes in a poll to determine the All-Time Ultimate World Cup Team. On 22 March 2010, Maradona was chosen number 1 in The Greatest 10 World Cup players of all time by the London-based newspaper "The Times". Argentinos Juniors named its stadium after Maradona on 26 December 2003. In 2003, Maradona was employed by the Libyan footballer Al-Saadi Gaddafi, the third son of Colonel Muammar Gaddafi, as a "technical consultant", while Al-Saadi was playing for the Italian club, Perugia, which was playing in Serie A at the time.

On 22 June 2005, it was announced that Maradona would return to former club Boca Juniors as a sports vice president in charge of managing the First Division roster (after a disappointing 2004–05 season, which coincided with Boca's centenary). His contract began 1 August 2005, and one of his first recommendations proved to be very effective: advising the club to hire Alfio Basile as the new coach. With Maradona fostering a close relationship with the players, Boca won the 2005 Apertura, the 2006 Clausura, the 2005 Copa Sudamericana and the 2005 Recopa Sudamericana.

On 15 August 2005, Maradona made his debut as host of a talk-variety show on Argentine television, La Noche del 10 ("The Night of the no. 10"). His main guest on opening night was Pelé; the two had a friendly chat, showing no signs of past differences. However, the show also included a cartoon villain with a clear physical resemblance to Pelé. In subsequent evenings, he led the ratings on all occasions but one. Most guests were drawn from the worlds of football and show business, including Ronaldo and Zinedine Zidane, but also included interviews with other notable friends and personalities such as Cuban leader Fidel Castro and boxers Roberto Durán and Mike Tyson. Maradona gave each of his guests a signed Argentina jersey, which Tyson wore when he arrived in Brazil, Argentina's biggest rivals.

In May 2006, Maradona agreed to take part in UK's Soccer Aid (a program to raise money for Unicef). In September 2006, Maradona, in his famous blue and white number 10, was the captain for Argentina in a three-day World Cup of Indoor Football tournament in Spain. On 26 August 2006, it was announced that Maradona was quitting his position in the club Boca Juniors because of disagreements with the AFA, who selected Alfio Basile to be the new coach of the Argentina national team. In 2008, award-winning Serbian filmmaker Emir Kusturica made a documentary about Maradona's life, entitled "Maradona".

On 1 September 2014, Maradona, along with many current and former footballing stars, took part in the "Match for Peace", which was played at the Stadio Olimpico in Rome, with the proceeds being donated entirely to charity. Maradona set up a goal for Roberto Baggio during the first half of the match, with a chipped through-ball over the defence with the outside of his left foot. Unusually, both Baggio and Maradona wore the number 10 shirt, despite playing on the same team. On 17 August 2015, Maradona visited Ali Bin Nasser, the Tunisian referee of the Argentina–England quarter-final match at the 1986 World Cup where Maradona scored his Hand of God, and paid tribute to him by giving him a signed Argentine jersey.

Maradona began his managerial career alongside former Argentinos Juniors midfield teammate Carlos Fren. The pair led Mandiyú of Corrientes in 1994 and Racing Club in 1995, with little success. In May 2011 he became manager of Dubai club Al Wasl FC in the United Arab Emirates. Maradona was sacked on 10 July 2012. In August 2013, Maradona moved on to become mental coach at Argentine club Deportivo Riestra. Maradona departed this role in 2017 to become the head coach of Fujairah, in the UAE second division, before leaving at the end of the season upon failure to secure promotion at the club.

After the resignation of Argentina national team coach Alfio Basile in 2008, Maradona immediately proposed his candidacy for the vacant role. According to several press sources, his major challengers included Diego Simeone, Carlos Bianchi, Miguel Ángel Russo and Sergio Batista. On 29 October 2008, AFA chairman Julio Grondona confirmed that Maradona would be the head coach of the national team from December 2008. On 19 November 2008, Maradona managed Argentina for the first time when Argentina played against Scotland at Hampden Park in Glasgow, which Argentina won 1–0.
After winning his first three matches in charge of the national team, he oversaw a 6–1 defeat to Bolivia, equalling the team's worst ever margin of defeat. With two matches remaining in the qualification tournament for the 2010 World Cup, Argentina was in fifth place and faced the possibility of failing to qualify, but victory in the last two matches secured qualification for the finals. After Argentina's qualification, Maradona used abusive language at the live post-game press conference, telling members of the media to "suck it and keep on sucking it". FIFA responded with a two-month ban on all footballing activity, which expired on 15 January 2010, and a CHF 25,000 fine, with a warning as to his future conduct. The friendly match scheduled to take place at home to the Czech Republic on 15 December, during the period of the ban, was cancelled. The only match Argentina played during Maradona's ban was a friendly away to Catalonia, which they lost 4–2.

At the World Cup finals in June 2010, Argentina started by winning 1–0 against Nigeria, followed by a 4–1 victory over South Korea on the strength of a Gonzalo Higuaín hat-trick. In the final match of the group stage, Argentina won 2–0 against Greece to win the group and advance to a second round, meeting Mexico. After defeating Mexico 3–1, however, Argentina was routed by Germany 4–0 in the quarter-finals to go out of the competition. Argentina was ranked fifth in the tournament. After the defeat to Germany, Maradona admitted that he was considering his future as Argentina coach, stating, "I may leave tomorrow." On 15 July 2010, the AFA said that he would be offered a new four-year deal that would keep him in charge through to the summer of 2014 when Brazil stages the World Cup. On 27 July, however, the AFA announced that its board had unanimously decided not to renew his contract. Afterwards, on 29 July, Maradona claimed that AFA president Julio Grondona and director of national teams (as well as his former Argentine national team and Sevilla coach) Carlos Bilardo had "lied to", "betrayed" and effectively sacked him from the role. He said, "They wanted me to continue, but seven of my staff should not go on, if he told me that, it meant he did not want me to keep working."

Born to a Roman Catholic family, his parents are Diego Maradona Senior and Dalma Salvadora Franco. Maradona married long-time fiancée Claudia Villafañe on 7 November 1984 in Buenos Aires, and they had two daughters, Dalma Nerea (born 2 April 1987) and Gianinna Dinorah (born 16 May 1989), by whom he became a grandfather in 2009.

Maradona and Villafañe divorced in 2004. Daughter Dalma has since asserted that the divorce was the best solution for all, as her parents remained on friendly terms. They travelled together to Naples for a series of homages in June 2005 and were seen together on other occasions, including the Argentina games during 2006 World Cup.

During the divorce proceedings, Maradona admitted he is the father of Diego Sinagra (born in Naples on 20 September 1986). The Italian courts had already ruled so in 1993, after Maradona refused to undergo DNA tests for proving or disproving his paternity. Diego Junior met Maradona for the first time in May 2003 after tricking his way onto a golf course in Italy where Maradona was playing. Sinagra is now a footballer playing in Italy. After the divorce, Claudia embarked on a career as a theatre producer, and Dalma was seeking an acting career; she had expressed her desire to attend the Actor's Studio in Los Angeles.

Maradona's mother, Dalma, died on 19 November 2011. He was in Dubai at the time, and desperately tried to fly back in time to see her, but was too late. She was 81 years old. His father, "Don" Diego, died on 25 June 2015 at age 87.

From the mid-1980s until 2004, Maradona was addicted to cocaine. He allegedly began using the drug in Barcelona in 1983. By the time he was playing for Napoli, he had a regular addiction, which began to interfere with his ability to play football.

Maradona has a tendency to put on weight and suffered increasingly from obesity, at one point weighing . He was obese from the end of his playing career until undergoing gastric bypass surgery in a clinic in Cartagena de Indias, Colombia, on 6 March 2005. His surgeon said that Maradona would follow a liquid diet for three months in order to return his normal weight. When Maradona resumed public appearances shortly thereafter, he displayed a notably thinner figure. On 29 March 2007, Maradona was readmitted to a hospital in Buenos Aires. He was treated for hepatitis and effects of alcohol abuse and was released on 11 April, but readmitted two days later. In the following days, there were constant rumors about his health, including three false claims of his death within a month. After transfer to a psychiatric clinic specialising in alcohol-related problems, he was discharged on 7 May. On 8 May 2007, Maradona appeared on Argentine television and stated that he had quit drinking and had not used drugs in two-and-a-half years.

Having previously been vocal in his support of neoliberal Argentine President Carlos Menem and his Harvard University-educated economist Domingo Cavallo, Maradona has shown sympathy to left-wing ideologies. He became friends with Cuban leader Fidel Castro while receiving treatment on the island, with Castro stating, "Diego is a great friend and very noble, too. There's also no question he’s a wonderful athlete and has maintained a friendship with Cuba to no material gain of his own." He has a portrait of Castro tattooed on his left leg and one of Fidel's second in command, fellow Argentine Che Guevara on his right arm. In his autobiography, "El Diego", he dedicated the book to various people, including Castro. He wrote, "To Fidel Castro and, through him, all the Cuban people."
Maradona was also a supporter of former Venezuelan President Hugo Chávez. In 2005, he came to Venezuela to meet Chávez, who received him in the Miraflores Palace. After this meeting, Maradona claimed that he had come with the aim of meeting a "great man" (""un grande"" in Spanish), but he had met instead a gigantic man (""un gigante"" in Spanish, meaning he was more than great). "I believe in Chávez, I am Chavista. Everything Fidel does, everything Chávez does, for me is the best." Maradona was the guest of honor of Chávez at the opening game of the 2007 Copa América held in Venezuela.

Maradona has declared his opposition to what he identifies as imperialism, notably during the 2005 Summit of the Americas in Mar del Plata, Argentina. There he protested George W. Bush's presence in Argentina, wearing a T-shirt labeled "STOP BUSH" (with the "s" in "Bush" being replaced with a swastika) and referring to Bush as "human garbage". In August 2007, Maradona went further, making an appearance on Chávez's weekly television show "Alo Presidente" and saying, "I hate everything that comes from the United States. I hate it with all my strength." In December 2008, Maradona expressed admiration for Bush's successor, President-elect Barack Obama, and held great expectations for him.
With his poor shanty town upbringing, Maradona has cultivated a man of the people persona. During a meeting with Pope John Paul II at the Vatican in 1987, they clashed on the issue of wealth disparity, with Maradona stating, "I argued with him because I was in the Vatican and I saw all these golden ceilings and afterwards I heard the Pope say the Church was worried about the welfare of poor kids. Sell your ceiling then amigo, do something!" In September 2014, Maradona met with Pope Francis in Rome, crediting Francis for inspiring him to return to religion after many years; he stated, "We should all imitate Pope Francis. If each one of us gives something to someone else, no one in the world would be starving."

In December 2007, Maradona presented a signed shirt with a message of support to the people of Iran: it is displayed in the Iranian Ministry of Foreign Affairs' museum. In April 2013, Maradona visited the tomb of Hugo Chávez and urged Venezuelans to elect the late leader's designated successor, Nicolás Maduro, to continue the socialist leader's legacy; "Continue the struggle," Maradona said on television. Maradona attended Maduro's final campaign rally in Caracas, signing footballs and kicking them to the crowd, and presented Maduro with an Argentina jersey. Having visited Chávez's tomb with Maradona, Maduro said, "Speaking with Diego was very emotional because comandante Chávez also loved him very much." Maradona participated and danced at the electoral campaign rally during the 2018 presidential elections in Venezuela.

In October 2015, Maradona thanked Queen Elizabeth II and the Houses of Parliament in London for giving him the chance to provide "true justice" as head of an organisation designed to help young children. In a video released on his official Facebook page, Maradona confirmed he would accept their nomination for him to become Latin American director for the non-governmental organisation Football for Unity.

In March 2009, Italian officials announced that Maradona still owed the Italian government €37 million in local taxes; €23.5 million of which was accrued interest on his original debt. They reported that thus far, Maradona had paid only €42,000, two luxury watches and a set of earrings.

The American newspaper "The Houston Chronicle" wrote about Maradona:
In Argentina, Maradona is considered a sports hero. On the idolatry that exists in Argentina, former teammate Jorge Valdano said, "At the time that Maradona retired from active football, left traumatized Argentina. Maradona was more than just a great footballer. It was a special compensation factor for a country that in a few years lived several military dictatorships and social frustrations of all kinds". Valdano added that "Maradona offered to the Argentines a way out of their collective frustration, and that's why people love him. There is a divine figure."

Ever since 1986, it is common for Argentines abroad to hear Maradona's name as a token of recognition, even in remote places. The Tartan Army sing a version of the Hokey Cokey in honour of the Hand of God goal against England. In Argentina, Maradona is often talked about in terms reserved for legends. In the Argentine film "El Hijo de la Novia" ("Son of the Bride"), somebody who impersonates a Catholic priest says to a bar patron, "They idolized him and then crucified him." When a friend scolds him for taking the prank too far, the fake priest retorts, "But I was talking about Maradona." He is the subject of the film "El Camino de San Diego", though he himself only appears in archive footage.

Maradona was included in many cameos in the Argentine comic book El Cazador de Aventuras. After the closing of it, the authors started a new short-lived comic book titled "El Die", using Maradona as the main character. Maradona has had several online Flash games that are entirely dedicated to his legacy. In Rosario, Argentina, locals organized the parody religion of the "Church of Maradona". The organization reformulates many elements from Christian tradition, such as Christmas or prayers, reflecting instead details from Maradona. It had 200 founding members, and tens of thousands more have become members via the church's official web site.
Many Argentine artists performed songs in tribute to Diego, such as "Maradó" by El Potro Rodrigo, "Maradona" by Andrés Calamaro, "Para siempre Diego" (Diego forever) by Los Ratones Paranoicos, "Para verte gambetear" (For seeing you dribble) by La Guardia Hereje, "Francotirador" (Sniper) by Attaque 77, "Dale Diez" (C'mon Diez) by Julio Lacarra, "Maradona blues" by Charly García, "Santa Maradona" (Saint Maradona) by Mano Negra, "La Vida Tombola" by Manu Chao, "¿Qué es Dios?" (What is God?) by Las Pastillas del Abuelo, "Pelusa" (Fluff) by Los Cafres, among others. There are also films, such as: "Maradona, La Mano de Dios" (Maradona, the Hand of God), "El Camino de San Diego" (Saint Diego's Road), "Amando a Maradona" (Loving Maradona), "Maradona by Kusturica".

By 1982, Maradona had become one of the biggest sports stars in the world and had endorsements with many companies, including Puma and Coca-Cola, earning him $1.5 million per year in endorsements. In 1982, he featured in a World Cup commercial for Coca-Cola, and a Japanese commercial for Puma. In 2010, Maradona appeared in a commercial for the French fashion house Louis Vuitton, indulging in a game of table football with fellow World Cup winners Pelé and Zinedine Zidane. Maradona features in the music video to the 2010 World Cup song "Waka Waka" by Shakira, with footage shown of him celebrating Argentina winning the 1986 World Cup.

A 2006 television commercial for Brazilian soft drink Guaraná Antarctica portrayed Maradona as a member of the Brazil national team, including wearing the yellow jersey and singing the Brazilian national anthem with Brazilian caps Kaká and Ronaldo. Later on in the commercial he wakes up realizing it was a nightmare after having drunk too much of the drink. This generated some controversy in the Argentine media after its release (although the commercial was not supposed to air on the Argentine market, fans could see it online). Maradona replied that he has no problem in wearing the Brazilian national squad jersey despite Argentina and Brazil having a tense rivalry in football, but that he would refuse to wear the shirt of River Plate, Boca Juniors' traditional rival. There is a documented phenomenon of Brazilians being named in honour of Maradona, an example being footballer Diego Costa.

In 2017, Maradona featured as a legendary player in the football video games "FIFA 18" and "Pro Evolution Soccer 2018". In 2018, a documentary film titled "Maradona" is to be released by Academy Award and BAFTA Award winning filmmaker Asif Kapadia, director of "Amy" (on singer Amy Winehouse) and "Senna" (on motor racing driver Ayrton Senna). Kapadia states, "Maradona is the third part of a trilogy about child geniuses and fame." He added, "I was fascinated by his journey, wherever he went there were moments of incredible brilliance and drama. He was a leader, taking his teams to the very top, but also many lows in his career. He was always the little guy fighting against the system... and he was willing to do anything, to use all of his cunning and intelligence to win."



Boca Juniors

Barcelona

Napoli

Argentina Youth

Argentina





</doc>
<doc id="8487" url="https://en.wikipedia.org/wiki?curid=8487" title="David Brewster">
David Brewster

Sir David Brewster (11 December 178110 February 1868) was a British scientist, inventor, author, and academic administrator. In science he is principally remembered for his experimental work in physical optics, mostly concerned with the study of the polarization of light and including the discovery of Brewster's angle. He studied the birefringence of crystals under compression and discovered photoelasticity, thereby creating the field of optical mineralogy. For this work, William Whewell dubbed him the "father of modern experimental optics" and "the Johannes Kepler of optics."

A pioneer in photography, Brewster invented an improved stereoscope, which he called "lenticular stereoscope" and which became the first portable 3D-viewing device. He also invented the binocular camera, two types of polarimeters, the polyzonal lens, the lighthouse illuminator, and the kaleidoscope.

As a historian of science, Brewster focused on the life and work of his hero, Isaac Newton. Brewster published a detailed biography of Newton in 1831 and later became the first scientific historian to examine many of the papers in Newton's "Nachlass". Brewster also wrote numerous works of popular science, and was one of the founders of the British Science Association, of which he was elected President in 1849. He became the public face of higher education in Scotland, serving as Principal of the University of St Andrews (1837–59) and later of the University of Edinburgh (1859–68). Brewster also edited the 18-volume "Edinburgh Encyclopædia".

David Brewster was born at the Canongate in Jedburgh, Roxburghshire, to Margaret Key (1753–1790) and James Brewster (c. 1735–1815), the rector of Jedburgh Grammar School and a teacher of high reputation. David was the third of six children, two daughters and four sons: James (1777–1847), minister at Craig, Ferryden; David; George (1784–1855), minister at Scoonie, Fife; and Patrick (1788–1859), minister at the abbey church, Paisley.

At the age of 12, David was sent to the University of Edinburgh (graduating MA in 1800), being intended for the clergy. He was licensed a minister of the Church of Scotland, but only preached from the pulpit on one occasion. He had already shown a strong inclination for natural science, and this had been fostered by his intimacy with a "self-taught philosopher, astronomer and mathematician", as Sir Walter Scott called him, of great local fame, James Veitch of Inchbonny, a man who was particularly skilful in making telescopes.

Though Brewster duly finished his theological studies and was licensed to preach, his other interests distracted him from the duties of his profession. In 1799 fellow-student Henry Brougham persuaded him to study the diffraction of light. The results of his investigations were communicated from time to time in papers to the "Philosophical Transactions" of London and other scientific journals. The fact that other scientists – notably Étienne-Louis Malus and Augustin Fresnel – were pursuing the same investigations contemporaneously in France does not invalidate Brewster's claim to independent discovery, even though in one or two cases the priority must be assigned to others. A lesser-known classmate of his, Thomas Dick, also went on to become a popular astronomical writer.

The most important subjects of his inquiries can be enumerated under the following five headings:

In this line of investigation, the prime importance belongs to the discovery of

These discoveries were promptly recognised. As early as 1807 the degree of LL.D. was conferred upon Brewster by Marischal College, Aberdeen; in 1815 he was elected a Fellow of the Royal Society of London, and received the Copley Medal; in 1818 he received the Rumford Medal of the society; and in 1816 the French Institute awarded him one-half of the prize of three thousand francs for the two most important discoveries in physical science made in Europe during the two preceding years. In 1821, he was made a foreign member of the Royal Swedish Academy of Sciences, and in 1822 a Foreign Honorary Member of the American Academy of Arts and Sciences.
Among the non-scientific public, his fame spread more effectually by his invention in about 1815 of the kaleidoscope, for which there was a great demand in both the United Kingdom, France, and the United States. As a reflection of this fame, Brewster portrait was later printed in some cigar boxes. Brewster chose renowned achromatic lens developer Philip Carpenter as the sole manufacturer of the kaleidoscope in 1817. Although Brewster patented the kaleidoscope in 1817 (GB 4136), a copy of the prototype was shown to London opticians and copied before the patent was granted. As a consequence, the kaleidoscope became produced in large numbers, but yielded no direct financial benefits to Brewster. It proved to be a massive success with two hundred thousand kaleidoscopes sold in London and Paris in just three months.
An instrument of more significance, the stereoscope, which – though of much later date (1849) – along with the kaleidoscope did more than anything else to popularise his name, was not as has often been asserted the invention of Brewster. Sir Charles Wheatstone discovered its principle and applied it as early as 1838 to the construction of a cumbersome but effective instrument, in which the binocular pictures were made to combine by means of mirrors. A dogged rival of Wheatstone's, Brewster was unwilling to credit him with the invention, however, and proposed that the true author of the stereoscope was a Mr. Elliot, a "Teacher of Mathematics" from Edinburgh, who, according to Brewster, had conceived of the principles as early as 1823 and had constructed a lensless and mirrorless prototype in 1839, through which one could view drawn landscape transparencies, since photography had yet to be invented. Brewster's personal contribution was the suggestion to use prisms for uniting the dissimilar pictures; and accordingly the lenticular stereoscope may fairly be said to be his invention.

A much more valuable and practical result of Brewster's optical researches was the improvement of the British lighthouse system. Although Fresnel, who had also the satisfaction of being the first to put it into operation, perfected the dioptric apparatus independently, Brewster was active earlier in the field than Fresnel, describing the dioptric apparatus in 1812. Brewster pressed its adoption on those in authority at least as early as 1820, two years before Fresnel suggested it, and it was finally introduced into lighthouses mainly through Brewster's persistent efforts.

Although Brewster's own discoveries were important, they were not his only service to science. He began writing in 1799 as a regular contributor to the "Edinburgh Magazine", of which he acted as editor at the age of twenty. In 1807, he undertook the editorship of the newly projected "Edinburgh Encyclopædia", of which the first part appeared in 1808, and the last not until 1830. The work was strongest in the scientific department, and many of its most valuable articles were from the pen of the editor. At a later period he was one of the leading contributors to the "Encyclopædia Britannica" (seventh and eighth editions) writing, among others, the articles on electricity, hydrodynamics, magnetism, microscope, optics, stereoscope, and voltaic electricity. He was elected a member of the American Antiquarian Society in 1816.

In 1819 Brewster undertook further editorial work by establishing, in conjunction with Robert Jameson (1774–1854), the "Edinburgh Philosophical Journal", which took the place of the "Edinburgh Magazine". The first ten volumes (1819–1824) were published under the joint editorship of Brewster and Jameson, the remaining four volumes (1825–1826) being edited by Jameson alone. After parting company with Jameson, Brewster started the "Edinburgh Journal of Science" in 1824, 16 volumes of which appeared under his editorship during the years 1824–1832, with very many articles from his own pen.

He contributed around three hundred papers to the transactions of various learned societies, and few of his contemporaries wrote as much for the various reviews. In the "North British Review" alone, seventy-five articles of his appeared. A list of his larger separate works will be found below. Special mention, however, must be made of the most important of them all: his biography of Sir Isaac Newton. In 1831 he published the "Life of Sir Isaac Newton", a short popular account of the philosopher's life, in "Murray's Family Library", followed by an 1832 American edition in Harper's Family Library; but it was not until 1855 that he was able to issue the much fuller "Memoirs of the Life, Writings and Discoveries of Sir Isaac Newton", a work which embodied the results of more than 20 years' investigation of original manuscripts and other available sources.

Brewster's position as editor brought him into frequent contact with the most eminent scientific men, and he was naturally among the first to recognise the benefit that would accrue from regular communication among those in the field of science. In a review of Charles Babbage's book "Decline of Science in England" in "John Murray's Quarterly Review", he suggested the creation of "an association of our nobility, clergy, gentry and philosophers". This was taken up by various "Declinarians" and found speedy realisation in the British Association for the Advancement of Science. Its first meeting was held at York in 1831; and Brewster, along with Babbage and Sir John Herschel, had the chief part in shaping its constitution.

In the same year in which the British Association held its first meeting, Brewster received the honour of knighthood and the decoration of the Royal Guelphic Order. In 1838, he was appointed principal of the united colleges of St Salvator and St Leonard, University of St Andrews. In 1849, he acted as president of the British Association and was elected one of the eight foreign associates of the Institute of France in succession to J. J. Berzelius; and ten years later, he accepted the office of principal of the University of Edinburgh, the duties of which he discharged until within a few months of his death. In 1855, the government of France made him an Officier de la Légion d'honneur.

He was a close friend of William Henry Fox Talbot, inventor of the calotype process, who sent Brewster early examples of his work. It was Brewster who suggested Talbot only patent his process in England, initiating the development of early photography in Scotland and eventually allowing for the formation of the first photographic society in the world, the Edinburgh Calotype Club, in 1843. Brewster was a prominent member of the club until its dissolution sometime in the mid-1850s; however, his interest in photography continued, and he was elected the first President of the Photographic Society of Scotland when it was founded in 1856.

Of a high-strung and nervous temperament, Brewster was somewhat irritable in matters of controversy; but he was repeatedly subjected to serious provocation. He was a man of highly honourable and fervently religious character. In estimating his place among scientific discoverers, the chief thing to be borne in mind is that his genius was not characteristically mathematical. His method was empirical, and the laws that he established were generally the result of repeated experiment. To the ultimate explanation of the phenomena with which he dealt he contributed nothing, and it is noteworthy although he did not maintain to the end of his life the corpuscular theory he never explicitly adopted the wave theory of light. Few would dispute the verdict of James David Forbes, an editor of the eighth edition of the "Encyclopædia Britannica": "His scientific glory is different in kind from that of Young and Fresnel; but the discoverer of the law of polarization of biaxial crystals, of optical mineralogy, and of double refraction by compression, will always occupy a foremost rank in the intellectual history of the age." In addition to the various works of Brewster already mentioned, the following may be added: "Notes and Introduction to Carlyle's translation of Legendre's Elements of Geometry" (1824); "Treatise on Optics" (1831); " Letters on Natural Magic", addressed to Sir Walter Scott (1832) "The Martyrs of Science, or the Lives of Galileo, Tycho Brahe, and Kepler" (1841); "More Worlds than One" (1854).

In his "Treatise" he demonstrated that vegetal colors were related with the absorption spectra and he described for the first time the red fluorescence of chlorophyll.

Brewster's Christian beliefs stirred him to respond against the idea of the transmutation of species and the theory of evolution. In 1845 he wrote a highly critical review of the evolutionist work "Vestiges of the Natural History of Creation", in the "North British Review". which he considered to be an insult to Christian revelation and a dangerous example of materialism.

In 1862, he responded to Darwin's "On the Origin of Species" and published the article "" in "Good Words". He stated that Darwin's book combined both "interesting facts and idle fancies" which made up a "dangerous and degrading speculation". He accepted adaptive changes, but he strongly opposed Darwin's statement about the "primordial form", which he considered an offensive idea to "both the naturalist and the Christian."

Brewster married twice. His first wife, Juliet Macpherson (c. 1776–1850), was a daughter of James Macpherson (1736–1796), a probable translator of Ossian poems. They married on 31 July 1810 in Edinburgh and had four sons and a daughter:

Brewster married a second time in Nice, on 26 (or 27) March 1857, to Jane Kirk Purnell (b. 1827), the second daughter of Thomas Purnell of Scarborough. Lady Brewster famously fainted at the Oxford evolution debate of 30 June 1860. Brewster died in 1868, and was buried at Melrose Abbey, next to his first wife and second son. The physics building at Heriot-Watt University is named in his honour.

A bust of Brewster is in the Hall of Heroes of the National Wallace Monument in Stirling.

Brewster's views on the possibility of evolution of intelligence on other planets, contrasted with the opinion of William Whewell, are cited in the novel "Barchester Towers".

He appears as a minor antagonist in the 2015 video game "Assassin's Creed Syndicate" as a scientist working for the game's opposing faction. He is assassinated by one of the protagonists, Evie Frye.

A street within the Kings Buildings complex (science buildings linked to Edinburgh University) was named in his memory in the early 21st century.





 


</doc>
<doc id="8488" url="https://en.wikipedia.org/wiki?curid=8488" title="Dual-tone multi-frequency signaling">
Dual-tone multi-frequency signaling

Dual-tone multi-frequency signaling (DTMF) is an in-band telecommunication signaling system using the voice-frequency band over telephone lines between telephone equipment and other communications devices and switching centers. DTMF was first developed in the Bell System in the United States, and became known under the trademark Touch-Tone for use in push-button telephones supplied to telephone customers, starting in 1963. DTMF is standardized as ITU-T Recommendation Q.23. It is also known in the UK as "MF4".

The Touch-Tone system using a telephone keypad gradually replaced the use of rotary dial and has become the industry standard for landline and mobile service. Other multi-frequency systems are used for internal signaling within the telephone network.

Prior to the development of DTMF, telephone numbers were dialed by users with a loop-disconnect (LD) signaling, more commonly known as pulse dialing (dial pulse, DP) in the U.S. It functions by interrupting the current in the local loop between the telephone exchange and the calling party's telephone at a precise rate with a switch in the telephone that is operated by the rotary dial as it spins back to its rest position after having been rotated to each desired number. The exchange equipment responds to the dial pulses either directly by operating relays, or by storing the number in a digit register recording the dialed number. The physical distance for which this type of dialing was possible was restricted by electrical distortions and was only possible on direct metallic links between end points of a line. Placing calls over longer distances required either operator assistance or provision of special subscriber trunk dialing equipment. Operators used an earlier type of multi-frequency signaling.

Multi-frequency signaling (MF) is a group of signaling methods that use a mixture of two pure tone (pure sine wave) sounds. Various MF signaling protocols were devised by the Bell System and CCITT. The earliest of these were for in-band signaling between switching centers, where long-distance telephone operators used a 16-digit keypad to input the next portion of the destination telephone number in order to contact the next downstream long-distance telephone operator. This semi-automated signaling and switching proved successful in both speed and cost effectiveness. Based on this prior success with using MF by specialists to establish long-distance telephone calls, dual-tone multi-frequency signaling was developed for end-user signaling without the assistance of operators.

The DTMF system uses a set of eight audio frequencies transmitted in pairs to represent 16 signals, represented by the ten digits, the letters A to D, and the symbols "#" and "*". As the signals are audible tones in the voice frequency range, they can be transmitted through electrical repeaters and amplifiers, and over radio and microwave links, thus eliminating the need for intermediate operators on long-distance circuits.

AT&T described the product as "a method for pushbutton signaling from customer stations using the voice transmission path." In order to prevent consumer telephones from interfering with the MF-based routing and switching between telephone switching centers, DTMF frequencies differ from all of the pre-existing MF signaling protocols between switching centers: MF/R1, R2, CCS4, CCS5, and others that were later replaced by SS7 digital signaling. DTMF was known throughout the Bell System by the trademark "Touch-Tone". The term was first used by AT&T in commerce on July 5, 1960 and was introduced to the public on November 18, 1963, when the first push-button telephone was made available to the public. It was a registered trademark by AT&T from September 4, 1962 to March 13, 1984. It is standardized by ITU-T Recommendation Q.23. In the UK, it is also known as MF4.

Other vendors of compatible telephone equipment called the Touch-Tone feature "tone dialing" or "DTMF", or used their other trade names such as "Digitone" by Northern Electric Company in Canada.

As a method of in-band signaling, DTMF signals were also used by cable television broadcasters to indicate the start and stop times of local commercial insertion points during station breaks for the benefit of cable companies. Until out-of-band signaling equipment was developed in the 1990s, fast, unacknowledged DTMF tone sequences could be heard during the commercial breaks of cable channels in the United States and elsewhere. Previously, terrestrial television stations used DTMF tones to control remote transmitters. In IP telephony, DTMF signals can also be delivered as either in-band or out-of-band tones, or even as a part of signaling protocols, as long as both endpoints agree on a common approach to adopt.

The engineers had envisioned telephones being used to access computers and automated response systems. They consulted with companies to determine the requirements. This led to the addition of the number sign<nowiki> (#, "pound" or "diamond" in this context, "hash", "square" or "gate" in the UK, and "</nowiki>octothorpe<nowiki>" by the original engineers) and </nowiki>asterisk or "star" (*) keys as well as a group of keys for menu selection: A, B, C and D. In the end, the lettered keys were dropped from most phones, and it was many years before the two symbol keys became widely used for vertical service codes such as *67 in the United States of America and Canada to suppress caller ID.

Public payphones that accept credit cards use these additional codes to send the information from the magnetic strip.

The AUTOVON telephone system of the United States Armed Forces used these signals to assert certain privilege and priority levels when placing telephone calls. Precedence is still a feature of military telephone networks, but using number combinations. For example, entering 93 before a number is a priority call.

Present-day uses of the A, B, C and D signals on telephone networks are few, and are exclusive to network control. For example, the A key is used on some networks to cycle through different carriers at will. The A, B, C and D tones are used in radio phone patch and repeater operations to allow, among other uses, control of the repeater while connected to an active phone line.

The *, #, A, B, C and D keys are still widely used worldwide by amateur radio operators and commercial two-way radio systems for equipment control, repeater control, remote-base operations and some telephone communications systems.

DTMF signaling tones can also be heard at the start or end of some VHS (Video Home System) cassette tapes. Information on the master version of the video tape is encoded in the DTMF tone. The encoded tone provides information to automatic duplication machines, such as format, duration and volume levels, in order to replicate the original video as closely as possible.

DTMF tones are used in some caller ID systems to transfer the caller ID information, but in the United States only Bell 202 modulated FSK signaling is used to transfer the data.

The DTMF telephone keypad is laid out as a matrix of push buttons in which each row represents the low frequency component and each column represents the high frequency component of the DTMF signal. The commonly used keypad has four rows and three columns, but a fourth column is present for some applications. Pressing a key sends a combination of the row and column frequencies. For example, the "1" key produces a superimposition of a 697 Hz low tone and a 1209 Hz high tone. Initial pushbutton designs employed levers, enabling each button to activate one row and one column contact. The tones are decoded by the switching center to determine the keys pressed by the user.

DTMF was originally decoded by tuned filter banks. By the end of the 20th century, digital signal processing became the predominant technology for decoding. DTMF decoding algorithms typically use the Goertzel algorithm. As DTMF signaling is often transmitted in-band with voice or other audio signals present simultaneously, the DTMF signal definition includes strict limits for timing (minimum duration and interdigit spacing), frequency deviations, harmonics, and amplitude relation of the two components with respect to each other ("twist").

National telephone systems define other tones, outside the DTMF specification, that indicate the status of lines, equipment, or the result of calls. Such call-progress tones are often also composed of multiple frequencies and are standardized in each country. The Bell System defined them in the Precise Tone Plan.




</doc>
<doc id="8489" url="https://en.wikipedia.org/wiki?curid=8489" title="Deuterocanonical books">
Deuterocanonical books

The deuterocanonical books (from the Greek meaning "belonging to the second canon") are books and passages considered by the Roman Catholic Church to be canonical parts of the Christian Old Testament but are not present in the Hebrew Bible. The term distinguished these texts both from those that were termed protocanonical books, which were the books of the Hebrew canon; and from the apocryphal books, which were those books of Jewish origin that were known sometimes to have been read in church as scripture but which were considered not to be canonical.

The deuterocanonical books of the Old Testament are:

This 16th-century debate drew on traditions witnessing a counterpart debate in the 4th and 5th centuries; occasioned then by the awareness that the Septuagint translation of the Hebrew Bible into Greek, which the early church used as its Old Testament, included several books not recognised in the Jewish canon of the bible as it had since been defined in Rabbinic Judaism. In this debate, which had preceded the dissemination of Jerome's Vulgate version, the books in the Hebrew bible had been termed "canonical"; the additional books that were recognised by the Christian churches had been termed "ecclesiastical", and those that were considered not to be in the Bible were termed "apocryphal".

Forms of the term "deuterocanonical" were adopted after the 16th century by the Eastern Orthodox Church to denote canonical books of the Septuagint not in the Hebrew Bible (a wider selection than that adopted by the Council of Trent), and also by the Ethiopian Orthodox Tewahedo Church to apply to works believed to be of Jewish origin translated in the Old Testament of the Ethiopic Bible; a wider selection still.

Since the 16th century, most Protestant Churches have accepted only works in the Masoretic Text of the Hebrew Bible as canonical books of the Old Testament, and hence classify all deuterocanonical texts (of whichever definition) with the Apocrypha.

Deuterocanonical is a term coined in 1566 by the theologian Sixtus of Siena, who had converted to Catholicism from Judaism, to describe scriptural texts considered canonical by the Catholic Church, but which recognition was considered "secondary". For Sixtus, this term included portions of both Old and New Testaments (Sixtus considers the final chapter of the Gospel of Mark as 'deuterocanonical'); and he also applies the term to the Book of Esther from the canon of the Hebrew Bible. The term was then taken up by other writers to apply specifically those books of the Old Testament which had been recognised as canonical by the Council of Trent, but which were not in the Hebrew canon

The acceptance of some of these books among early Christians was widespread, though not universal, and surviving Bibles from the early Church always include, with varying degrees of recognition, books now called "deuterocanonical". Some say that their canonicity seems not to have been doubted in the Church until it was challenged by Jews after AD 100, sometimes postulating a hypothetical Council of Jamnia. Regional councils in the West published official canons that included these books as early as the 4th and 5th centuries.

The "Catholic Encyclopedia" states that "At Jerusalem there was a renascence, perhaps a survival, of Jewish ideas, the tendency there being distinctly unfavourable to the deuteros. St. Cyril of that see, while vindicating for the Church the right to fix the Canon, places them among the apocrypha and forbids all books to be read privately which are not read in the churches. In Antioch and Syria the attitude was more favourable. St. Epiphanius shows hesitation about the rank of the deuteros; he esteemed them, but they had not the same place as the Hebrew books in his regard. The historian Eusebius attests the widespread doubts in his time; he classes them as antilegomena, or disputed writings, and, like Athanasius, places them in a class intermediate between the books received by all and the apocrypha."

"In the Latin Church, all through the Middle Ages we find evidence of hesitation about the character of the deuterocanonicals. There is a current friendly to them, another one distinctly unfavourable to their authority and sacredness, while wavering between the two are a number of writers whose veneration for these books is tempered by some perplexity as to their exact standing, and among those we note St. Thomas Aquinas. Few are found to unequivocally acknowledge their canonicity. The prevailing attitude of Western medieval authors is substantially that of the Greek Fathers. The chief cause of this phenomenon in the West is to be sought in the influence, direct and indirect, of St. Jerome's depreciating Prologus."

Meanwhile, "the protocanonical books of the Old Testament correspond with those of the Bible of the Hebrews, and the Old Testament as received by Protestants."

Fragments of three deuterocanonical (Sirach, Tobit & Letter of Jeremiah) books have been found among the Dead Sea Scrolls found at Qumran, in addition to several partial copies of "I Enoch" and "Jubilees" from the Ethiopic deuterocanon, and Psalm 151 from the Eastern Orthodox Church deuterocanon.

"Sirach", whose Hebrew text was already known from the Cairo Geniza, has been found in two scrolls (2QSir or 2Q18, 11QPs_a or 11Q5) in Hebrew. Another Hebrew scroll of "Sirach" has been found in Masada (MasSir). Five fragments from the "Book of Tobit" have been found in Qumran written in Aramaic and in one written in Hebrew (papyri 4Q, nos. 196–200). The "Letter of Jeremiah" (or "Baruch" chapter 6) has been found in cave 7 (papyrus 7Q2) in Greek. It has been theorized by recent scholars that the Qumran library (of approximately 1,100 manuscripts found in the eleven caves at Qumran) was not entirely produced at Qumran, but may have included part of the library of the Jerusalem Temple, that may have been hidden in the caves for safekeeping at the time the Temple was destroyed by Romans in 70 AD.

Table of Deuterocanonical and Apocryphal books included in the Septuagint
The large majority of Old Testament references in the New Testament are taken from the Koine Greek Septuagint (LXX) – editions of which include the deuterocanonical books, as well as apocrypha – both of which are called collectively "anagignoskomena" (""Readable," namely worthy of reading"). No two Septuagint codices contain the same apocrypha, and the three earliest manuscripts of the LXX show uncertainty as to which books constitute the complete list of biblical books. Codex Vaticanus (B) lacks any of the books of Maccabees, while Codex Sinaiticus (Aleph) omits Baruch and the letter of Jeremiah, but includes 1 and 4 Maccabees. Codex Alexandrinus includes the Psalms of Solomon and Maccabees 1–4. All three codices include Psalm 151 in addition to the canonical 150 Psalms; and all three codices include Greek Esdras as 'Ezra A', with the canonical Ezra-Nehemiah counted as 'Ezra B'.

Greek Psalm manuscripts from the fifth century contain three New Testament "psalms": the Magnificat, the Benedictus, the Nunc dimittis from Luke's birth narrative, and the conclusion of the hymn that begins with the "Gloria in Excelsis". Beckwith states that manuscripts of anything like the capacity of Codex Alexandrinus were not used in the first centuries of the Christian era, and believes that the comprehensive codices of the Septuagint, which start appearing in the fourth century AD, are all of Christian origin.

Some deuterocanonicals appear to have been written originally in Hebrew, but the original text has long been lost. Archaeological finds discovered both Psalm 151 and the Book of Tobit in Hebrew among the Dead Sea Scrolls. The Septuagint was widely accepted and used by Greek-speaking Jews in the 1st century, even in the region of Roman Judea, and therefore naturally became the text most widely used by early Christians, who were predominantly Greek speaking.

In the New Testament, Hebrews 11:35 is understood by some as referring to an event that was recorded in one of the deuterocanonical books, 2 Maccabees. For instance, the author of Hebrews references oral tradition which spoke of an Old Testament prophet who was sawn in half in Hebrews 11:37, two verses after the 2nd Maccabees reference. Other New Testament authors such as Paul also reference or quote period literature which was familiar to the audience but that was not included in the deuterocanonical or the protocanonical Old Testament books.

The Jewish historian Josephus (c. 94 AD) speaks of there being 22 books in the canon of the Hebrew Bible, reported also by the Christian bishop Athanasius.

Origen of Alexandria (c. 240 AD) also records 22 canonical books of the Hebrew Bible cited by Eusebius; among them are the Epistle of Jeremiah and the Maccabees as canonical books.

In the Muratorian fragment (170AD) it can be found that the book of the Wisdom of Solomon was counted by the church, although it is not known if another one was accepted because the document lacks a part.

Eusebius wrote in his "Church History" (c. 324 AD) that Bishop Melito of Sardis in the 2nd century AD considered the deuterocanonical Wisdom of Solomon as part of the Old Testament and that it was considered canonical by Jews and Christians. On the other hand, the contrary claim has been made: "In the catalogue of Melito, presented by Eusebius, after Proverbs, the word Wisdom occurs, which nearly all commentators have been of opinion is only another name for the same book, and not the name of the book now called 'The Wisdom of Solomon'."

Cyril of Jerusalem (c. 350 AD), in his "Catechetical Lectures" cites as canonical books "Jeremiah one, including Baruch and Lamentations and the Epistle (of Jeremiah)".

In Athanasius's canonical books list (367 AD) the Book of Baruch and the Letter of Jeremiah are included and Esther is omitted. At the same time, he mentioned that certain other books, including four deuterocanonical books (the Wisdom of Solomon, the Wisdom of Sirach, Judith and Tobit), the book of Esther and also the Didache and The Shepherd of Hermas, while not being part of the Canon, "were appointed by the Fathers to be read". He excluded what he called "apocryphal writings" entirely.

Epiphanius of Salamis (c. 385 AD) mentions that "there are 27 books given the Jews by God, but they are counted as 22, however, like the letters of their Hebrew alphabet, because ten books are doubled and reckoned as five". He wrote in his "Panarion" that Jews had in their books the deuterocanonical Epistle of Jeremiah and Baruch, both combined with Jeremiah and Lamentations in only one book. While Wisdom of Sirach and the Wisdom of Solomon were books of disputed canonicity.

Augustine (c. 397 AD) writes in his book "On Christian Doctrine (Book II Chapter 8)" that two books of Maccabees, Tobias, Judith, Wisdom of Solomon and Ecclesiasticus are canonical books.

According to the monk Rufinus of Aquileia (c. 400 AD) the deuterocanonical books were not called canonical but ecclesiastical books. In this category Rufinus includes the Wisdom of Solomon, Sirach, Judith, Tobit and two books of Maccabees. Rufinus makes no mention of Baruch or the Epistle of Jeremiah.

Pope Innocent I (405 AD) sent a letter to the bishop of Toulouse citing deuterocanonical books as a part of the Old Testament Canon.

In later copyings of the canons of the Council of Laodicea (from 364 AD) a canon list became appended to Canon 59, likely before the mid fifth century, which affirmed that Jeremiah, and Baruch, the Lamentations, and the Epistle (of Jeremiah) were canonical, while excluding the other deuterocanonical books.

The Council of Rome (382 AD), where the Decretum Gelasianum, which is a work written by an anonymous scholar between 519 and 553, cites a list of books of Scripture presented as having been made canonical by the Council of Rome. This list mentions all the deuterocanonical books except Baruch and the Letter of Jermiah as a part of the Old Testament Canon.

The Synod of Hippo (in 393 AD), followed by the Council of Carthage (397) and the Council of Carthage (419), may be the first councils that explicitly accepted the first canon which includes a selection of books that did not appear in the Hebrew Bible; the councils were under significant influence of Augustine of Hippo, who regarded the canon as already closed.

Canon XXIV from the Synod of Hippo (393 AD) records the Scriptures which are considered canonical; the Old Testament books as follows:

On 28 August 397, the Council of Carthage (397 AD) confirmed the canon issued at Hippo; the recurrence of the Old Testament part as stated:
The Council of Carthage (419 AD) in its canon 24 lists the deuterocanonical books except Baruch and the Epistle of Jeremiah as Canonical Scripture.

The Apostolic Canons approved by the Eastern Council in Trullo in 692 AD (not recognized by the Catholic Church) states that are venerable and sacred the first three books of Maccabees and Wisdom of Sirach

In the Council of Florence (1442 AD), a list was promulgated of the books of the Bible, including the books of Judith, Esther, Wisdom, Ecclesiasticus, Baruch and two books of the Maccabees as Canonical books. 

Finally the Council of Trent (1546 AD) adopted an understanding of the canons of these previous councils as corresponding to its own list of deuterocanonical books. This understanding rested on two historical presumptions which are contested in current research; that the where these councils and synods noted the 'Book of Jeremiah', they intended the Book of Baruch to be silently understood (including the Letter of Jeremiah); and that where these synods and councils noted 'two books of Esdras', these two books were to be understood as Ezra and Nehemiah counted separately; not (as was universal in Septuagint manuscripts of the time, in the Old Latin Bible and in the works of Augustine) as 1 Esdras and Ezra-Nehemiah.

Jerome in the Vulgate's prologues describes a canon which excludes the deuterocanonical books. In his "Prologues", Jerome mentions all of the deuterocanonical and apocryphal works by name as being apocryphal or "not in the canon" except for "Prayer of Manasses" and "Baruch". He mentions "Baruch" by name in his "Prologue to Jeremiah" and notes that it is neither read nor held among the Hebrews, but does not explicitly call it apocryphal or "not in the canon". The inferior status to which the deuterocanonical books were relegated by authorities like Jerome is seen by some as being due to a rigid conception of canonicity, one demanding that a book, to be entitled to this supreme dignity, must be received by all, must have the sanction of Jewish antiquity, and must moreover be adapted not only to edification, but also to the "confirmation of the doctrine of the Church".

J. N. D. Kelly states that "Jerome, conscious of the difficulty of arguing with Jews on the basis of books they spurned and anyhow regarding the Hebrew original as authoritative, was adamant that anything not found in it was 'to be classed among the apocrypha', not in the canon; later he grudgingly conceded that the Church read some of these books for edification, but not to support doctrine."

Eventually however, Jerome's Vulgate did include the deuterocanonical books as well as apocrypha. Jerome referenced and quoted from some as scripture despite describing them as "not in the canon". Michael Barber asserts that, although Jerome was once suspicious of the apocrypha, he later viewed them as Scripture. Barber argues that this is clear from Jerome's epistles; he cites Jerome's letter to Eustochium, in which Jerome quotes Sirach 13:2. Elsewhere Jerome apparently also refers to Baruch, the Story of Susannah and Wisdom as scripture. Henry Barker states that Jerome quotes the Apocrypha with marked respect, and even as "Scripture", giving them an ecclesiastical if not a canonical position and use. Luther also wrote introductions to the books of the Apocrypha, and occasionally quoted from some to support an argument.

In his prologue to Judith, without using the word canon, Jerome mentioned that Judith was held to be scriptural by the First Council of Nicaea.

In his reply to Rufinus, Jerome affirmed that he was consistent with the choice of the church regarding which version of the deuterocanonical portions of Daniel to use, which the Jews of his day did not include:

Thus Jerome acknowledged the principle by which the canon would be settled – the judgment of the Church (at least the local churches in this case) rather than his own judgment or the judgment of Jews; though concerning translation of Daniel to Greek, he wondered why one should use the version of a translator whom he regarded as heretic and judaizer (Theodotion).

The Vulgate is also important as the touchstone of the canon concerning which parts of books are canonical. When the Council of Trent listed the books included in the canon, it qualified the books as being "entire with all their parts, as they have been used to be read in the Catholic Church, and as they are contained in the old Latin vulgate edition". This decree was clarified somewhat by Pope Pius XI on 2 June 1927, who allowed that the Comma Johanneum was open to dispute, and it was further explicated by Pope Pius XII's "Divino afflante Spiritu".

The Council of Trent also promulgated the Vulgate bible as the official Latin version of the Bible for the Roman Catholic Church. Jerome, the translator of most of this version in the early 5th century had translated the Old Testament books afresh directly from the Hebrew Bible, rather than from the Greek Septuagint, and had then explicitly rejected all Septuagint books and passages not found in the Hebrew as "apocryphal"; and although he had subsequently translated some of these texts under sufferance (marking them with an obelus), he had maintained throughout that none of these books and additions were canonical and recorded this opinion in his prologues to each book. In the medieval period however, Latin translations of the Septuagint books that Jerome had refused altogether to translate had nevertheless become widely included in the Vulgate Bible; as too had Latin versions of other texts that had never been found in the Septuagint at all. The Council of Trent therefore needed to clarify which of the Old Testament books in 16th century Vulgate bibles were in the canon; and which were not.

Table of Deuterocanonical and Apocryphal books included in the Latin Vulgate

Philip Schaff says that "the Council of Hippo in 393, and the third (according to another reckoning the sixth) Council of Carthage in 397, under the influence of Augustine, who attended both, fixed the catholic canon of the Holy Scriptures, including the Apocrypha of the Old Testament, ... This decision of the transmarine church however, was subject to ratification; and the concurrence of the Roman see it received when Innocent I and Gelasius I (AD 414) repeated the same index of biblical books. Schaff says that this canon remained undisturbed till the sixteenth century, and was sanctioned by the Council of Trent at its fourth session," although as the "Catholic Encyclopedia" reports, "in the Latin Church, all through the Middle Ages we find evidence of hesitation about the character of the deuterocanonicals... Few are found to unequivocally acknowledge their canonicity," but that the countless manuscript copies of the Vulgate produced by these ages, with a slight, probably accidental, exception, uniformly embrace the complete Roman Catholic Old Testament.

Exceptions to this narrative are Baruch and the Letter of Jeremiah, which appear in the Greek canon lists of the Council of Laodicea, Athanasius (367 AD), Cyril of Jerusalem (c. 350 AD), and Epiphanius of Salamis (c. 385 AD) but are not separately listed as canonical in the Latin accounts of the Canons of Laodicea or any other Western synods and councils, nor are specified as canonical by Innocent I and Gelasius I, nor are present in any complete Vulgate bibles earlier the 9th century; and even after that date, do not become common in the Vulgate Old Testament until the 13th century. In the Old Latin version of the bible, these two works appear to have been incorporated into the Book of Jeremiah, and Latin Fathers of the 4th century and earlier always cite their texts as being from that book. However, when Jerome translated Jeremiah afresh from the Hebrew text, which is considerably longer than the Greek Septuagint text and with chapters in a different order, he steadfastly refused to incorporate either Baruch or the Letter of Jeremiah from the Greek. As the Vulgate bible supplanted the Old Latin in western church use in subsequent centuries, so Baruch and the letter of Jeremiah are no longer treated as canonical in the works of Fathers who favoured the Vulgate; Gregory the Great, Isidore of Seville and Bede. In the 9th century these two works were reintroduced into the Vulgate bibles produced under the influence of Theodulf of Orleans, originally as additional chapters to the Vulgate book of Jeremiah. Subsequently, and especially in the Paris Bibles of the 13th century, they are found together as a single, combined book after Lamentations.

The canonical status of Greek Esdras in the Western church is less easy to track; as references to Esdras in canon lists may refer either to this book, or to Greek Ezra-Nehemiah, or both. Greek Esdras provides a free translation into Greek of the Hebrew canonical book of Ezra-Nehemiah plus chapters 35 and 36 of the Book of Chronicles with other additional matter; but with the sections specific to Nehemiah removed. In the surviving Greek pandect bibles of the 4th and 5th centuries; this text always stands as 'Esdras A' while the Greek translation of the whole of canonical Ezra-Nehemiah stands as 'Esdras B'; and the same is found in the surviving witness of the Old Latin Bible. When Latin fathers of the early church cite quotations from 'Ezra' it is overwhelmingly 'Esdras A' to which they refer; as in Augustine 'City of God' 18:36. Citations of the 'Nehemiah' sections of Old Latin 'Esdras B' are much rarer; and no Old Latin citations from the 'Ezra' sections of 'Esdras B' are known before Bede in the 8th century. Accordingly, Bogaert has proposed that all references to the 'two books of Ezra' in both Latin and Greek authorities and councils may be best understood as denoting Esdras A and Esdras B; where most previous scholars had interpreted this phrase as an early reference to Ezra and Nehemiah as separate works. In Jerome's Vulgate bible however, there is only one Book of Ezra, translating Hebrew Ezra-Nehemiah and corresponding to Greek Esdras B; Esdras A being considered by Jerome as a variant version of the Hebrew originals. In the prologue to Ezra Jerome states that 3 Esdras and 4 Esdras are apocryphal.

From the 9th century, occasional Latin Vulgate manuscripts are found in which Jerome's single Ezra text is split to form the separate books of Ezra and Nehemiah; and in the Paris bibles of the 13th century this split has become universal, with Esdras A being reintroduced as '3 Esdras' and Latin Esdras being added as '4 Esdras'. At the Council of Trent neither '3 Esdras' nor 4 Esdras were accepted as deuterocanonical books; but were eventually printed in the section of 'Apocrypha' in the Sixto-Clementine Vulgate, along with the Prayer of Manasses.

The Council of Trent in 1546 restated the list of books included in the canon as it had been set out in the Council of Florence. In respect of the deuterocanonical books this list conformed with the canon lists of Western synods of the late 4th century, other than including Baruch with the Letter of Jeremiah as a separate book, and in excluding Greek Esdras While the majority at Trent supported this decision there were participants in the minority who disagreed with accepting any other than the protocanonical books in the canon. Among the minority, at Trent, were Cardinals Seripando and Cajetan, the latter an opponent of Luther at Augsburg.

Outside the Roman Catholic Church, the term deuterocanonical is sometimes used, by way of analogy, to describe books that Eastern Orthodoxy, and Oriental Orthodoxy included in the Old Testament that are not part of the Jewish Tanakh, nor the Protestant Old Testament. Among Orthodox, the term is understood to mean that they were compiled separately from the primary canon, as explained in 2 Esdras, where Esdras is instructed to keep certain books separate and hidden.

The Eastern Orthodox Churches have traditionally included all the books of the Septuagint in their Old Testaments. The Greeks use the word "Anagignoskomena" (Ἀναγιγνωσκόμενα "readable, worthy to be read") to describe the books of the Greek Septuagint that are not present in the Hebrew Tanakh. When Orthodox theologians use the term "deuterocanonical", it is important to note that the meaning is not identical to the Roman Catholic usage. In Orthodox Christianity, deuterocanonical means that a book is part of the corpus of the Old Testament (i.e. is read during the services) but has secondary authority. In other words, deutero (second) applies to authority or witnessing power, whereas in Roman Catholicism, deutero applies to chronology (the fact that these books were confirmed later), not to authority.

The Eastern Orthodox canon includes the deuterocanonical books listed above, plus 3 Maccabees and 1 Esdras (also included in the Clementine Vulgate), while Baruch is divided from the Epistle of Jeremiah, making a total of 49 Old Testament books in contrast with the Protestant 39-book canon.

Like the Roman Catholic deuterocanonical books, these texts are integrated with the rest of the Old Testament, not printed in a separate section.

Other texts printed in Orthodox Bibles are considered of some value (like the additional Psalm 151, and the Prayer of Manasseh) or are included as an appendix (like the Greek 4 Maccabees, and the Slavonic 2 Esdras).

In the Amharic Bible used by the Ethiopian Orthodox Church (an Oriental Orthodox Church), those books of the Old Testament that are still counted as canonical, but not by all other Churches, are often set in a separate section titled ""Deeyutrokanoneekal"" (ዲዩትሮካኖኒካል), which is the same word. The Ethiopian Orthodox Deuterocanon, in addition to the standard set listed above, along with the books of Esdras and "Prayer of Minasse", also includes some books that are still held canonical by only the Ethiopian Church, including Enoch or "Henok" (I Enoch), "Kufale" (Jubilees) and 1, 2 and 3 Meqabyan (which are sometimes wrongly confused with the "Books of Maccabees").

There is a great deal of overlap between the Apocrypha section of the original 1611 King James Bible and the Catholic deuterocanon, but the two are distinct. The Apocrypha section of the original 1611 King James Bible includes, in addition to the deuterocanonical books, the following three books, which were not included in the list of the canonical books by the Council of Trent:

These books make up the Apocrypha section of the Clementine Vulgate: 3 Esdras (1 Esdras); 4 Esdras (2 Esdras); and the Prayer of Manasseh, where they are specifically described as "outside of the series of the canon". The 1609 Douai Bible includes them in an appendix, but they have not been included in English Catholic Bibles since the Challoner revision of the Douai Bible in 1750. They are found, along with the deuterocanonical books, in the Apocrypha section of certain Protestant Bibles (some versions of the King James, for example).

Using the word apocrypha (Greek: hidden away) to describe texts, although not necessarily pejorative, implies to some people that the writings in question should not be included in the canon of the Bible. This classification commingles them with certain non-canonical gospels and New Testament apocrypha. The "Style Manual for the Society of Biblical Literature" recommends the use of the term "deuterocanonical literature" instead of "Apocrypha" in academic writing.

The Thirty-nine Articles of Religion of the Church of England lists the deuterocanonical books as suitable to be read for "example of life and instruction of manners, but yet doth not apply them to establish any doctrine". The early lectionaries of the Anglican Church (as included in the Book of Common Prayer of 1662) included the deuterocanonical books amongst the cycle of readings, and passages from them were used regularly in services (such as the Kyrie Pantokrator and the Benedicite).

Readings from the deuterocanonical books are now included in most, if not all, of the modern lectionaries in the Anglican Communion, based on the Revised Common Lectionary (in turn based on the post-conciliar Roman Catholic lectionary), though alternative readings from protocanonical books are also provided.

Luther did not accept deuterocanonical books in his Old Testament, terming them "Apocrypha, that are books which are not considered equal to the Holy Scriptures, but are useful and good to read."

The Westminster Confession of Faith, a Calvinist document that serves as a systematic summary of doctrine for the Church of Scotland and other Presbyterian Churches worldwide, recognizes only the sixty-six books of the Protestant canon as authentic Scripture. Chapter 1, Article 3 of the Confession reads: "The books commonly called Apocrypha, not being of divine inspiration, are no part of the Canon of Scripture; and therefore are of no authority in the Church of God, nor to be any otherwise approved, or made use of, than other human writings."

The Belgic Confession, used in Reformed churches, devotes a section (Article 6) to "The difference between the canonical and apocryphal books" and asserts that "All which the Church may read and take instruction from, so far as they agree with the canonical books; but they are far from having such power and efficacy as that we may from their testimony confirm any point of faith or of the Christian religion; much less to detract from the authority of the other sacred books."

Judaism and most Protestant versions of the Bible exclude these books. It is commonly said that Judaism officially excluded the deuterocanonicals and the additional Greek texts listed here from their Scripture in the Council of Jamnia (c. 70–90 AD), but this claim is disputed.

The term "deuterocanonical" is sometimes used to describe the canonical antilegomena, those books of the New Testament which, like the deuterocanonicals of the Old Testament, were not universally accepted by the early Church. These books may be called the "New Testament deuterocanonicals", which are now included in the 27 books of the New Testament recognized by almost all Christians. The deuterocanonicals of the New Testament are as follows:

Luther made an attempt to remove the books of Hebrews, James, Jude and Revelation from the canon (notably, he perceived them to go against his new doctrines such as "sola gratia" and "sola fide"), but this was not generally accepted among his followers. However, these books are ordered last in the German-language Luther Bible to this day.





</doc>
<doc id="8490" url="https://en.wikipedia.org/wiki?curid=8490" title="Discus throw">
Discus throw

The discus throw () is a track and field event in which an athlete throws a heavy disc—called a discus—in an attempt to mark a farther distance than their competitors. It is an ancient sport, as demonstrated by the fifth-century-BC Myron statue, "Discobolus". Although not part of the modern pentathlon, it was one of the events of the ancient Greek pentathlon, which can be dated back to at least to 708 BC.

Discus is a routine part of most modern track-and-field meets at all levels and is a sport which is particularly iconic of the Olympic Games. The men's competition has been a part of the modern Summer Olympic Games since the first Olympic games in 1896. Images of discus throwers figured prominently in advertising for early modern Games, such as fundraising stamps for the 1896 games and for the 1920 and 1948 Summer Olympics.

The discus was re-discovered in Magdeburg, Germany, by Christian Georg Kohlrausch and his students in the 1870s. His work around the discus and the earlier throwing techniques have been published since the 1880.

The first modern athlete to throw the discus while rotating the whole body was František Janda-Suk from Bohemia (present Czech Republic). He invented this technique when studying the position of the famous statue of Discobolus. After only one year of developing the technique he gained the olympic silver in 1900.

The women's competition was added to the Olympic program in the 1928 games, although they had been competing at some national and regional levels previously.

The men's discus is a heavy lenticular disc with a weight of and diameter of , the women's discus has a weight of and diameter of .

Under IAAF (international) rules, Youth boys (16–17 years) throw the discus, the Junior men (18–19 years) throw the unique discus, and the girls/women of those ages throw the discus.

In international competition, men throw the 2 kg discus through to age 49. The discus is thrown by ages 50–59, and men age 60 and beyond throw the discus. Women throw the discus through to age 74. Starting with age 75, women throw the discus.

The typical discus has sides made of plastic, wood, fiberglass, carbon fiber or metal with a metal rim and a metal core to attain the weight. The rim must be smooth, with no roughness or finger holds. A discus with more weight in the rim produces greater angular momentum for any given spin rate, and thus more stability, although it is more difficult to throw. However, a higher rim weight, if thrown correctly, can lead to a farther throw. A solid rubber discus is sometimes used (see in the United States).

To make a throw, the competitor starts in a circle of diameter, which is recessed in a concrete pad by . The thrower typically takes an initial stance facing away from the direction of the throw. He then spins anticlockwise (for right-handers) around one and a half times through the circle to build momentum, then releases his throw. The discus must land within a 34.92-degree sector. The rules of competition for discus are virtually identical to those of shot put, except that the circle is larger, a stop board is not used and there are no form rules concerning how the discus is to be thrown.
The basic motion is a forehanded sidearm movement. The discus is spun off the index finger or the middle finger of the throwing hand. In flight the disc spins clockwise when viewed from above for a right-handed thrower, and anticlockwise for a left-handed thrower. As well as achieving maximum momentum in the discus on throwing, the discus' distance is also determined by the trajectory the thrower imparts, as well as the aerodynamic behavior of the discus. Generally, throws into a moderate headwind achieve the maximum distance. Also, a faster-spinning discus imparts greater gyroscopic stability. The technique of discus throwing is quite difficult to master and needs lots of experience to get right, thus most top throwers are 30 years old or more.

The discus technique can be broken down into phases. The purpose is to transfer from the back to the front of the throwing circle while turning through one and a half circles. The speed of delivery is high, and speed is built up during the throw (slow to fast). Correct technique involves the buildup of torque so that maximum force can be applied to the discus on delivery.

During the wind-up, weight is evenly distributed between the feet, which are about shoulder distance and not overly active. The wind-up sets the tone for the entire throw; the rhythm of the throw is very important.

Focusing on rhythm can bring about the consistency to get in the right positions that many throwers lack. Executing a sound discus throw with solid technique requires perfect balance. This is due to the throw being a linear movement combined with a one and a half rotation and an implement at the end of one arm. Thus, a good discus thrower needs to maintain balance within the circle.

For a right handed thrower, the next stage is to move the weight over the left foot. From this position the right foot is raised, and the athlete 'runs' across the circle. There are various techniques for this stage where the leg swings out to a small or great extent, some athletes turn on their left heel (e.g. Ilke Wylluda) but turning on the ball of the foot is far more common.

The aim is to land in the 'power position', the right foot should be in the center and the heel should not touch the ground at any point. The left foot should land very quickly after the right. Weight should be mostly over the back foot with as much torque as possible in the body—so the right arm is high and far back. This is very hard to achieve.
Power position.

The critical stage is the delivery of the discus, from this 'power position' the hips drive through hard, and will be facing the direction of the throw on delivery. Athletes employ various techniques to control the end-point and recover from the throw, such as fixing feet (to pretty much stop dead), or an active reverse spinning onto the left foot (e.g. Virgilijus Alekna).

Sports scientist Richard Ganslen researched the "Aerodynamics of the Discus", reporting the discus will stall at an angle of 29°.

The discus throw has been the subject of a number of well-known ancient Greek statues and Roman copies such as the Discobolus and Discophoros. The discus throw also appears repeatedly in ancient Greek mythology, featured as a means of manslaughter in the cases of Hyacinth, Crocus, Phocus, and Acrisius, and as a named event in the funeral games of Patroclus.

Discus throwers have been selected as a main motif in numerous collectors' coins. One of the recent samples is the €10 Greek Discus commemorative coin, minted in 2003 to commemorate the 2004 Summer Olympics. On the obverse of the coin a modern athlete is seen in the foreground in a half-turned position, while in the background an ancient discus thrower has been captured in a lively bending motion, with the discus high above his head, creating a vivid representation of the sport.

In U.S. high school track and field, boys typically throw a discus weighing 1.6 kg (3 lb 9 oz) and the girls throw the 1 kg (2.2 lb) women's discus. Under USATF Youth rules, boys throw the 1 kg discus between the ages of 11–14, and transition to the 1.6 kg discus as 15- to 18-year-olds. Girls throw the 1 kg discus as 11- to 18-year-olds.

Under US high school rules, if a discus hits the surrounding safety cage and is deflected into the sector, it is ruled a foul. In contrast, under IAAF, WMA, NCAA and USATF rules, it is ruled a legal throw. Additionally, under US high school rules, distances thrown are rounded down to the nearest whole inch, rather than the nearest centimetre.

US high school rules allow the use of a solid rubber discus; it is cheaper and easier to learn to throw (due to its more equal distribution of weight, as opposed to the heavy rim weight of the metal rim/core discus), but less durable.







</doc>
<doc id="8492" url="https://en.wikipedia.org/wiki?curid=8492" title="Discrete mathematics">
Discrete mathematics

Discrete mathematics is the study of mathematical structures that are fundamentally discrete rather than continuous. In contrast to real numbers that have the property of varying "smoothly", the objects studied in discrete mathematics – such as integers, graphs, and statements in logic – do not vary smoothly in this way, but have distinct, separated values. Discrete mathematics therefore excludes topics in "continuous mathematics" such as calculus and analysis. Discrete objects can often be enumerated by integers. More formally, discrete mathematics has been characterized as the branch of mathematics dealing with countable sets (sets that have the same cardinality as subsets of the natural numbers, including rational numbers but not real numbers). However, there is no exact definition of the term "discrete mathematics." Indeed, discrete mathematics is described less by what is included than by what is excluded: continuously varying quantities and related notions.

The set of objects studied in discrete mathematics can be finite or infinite. The term finite mathematics is sometimes applied to parts of the field of discrete mathematics that deals with finite sets, particularly those areas relevant to business.

Research in discrete mathematics increased in the latter half of the twentieth century partly due to the development of digital computers which operate in discrete steps and store data in discrete bits. Concepts and notations from discrete mathematics are useful in studying and describing objects and problems in branches of computer science, such as computer algorithms, programming languages, cryptography, automated theorem proving, and software development. Conversely, computer implementations are significant in applying ideas from discrete mathematics to real-world problems, such as in operations research.

Although the main objects of study in discrete mathematics are discrete objects, analytic methods from continuous mathematics are often employed as well.

In university curricula, "Discrete Mathematics" appeared in the 1980s, initially as a computer science support course; its contents were somewhat haphazard at the time. The curriculum has thereafter developed in conjunction with efforts by ACM and MAA into a course that is basically intended to develop mathematical maturity in freshmen; therefore it is nowadays a prerequisite for mathematics majors in some universities as well. Some high-school-level discrete mathematics textbooks have appeared as well. At this level, discrete mathematics is sometimes seen as a preparatory course, not unlike precalculus in this respect.

The Fulkerson Prize is awarded for outstanding papers in discrete mathematics.

The history of discrete mathematics has involved a number of challenging problems which have focused attention within areas of the field. In graph theory, much research was motivated by attempts to prove the four color theorem, first stated in 1852, but not proved until 1976 (by Kenneth Appel and Wolfgang Haken, using substantial computer assistance).

In logic, the second problem on David Hilbert's list of open problems presented in 1900 was to prove that the axioms of arithmetic are consistent. Gödel's second incompleteness theorem, proved in 1931, showed that this was not possible – at least not within arithmetic itself. Hilbert's tenth problem was to determine whether a given polynomial Diophantine equation with integer coefficients has an integer solution. In 1970, Yuri Matiyasevich proved that this could not be done.

The need to break German codes in World War II led to advances in cryptography and theoretical computer science, with the first programmable digital electronic computer being developed at England's Bletchley Park with the guidance of Alan Turing and his seminal work, On Computable Numbers. At the same time, military requirements motivated advances in operations research. The Cold War meant that cryptography remained important, with fundamental advances such as public-key cryptography being developed in the following decades. Operations research remained important as a tool in business and project management, with the critical path method being developed in the 1950s. The telecommunication industry has also motivated advances in discrete mathematics, particularly in graph theory and information theory. Formal verification of statements in logic has been necessary for software development of safety-critical systems, and advances in automated theorem proving have been driven by this need.

Computational geometry has been an important part of the computer graphics incorporated into modern video games and computer-aided design tools.

Several fields of discrete mathematics, particularly theoretical computer science, graph theory, and combinatorics, are important in addressing the challenging bioinformatics problems associated with understanding the tree of life.

Currently, one of the most famous open problems in theoretical computer science is the P = NP problem, which involves the relationship between the complexity classes P and NP. The Clay Mathematics Institute has offered a $1 million USD prize for the first correct proof, along with prizes for six other mathematical problems.

Theoretical computer science includes areas of discrete mathematics relevant to computing. It draws heavily on graph theory and mathematical logic. Included within theoretical computer science is the study of algorithms for computing mathematical results. Computability studies what can be computed in principle, and has close ties to logic, while complexity studies the time taken by computations. Automata theory and formal language theory are closely related to computability. Petri nets and process algebras are used to model computer systems, and methods from discrete mathematics are used in analyzing VLSI electronic circuits. Computational geometry applies algorithms to geometrical problems, while computer image analysis applies them to representations of images. Theoretical computer science also includes the study of various continuous computational topics.

Information theory involves the quantification of information. Closely related is coding theory which is used to design efficient and reliable data transmission and storage methods. Information theory also includes continuous topics such as: analog signals, analog coding, analog encryption.

Logic is the study of the principles of valid reasoning and inference, as well as of consistency, soundness, and completeness. For example, in most systems of logic (but not in intuitionistic logic) Peirce's law ((("P"→"Q")→"P")→"P") is a theorem. For classical logic, it can be easily verified with a truth table. The study of mathematical proof is particularly important in logic, and has applications to automated theorem proving and formal verification of software.

Logical formulas are discrete structures, as are proofs, which form finite trees or, more generally, directed acyclic graph structures (with each inference step combining one or more premise branches to give a single conclusion). The truth values of logical formulas usually form a finite set, generally restricted to two values: "true" and "false", but logic can also be continuous-valued, e.g., fuzzy logic. Concepts such as infinite proof trees or infinite derivation trees have also been studied, e.g. infinitary logic.

Set theory is the branch of mathematics that studies sets, which are collections of objects, such as {blue, white, red} or the (infinite) set of all prime numbers. Partially ordered sets and sets with other relations have applications in several areas.

In discrete mathematics, countable sets (including finite sets) are the main focus. The beginning of set theory as a branch of mathematics is usually marked by Georg Cantor's work distinguishing between different kinds of infinite set, motivated by the study of trigonometric series, and further development of the theory of infinite sets is outside the scope of discrete mathematics. Indeed, contemporary work in descriptive set theory makes extensive use of traditional continuous mathematics.

Combinatorics studies the way in which discrete structures can be combined or arranged.
Enumerative combinatorics concentrates on counting the number of certain combinatorial objects - e.g. the twelvefold way provides a unified framework for counting permutations, combinations and partitions.
Analytic combinatorics concerns the enumeration (i.e., determining the number) of combinatorial structures using tools from complex analysis and probability theory. In contrast with enumerative combinatorics which uses explicit combinatorial formulae and generating functions to describe the results, analytic combinatorics aims at obtaining asymptotic formulae.
Design theory is a study of combinatorial designs, which are collections of subsets with certain intersection properties.
Partition theory studies various enumeration and asymptotic problems related to integer partitions, and is closely related to q-series, special functions and orthogonal polynomials. Originally a part of number theory and analysis, partition theory is now considered a part of combinatorics or an independent field.
Order theory is the study of partially ordered sets, both finite and infinite.

Graph theory, the study of graphs and networks, is often considered part of combinatorics, but has grown large enough and distinct enough, with its own kind of problems, to be regarded as a subject in its own right. Graphs are one of the prime objects of study in discrete mathematics. They are among the most ubiquitous models of both natural and human-made structures. They can model many types of relations and process dynamics in physical, biological and social systems. In computer science, they can represent networks of communication, data organization, computational devices, the flow of computation, etc. In mathematics, they are useful in geometry and certain parts of topology, e.g. knot theory. Algebraic graph theory has close links with group theory. There are also continuous graphs, however for the most part research in graph theory falls within the domain of discrete mathematics.

Discrete probability theory deals with events that occur in countable sample spaces. For example, count observations such as the numbers of birds in flocks comprise only natural number values {0, 1, 2, ...}. On the other hand, continuous observations such as the weights of birds comprise real number values and would typically be modeled by a continuous probability distribution such as the normal. Discrete probability distributions can be used to approximate continuous ones and vice versa. For highly constrained situations such as throwing dice or experiments with decks of cards, calculating the probability of events is basically enumerative combinatorics.

Number theory is concerned with the properties of numbers in general, particularly integers. It has applications to cryptography and cryptanalysis, particularly with regard to modular arithmetic, diophantine equations, linear and quadratic congruences, prime numbers and primality testing. Other discrete aspects of number theory include geometry of numbers. In analytic number theory, techniques from continuous mathematics are also used. Topics that go beyond discrete objects include transcendental numbers, diophantine approximation, p-adic analysis and function fields.

Algebraic structures occur as both discrete examples and continuous examples. Discrete algebras include: boolean algebra used in logic gates and programming; relational algebra used in databases; discrete and finite versions of groups, rings and fields are important in algebraic coding theory; discrete semigroups and monoids appear in the theory of formal languages.

A function defined on an interval of the integers is usually called a sequence. A sequence could be a finite sequence from a data source or an infinite sequence from a discrete dynamical system. Such a discrete function could be defined explicitly by a list (if its domain is finite), or by a formula for its general term, or it could be given implicitly by a recurrence relation or difference equation. Difference equations are similar to a differential equations, but replace differentiation by taking the difference between adjacent terms; they can be used to approximate differential equations or (more often) studied in their own right. Many questions and methods concerning differential equations have counterparts for difference equations. For instance, where there are integral transforms in harmonic analysis for studying continuous functions or analogue signals, there are discrete transforms for discrete functions or digital signals. As well as the discrete metric there are more general discrete or finite metric spaces and finite topological spaces.

Discrete geometry and combinatorial geometry are about combinatorial properties of "discrete collections" of geometrical objects. A long-standing topic in discrete geometry is tiling of the plane. Computational geometry applies algorithms to geometrical problems.

Although topology is the field of mathematics that formalizes and generalizes the intuitive notion of "continuous deformation" of objects, it gives rise to many discrete topics; this can be attributed in part to the focus on topological invariants, which themselves usually take discrete values.
See combinatorial topology, topological graph theory, topological combinatorics, computational topology, discrete topological space, finite topological space, topology (chemistry).

Operations research provides techniques for solving practical problems in engineering, business, and other fields — problems such as allocating resources to maximize profit, or scheduling project activities to minimize risk. Operations research techniques include linear programming and other areas of optimization, queuing theory, scheduling theory, network theory. Operations research also includes continuous topics such as continuous-time Markov process, continuous-time martingales, process optimization, and continuous and hybrid control theory.

Decision theory is concerned with identifying the values, uncertainties and other issues relevant in a given decision, its rationality, and the resulting optimal decision.

Utility theory is about measures of the relative economic satisfaction from, or desirability of, consumption of various goods and services.

Social choice theory is about voting. A more puzzle-based approach to voting is ballot theory.

Game theory deals with situations where success depends on the choices of others, which makes choosing the best course of action more complex. There are even continuous games, see differential game. Topics include auction theory and fair division.

Discretization concerns the process of transferring continuous models and equations into discrete counterparts, often for the purposes of making calculations easier by using approximations. Numerical analysis provides an important example.

There are many concepts in continuous mathematics which have discrete versions, such as discrete calculus, discrete probability distributions, discrete Fourier transforms, discrete geometry, discrete logarithms, discrete differential geometry, discrete exterior calculus, discrete Morse theory, difference equations, discrete dynamical systems, and discrete vector measures.

In applied mathematics, discrete modelling is the discrete analogue of continuous modelling. In discrete modelling, discrete formulae are fit to data. A common method in this form of modelling is to use recurrence relation.

In algebraic geometry, the concept of a curve can be extended to discrete geometries by taking the spectra of polynomial rings over finite fields to be models of the affine spaces over that field, and letting subvarieties or spectra of other rings provide the curves that lie in that space. Although the space in which the curves appear has a finite number of points, the curves are not so much sets of points as analogues of curves in continuous settings. For example, every point of the form formula_1 for formula_2 a field can be studied either as formula_3, a point, or as the spectrum formula_4 of the local ring at (x-c), a point together with a neighborhood around it. Algebraic varieties also have a well-defined notion of tangent space called the Zariski tangent space, making many features of calculus applicable even in finite settings.

The time scale calculus is a unification of the theory of difference equations with that of differential equations, which has applications to fields requiring simultaneous modelling of discrete and continuous data. Another way of modeling such a situation is the notion of hybrid dynamical system.





</doc>
<doc id="8494" url="https://en.wikipedia.org/wiki?curid=8494" title="DDT">
DDT

Dichlorodiphenyltrichloroethane, commonly known as DDT, is a colorless, tasteless, and almost odorless crystalline chemical compound, an organochlorine, originally developed as an insecticide, and ultimately becoming infamous for its environmental impacts. It was first synthesized in 1874. DDT's insecticidal action was discovered by the Swiss chemist Paul Hermann Müller in 1939. DDT was used in the second half of World War II to control malaria and typhus among civilians and troops. Müller was awarded the Nobel Prize in Physiology or Medicine "for his discovery of the high efficiency of DDT as a contact poison against several arthropods" in 1948.

By October 1945, DDT was available for public sale in the United States. Although it was promoted by government and industry for use as an agricultural and household pesticide, there were also concerns about its use from the beginning. Opposition to DDT was focused by the 1962 publication of Rachel Carson's book "Silent Spring". It cataloged environmental impacts that coincided with widespread use of DDT in agriculture in the United States, and it questioned the logic of broadcasting potentially dangerous chemicals into the environment with little prior investigation of their environmental and health effects. The book claimed that DDT and other pesticides had been shown to cause cancer and that their agricultural use was a threat to wildlife, particularly birds. Its publication was a seminal event for the environmental movement and resulted in a large public outcry that eventually led, in 1972, to a ban on DDT's agricultural use in the United States. A worldwide ban on agricultural use was formalized under the Stockholm Convention on Persistent Organic Pollutants, but its limited and still-controversial use in disease vector control continues, because of its effectiveness in reducing malarial infections, balanced by environmental and other health concerns.

Along with the passage of the Endangered Species Act, the United States ban on DDT is a major factor in the comeback of the bald eagle (the national bird of the United States) and the peregrine falcon from near-extinction in the contiguous United States.

DDT is similar in structure to the insecticide methoxychlor and the acaricide dicofol. It is highly hydrophobic and nearly insoluble in water but has good solubility in most organic solvents, fats and oils. DDT does not occur naturally and is synthesised by a Friedel–Crafts hydroxyalkylation reaction between chloral () and chlorobenzene (), in the presence of an acidic catalyst. DDT has been marketed under trade names including Anofex, Cezarex, Chlorophenothane, Clofenotane, Dicophane, Dinocide, Gesarol, Guesapon, Guesarol, Gyron, Ixodex, Neocid, Neocidol and Zerdane.

Commercial DDT is a mixture of several closely–related compounds. The major component (77%) is the "p","p' " isomer (pictured above). The "o","p' " isomer (pictured to the right) is also present in significant amounts (15%). Dichlorodiphenyldichloroethylene (DDE) and dichlorodiphenyldichloroethane (DDD) make up the balance. DDE and DDD are the major metabolites and environmental breakdown products. DDT, DDE and DDD are sometimes referred to collectively as DDX.

DDT has been formulated in multiple forms, including solutions in xylene or petroleum distillates, emulsifiable concentrates, water-wettable powders, granules, aerosols, smoke candles and charges for vaporizers and lotions.

From 1950 to 1980, DDT was extensively used in agriculture – more than 40,000 tonnes each year worldwide – and it has been estimated that a total of 1.8 million tonnes have been produced globally since the 1940s. In the United States, it was manufactured by some 15 companies, including Monsanto, Ciba, Montrose Chemical Company, Pennwalt, and Velsicol Chemical Corporation. Production peaked in 1963 at 82,000 tonnes per year. More than 600,000 tonnes (1.35 billion pounds) were applied in the US before the 1972 ban. Usage peaked in 1959 at about 36,000 tonnes.

In 2009, 3,314 tonnes were produced for malaria control and visceral leishmaniasis. India is the only country still manufacturing DDT, and is the largest consumer.<ref name="DDTBP.1/2"></ref> China ceased production in 2007.

In insects, DDT opens sodium ion channels in neurons, causing them to fire spontaneously, which leads to spasms and eventual death. Insects with certain mutations in their sodium channel gene are resistant to DDT and similar insecticides. DDT resistance is also conferred by up-regulation of genes expressing cytochrome P450 in some insect species, as greater quantities of some enzymes of this group accelerate the toxin's metabolism into inactive metabolites. (The same enzyme family is up-regulated in mammals too, e.g., in response to ethanol consumption.) Genomic studies in the model genetic organism "Drosophila melanogaster" revealed that high level DDT resistance is polygenic, involving multiple resistance mechanisms.

DDT was first synthesized in 1874 by Othmar Zeidler under the supervision of Adolf von Baeyer. It was further described in 1929 in a dissertation by W. Bausch and in two subsequent publications in 1930. The insecticide properties of "multiple chlorinated aliphatic or fat-aromatic alcohols with at least one trichloromethane group" were described in a patent in 1934 by Wolfgang von Leuthold. DDT's insecticidal properties were not, however, discovered until 1939 by the Swiss scientist Paul Hermann Müller, who was awarded the 1948 Nobel Prize in Physiology and Medicine for his efforts.

DDT is the best-known of several chlorine-containing pesticides used in the 1940s and 1950s. With pyrethrum in short supply, DDT was used extensively during World War II by the Allies to control the insect vectors of typhus – nearly eliminating the disease in many parts of Europe. In the South Pacific, it was sprayed aerially for malaria and dengue fever control with spectacular effects. While DDT's chemical and insecticidal properties were important factors in these victories, advances in application equipment coupled with competent organization and sufficient manpower were also crucial to the success of these programs.

In 1945, DDT was made available to farmers as an agricultural insecticide and played a role in the final (for a time) elimination of malaria in Europe and North America.

In 1955, the World Health Organization commenced a program to eradicate malaria in countries with low to moderate transmission rates worldwide, relying largely on DDT for mosquito control and rapid diagnosis and treatment to reduce transmission. The program eliminated the disease in "North America, Europe, the former Soviet Union," and in "Taiwan, much of the Caribbean, the Balkans, parts of northern Africa, the northern region of Australia, and a large swath of the South Pacific" and dramatically reduced mortality in Sri Lanka and India.

However, failure to sustain the program, increasing mosquito tolerance to DDT, and increasing parasite tolerance led to a resurgence. In many areas early successes partially or completely reversed, and in some cases rates of transmission increased. The program succeeded in eliminating malaria only in areas with "high socio-economic status, well-organized healthcare systems, and relatively less intensive or seasonal malaria transmission".

DDT was less effective in tropical regions due to the continuous life cycle of mosquitoes and poor infrastructure. It was not applied at all in sub-Saharan Africa due to these perceived difficulties. Mortality rates in that area never declined to the same dramatic extent, and now constitute the bulk of malarial deaths worldwide, especially following the disease's resurgence as a result of resistance to drug treatments and the spread of the deadly malarial variant caused by "Plasmodium falciparum". Eradication was abandoned in 1969 and attention instead focused on controlling and treating the disease. Spraying programs (especially using DDT) were curtailed due to concerns over safety and environmental effects, as well as problems in administrative, managerial and financial implementation. Efforts shifted from spraying to the use of bednets impregnated with insecticides and other interventions.

By October 1945, DDT was available for public sale in the United States, used both as an agricultural pesticide and as a household insecticide. Although its use was promoted by government and the agricultural industry, US scientists such as FDA pharmacologist Herbert O. Calvery expressed concern over possible hazards associated with DDT as early as 1944. In 1947, Dr. Bradbury Robinson, a physician and nutritionist practicing in St. Louis, Michigan, warned of the dangers of using the pesticide DDT in agriculture. DDT had been researched and manufactured in St. Louis by the Michigan Chemical Corporation, later purchased by Velsicol Chemical Corporation, and had become an important part of the local economy. Citing research performed by Michigan State University in 1946, Robinson, a past president of the local Conservation Club, opined that: ... perhaps the greatest danger from D.D.T. is that its extensive use in farm areas is most likely to upset the natural balances, not only killing beneficial insects in great number but by bringing about the death of fish, birds, and other forms of wild life either by their feeding on insects killed by D.D.T. or directly by ingesting the poison.

As its production and use increased, public response was mixed. At the same time that DDT was hailed as part of the "world of tomorrow," concerns were expressed about its potential to kill harmless and beneficial insects (particularly pollinators), birds, fish, and eventually humans. The issue of toxicity was complicated, partly because DDT's effects varied from species to species, and partly because consecutive exposures could accumulate, causing damage comparable to large doses. A number of states attempted to regulate DDT. In the 1950s the federal government began tightening regulations governing its use. These events received little attention. Women like Dorothy Colson and Mamie Ella Plyler of Claxton, Georgia gathered evidence about DDT's effects and wrote to the Georgia Department of Public Health, the National Health Council in New York City, and other organizations.

In 1957 "The New York Times" reported an unsuccessful struggle to restrict DDT use in Nassau County, New York, and the issue came to the attention of the popular naturalist-author Rachel Carson. William Shawn, editor of "The New Yorker", urged her to write a piece on the subject, which developed into her 1962 book "Silent Spring". The book argued that pesticides, including DDT, were poisoning both wildlife and the environment and were endangering human health. "Silent Spring" was a best seller, and public reaction to it launched the modern environmental movement in the United States. The year after it appeared, President John F. Kennedy ordered his Science Advisory Committee to investigate Carson's claims. The committee's report "add[ed] up to a fairly thorough-going vindication of Rachel Carson’s Silent Spring thesis," in the words of the journal "Science", and recommended a phaseout of "persistent toxic pesticides".

DDT became a prime target of the growing anti-chemical and anti-pesticide movements, and in 1967 a group of scientists and lawyers founded the Environmental Defense Fund (EDF) with the specific goal of enacting a ban on DDT. Victor Yannacone, Charles Wurster, Art Cooley and others in the group had all witnessed bird kills or declines in bird populations and suspected that DDT was the cause. In their campaign against the chemical, EDF petitioned the government for a ban and filed lawsuits. Around this time, toxicologist David Peakall was measuring DDE levels in the eggs of peregrine falcons and California condors and finding that increased levels corresponded with thinner shells.

In response to an EDF suit, the U.S. District Court of Appeals in 1971 ordered the EPA to begin the de-registration procedure for DDT. After an initial six-month review process, William Ruckelshaus, the Agency's first Administrator rejected an immediate suspension of DDT's registration, citing studies from the EPA's internal staff stating that DDT was not an imminent danger. However, these findings were criticized, as they were performed mostly by economic entomologists inherited from the United States Department of Agriculture, who many environmentalists felt were biased towards agribusiness and understated concerns about human health and wildlife. The decision thus created controversy.

The EPA held seven months of hearings in 1971–1972, with scientists giving evidence for and against DDT. In the summer of 1972, Ruckelshaus announced the cancellation of most uses of DDT – exempting public health uses under some conditions. Immediately after the announcement, both EDF and the DDT manufacturers filed suit against EPA. Industry sought to overturn the ban, while EDF wanted a comprehensive ban. The cases were consolidated, and in 1973 the United States Court of Appeals for the District of Columbia Circuit ruled that the EPA had acted properly in banning DDT.

Some uses of DDT continued under the public health exemption. For example, in June 1979, the California Department of Health Services was permitted to use DDT to suppress flea vectors of bubonic plague. DDT continued to be produced in the United States for foreign markets until 1985, when over 300 tons were exported.

In the 1970s and 1980s, agricultural use was banned in most developed countries, beginning with Hungary in 1968 followed by Norway and Sweden in 1970, West Germany and the United States in 1972, but not in the United Kingdom until 1984. By 1991 total bans, including for disease control, were in place in at least 26 countries; for example Cuba in 1970, the US in the 1980s, Singapore in 1984, Chile in 1985 and the Republic of Korea in 1986.

The Stockholm Convention on Persistent Organic Pollutants, which took effect in 2004, put a global ban on several persistent organic pollutants, and restricted DDT use to vector control. The Convention was ratified by more than 170 countries. Recognizing that total elimination in many malaria-prone countries is currently unfeasible absent affordable/effective alternatives, the convention exempts public health use within World Health Organization (WHO) guidelines from the ban. Resolution 60.18 of the World Health Assembly commits WHO to the Stockholm Convention's aim of reducing and ultimately eliminating DDT. Malaria Foundation International states, "The outcome of the treaty is arguably better than the status quo going into the negotiations. For the first time, there is now an insecticide which is restricted to vector control only, meaning that the selection of resistant mosquitoes will be slower than before."

Despite the worldwide ban, agricultural use continued in India, North Korea, and possibly elsewhere.<ref name="DDTBP.1/2"></ref> As of 2013 an estimated 3,000 to 4,000 tons of DDT were produced for disease vector control, including 2786 tons in India. DDT is applied to the inside walls of homes to kill or repel mosquitoes. This intervention, called indoor residual spraying (IRS), greatly reduces environmental damage. It also reduces the incidence of DDT resistance. For comparison, treating of cotton during a typical U.S. growing season requires the same amount of chemical as roughly 1,700 homes.

DDT is a persistent organic pollutant that is readily adsorbed to soils and sediments, which can act both as sinks and as long-term sources of exposure affecting organisms. Depending on conditions, its soil half-life can range from 22 days to 30 years. Routes of loss and degradation include runoff, volatilization, photolysis and aerobic and anaerobic biodegradation. Due to hydrophobic properties, in aquatic ecosystems DDT and its metabolites are absorbed by aquatic organisms and adsorbed on suspended particles, leaving little DDT dissolved in the water (however, its half-life in aquatic environments is listed by the National Pesticide Information Center as 150 years). Its breakdown products and metabolites, DDE and DDD, are also persistent and have similar chemical and physical properties. DDT and its breakdown products are transported from warmer areas to the Arctic by the phenomenon of global distillation, where they then accumulate in the region's food web.

Medical researchers in 1974 found a measurable and significant difference in the presence of DDT in human milk between mothers who lived in New Brunswick and mothers who lived in Nova Scotia, "possibly because of the wider use of insecticide sprays in the past."

Because of its lipophilic properties, DDT can bioaccumulate, especially in predatory birds. DDT is toxic to a wide range of living organisms, including marine animals such as crayfish, daphnids, sea shrimp and many species of fish. DDT, DDE and DDD magnify through the food chain, with apex predators such as raptor birds concentrating more chemicals than other animals in the same environment. They are stored mainly in body fat. DDT and DDE are resistant to metabolism; in humans, their half-lives are 6 and up to 10 years, respectively. In the United States, these chemicals were detected in almost all human blood samples tested by the Centers for Disease Control in 2005, though their levels have sharply declined since most uses were banned. Estimated dietary intake has declined, although FDA food tests commonly detect it.

The chemical and its breakdown products DDE and DDD caused eggshell thinning and population declines in multiple North American and European bird of prey species. DDE-related eggshell thinning is considered a major reason for the decline of the bald eagle, brown pelican, peregrine falcon and osprey. However, birds vary in their sensitivity to these chemicals, with birds of prey, waterfowl and song birds being more susceptible than chickens and related species. Even in 2010, California condors that feed on sea lions at Big Sur that in turn feed in the Palos Verdes Shelf area of the Montrose Chemical Superfund site exhibited continued thin-shell problems, though DDT's role in the decline of the California condor is disputed.

The biological thinning mechanism is not entirely understood, but DDE appears to be more potent than DDT, and strong evidence indicates that p,p'-DDE inhibits calcium ATPase in the membrane of the shell gland and reduces the transport of calcium carbonate from blood into the eggshell gland. This results in a dose-dependent thickness reduction. Other evidence indicates that o,p'-DDT disrupts female reproductive tract development, later impairing eggshell quality. Multiple mechanisms may be at work, or different mechanisms may operate in different species.

DDT is an endocrine disruptor. It is considered likely to be a human carcinogen although the majority of studies suggest it is not directly genotoxic. DDE acts as a weak androgen receptor antagonist, but not as an estrogen. p,p'-DDT, DDT's main component, has little or no androgenic or estrogenic activity. The minor component o,p'-DDT has weak estrogenic activity.

DDT is classified as "moderately toxic" by the US National Toxicology Program (NTP) and "moderately hazardous" by WHO, based on the rat oral of 113 mg/kg. Indirect exposure is considered relatively non-toxic for humans.

Primarily through the tendency for DDT to buildup in areas of the body with high lipid content, chronic exposure can affect reproductive capabilities and the embryo or fetus.

In 2015, the International Agency for Research on Cancer classifies DDT as Group 2A "probably carcinogenic to humans". Previous assessments by the U.S. National Toxicology Program classified it as "reasonably anticipated to be a carcinogen" and by the EPA classified DDT, DDE and DDD as class B2 "probable" carcinogens; these evaluations were based mainly on animal studies. 

A 2005 Lancet review stated that occupational DDT exposure was associated with increased pancreatic cancer risk in 2 case control studies, but another study showed no DDE dose-effect association. Results regarding a possible association with liver cancer and biliary tract cancer are conflicting: workers who did not have direct occupational DDT contact showed increased risk. White men had an increased risk, but not white women or black men. Results about an association with multiple myeloma, prostate and testicular cancer, endometrial cancer and colorectal cancer have been inconclusive or generally do not support an association. A 2017 review of liver cancer studies concluded that "organochlorine pesticides, including DDT, may increase hepatocellular carcinoma risk."

A 2009 review, whose co-authors included persons engaged in DDT-related litigation, reached broadly similar conclusions, with an equivocal association with testicular cancer. Case–control studies did not support an association with leukemia or lymphoma.

The question of whether DDT or DDE are risk factors in breast cancer has not been conclusively answered. Several meta analyses of observational studies have concluded that there is no overall relationship between DDT exposure and breast cancer risk. The United States Institute of Medicine reviewed data on the association of breast cancer with DDT exposure in 2012 and concluded that a causative relationship could neither be proven nor disproven.

A 2007 case control study using archived blood samples found that breast cancer risk was increased 5-fold among women who were born prior to 1931 and who had high serum DDT levels in 1963. Reasoning that DDT use became widespread in 1945 and peaked around 1950, they concluded that the ages of 14–20 were a critical period in which DDT exposure leads to increased risk. This study, which suggests a connection between DDT exposure and breast cancer that would not be picked up by most studies, has received variable commentary in third party reviews. One review suggested that "previous studies that measured exposure in older women may have missed the critical period." The National Toxicology Program notes that while the majority of studies have not found a relationship between DDT exposure and breast cancer that positive associations have been seen in a "few studies among women with higher levels of exposure and among certain subgroups of women"

A 2015 case control study identified a link (odds ratio 3.4) between "in-utero" exposure (as estimated from archived maternal blood samples) and breast cancer diagnosis in daughters. The findings "support classification of DDT as an endocrine disruptor, a predictor of breast cancer, and a marker of high risk".

Malaria remains the primary public health challenge in many countries. In 2015, there were 214 million cases of malaria worldwide resulting in an estimated 438,000 deaths, 90% of which occurred in Africa. DDT is one of many tools to fight the disease. Its use in this context has been called everything from a "miracle weapon [that is] like Kryptonite to the mosquitoes," to "toxic colonialism".

Before DDT, eliminating mosquito breeding grounds by drainage or poisoning with Paris green or pyrethrum was sometimes successful. In parts of the world with rising living standards, the elimination of malaria was often a collateral benefit of the introduction of window screens and improved sanitation. A variety of usually simultaneous interventions represents best practice. These include antimalarial drugs to prevent or treat infection; improvements in public health infrastructure to diagnose, sequester and treat infected individuals; bednets and other methods intended to keep mosquitoes from biting humans; and vector control strategies such as larvaciding with insecticides, ecological controls such as draining mosquito breeding grounds or introducing fish to eat larvae and indoor residual spraying (IRS) with insecticides, possibly including DDT. IRS involves the treatment of interior walls and ceilings with insecticides. It is particularly effective against mosquitoes, since many species rest on an indoor wall before or after feeding. DDT is one of 12 WHO–approved IRS insecticides.

WHO's anti-malaria campaign of the 1950s and 1960s relied heavily on DDT and the results were promising, though temporary in developing countries. Experts tie malarial resurgence to multiple factors, including poor leadership, management and funding of malaria control programs; poverty; civil unrest; and increased irrigation. The evolution of resistance to first-generation drugs (e.g. chloroquine) and to insecticides exacerbated the situation. Resistance was largely fueled by unrestricted agricultural use. Resistance and the harm both to humans and the environment led many governments to curtail DDT use in vector control and agriculture. In 2006 WHO reversed a longstanding policy against DDT by recommending that it be used as an indoor pesticide in regions where malaria is a major problem.

Once the mainstay of anti-malaria campaigns, as of 2008 only 12 countries used DDT, including India and some southern African states, though the number was expected to rise.

When it was introduced in World War II, DDT was effective in reducing malaria morbidity and mortality. WHO's anti-malaria campaign, which consisted mostly of spraying DDT and rapid treatment and diagnosis to break the transmission cycle, was initially successful as well. For example, in Sri Lanka, the program reduced cases from about one million per year before spraying to just 18 in 1963 and 29 in 1964. Thereafter the program was halted to save money and malaria rebounded to 600,000 cases in 1968 and the first quarter of 1969. The country resumed DDT vector control but the mosquitoes had evolved resistance in the interim, presumably because of continued agricultural use. The program switched to malathion, but despite initial successes, malaria continued its resurgence into the 1980s.

DDT remains on WHO's list of insecticides recommended for IRS. After the appointment of Arata Kochi as head of its anti-malaria division, WHO's policy shifted from recommending IRS only in areas of seasonal or episodic transmission of malaria, to advocating it in areas of continuous, intense transmission. WHO reaffirmed its commitment to phasing out DDT, aiming "to achieve a 30% cut in the application of DDT world-wide by 2014 and its total phase-out by the early 2020s if not sooner" while simultaneously combating malaria. WHO plans to implement alternatives to DDT to achieve this goal.

South Africa continues to use DDT under WHO guidelines. In 1996, the country switched to alternative insecticides and malaria incidence increased dramatically. Returning to DDT and introducing new drugs brought malaria back under control. Malaria cases increased in South America after countries in that continent stopped using DDT. Research data showed a strong negative relationship between DDT residual house sprayings and malaria. In a research from 1993 to 1995, Ecuador increased its use of DDT and achieved a 61% reduction in malaria rates, while each of the other countries that gradually decreased its DDT use had large increases.

In some areas resistance reduced DDT's effectiveness. WHO guidelines require that absence of resistance must be confirmed before using the chemical. Resistance is largely due to agricultural use, in much greater quantities than required for disease prevention.

Resistance was noted early in spray campaigns. Paul Russell, former head of the Allied Anti-Malaria campaign, observed in 1956 that "resistance has appeared after six or seven years." Resistance has been detected in Sri Lanka, Pakistan, Turkey and Central America and it has largely been replaced by organophosphate or carbamate insecticides, "e.g." malathion or bendiocarb.

In many parts of India, DDT is ineffective. Agricultural uses were banned in 1989 and its anti-malarial use has been declining. Urban use ended. One study concluded that "DDT is still a viable insecticide in indoor residual spraying owing to its effectivity in well supervised spray operation and high excito-repellency factor."

Studies of malaria-vector mosquitoes in KwaZulu-Natal Province, South Africa found susceptibility to 4% DDT (WHO's susceptibility standard), in 63% of the samples, compared to the average of 87% in the same species caught in the open. The authors concluded that "Finding DDT resistance in the vector "An. arabiensis", close to the area where we previously reported pyrethroid-resistance in the vector "An. funestus" Giles, indicates an urgent need to develop a strategy of insecticide resistance management for the malaria control programmes of southern Africa."

DDT can still be effective against resistant mosquitoes and the avoidance of DDT-sprayed walls by mosquitoes is an additional benefit of the chemical. For example, a 2007 study reported that resistant mosquitoes avoided treated huts. The researchers argued that DDT was the best pesticide for use in IRS (even though it did not afford the most protection from mosquitoes out of the three test chemicals) because the others pesticides worked primarily by killing or irritating mosquitoes – encouraging the development of resistance. Others argue that the avoidance behavior slows eradication. Unlike other insecticides such as pyrethroids, DDT requires long exposure to accumulate a lethal dose; however its irritant property shortens contact periods. "For these reasons, when comparisons have been made, better malaria control has generally been achieved with pyrethroids than with DDT." In India outdoor sleeping and night duties are common, implying that "the excito-repellent effect of DDT, often reported useful in other countries, actually promotes outdoor transmission."

IRS is effective if at least 80% of homes and barns in a residential area are sprayed. Lower coverage rates can jeopardize program effectiveness. Many residents resist DDT spraying, objecting to the lingering smell, stains on walls, and the potential exacerbation of problems with other insect pests. Pyrethroid insecticides (e.g. deltamethrin and lambda-cyhalothrin) can overcome some of these issues, increasing participation.

A 1994 study found that South Africans living in sprayed homes have levels that are several orders of magnitude greater than others. Breast milk from South African mothers contains high levels of DDT and DDE. It is unclear to what extent these levels arise from home spraying vs food residues. Evidence indicates that these levels are associated with infant neurological abnormalities.

Most studies of DDT's human health effects have been conducted in developed countries where DDT is not used and exposure is relatively low.

Illegal diversion to agriculture is also a concern as it is difficult to prevent and its subsequent use on crops is uncontrolled. For example, DDT use is widespread in Indian agriculture, particularly mango production and is reportedly used by librarians to protect books. Other examples include Ethiopia, where DDT intended for malaria control is reportedly used in coffee production, and Ghana where it is used for fishing." The residues in crops at levels unacceptable for export have been an important factor in bans in several tropical countries. Adding to this problem is a lack of skilled personnel and management.

A few people and groups have argued that limitations on DDT use for public health purposes have caused unnecessary morbidity and mortality from vector-borne diseases, with some claims of malaria deaths ranging as high as the hundreds of thousands and millions. Robert Gwadz of the US National Institutes of Health said in 2007, "The ban on DDT may have killed 20 million children." These arguments were rejected as "outrageous" by former WHO scientist Socrates Litsios. May Berenbaum, University of Illinois entomologist, says, "to blame environmentalists who oppose DDT for more deaths than Hitler is worse than irresponsible." 
Criticisms of a DDT "ban" often specifically reference the 1972 United States ban (with the erroneous implication that this constituted a worldwide ban and prohibited use of DDT in vector control). Reference is often made to "Silent Spring," even though Carson never pushed for a DDT ban. John Quiggin and Tim Lambert wrote, "the most striking feature of the claim against Carson is the ease with which it can be refuted."

Investigative journalist Adam Sarvana and others characterize these notions as "myths" promoted principally by Roger Bate of the pro-DDT advocacy group Africa Fighting Malaria (AFM).

Organophosphate and carbamate insecticides, "e.g." malathion and bendiocarb, respectively, are more expensive than DDT per kilogram and are applied at roughly the same dosage. Pyrethroids such as deltamethrin are also more expensive than DDT, but are applied more sparingly (0.02–0.3 g/m vs 1–2 g/m), so the net cost per house is about the same.

Before DDT, malaria was successfully eliminated or curtailed in several tropical areas by removing or poisoning mosquito breeding grounds and larva habitats, for example by eliminating standing water. These methods have seen little application in Africa for more than half a century. According to CDC, such methods are not practical in Africa because ""Anopheles gambiae", one of the primary vectors of malaria in Africa, breeds in numerous small pools of water that form due to rainfall ... It is difficult, if not impossible, to predict when and where the breeding sites will form, and to find and treat them before the adults emerge."

The relative effectiveness of IRS versus other malaria control techniques (e.g. bednets or prompt access to anti-malarial drugs) varies and is dependent on local conditions.

A WHO study released in January 2008 found that mass distribution of insecticide-treated mosquito nets and artemisinin–based drugs cut malaria deaths in half in malaria-burdened Rwanda and Ethiopia. IRS with DDT did not play an important role in mortality reduction in these countries.

Vietnam has enjoyed declining malaria cases and a 97% mortality reduction after switching in 1991 from a poorly funded DDT-based campaign to a program based on prompt treatment, bednets and pyrethroid group insecticides.

In Mexico, effective and affordable chemical and non-chemical strategies were so successful that the Mexican DDT manufacturing plant ceased production due to lack of demand.

A review of fourteen studies in sub-Saharan Africa, covering insecticide-treated nets, residual spraying, chemoprophylaxis for children, chemoprophylaxis or intermittent treatment for pregnant women, a hypothetical vaccine and changing front–line drug treatment, found decision making limited by the lack of information on the costs and effects of many interventions, the small number of cost-effectiveness analyses, the lack of evidence on the costs and effects of packages of measures and the problems in generalizing or comparing studies that relate to specific settings and use different methodologies and outcome measures. The two cost-effectiveness estimates of DDT residual spraying examined were not found to provide an accurate estimate of the cost-effectiveness of DDT spraying; the resulting estimates may not be good predictors of cost-effectiveness in current programs.

However, a study in Thailand found the cost per malaria case prevented of DDT spraying (US$1.87) to be 21% greater than the cost per case prevented of lambda-cyhalothrin–treated nets (US$1.54), casting some doubt on the assumption that DDT was the most cost-effective measure. The director of Mexico's malaria control program found similar results, declaring that it was 25% cheaper for Mexico to spray a house with synthetic pyrethroids than with DDT. However, another study in South Africa found generally lower costs for DDT spraying than for impregnated nets.

A more comprehensive approach to measuring cost-effectiveness or efficacy of malarial control would not only measure the cost in dollars, as well as the number of people saved, but would also consider ecological damage and negative human health impacts. One preliminary study found that it is likely that the detriment to human health approaches or exceeds the beneficial reductions in malarial cases, except perhaps in epidemics. It is similar to the earlier study regarding estimated theoretical infant mortality caused by DDT and subject to the criticism also mentioned earlier.

A study in the Solomon Islands found that "although impregnated bed nets cannot entirely replace DDT spraying without substantial increase in incidence, their use permits reduced DDT spraying."

A comparison of four successful programs against malaria in Brazil, India, Eritrea and Vietnam does not endorse any single strategy but instead states, "Common success factors included conducive country conditions, a targeted technical approach using a package of effective tools, data-driven decision-making, active leadership at all levels of government, involvement of communities, decentralized implementation and control of finances, skilled technical and managerial capacity at national and sub-national levels, hands-on technical and programmatic support from partner agencies, and sufficient and flexible financing."

DDT resistant mosquitoes have generally proved susceptible to pyrethroids. Thus far, pyrethroid resistance in "Anopheles" has not been a major problem.









</doc>
<doc id="8495" url="https://en.wikipedia.org/wiki?curid=8495" title="Data set">
Data set

A data set (or dataset) is a collection of data. Most commonly a data set corresponds to the contents of a single database table, or a single statistical data matrix, where every column of the table represents a particular variable, and each row corresponds to a given member of the data set in question. The data set lists values for each of the variables, such as height and weight of an object, for each member of the data set. Each value is known as a datum. The data set may comprise data for one or more members, corresponding to the number of rows. The term data set may also be used more loosely, to refer to the data in a collection of closely related tables, corresponding to a particular experiment or event. An example of this type is the data sets collected by space agencies performing experiments with instruments aboard space probes. Data sets that are so large that traditional data processing applications are inadequate to deal with them are known as big data.

In the open data discipline, data set is the unit to measure the information released in a public open data repository. The European Open Data portal aggregates more than half a million data sets. In this field other definitions have been proposed but currently there is not an official one. Some other issues (real-time data sources, non-relational data sets, etc.) increases the difficulty to reach a consensus about it.

Several characteristics define a data set's structure and properties. These include the number and types of the attributes or variables, and various statistical measures applicable to them, such as standard deviation and kurtosis.

The values may be numbers, such as real numbers or integers, for example representing a person's height in centimeters, but may also be nominal data (i.e., not consisting of numerical values), for example representing a person's ethnicity. More generally, values may be of any of the kinds described as a level of measurement. For each variable, the values are normally all of the same kind. However, there may also be "missing values", which must be indicated in some way.

In statistics, data sets usually come from actual observations obtained by sampling a statistical population, and each row corresponds to the observations on one element of that population. Data sets may further be generated by algorithms for the purpose of testing certain kinds of software. Some modern statistical analysis software such as SPSS still present their data in the classical data set fashion. If data is missing or suspicious an imputation method may be used to complete a data set.

Several classic data sets have been used extensively in the statistical literature:




</doc>
<doc id="8496" url="https://en.wikipedia.org/wiki?curid=8496" title="DMA">
DMA

DMA may refer to:












</doc>
<doc id="8498" url="https://en.wikipedia.org/wiki?curid=8498" title="Diagnostic and Statistical Manual of Mental Disorders">
Diagnostic and Statistical Manual of Mental Disorders

The Diagnostic and Statistical Manual of Mental Disorders (DSM) is published by the American Psychiatric Association (APA) and offers a common language and standard criteria for the classification of mental disorders. It is used, or relied upon, by clinicians, researchers, psychiatric drug regulation agencies, health insurance companies, pharmaceutical companies, the legal system, and policy makers together with alternatives such as the , produced by the WHO.

The DSM is now in its fifth edition, the DSM-5, published on May 18, 2013. The DSM evolved from systems for collecting census and psychiatric hospital statistics, and from a United States Army manual. Revisions since its first publication in 1952 have incrementally added to the total number of mental disorders, although also removing those no longer considered to be mental disorders.

The International Classification of Diseases (ICD) is the other common manual for mental disorders. It is distinguished from the DSM in it covers health as a whole. While the DSM is the most popular diagnostic system for mental disorders in the US, the ICD is used more in Europe and other parts of the world, giving it a far larger reach than the DSM. The DSM-IV-TR (4th. ed.) contains specific codes allowing comparisons between the DSM and the ICD manuals, which may not systematically match because revisions are not simultaneously coordinated. Though recent editions of the DSM and ICD have become similar due to collaborative agreements, each one contains information absent from the other. 

While the DSM received praise for standardizing psychiatric diagnostic categories and criteria, it also generated controversy and criticism. Critics, including the National Institute of Mental Health, argue the DSM represents an unscientific and subjective system. There are ongoing issues concerning the validity and reliability of the diagnostic categories; the reliance on superficial symptoms; the use of artificial dividing lines between categories and from "normality"; possible cultural bias; and medicalization of human distress. The publication of the DSM, with tightly guarded copyrights, now makes APA over $5 million a year, historically totaling over $100 million.

Many mental health professionals use the manual to determine and help communicate a patient's diagnosis after an evaluation; hospitals, clinics, and insurance companies in the US also often require a DSM diagnosis for all patients treated. The DSM can be used clinically in this way, and to categorize patients using diagnostic criteria for research purposes. Studies done on specific disorders often recruit patients whose symptoms match the criteria listed in the DSM for that disorder. An international survey of psychiatrists in sixty-six countries compared the use of the ICD-10 and DSM-IV; it found the former was more often used for clinical diagnosis while the latter was more valued for research.

DSM-5, and the abbreviations for all previous editions, are registered trademarks owned by the APA.

The initial impetus for developing a classification of mental disorders in the United States was the need to collect statistical information. The first official attempt was the 1840 census, which used a single category: "idiocy/insanity". Three years later, the American Statistical Association made an official protest to the U.S. House of Representatives, stating that "the most glaring and remarkable errors are found in the statements respecting nosology, prevalence of insanity, blindness, deafness, and dumbness, among the people of this nation", pointing out that in many towns African-Americans were all marked as insane, and calling the statistics essentially useless.

The Association of Medical Superintendents of American Institutions for the Insane was formed in 1844, changing its name in 1892 to the American Medico-Psychological Association, and in 1921 to the present American Psychiatric Association (APA).

Edward Jarvis and later Francis Amasa Walker helped expand the census, from two volumes in 1870 to twenty-five volumes in 1880. Frederick H. Wines was appointed to write a 582-page volume called "Report on the Defective, Dependent, and Delinquent Classes of the Population of the United States, As Returned at the Tenth Census (June 1, 1880)" (published 1888). Wines used seven categories of mental illness: dementia, dipsomania (uncontrollable craving for alcohol), epilepsy, mania, melancholia, monomania and paresis. These categories were also adopted by the Association.

In 1917, together with the National Commission on Mental Hygiene (now Mental Health America), the APA developed a new guide for mental hospitals called the "Statistical Manual for the Use of Institutions for the Insane". This included twenty-two diagnoses and would be revised several times by the APA over the years. Along with the New York Academy of Medicine, the APA also provided the psychiatric nomenclature subsection of the US general medical guide, the "Standard Classified Nomenclature of Disease", referred to as the "Standard".

World War II saw the large-scale involvement of US psychiatrists in the selection, processing, assessment, and treatment of soldiers. This moved the focus away from mental institutions and traditional clinical perspectives. A committee headed by psychiatrist Brigadier General William C. Menninger developed a new classification scheme called Medical 203, that was issued in 1943 as a War Department Technical Bulletin under the auspices of the Office of the Surgeon General. The foreword to the DSM-I states the US Navy had itself made some minor revisions but "the Army established a much more sweeping revision, abandoning the basic outline of the Standard and attempting to express present day concepts of mental disturbance. This nomenclature eventually was adopted by all Armed Forces", and "assorted modifications of the Armed Forces nomenclature [were] introduced into many clinics and hospitals by psychiatrists returning from military duty." The Veterans Administration also adopted a slightly modified version of Medical 203.

In 1949, the World Health Organization published the sixth revision of the International Statistical Classification of Diseases (ICD), which included a section on mental disorders for the first time. The foreword to DSM-1 states this "categorized mental disorders in rubrics similar to those of the Armed Forces nomenclature." An APA Committee on Nomenclature and Statistics was empowered to develop a version specifically for use in the United States, to standardize the diverse and confused usage of different documents. In 1950, the APA committee undertook a review and consultation. It circulated an adaptation of Medical 203, the VA system, and the Standard's Nomenclature to approximately 10% of APA members. 46% replied, of which 93% approved, and after some further revisions (resulting in its being called DSM-I), the Diagnostic and Statistical Manual of Mental Disorders was approved in 1951 and published in 1952. The structure and conceptual framework were the same as in Medical 203, and many passages of text were identical. The manual was 130 pages long and listed 106 mental disorders. These included several categories of "personality disturbance", generally distinguished from "neurosis" (nervousness, egodystonic).

In 1952, the APA listed homosexuality in the DSM as a sociopathic personality disturbance. "", a large-scale 1962 study of homosexuality by Irving Bieber and other authors, was used to justify inclusion of the disorder as a supposed pathological hidden fear of the opposite sex caused by traumatic parent–child relationships. This view was very influential in the medical profession. In 1956, however, the psychologist Evelyn Hooker performed a study comparing the happiness and well-adjusted nature of self-identified homosexual men with heterosexual men and found no difference. Her study stunned the medical community and made her a heroine to many gay men and lesbians, but homosexuality remained in the DSM until May 1974.

In the 1960s, there were many challenges to the concept of mental illness itself. These challenges came from psychiatrists like Thomas Szasz, who argued mental illness was a myth used to disguise moral conflicts; from sociologists such as Erving Goffman, who said mental illness was another example of how society labels and controls non-conformists; from behavioural psychologists who challenged psychiatry's fundamental reliance on unobservable phenomena; and from gay rights activists who criticised the APA's listing of homosexuality as a mental disorder. A study published in "Science" by Rosenhan received much publicity and was viewed as an attack on the efficacy of psychiatric diagnosis.

Although the APA was closely involved in the next significant revision of the mental disorder section of the ICD (version 8 in 1968), it decided to go ahead with a revision of the DSM. It was published in 1968, listed 182 disorders, and was 134 pages long. It was quite similar to the DSM-I. The term "reaction" was dropped, but the term "neurosis" was retained. Both the DSM-I and the DSM-II reflected the predominant psychodynamic psychiatry, although they also included biological perspectives and concepts from Kraepelin's system of classification. Symptoms were not specified in detail for specific disorders. Many were seen as reflections of broad underlying conflicts or maladaptive reactions to life problems, rooted in a distinction between neurosis and psychosis (roughly, anxiety/depression broadly in touch with reality, or hallucinations/delusions appearing disconnected from reality). Sociological and biological knowledge was incorporated, in a model that did not emphasize a clear boundary between normality and abnormality. The idea that personality disorders did not involve emotional distress was discarded.

An influential 1974 paper by Robert Spitzer and Joseph L. Fleiss demonstrated the second edition of the DSM (DSM-II) was an unreliable diagnostic tool. They found different practitioners using the DSM-II rarely agreed when diagnosing patients with similar problems. In reviewing previous studies of eighteen major diagnostic categories, Fleiss and Spitzer concluded "there are no diagnostic categories for which reliability is uniformly high. Reliability appears to be only satisfactory for three categories: mental deficiency, organic brain syndrome (but not its subtypes), and alcoholism. The level of reliability is no better than fair for psychosis and schizophrenia and is poor for the remaining categories".

As described by Ronald Bayer, a psychiatrist and gay rights activist, specific protests by gay rights activists against the APA began in 1970, when the organization held its convention in San Francisco. The activists disrupted the conference by interrupting speakers and shouting down and ridiculing psychiatrists who viewed homosexuality as a mental disorder. In 1971, gay rights activist Frank Kameny worked with the Gay Liberation Front collective to demonstrate against the APA's convention. At the 1971 conference, Kameny grabbed the microphone and yelled: "Psychiatry is the enemy incarnate. Psychiatry has waged a relentless war of extermination against us. You may take this as a declaration of war against you."

This activism occurred in the context of a broader anti-psychiatry movement that had come to the fore in the 1960s and was challenging the legitimacy of psychiatric diagnosis. Anti-psychiatry activists protested at the same APA conventions, with some shared slogans and intellectual foundations.

Presented with data from researchers such as Alfred Kinsey and Evelyn Hooker, the sixth printing of the DSM-II, in 1974, no longer listed homosexuality as a category of disorder. After a vote by the APA trustees in 1973, and confirmed by the wider APA membership in 1974, the diagnosis was replaced with the category of "sexual orientation disturbance".

In 1974, the decision to create a new revision of the DSM was made, and Robert Spitzer was selected as chairman of the task force. The initial impetus was to make the DSM nomenclature consistent with the International Statistical Classification of Diseases and Related Health Problems (ICD), published by the World Health Organization. The revision took on a far wider mandate under the influence and control of Spitzer and his chosen committee members. One goal was to improve the uniformity and validity of psychiatric diagnosis in the wake of a number of critiques, including the famous Rosenhan experiment. There was also a need to standardize diagnostic practices within the US and with other countries after research showed psychiatric diagnoses differed between Europe and the US. The establishment of these criteria was an attempt to facilitate the pharmaceutical regulatory process.

The criteria adopted for many of the mental disorders were taken from the Research Diagnostic Criteria (RDC) and Feighner Criteria, which had just been developed by a group of research-orientated psychiatrists based primarily at Washington University in St. Louis and the New York State Psychiatric Institute. Other criteria, and potential new categories of disorder, were established by consensus during meetings of the committee, as chaired by Spitzer. A key aim was to base categorization on colloquial English descriptive language (which would be easier to use by federal administrative offices), rather than assumptions of cause, although its categorical approach assumed each particular pattern of symptoms in a category reflected a particular underlying pathology (an approach described as "neo-Kraepelinian"). The psychodynamic or physiologic view was abandoned, in favor of a regulatory or legislative model. A new "multiaxial" system attempted to yield a picture more amenable to a statistical population census, rather than a simple diagnosis. Spitzer argued "mental disorders are a subset of medical disorders" but the task force decided on the DSM statement: "Each of the mental disorders is conceptualized as a clinically significant behavioral or psychological syndrome." The personality disorders were placed on axis II along with mental retardation.

The first draft of the DSM-III was prepared within a year. It introduced many new categories of disorder, while deleting or changing others. A number of the unpublished documents discussing and justifying the changes have recently come to light. Field trials sponsored by the U.S. National Institute of Mental Health (NIMH) were conducted between 1977 and 1979 to test the reliability of the new diagnoses. A controversy emerged regarding deletion of the concept of neurosis, a mainstream of psychoanalytic theory and therapy but seen as vague and unscientific by the DSM task force. Faced with enormous political opposition, the DSM-III was in serious danger of not being approved by the APA Board of Trustees unless "neurosis" was included in some capacity; a political compromise reinserted the term in parentheses after the word "disorder" in some cases. Additionally, the diagnosis of ego-dystonic homosexuality replaced the DSM-II category of "sexual orientation disturbance".

Finally published in 1980, the DSM-III was 494 pages and listed 265 diagnostic categories. It rapidly came into widespread international use and has been termed a revolution or transformation in psychiatry. However, Robert Spitzer later criticized his own work on it in an interview with Adam Curtis, saying it led to the medicalization of 20-30 percent of the population who may not have had any serious mental problems.

When DSM-III was published, the developers made extensive claims about the reliability of the radically new diagnostic system they had devised, which relied on data from special field trials. However, according to a 1994 article by Stuart A. Kirk:

Twenty years after the reliability problem became the central focus of DSM-III, there is still not a single multi-site study showing that DSM (any version) is routinely used with high reliably by regular mental health clinicians. Nor is there any credible evidence that any version of the manual has greatly increased its reliability beyond the previous version. There are important methodological problems that limit the generalisability of most reliability studies. Each reliability study is constrained by the training and supervision of the interviewers, their motivation and commitment to diagnostic accuracy, their prior skill, the homogeneity of the clinical setting in regard to patient mix and base rates, and the methodological rigor achieved by the investigator…
In 1987, the DSM-III-R was published as a revision of the DSM-III, under the direction of Spitzer. Categories were renamed and reorganized, and significant changes in criteria were made. Six categories were deleted while others were added. Controversial diagnoses, such as pre-menstrual dysphoric disorder and masochistic personality disorder, were considered and discarded. "Ego-dystonic homosexuality" was also removed and was largely subsumed under "sexual disorder not otherwise specified", which can include "persistent and marked distress about one's sexual orientation." Altogether, the DSM-III-R contained 292 diagnoses and was 567 pages long. Further efforts were made for the diagnoses to be purely descriptive, although the introductory text stated for at least some disorders, "particularly the Personality Disorders, the criteria require much more inference on the part of the observer" (p. xxiii).

In 1994, DSM-IV was published, listing 410 disorders in 886 pages. The task force was chaired by Allen Frances. A steering committee of twenty-seven people was introduced, including four psychologists. The steering committee created thirteen work groups of five to sixteen members. Each work group had about twenty advisers. The work groups conducted a three-step process: first, each group conducted an extensive literature review of their diagnoses; then, they requested data from researchers, conducting analyses to determine which criteria required change, with instructions to be conservative; finally, they conducted multicenter field trials relating diagnoses to clinical practice. A major change from previous versions was the inclusion of a clinical significance criterion to almost half of all the categories, which required symptoms cause "clinically significant distress or impairment in social, occupational, or other important areas of functioning". Some personality disorder diagnoses were deleted or moved to the appendix.

A "text revision" of the DSM-IV, known as the DSM-IV-TR, was published in 2000. The diagnostic categories and the vast majority of the specific criteria for diagnosis were unchanged. The text sections giving extra information on each diagnosis were updated, as were some of the diagnostic codes to maintain consistency with the ICD. The DSM-IV-TR was organized into a five-part axial system. The first axis incorporated clinical disorders. The second axis covered personality disorders and intellectual disabilities. The remaining axes covered medical, psychosocial, environmental, and childhood factors functionally necessary to provide diagnostic criteria for health care assessments.

The DSM-IV-TR characterizes a mental disorder as "a clinically significant behavioral or psychological syndrome or pattern that occurs in an individual [which] is associated with present distress… or disability… or with a significant increased risk of suffering." It also notes "no definition adequately specifies precise boundaries for the concept of 'mental disorder'… different situations call for different definitions". It states "there is no assumption that each category of mental disorder is a completely discrete entity with absolute boundaries dividing it from other mental disorders or from no mental disorder" (APA, 1994 and 2000).

The DSM-IV is a categorical classification system. The categories are prototypes, and a patient with a close approximation to the prototype is said to have that disorder. DSM-IV states, "there is no assumption each category of mental disorder is a completely discrete entity with absolute boundaries" but isolated, low-grade and non-criterion (unlisted for a given disorder) symptoms are not given importance. Qualifiers are sometimes used, for example mild, moderate or severe forms of a disorder. For nearly half the disorders, symptoms must be sufficient to cause "clinically significant distress or impairment in social, occupational, or other important areas of functioning", although DSM-IV-TR removed the distress criterion from tic disorders and several of the paraphilias due to their egosyntonic nature. Each category of disorder has a numeric code taken from the ICD coding system, used for health service (including insurance) administrative purposes.

With the advent of the DSM-5 in 2013, the APA eliminated the longstanding multiaxial system for mental disorders.

Previously, the DSM-IV organized each psychiatric diagnosis into five dimensions (axes) relating to different aspects of disorder or disability:
Mental/Psychiatric/Behavioral/Learning conditions include, but are not limited to: depression, anxiety disorders, bipolar disorder, ADHD, autism spectrum disorders, anorexia nervosa, bulimia nervosa, and schizophrenia.

Personality Disorders include, but are not limited to: paranoid personality disorder, schizoid personality disorder, schizotypal personality disorder, borderline personality disorder, antisocial personality disorder, narcissistic personality disorder, histrionic personality disorder, avoidant personality disorder, dependent personality disorder, obsessive-compulsive personality disorder; and organic intellectual disabilities.

Common medical/physical conditions or diseases that may result in and/or exacerbate some of the aforementioned mental/psychiatric conditions OR that may be aggravated by the aforementioned mental/psychiatric conditions include, but are not limited to: brain injuries, terminal diseases, pregnancy, cancer, epilepsy, idiopathic physiological conditions and virtually any other conditions, ailments and/or injuries which may affect the patient's mental health.. Many Biopsychosocial Assessments incorporate multiple factors that adversely affect the patient's, client's and/or subject's overall well-being and homeostasis.

Typical psychosocial influences that are usually listed as having negative impact on life, mentality and health include, but are not limited to: Environmental factors of dysfunction such as those experienced within home, school and work; Social factors such as issues with drug use (not diagnosed), enabling friends and conflicts with coworkers; Family complications such as divorce, social service involvement and court ordered placements; Various stressors such as recent accident, natural disaster and other traumatic occurrences (i.e. assault, death, abuse); Financial problems such as bankruptcy, job loss and debts; and service needs such as lack of medical insurance, inability to find adequate treatment and inaccessibility to necessary state and federal programs.

The DSM-IV does not specifically cite its sources, but there are four volumes of "sourcebooks" intended to be APA's documentation of the guideline development process and supporting evidence, including literature reviews, data analyses and field trials. The Sourcebooks have been said to provide important insights into the character and quality of the decisions that led to the production of DSM-IV, and hence the scientific credibility of contemporary psychiatric classification.

The fifth edition of the Diagnostic and Statistical Manual of Mental Disorders (DSM), the DSM-5, was approved by the Board of Trustees of the APA on December 1, 2012. Published on May 18, 2013, the DSM-5 contains extensively revised diagnoses and, in some cases, broadens diagnostic definitions while narrowing definitions in other cases. The DSM-5 is the first major edition of the manual in twenty years.

A significant change in the fifth edition is the deletion of the subtypes of schizophrenia (paranoid, disorganized, catatonic, undifferentiated and residual).

The deletion of the subsets of autistic spectrum disorder (namely, Asperger's syndrome, classic autism, Rett syndrome, childhood disintegrative disorder and pervasive developmental disorder not otherwise specified) was also implemented, with specifiers with regard to intensity (mild, moderate and severe). Severity is based on social communication impairments and restricted, repetitive patterns of behaviour, with three levels: 1 (requiring support), 2 (requiring substantial support) and 3 (requiring very substantial support).

During the revision process, the APA website periodically listed several sections of the DSM-5 for review and discussion.

Beginning with the fifth edition, it is intended diagnostic guidelines revisions will be added more often to keep up with research in the field. It is notable the DSM-5 is identified with Arabic rather than Roman numerals. Beginning with DSM-5, the American Psychiatric Association will use decimals to identify incremental updates (e.g., DSM-5.1, DSM-5.2) and whole numbers for new editions (e.g., DSM-5, DSM-6), similar to the scheme used for software versioning.

The revisions of the DSM from the 3rd Edition forward have been mainly concerned with diagnostic reliability—the degree to which different diagnosticians agree on a diagnosis. It was argued{Henrik Walter} that a science of psychiatry can only advance if diagnosis is reliable. If clinicians and researchers frequently disagree about the diagnosis of a patient, then research into the causes and effective treatments of those disorders cannot advance. Hence, diagnostic reliability was a major concern of DSM-III. When the diagnostic reliability problem was thought to be solved, subsequent editions of the DSM were concerned mainly with "tweaking" the diagnostic criteria. Unfortunately, neither the issue of reliability or validity was settled. However, most psychiatric education post DSM-III focused on issues of treatment—especially drug treatment—and less on diagnostic concerns. In fact, Thomas R. Insel, M.D., Director of the NIMH, stated in 2013 that the agency would no longer fund research projects that rely exclusively on DSM criteria due to its lack of validity. Field trials of DSM-5 brought the debate of reliability back into the limelight as some disorders showed poor reliability. For example, major depressive disorder, a common mental illness, had a poor reliability kappa statistic of 0.28, indicating that clinicians frequently disagreed on this diagnosis in the same patients. The most reliable diagnosis was major neurocognitive disorder with a kappa of 0.78.

By design, the DSM is primarily concerned with the signs and symptoms of mental disorders, rather than the underlying causes. It claims to collect them together based on statistical or clinical patterns. As such, it has been compared to a naturalist's field guide to birds, with similar advantages and disadvantages. The lack of a causative or explanatory basis, however, is not specific to the DSM, but rather reflects a general lack of pathophysiological understanding of psychiatric disorders. As DSM-III chief architect Robert Spitzer and DSM-IV editor Michael First outlined in 2005, "little progress has been made toward understanding the pathophysiological processes and cause of mental disorders. If anything, the research has shown the situation is even more complex than initially imagined, and we believe not enough is known to structure the classification of psychiatric disorders according to etiology."

The DSM's focus on superficial symptoms is claimed to be largely a result of necessity (assuming such a manual is nevertheless produced), since there is no agreement on a more explanatory classification system. Reviewers note, however, that this approach is undermining research, including in genetics, because it results in the grouping of individuals who have very little in common except superficial criteria as per DSM or ICD diagnosis.

Despite the lack of consensus on underlying causation, advocates for specific psychopathological paradigms have nonetheless faulted the current diagnostic scheme for not incorporating evidence-based models or findings from other areas of science. A recent example is evolutionary psychologists' criticism that the DSM does not differentiate between genuine cognitive malfunctions and those induced by psychological adaptations, a key distinction within evolutionary psychology but one that is widely challenged within general psychology. Another example is the strong operationalist viewpoint, which contends that reliance on operational definitions, as purported by the DSM, necessitates that intuitive concepts like depression be replaced by specific measurable concepts before they are scientifically meaningful. One critic states of psychologists that "Instead of replacing 'metaphysical' terms such as 'desire' and 'purpose', they used it to legitimize them by giving them operational definitions…the initial, quite radical operationalist ideas eventually came to serve as little more than a 'reassurance fetish' (Koch 1992) for mainstream methodological practice."

A 2013 review published in the "European Archives of Psychiatry and Clinical Neuroscience" states "that psychiatry targets the phenomena of consciousness, which, unlike somatic symptoms and signs, cannot be grasped on the analogy with material thing-like objects." As an example of the problem of the superficial characterization of psychiatric signs and symptoms, the authors gave the example of a patient saying they "feel depressed, sad, or down", showing that such a statement could indicate various underlying experiences: "not only depressed mood but also, for instance, irritation, anger, loss of meaning, varieties of fatigue, ambivalence, ruminations of different kinds, hyper-reflectivity, thought pressure, psychological anxiety, varieties of depersonalization, and even voices with negative content, and so forth." The structured interview comes with "danger of over confidence in the face value of the answers, as if a simple 'yes' or 'no' truly confirmed or denied the diagnostic criterion at issue." The authors gave an example: A patient who was being administered the Structured Clinical Interview for the DSM-IV Axis I Disorders denied thought insertion, but during a "conversational, phenomenological interview", a semi-structured interview tailored to the patient, the same patient admitted to experiencing thought insertion, along with a delusional elaboration. The authors suggested 2 reasons for this discrepancy: either the patient did not "recognize his own experience in the rather blunt, implicitly either/or formulation of the structured-interview question", or the experience did not "fully articulate itself" until the patient started talking about his experiences.

Despite caveats in the introduction to the DSM, it has long been argued that its system of classification makes unjustified categorical distinctions between disorders and uses arbitrary cut-offs between normal and abnormal. A 2009 psychiatric review noted that attempts to demonstrate natural boundaries between related DSM syndromes, or between a common DSM syndrome and normality, have failed. Some argue that rather than a categorical approach, a fully dimensional, spectrum or complaint-oriented approach would better reflect the evidence.

In addition, it is argued that the current approach based on exceeding a threshold of symptoms does not adequately take into account the context in which a person is living, and to what extent there is internal disorder of an individual versus a psychological response to adverse situations. The DSM does include a step ("Axis IV") for outlining "Psychosocial and environmental factors contributing to the disorder" once someone is diagnosed with that particular disorder.

Because an individual's degree of impairment is often not correlated with symptom counts and can stem from various individual and social factors, the DSM's standard of distress or disability can often produce false positives. On the other hand, individuals who do not meet symptom counts may nevertheless experience comparable distress or disability in their life.

Some psychiatrists argue that current diagnostic standards rely on an exaggerated interpretation of neurophysiological findings and so understate the scientific importance of social-psychological variables. Advocating a more culturally sensitive approach to psychology, critics such as Carl Bell and Marcello Maviglia contend that the cultural and ethnic diversity of individuals is often discounted by researchers and service providers. In addition, current diagnostic guidelines have been criticized as having a fundamentally Euro-American outlook. Although these guidelines have been widely implemented, opponents argue that even when a diagnostic criterion set is accepted across different cultures, it does not necessarily indicate that the underlying constructs have any validity within those cultures; even reliable application can only demonstrate consistency, not legitimacy. Cross-cultural psychiatrist Arthur Kleinman contends that the Western bias is ironically illustrated in the introduction of cultural factors to the DSM-IV: the fact that disorders or concepts from non-Western or non-mainstream cultures are described as "culture-bound", whereas standard psychiatric diagnoses are given no cultural qualification whatsoever, is to Kleinman revelatory of an underlying assumption that Western cultural phenomena are universal. Kleinman's negative view toward the culture-bound syndrome is largely shared by other cross-cultural critics, common responses included both disappointment over the large number of documented non-Western mental disorders still left out, and frustration that even those included were often misinterpreted or misrepresented. Many mainstream psychiatrists have also been dissatisfied with these new culture-bound diagnoses, although not for the same reasons. Robert Spitzer, a lead architect of the DSM-III, has held the opinion that the addition of cultural formulations was an attempt to placate cultural critics, and that they lack any scientific motivation or support. Spitzer also posits that the new culture-bound diagnoses are rarely used in practice, maintaining that the standard diagnoses apply regardless of the culture involved. In general, the mainstream psychiatric opinion remains that if a diagnostic category is valid, cross-cultural factors are either irrelevant or are only significant to specific symptom presentations. One of the results was the development of the Azibo Nosology by Daudi Ajani Ya Azibo as an alternative to the DSM to treat African and African American patients.

It has also been alleged that the way the categories of the DSM are structured, as well as the substantial expansion of the number of categories, are representative of an increasing medicalization of human nature, which may be attributed to disease mongering by psychiatrists and pharmaceutical companies, the power and influence of the latter having grown dramatically in recent decades. Of the authors who selected and defined the DSM-IV psychiatric disorders, roughly half have had financial relationships with the pharmaceutical industry at one time, raising the prospect of a direct conflict of interest. The same article concludes that the connections between panel members and the drug companies were particularly strong in those diagnoses where drugs are the first line of treatment, such as schizophrenia and mood disorders, where 100% of the panel members had financial ties with the pharmaceutical industry. In 2005, then APA President Steven Sharfstein released a statement in which he conceded that psychiatrists had "allowed the biopsychosocial model to become the bio-bio-bio model".

However, although the number of identified diagnoses has increased by more than 300% (from 106 in DSM-I to 365 in DSM-IV-TR), psychiatrists such as Zimmerman and Spitzer argue it almost entirely represents greater specification of the forms of pathology, thereby allowing better grouping of more similar patients. However, William Glasser refers to the DSM as "phony diagnostic categories", arguing that "it was developed to help psychiatrists – to help them make money". In addition, the publishing of the DSM, with tightly guarded copyrights, has in itself earned over $100 million for the APA.

A client is a person who accesses psychiatric services and may have been given a diagnosis from the DSM, while a survivor self-identifies as a person who has endured a psychiatric intervention and the mental health system (which may have involved involuntary commitment and involuntary treatment). A term adopted by many users of psychiatric services is "consumer." This term was chosen to eliminate the "patient" label and restore the person to an active role as a user or consumer of services. Some individuals are relieved to find that they have a recognized condition that they can apply a name to and this has led to many people self-diagnosing. Others, however, question the accuracy of the diagnosis, or feel they have been given a "label" that invites social stigma and discrimination (the terms "mentalism" and "sanism" have been used to describe such discriminatory treatment).

Diagnoses can become internalized and affect an individual's self-identity, and some psychotherapists have found that the healing process can be inhibited and symptoms can worsen as a result. Some members of the psychiatric survivors movement (more broadly the consumer/survivor/ex-patient movement) actively campaign against their diagnoses, or the assumed implications, and/or against the DSM system in general. Additionally, it has been noted that the DSM often uses definitions and terminology that are inconsistent with a recovery model, and such content can erroneously imply excess psychopathology (e.g. multiple "comorbid" diagnoses) or chronicity.

Psychiatrist Allen Frances has been critical of proposed revisions to the DSM-5. In a 2012 "New York Times" editorial, Frances warned that if this DSM version is issued unamended by the APA, "it will medicalize normality and result in a glut of unnecessary and harmful drug prescription." In a December 2, 2012 blog post in "Psychology Today", Frances provides his "…list of DSM 5's ten most potentially harmful changes":

Frances and others have published debates on what they see as the six most essential questions in psychiatric diagnosis:

In 2011, psychologist Brent Robbins co-authored a national letter for the Society for Humanistic Psychology that has brought thousands into the public debate about the DSM. Over 15,000 individuals and mental health professionals have signed a petition in support of the letter. Thirteen other American Psychological Association divisions have endorsed the petition. Robbins has noted that under the new guidelines, certain responses to grief could be labeled as pathological disorders, instead of being recognized as being normal human experiences.



</doc>
<doc id="8500" url="https://en.wikipedia.org/wiki?curid=8500" title="Dar es Salaam">
Dar es Salaam

Dar es Salaam (Dar) (from ', "the house of peace"; formerly Mzizima) is the former capital as well as the most populous city in Tanzania and a regionally important economic centre. Located on the Swahili coast, the city is one of the fastest growing cities in the world.

Until 1974, Dar es Salaam served as Tanzania’s capital city, at which point the capital city commenced transferring to Dodoma, which was officially completed in 1996. However, as of 2017, it continues to remain a focus of central government bureaucracy, although this is in the process of fully moving to Dodoma. In addition, it is Tanzania's most prominent city in arts, fashion, media, music, film and television and a leading financial centre, with the Dar es Salaam Stock Exchange (DSE) being the country's first and most important stock exchange market. The city is the leading arrival and departure point for most tourists who visit Tanzania, including the national parks for safaris and the islands of Unguja and Pemba. Dar es Salaam is also the largest and most populous Swahili-speaking city in the world.

It is the capital of the co-extensive Dar es Salaam Region, which is one of Tanzania's 31 administrative regions and consists of five districts: Kinondoni in the north, Ilala in the centre, Ubungo, Temeke in the south and Kigamboni in the east across the Kurasini creek. The region had a population of 4,364,541 as of the official 2012 census.

In the 19th century, Mzizima (Swahili for "healthy town") was a coastal fishing village on the periphery of Indian Ocean trade routes. In 1865 or 1866, Sultan Majid bin Said of Zanzibar began building a new city very close to Mzizima and named it Dar es Salaam. The name is commonly translated as "abode/home of peace", based on the Arabic "dar" ("house"), and the Arabic "es salaam" ("of peace"). Dar es Salaam fell into decline after Majid's death in 1870, but was revived in 1887 when the German East Africa Company established a station there. The town's growth was facilitated by its role as the administrative and commercial centre of German East Africa and industrial expansion resulting from the construction of the Central Railway Line in the early 1900s.

German East Africa was captured by the British during World War I and became Tanganyika, with Dar es Salaam remaining the administrative and commercial centre. Under British indirect rule, separate European (e.g., Oyster Bay) and African (e.g., Kariakoo and Ilala) areas developed at a distance from the city centre. The city's population also included a large number of workers from British India, many of whom came to dominate trade and commerce. After World War II, Dar es Salaam experienced a period of rapid growth.

Political developments, including the formation and growth of the Tanganyika African National Union, led to Tanganyika attaining independence from colonial rule in December 1961. Dar es Salaam continued to serve as its capital, even when in 1964 Tanganyika and Zanzibar merged to form Tanzania. In 1973, however, provisions were made to relocate the capital to Dodoma, a more centrally located city in the interior. The relocation process has not yet been completed, and Dar es Salaam remains Tanzania's primary city.

In 1967, the Tanzanian government declared the "Ujamaa policy", that set Tanzania into a socialist path. The move slowed down the potential growth of the city as the government encouraged people not to move in cities but stay in Ujamaa socialist villages. But by the 1980s the Ujamaa policy proved to be a failure into combating increasing poverty, hunger, and delayed development that Tanzania faced. This led to the 1980s liberalization policy that virtually ended socialism and its spirit within the Tanzania's government.

Until the late 1990s, Dar es Salaam was not put into the same category as Africa's leading cities like Nairobi, Johannesburg, Lagos, or Addis Ababa. But the 2000s decade became the turning point as the city experienced one of Africa's fastest urbanization rates as businesses were opened and prospered, growth in the construction sector with multi-storey building, bridges and roads, Tanzanian banks headquartered in the city started to run more proper, the Dar es Salaam Stock Exchange expanded, and the Dar es Salaam harbour proved to be the most important in Tanzania and prominent for entrepot trade with landlocked countries like the Democratic Republic of Congo, Rwanda, Burundi, and Zambia. The CBD skyline hosts tall buildings, among them the 35-floor PSPF Tower, finished in 2015, and "the Tanzania" "Port"s "Authority" "(TPA) Tower", currently under construction .

Dar es Salaam is located at 6°48' South, 39°17' East (−6.8000, 39.2833), on a natural harbour on the eastern coast of East Africa, with sandy beaches in some areas.

The region of Dar es Salaam is divided into five districts.

Dar es Salaam Region is divided into five administrative districts. All five are governed as municipal councils, and so all of the city's suburbs or wards are affiliated with them. The regional commissioner is Paul Makonda.

Kinondoni is the most populated amongst the districts, with half of the city's population residing within it. It is also home to high-income suburbs. These include:

Ilala is the administrative district of Dar es Salaam where almost all government offices and ministries are housed. The Central Business District (locally called "Posta") is located in this district. It is the transportation hub of the city, as the Julius Nyerere International Airport, Central Railway Station and Tazara Railway Station are all within the district boundaries. The residential areas are mainly middle to high-income, and some of these are:

Temeke is the industrial district of the city, where the manufacturing centers (heavy and light industry) are located. The Port of Dar es Salaam, which is the largest in the country, is found east of Temeke.

Temeke is believed to have the largest concentration of low-income residents due to industry. Port officials, military and police officers live there.

The Ubungo terminal serves as a transportation link to most large Dar es Salaam urban nodes. The narrow-gauge commuter rail runs from there to the city centre, with ten level crossings along the route.


Due to close proximity to the equator and the warm Indian Ocean, the city experiences tropical climatic conditions, typified by hot and humid weather throughout much of the year. It has a tropical wet and dry climate (Köppen: Aw). Annual rainfall is approximately , and in a normal year there are two rainy seasons: "the long rains" in April and May and "the short rains" in November and December.

"In 1949 the town became a municipality...[with] four honourable nominated Town Councillors who elected a Mayor." "Until June 1996, Dar es Salaam was managed by the Dar es Salaam City Council...the highest policy-making body in the city." As of 2017 Paul Makonda serves as the commissioner of Dar es Salaam Region.

As any growing city Dar es Salaam is the city in Tanzania to which villagers flock for better opportunities. Westerners and Asians are also settling in Dar es Salaam, and the movement of foreigners has put a good work load on the relevant government body for developing better policies to accommodate the growing and the diverse population of the Dar es salaam together with its suburbs.

Dar es Salaam is the most populous city in Tanzania. With a population increase of 5.6 percent per year from 2002 to 2012, it is the third-fastest-growing city in Africa, after Bamako and Lagos, and the ninth-fastest-growing in the world. The metro population is expected to reach 5.12 million by 2020 and predicted to be as high as 76 million by the year 2100, making it the second largest city on earth (after Lagos), by 2100.

According to the 2012 national census, the region had a population of 4,364,541, which was much higher than the pre-census projection of 3,270,255. For 2002–2012, the region's 5.6 percent average annual population growth rate was the highest in the country. It was also the most densely populated region with 3,133 people per square kilometer.

The sprawling suburbs furthest from the city centre are generally populated by Tanzanians of African descent, with the exception of Oyster Bay, where there is a large population of foreign expatriates. The edges of Dar es Salaam are spreading rapidly, severely taxing the transportation network (which aside from ferries, lacks any kind of mass transit facilities) and raising the prospect of future urban overcrowding.

Dar es Salaam is Tanzania's most important city for both business and government. The city contains high concentrations of trade and other services and manufacturing compared to other parts of Tanzania, which has about 80 percent of its population in rural areas. Downtown includes small businesses, many of which are run by traders and proprietors whose families originated from the Middle East and the Indian sub-continent—areas of the world with which the settlements of the Tanzanian coast have had long-standing trading relations.

The Dar es Salaam Central Business District is made up of Kisutu, Kivukoni, Upanga and Kariakoo areas is Tanzania's largest city CBD. All three areas making up the downtown are found in the Ilala district. Kivukoni has the city's important fish market, the Magogoni fish market. Kivukoni also is the place where the Tanzania's central bank, The Bank of Tanzania is located, so is the Dar es Salaam Stock Exchange. Kisutu has businesses and offices and is the location of Dar es Salaam central railway station, the PSPF Towers and the TPA tower.
Dar es Salaam has a problem with slums. According to a United Nations estimate, 70 percent of the city's population lives in informal settlements. The poorer residents crowd into downtown areas or large slums, many without running water or basic services. The more wealthy live in beachside mansions in the city's northern districts.

Dar es Salaam has had a major construction boom. The PSPF Twin Towers with more than 35 stories is the tallest building in the city and the country. Dar es Salaam has major infrastructural challenges, including an outdated transport system and occasional power rationing.

Dar es Salaam hosts the Mlimani City shopping Mall.

Dar es Salaam on a natural harbour on the Indian Ocean, is one of the hub of the Tanzanian transportation system as the main railways and several highways originate in or near the city to serve convenient means of transportation for commuters.

The most common form of transport in Dar es Salaam are the public buses, called "dala dala", which are often found at the major bus terminals of Makumbusho and Ubungo. Since the introduction of motorcycle transit business known as "Bodaboda", most of the people prefer this type of transportation which allows them to get into the city faster compared to the minibuses which face a lot of traffic. Other types of transport include motorcycles and Bajaj.

The government has been introducing a bus rapid transport or metro bus system under the Dar es Salaam bus rapid transit meaning 'mwendo kasi' in Kiswahili. The metro buses are managed by UDA (Usafiri Dar es Salaam).

The bus rapid transit system Phase 1 is completed and already in operation by the Dar es Salaam Rapid Transit Agency, a government-private sector entity, and began operation on 10 May 2016. It is branded as UDA-RT (Usafiri Dar es Salaam Rapid Transit). The first section runs between Kimara in the northwest to Kivukoni on the northern headland of the harbour. Phase 1 was funded by the World Bank, African Development Bank and the Tanzanian government.

The city has the country's busiest port: The port is located on the west of the Indian Ocean, Kurasini creek south east of Dar es Salaam's central business District. The Port of Dar es Salaam handles 90% of the country's cargo. 

Due to huge influx of cargo and the slow pace of expansion a new cargo port northwest of Dar es Salaam is proposed at Bagamoyo.

MV Kigamboni ferries are running between south east of Kivukoni and north west of Kigamboni in Dar es Salaam.

Travel to Urban and sub urban parts of Dar es Salaam is provided by the Dar es Salaam commuter rail.

Tanzania Railways operates the Central Line from Dar es Salaam to Kigoma

The city also hosts the head office of Tanzania Zambia Railways Authority (TAZARA) built in the late 1960s to early 1970s. The main terminal is located west of Dar es Salaam's central business district in north Yombo Vituka along Nelson Mandela road. The TAZARA Railway connects Dar es Salaam to Zambia.

The Julius Nyerere International Airport is the principal airport serving the country with two operating terminals and one under construction; Terminal Three at Kipawa in Ilala Municipality. The airport is located west of Dar es Salaam's central business district.

Dar es Salaam (and specifically the area of Oyster Bay) is home to the brightly coloured and tourist-oriented Tingatinga painting style. The Nyumba ya sanaa ("House of Art") is a cultural centre, workshop and shop dedicated to Tanzanian art, showcasing and promoting Tanzanian craftmanship. Prominent Tanzanian sculptor George Lilanga has donated some of his works to the centre, including decorations of the building's main entrance.

The music scene in Dar es Salaam is divided between several styles. The longest standing style is live dance music (muziki wa dansi) bands such as DDC Mlimani Park Orchestra and Malaika Musical Band as examples. Taarab which was traditionally strong in Zanzibar has also found a niche. However, it remains small compared both to dance music and "Bongo Flava", a broad category that represents the Tanzanian take on Hip Hop and R&B, which has quickly become the most popular locally produced music. Traditional music, which locally is used to refer to tribal music is still performed but typically only on family oriented occasions such as weddings. Recently there has been development of another music niche, a taste that is rising and to be prominent as BongoFlava known as Singeli with star singers such as Msaga Sumu and Man Fongo.

This rap scene is also present.

In the 1970s, the Ministry of National Youth Culture aimed to create a national culture, which stressed the importance of music. Dar es Salaam became the music center in Tanzania, with the local radio showcasing new bands and dominating the music and cultural scene. With this ujamaa, or family, mentality governing culture and music a unified people’s culture was created, leading to the rise of hip hop music. Throughout the years, the radio in Dar es Salaam has played a major role in the dissemination of music because many people don’t have television and cassettes are used over CDs.

Due in part to the growth of the expatriate community and the increasing importance of tourism, the number of restaurants serving international cuisines has risen rapidly. The city offers a diversity of cuisine, ranging from traditional Tanzanian Barbecue-style options, such as "Nyama Choma" (Roasted meat—served with rice or ugali) and "Mishkaki" (Shish kebab—usually barbecued and served with salt, hot chili peppers, chapati, fries, and rice on the side), as well as the long-established traditional Indian and Zanzibari cuisine, to options from all corners of the globe, including Arab, Chinese, Thai, Turkish, Italian, and Japanese food. People who are looking for a light meal or a snack and prefer neither fast food nor a meal from the traditional restaurants buy their food from street vendors, who usually sell good food and snacks at low prices. Samosas ("sambusas") with coconut chutney are the most common snack street food items within the city, as the area is largely influenced by the fresh food products and spices imported from India.

Dar es Salaam has two of the five museums comprising the National Museum of Tanzania consortium, namely the National Museum proper and the Makumbusho Cultural Centre & Village Museum. The National Museum is dedicated to the history of Tanzania; most notably, it exhibits some of the bones of "Paranthropus boisei" that were among the findings of Louis Leakey at Olduvai. The Makumbusho Cultural Centre & Village Museum, located in the outskirts of the city on the road to Bagamoyo, showcases traditional huts from 16 different Tanzanian ethnic groups. There are also examples of traditional cultivations, and traditional music and dance shows are held daily. In 2016, there was a breakthrough discovery in Northern Tanzania by a scientist, from the University of Dar es Salaam, of footprints thought to be of a hominid that predates Homo sapiens.

Close to the National Museum are also the botanical gardens, with tropical plants and trees.

There are beaches on the Msasani peninsula north of Dar es Salaam and in Kigamboni to the south. Trips to the nearby islands of the Dar es Salaam Marine Reserve are a popular daytrip from the city and a spot for snorkeling, swimming and sunbathing. Bongoyo Island can be reached by boat from the Msasani Slipway.

Dar es Salaam is the sports center of Tanzania. Dar es Salaam hosts the second largest stadium in East and Central Africa (National Stadium), which can accommodate up to 60,000 people.
The National Stadium hosts Dar es Salaam's Young Africans Sports Club, Simba Sports Club, Azam F.C. and other Tanzanian football clubs, and international matches. There is a proposal to build a new stadium in Dodoma, much bigger in capacity than the present one in Dar es Salaam by the government as a donation from the Moroccan Kingdom.

Apart from the National Stadium, Dar es Salaam is home to the Uhuru Stadium (used mainly for local tournaments and political gatherings), Karume Memorial Stadium (the home of the Tanzania Football Federation). The stadium is situated west of Kurasini.

The Gymkhana Golf Courses located north west of the Kivukoni area (between the city centre looking on to the shores of the Indian Ocean in the east and Barack Obama Drive), also has tennis courts, squash courts, and a fitness club. Outside of the metropolitan districts, there is the Lugalo Military Golf Course (located in the Lugalo Military Barracks).

Dar es Salaam's Mama Africa school, founded in 2003, is known for training some of Africa's finest acrobats.

Newspapers in Dar es Salaam are often sold by people prowling through stationary traffic at road intersections. English-language ones, with online presences, include "The Citizen" and "The Guardian" and the Kiswahili dailies, "Tanzania Daima" and "Mwananchi". "Business Times" is the only financial and economic newspaper in the city. It was established in 1988 and became the first private newspaper in Tanzania. "Business Times" owns "Majira", another Kiswahili newspaper.

Dar es Salaam is home to ITV, Channel Ten Television Station formerly known as Dar es Salaam Television (DTV) and Azam TV, a subscription-based service from the Azam group of companies.

Ayo TV, a television station, is also based in Ubungo, Dar es Salaam, as is the Tanzania Broadcasting Corporation.

Installation of a trans-Indian Ocean backbone cable in 2009 has, in theory, made Internet access much more readily available in Dar in particular and in East Africa in general. However, roll-out to end-users is slow, partly because of spotty telephone line coverage at the moment provided by the Tanzania Telecommunications Company Limited, partly due to the substantial prices and long contracts demanded for purchase of bandwidth for small ISPs. Mobile-telephone access to the Internet via 3G and 3.75G is still relatively expensive. 4G is making its way through major cities and towns with plans to go countrywide in the advanced planning stages.

Internet cafés are found in the city centre and free wifi hotspots in various government and non government institutions as well as public transport.

The expressed aim of the SEACOM cable is to enable East Africa to develop economically through increased online trading.

Dar es Salaam is the educational centre of Tanzania. The city is home to several institutions of higher learning. Below are 8 as follows:


Below is a list of nineteen notable people who lived in Dar es Salaam:


Dar es Salaam is twinned with:

Kigoma



</doc>
<doc id="8501" url="https://en.wikipedia.org/wiki?curid=8501" title="Distributed computing">
Distributed computing

Distributed computing is a field of computer science that studies distributed systems. A "distributed system" is a system whose components are located on different networked computers, which then communicate and coordinate their actions by passing messages to each other. The components interact with each other in order to achieve a common goal. Three significant characteristics of distributed systems are: concurrency of components, lack of a global clock, and independent failure of components. Examples of distributed systems vary from SOA-based systems to massively multiplayer online games to peer-to-peer applications.

A computer program that runs within a distributed system is called a distributed program (and distributed programming is the process of writing such programs). There are many different types of implementations for the message passing mechanism, including pure HTTP, RPC-like connectors and message queues.

"Distributed computing" also refers to the use of distributed systems to solve computational problems. In "distributed computing", a problem is divided into many tasks, each of which is solved by one or more computers, which communicate with each other via message passing.

The word "parallel" in terms such as "parallel system", "distributed programming", and "distributed algorithm" originally referred to computer networks where individual computers were physically distributed within some geographical area. The terms are nowadays used in a much wider sense, even referring to autonomous processes that run on the same physical computer and interact with each other by message passing.

While there is no single definition of a distributed system, the following defining properties are commonly used:

A distributed system may have a common goal, such as solving a large computational problem; the user then perceives the collection of autonomous processors as a unit. Alternatively, each computer may have its own user with individual needs, and the purpose of the distributed system is to coordinate the use of shared resources or provide communication services to the users.

Other typical properties of distributed systems include the following:

Distributed systems are groups of networked computers, which have the same goal for their work.
The terms "concurrent computing", "parallel computing", and "distributed computing" have a lot of overlap, and no clear distinction exists between them. The same system may be characterized both as "parallel" and "distributed"; the processors in a typical distributed system run concurrently in parallel. Parallel computing may be seen as a particular tightly coupled form of distributed computing, and distributed computing may be seen as a loosely coupled form of parallel computing. Nevertheless, it is possible to roughly classify concurrent systems as "parallel" or "distributed" using the following criteria:
The figure on the right illustrates the difference between distributed and parallel systems. Figure (a) is a schematic view of a typical distributed system; the system is represented as a network topology in which each node is a computer and each line connecting the nodes is a communication link. Figure (b) shows the same distributed system in more detail: each computer has its own local memory, and information can be exchanged only by passing messages from one node to another by using the available communication links. Figure (c) shows a parallel system in which each processor has a direct access to a shared memory.

The situation is further complicated by the traditional uses of the terms parallel and distributed "algorithm" that do not quite match the above definitions of parallel and distributed "systems" (see below for more detailed discussion). Nevertheless, as a rule of thumb, high-performance parallel computation in a shared-memory multiprocessor uses parallel algorithms while the coordination of a large-scale distributed system uses distributed algorithms.

The use of concurrent processes that communicate by message-passing has its roots in operating system architectures studied in the 1960s. The first widespread distributed systems were local-area networks such as Ethernet, which was invented in the 1970s.

ARPANET, the predecessor of the Internet, was introduced in the late 1960s, and ARPANET e-mail was invented in the early 1970s. E-mail became the most successful application of ARPANET, and it is probably the earliest example of a large-scale distributed application. In addition to ARPANET, and its successor, the Internet, other early worldwide computer networks included Usenet and FidoNet from the 1980s, both of which were used to support distributed discussion systems.

The study of distributed computing became its own branch of computer science in the late 1970s and early 1980s. The first conference in the field, Symposium on Principles of Distributed Computing (PODC), dates back to 1982, and its counterpart International Symposium on Distributed Computing (DISC) was first held in Ottawa in 1985 as the International Workshop on Distributed Algorithms on Graphs.

Various hardware and software architectures are used for distributed computing. At a lower level, it is necessary to interconnect multiple CPUs with some sort of network, regardless of whether that network is printed onto a circuit board or made up of loosely coupled devices and cables. At a higher level, it is necessary to interconnect processes running on those CPUs with some sort of communication system.

Distributed programming typically falls into one of several basic architectures: client–server, three-tier, "n"-tier, or peer-to-peer; or categories: loose coupling, or tight coupling.


Another basic aspect of distributed computing architecture is the method of communicating and coordinating work among concurrent processes. Through various message passing protocols, processes may communicate directly with one another, typically in a master/slave relationship. Alternatively, a "database-centric" architecture can enable distributed computing to be done without any form of direct inter-process communication, by utilizing a shared database.

Reasons for using distributed systems and distributed computing may include:

Examples of distributed systems and applications of distributed computing include the following:

Many tasks that we would like to automate by using a computer are of question–answer type: we would like to ask a question and the computer should produce an answer. In theoretical computer science, such tasks are called computational problems. Formally, a computational problem consists of "instances" together with a "solution" for each instance. Instances are questions that we can ask, and solutions are desired answers to these questions.

Theoretical computer science seeks to understand which computational problems can be solved by using a computer (computability theory) and how efficiently (computational complexity theory). Traditionally, it is said that a problem can be solved by using a computer if we can design an algorithm that produces a correct solution for any given instance. Such an algorithm can be implemented as a computer program that runs on a general-purpose computer: the program reads a problem instance from input, performs some computation, and produces the solution as output. Formalisms such as random access machines or universal Turing machines can be used as abstract models of a sequential general-purpose computer executing such an algorithm.

The field of concurrent and distributed computing studies similar questions in the case of either multiple computers, or a computer that executes a network of interacting processes: which computational problems can be solved in such a network and how efficiently? However, it is not at all obvious what is meant by "solving a problem" in the case of a concurrent or distributed system: for example, what is the task of the algorithm designer, and what is the concurrent or distributed equivalent of a sequential general-purpose computer?

The discussion below focuses on the case of multiple computers, although many of the issues are the same for concurrent processes running on a single computer.

Three viewpoints are commonly used:


In the case of distributed algorithms, computational problems are typically related to graphs. Often the graph that describes the structure of the computer network "is" the problem instance. This is illustrated in the following example.

Consider the computational problem of finding a coloring of a given graph "G". Different fields might take the following approaches:

While the field of parallel algorithms has a different focus than the field of distributed algorithms, there is a lot of interaction between the two fields. For example, the Cole–Vishkin algorithm for graph coloring was originally presented as a parallel algorithm, but the same technique can also be used directly as a distributed algorithm.

Moreover, a parallel algorithm can be implemented either in a parallel system (using shared memory) or in a distributed system (using message passing). The traditional boundary between parallel and distributed algorithms (choose a suitable network vs. run in any given network) does not lie in the same place as the boundary between parallel and distributed systems (shared memory vs. message passing).

In parallel algorithms, yet another resource in addition to time and space is the number of computers. Indeed, often there is a trade-off between the running time and the number of computers: the problem can be solved faster if there are more computers running in parallel (see speedup). If a decision problem can be solved in polylogarithmic time by using a polynomial number of processors, then the problem is said to be in the class NC. The class NC can be defined equally well by using the PRAM formalism or Boolean circuits—PRAM machines can simulate Boolean circuits efficiently and vice versa.

In the analysis of distributed algorithms, more attention is usually paid on communication operations than computational steps. Perhaps the simplest model of distributed computing is a synchronous system where all nodes operate in a lockstep fashion. During each "communication round", all nodes in parallel (1) receive the latest messages from their neighbours, (2) perform arbitrary local computation, and (3) send new messages to their neighbors. In such systems, a central complexity measure is the number of synchronous communication rounds required to complete the task.

This complexity measure is closely related to the diameter of the network. Let "D" be the diameter of the network. On the one hand, any computable problem can be solved trivially in a synchronous distributed system in approximately 2"D" communication rounds: simply gather all information in one location ("D" rounds), solve the problem, and inform each node about the solution ("D" rounds).

On the other hand, if the running time of the algorithm is much smaller than "D" communication rounds, then the nodes in the network must produce their output without having the possibility to obtain information about distant parts of the network. In other words, the nodes must make globally consistent decisions based on information that is available in their "local neighbourhood". Many distributed algorithms are known with the running time much smaller than "D" rounds, and understanding which problems can be solved by such algorithms is one of the central research questions of the field.

Another commonly used measure is the total number of bits transmitted in the network (cf. communication complexity).

Traditional computational problems take the perspective that we ask a question, a computer (or a distributed system) processes the question for a while, and then produces an answer and stops. However, there are also problems where we do not want the system to ever stop. Examples of such problems include the dining philosophers problem and other similar mutual exclusion problems. In these problems, the distributed system is supposed to continuously coordinate the use of shared resources so that no conflicts or deadlocks occur.

There are also fundamental challenges that are unique to distributed computing. The first example is challenges that are related to "fault-tolerance". Examples of related problems include consensus problems, Byzantine fault tolerance, and self-stabilisation.

A lot of research is also focused on understanding the "asynchronous" nature of distributed systems:
Election

"Coordinator election" (or "leader election") is the process of designating a single process as the organizer of some task distributed among several computers (nodes). Before the task is begun, all network nodes are either unaware which node will serve as the "coordinator" (or leader) of the task, or unable to communicate with the current coordinator. After a coordinator election algorithm has been run, however, each node throughout the network recognizes a particular, unique node as the task coordinator.

The network nodes communicate among themselves in order to decide which of them will get into the "coordinator" state. For that, they need some method in order to break the symmetry among them. For example, if each node has unique and comparable identities, then the nodes can compare their identities, and decide that the node with the highest identity is the coordinator.

The definition of this problem is often attributed to LeLann, who formalized it as a method to create a new token in a token ring network in which the token has been lost.

Coordinator election algorithms are designed to be economical in terms of total bytes transmitted, and time. The algorithm suggested by Gallager, Humblet, and Spira for general undirected graphs has had a strong impact on the design of distributed algorithms in general, and won the Dijkstra Prize for an influential paper in distributed computing.

Many other algorithms were suggested for different kind of network graphs, such as undirected rings, unidirectional rings, complete graphs, grids, directed Euler graphs, and others. A general method that decouples the issue of the graph family from the design of the coordinator election algorithm was suggested by Korach, Kutten, and Moran.

In order to perform coordination, distributed systems employ the concept of coordinators. The coordinator election problem is to choose a process from among a group of processes on different processors in a distributed system to act as the central coordinator. Several central coordinator election algorithms exist.

So far the focus has been on "designing" a distributed system that solves a given problem. A complementary research problem is "studying" the properties of a given distributed system.

The halting problem is an analogous example from the field of centralised computation: we are given a computer program and the task is to decide whether it halts or runs forever. The halting problem is undecidable in the general case, and naturally understanding the behaviour of a computer network is at least as hard as understanding the behaviour of one computer.

However, there are many interesting special cases that are decidable. In particular, it is possible to reason about the behaviour of a network of finite-state machines. One example is telling whether a given network of interacting (asynchronous and non-deterministic) finite-state machines can reach a deadlock. This problem is PSPACE-complete, i.e., it is decidable, but it is not likely that there is an efficient (centralised, parallel or distributed) algorithm that solves the problem in the case of large networks.







</doc>
<doc id="8504" url="https://en.wikipedia.org/wiki?curid=8504" title="Dublin">
Dublin

Dublin (; ) is the capital and largest city in Ireland. Dublin is in the province of Leinster on the east coast of Ireland, at the mouth of the River Liffey and bordered on the south by the Wicklow Mountains. The city has an urban area population of 1,173,179. The population of the Dublin Region, , was 1,347,359 and the population of the Greater Dublin area was 1,904,806.

There is archaeological debate regarding precisely where Dublin was established by Celtic-speaking people in the 7th century AD. Later expanded as a Viking settlement, the Kingdom of Dublin became Ireland's principal city following the Norman invasion. The city expanded rapidly from the 17th century and was briefly the second largest city in the British Empire before the Acts of Union in 1800. Following the partition of Ireland in 1922, Dublin became the capital of the Irish Free State, later renamed Ireland.

As of 2010, Dublin was listed by the Globalization and World Cities Research Network (GaWC) as a global city, with a ranking of "Alpha-", which places it amongst the top thirty cities in the world. It is a historical and contemporary centre for education, the arts, administration, economy and industry.

The name "Dublin" comes from the Irish word "Dubhlinn", early Classical Irish "Dubhlind"/"Duibhlind", from "dubh" (, , ) meaning "black, dark", and "lind" () "pool", referring to a dark tidal pool. This tidal pool was located where the River Poddle entered the Liffey, on the site of the castle gardens at the rear of Dublin Castle. In Modern Irish the name is "Duibhlinn", and Irish rhymes from Dublin County show that in Dublin Leinster Irish it was pronounced "Duílinn" (). The original pronunciation is preserved in the names for the city in other languages such as Old English "Difelin", Old Norse "Dyflin", modern Icelandic "Dyflinn" and modern Manx "Divlyn" as well as Welsh "Dulyn". Other localities in Ireland also bear the name "Duibhlinn", variously anglicized as Devlin, Divlin and Difflin. Historically, scribes using the Gaelic script wrote "bh" with a dot over the "b", rendering Duḃlinn or Duiḃlinn. Those without knowledge of Irish omitted the dot, spelling the name as "Dublin". Variations on the name are also found in traditionally Gaelic-speaking areas of Scotland (Gàidhealtachd, cognate with Irish Gaeltachta), such as "An Linne Dhubh" ("the black pool"), which is part of Loch Linnhe.

It is now thought that the Viking settlement was preceded by a Christian ecclesiastical settlement known as "Duibhlinn", from which "Dyflin" took its name. Beginning in the 9th and 10th century, there were two settlements where the modern city stands. The Viking settlement of about 841, "Dyflin", and a Gaelic settlement, Áth Cliath ("ford of hurdles") further up river, at the present day Father Mathew Bridge (also known as Dublin Bridge), at the bottom of Church Street. ', meaning "town of the hurdled ford", is the common name for the city in modern Irish. ' is a place name referring to a fording point of the River Liffey near Father Mathew Bridge. "" was an early Christian monastery, believed to have been in the area of Aungier Street, currently occupied by Whitefriar Street Carmelite Church. There are other towns of the same name, such as "Àth Cliath" in East Ayrshire, Scotland, which is Anglicised as Hurlford.

The area of Dublin Bay has been inhabited by humans since prehistoric times, but the writings of Ptolemy (the Greco-Roman astronomer and cartographer) in about AD 140 provide possibly the earliest reference to a settlement there. He called it "Eblana polis" ().

Dublin celebrated its 'official' millennium in 1988, meaning the Irish government recognised 988 as the year in which the city was settled and that this first settlement would later become the city of Dublin.
It is now thought the Viking settlement was preceded by a Christian ecclesiastical settlement known as "Duibhlinn", from which "Dyflin" took its name. Beginning in the 9th and 10th century, there were two settlements which later became the modern Dublin. The subsequent Scandinavian settlement centred on the River Poddle, a tributary of the Liffey in an area now known as Wood Quay. The Dubhlinn was a small lake used to moor ships; the Poddle connected the lake with the Liffey. This lake was covered during the early 18th century as the city grew. The Dubhlinn lay where the Castle Garden is now located, opposite the Chester Beatty Library in Dublin Castle. "Táin Bó Cuailgne" ("The Cattle Raid of Cooley") refers to "Dublind rissa ratter Áth Cliath", meaning "Dublin, which is called Ath Cliath".

Dublin was established as a Viking settlement in the 10th century and, despite a number of rebellions by the native
Irish, it remained largely under Viking control until the Norman invasion of Ireland was launched from Wales in 1169. It was upon the death of Muirchertach Mac Lochlainn in early 1166 that Ruaidrí Ua Conchobair, King of Connacht, proceeded to Dublin and was inaugurated "King of Ireland" without opposition. Arguably, he was the primitive undebated full king of Ireland and also the only Gaelic one.

According to some historians, part of the city's early economic growth is attributed to a trade in slaves. Slavery in Ireland and Dublin reached its pinnacle in the 9th and 10th centuries. Prisoners of slave raids and kidnappings which captured men, women and children brought revenue to the Celtic Irish Sea raiders, as well as to the Vikings who had initiated the practice. The victims came from Wales, England, Normandy and beyond.

The King of Leinster, Diarmait Mac Murchada, after his exile by Ruaidhrí, enlisted the help of Strongbow, the Earl of Pembroke, to conquer Dublin. Following Mac Murrough's death, Strongbow declared himself King of Leinster after gaining control of the city. In response to Strongbow's successful invasion, King Henry II of England reaffirmed his sovereignty by mounting a larger invasion in 1171 and pronounced himself Lord of Ireland. Around this time, the county of the City of Dublin was established along with certain liberties adjacent to the city proper. This continued down to 1840 when the barony of Dublin City was separated from the barony of Dublin. Since 2001, both baronies have been redesignated the City of Dublin.

Dublin Castle, which became the centre of Norman power in Ireland, was founded in 1204 as a major defensive work on the orders of King John of England. Following the appointment of the first Lord Mayor of Dublin in 1229, the city expanded and had a population of 8,000 by the end of the 13th century. Dublin prospered as a trade centre, despite an attempt by King Robert I of Scotland to capture the city in 1317. It remained a relatively small walled medieval town during the 14th century and was under constant threat from the surrounding native clans. In 1348, the Black Death, a lethal plague which had ravaged Europe, took hold in Dublin and killed thousands over the following decade.

Dublin was incorporated into the English Crown as the Pale, which was a narrow strip of English settlement along the eastern seaboard. The Tudor conquest of Ireland in the 16th century spelt a new era for Dublin, with the city enjoying a renewed prominence as the centre of administrative rule in Ireland. Determined to make Dublin a Protestant city, Queen Elizabeth I of England established Trinity College in 1592 as a solely Protestant university and ordered that the Catholic St. Patrick's and Christ Church cathedrals be converted to Protestant.

The city had a population of 21,000 in 1640 before a plague in 1649–51 wiped out almost half of the city's inhabitants. However, the city prospered again soon after as a result of the wool and linen trade with England, reaching a population of over 50,000 in 1700.

As the city continued to prosper during the 18th century, Georgian Dublin became, for a short period, the second largest city of the British Empire and the fifth largest city in Europe, with the population exceeding 130,000. The vast majority of Dublin's most notable architecture dates from this period, such as the Four Courts and the Custom House. Temple Bar and Grafton Street are two of the few remaining areas that were not affected by the wave of Georgian reconstruction and maintained their medieval character.

Dublin grew even more dramatically during the 18th century, with the construction of many new districts and buildings, such as Merrion Square, Parliament House and the Royal Exchange. The Wide Streets Commission was established in 1757 at the request of Dublin Corporation to govern architectural standards on the layout of streets, bridges and buildings. In 1759, the Guinness brewery was founded, and would eventually grow to become the largest brewery in the world and largest employer in Dublin.

Dublin suffered a period of political and economic decline during the 19th century following the Acts of Union 1800, under which the seat of government was transferred to the Westminster Parliament in London. The city played no major role in the Industrial Revolution, but remained the centre of administration and a transport hub for most of the island. Ireland had no significant sources of coal, the fuel of the time, and Dublin was not a centre of ship manufacturing, the other main driver of industrial development in Britain and Ireland. Belfast developed faster than Dublin during this period on a mixture of international trade, factory-based linen cloth production and shipbuilding.
The Easter Rising of 1916, the Irish War of Independence, and the subsequent Irish Civil War resulted in a significant amount of physical destruction in central Dublin. The Government of the Irish Free State rebuilt the city centre and located the new parliament, the Oireachtas, in Leinster House. Since the beginning of Norman rule in the 12th century, the city has functioned as the capital in varying geopolitical entities: Lordship of Ireland (1171–1541), Kingdom of Ireland (1541–1800), as part of the United Kingdom of Great Britain and Ireland (1801–1922), and the Irish Republic (1919–1922). Following the partition of Ireland in 1922, it became the capital of the Irish Free State (1922–1937) and now is the capital of Ireland. One of the memorials to commemorate that time is the Garden of Remembrance.

Dublin was also victim to the Northern Irish Troubles. During this 30 year conflict, violence mainly engulfed Northern Ireland. However, the Provisional IRA drew some support from within the Republic, including from Dublin. A Loyalist paramilitary group, the Ulster Volunteer Force, bombed the city during this time - notably in an atrocity known as the Dublin and Monaghan bombings in which 34 people died, mainly in Dublin itself.

Since 1997, the landscape of Dublin has changed. The city was at the forefront of Ireland’s economic expansion during the Celtic Tiger period, with private sector and state development of housing, transport and business. Following an economic decline during the Great Recession, Dublin has rebounded and as of 2017 has close to full employment.

From 1842, the boundaries of the city were comprehended by the baronies of Dublin City and the Barony of Dublin. In 1930, the boundaries were extended by the Local Government (Dublin) Act. Later, in 1953, the boundaries were again extended by the Local Government Provisional Order Confirmation Act.

Dublin City Council is a unicameral assembly of 63 members elected every five years from Local Election Areas. It is presided over by the Lord Mayor, who is elected for a yearly term and resides in Dublin's Mansion House. Council meetings occur at Dublin City Hall, while most of its administrative activities are based in the Civic Offices on Wood Quay. The party or coalition of parties, with the majority of seats adjudicates committee members, introduces policies, and appoints the Lord Mayor. The Council passes an annual budget for spending on areas such as housing, traffic management, refuse, drainage, and planning. The Dublin City Manager is responsible for implementing City Council decisions.

As the capital city, Dublin is the seat of the national parliament of Ireland, the Oireachtas. It is composed of the President of Ireland, Seanad Éireann as the upper house, and Dáil Éireann as the lower house. The President resides in Áras an Uachtaráin in Phoenix Park, while both houses of the Oireachtas meet in Leinster House, a former ducal palace on Kildare Street. It has been the home of the Irish parliament since the creation of the Irish Free State in 1922. The old Irish Houses of Parliament of the Kingdom of Ireland are located in College Green.

Government Buildings house the Department of the Taoiseach, the Council Chamber, the Department of Finance and the Office of the Attorney General. It consists of a main building (completed 1911) with two wings (completed 1921). It was designed by Thomas Manley Dean and Sir Aston Webb as the Royal College of Science. The First Dáil originally met in the Mansion House in 1919. The Irish Free State government took over the two wings of the building to serve as a temporary home for some ministries, while the central building became the College of Technology until 1989. Although both it and Leinster House were intended to be temporary, they became the permanent homes of parliament from then on.

For elections to Dáil Éireann, the city is divided into five constituencies: Dublin Central (3 seats), Dublin Bay North (5 seats), Dublin North-West (3 seats), Dublin South-Central (4 seats) and Dublin Bay South (4 seats). Nineteen TD's are elected in total.

In the 2016 general election the Dublin Region elected 14 Fine Gael, 7 Sinn Féin, 6 Fianna Fáil, 3 People Before Profit, 2 Socialist Party, 2 Labour Party, 2 Green Party, 1 Social Democrats and 7 Independent TDs.

Dublin is situated at the mouth of the River Liffey and encompasses a land area of approximately in east-central Ireland. It is bordered by a low mountain range to the south and surrounded by flat farmland to the north and west. The
Liffey divides the city in two between the Northside and the Southside. Each of these is further divided by two lesser rivers – the River Tolka running southeast into Dublin Bay, and the River Dodder running northeast to the mouth of the Liffey. Two further water bodies – the Grand Canal on the southside and the Royal Canal on the northside – ring the inner city on their way from the west and the River Shannon.

The River Liffey bends at Leixlip from a northeasterly route to a predominantly eastward direction, and this point also marks the transition to urban development from more agricultural land usage.

A north-south division at one time did traditionally exist, with the River Liffey as the divider. The Northside was generally seen as working class to lower middle class, while the Southside was seen as middle class to upper-middle class. There have also been some social divisions evident between the coastal suburbs in the east of the city, and the newer developments further to the west.

In some tourism and real-estate marketing contexts, Dublin is sometimes divided into a number of quarters or districts. These include, the 'Medieval Quarter' (in the area of Dublin Castle, Christ Church and St Patrick's Cathedral and the old city walls), the 'Georgian Quarter' (including the area around St Stephen's Green, Trinity College, and Merrion Square), the 'Docklands Quarter' (around the Dublin Docklands and Silicon Docks), the 'Cultural Quarter' (around Temple Bar), and 'Creative Quarter' (between South William Street and George's Street).

Similar to much of the rest of northwestern Europe, Dublin experiences a maritime climate ("Cfb") with cool summers, mild winters, and a lack of temperature extremes. The average maximum January temperature is , while the average maximum July temperature is . On average, the sunniest months are May and June, while the wettest month is October with of rain, and the driest month is February with . Rainfall is evenly distributed throughout the year.

Dublin's sheltered location on the east coast makes it the driest place in Ireland, receiving only about half the rainfall of the west coast. Ringsend in the south of the city records the lowest rainfall in the country, with an average annual precipitation of , with the average annual precipitation in the city centre being . The main precipitation in winter is rain; however snow showers do occur between November and March. Hail is more common than snow. The city experiences long summer days and short winter days. Strong Atlantic winds are most common in autumn. These winds can affect Dublin, but due to its easterly location, it is least affected compared to other parts of the country. However, in winter, easterly winds render the city colder and more prone to snow showers.

In the 20th century, smog and air-pollution were an issue in the city, precipitating a ban on bituminous fuels across Dublin. The ban was implemented in 1990 to address black smoke concentrations, that had been linked to cardiovascular and respiratory deaths in residents. Since the ban, non-trauma death rates, respiratory death rates and cardiovascular death rates have declined - by an estimated 350 deaths annually.

Dublin has many landmarks and monuments dating back hundreds of years. One of the oldest is Dublin Castle, which was first founded as a major defensive work on the orders of England's King John in 1204, shortly after the Norman invasion of Ireland in 1169, when it was commanded that a castle be built with strong walls and good ditches for the defence of the city, the administration of justice, and the protection of the King's treasure. Largely complete by 1230, the castle was of typical Norman courtyard design, with a central square without a keep, bounded on all sides by tall defensive walls and protected at each corner by a circular tower. Sited to the south-east of Norman Dublin, the castle formed one corner of the outer perimeter of the city, using the River Poddle as a natural means of defence.
One of Dublin's newest monuments is the Spire of Dublin, or officially titled "Monument of Light". It is a conical spire made of stainless steel and is located on O'Connell Street. It replaces Nelson's Pillar and is intended to mark Dublin's place in the 21st century. The spire was designed by Ian Ritchie Architects, who sought an "Elegant and dynamic simplicity bridging art and technology". The base of the monument is lit and the top is illuminated to provide a beacon in the night sky across the city. The Book of Kells, located in the library of Trinity College, Dublin, is one of the city's most visited sites. The Book of Kells is an illustrated manuscript created by Irish monks circa 800 AD. The Ha'penny Bridge, an iron footbridge over the River Liffey, is one of the most photographed sights in Dublin and is considered to be one of Dublin's most iconic landmarks.

Other landmarks and monuments include the Mansion House, the Anna Livia monument, the Molly Malone statue, Christ Church Cathedral, St Patrick's Cathedral, Saint Francis Xavier Church on Upper Gardiner Street near Mountjoy Square, The Custom House and Áras an Uachtaráin. The Poolbeg Towers are also landmark features of Dublin, and visible from various spots around the city.

There are many green-spaces around the city, and Dublin City Council manages over of parks. Public parks include the Phoenix Park, Herbert Park and St Stephen's Green. The Phoenix Park is about west of the city centre, north of the River Liffey. Its perimeter wall encloses , making it one of the largest walled city parks in Europe. It includes large areas of grassland and tree-lined avenues, and since the 17th century has been home to a herd of wild Fallow deer. The residence of the President of Ireland (Áras an Uachtaráin), which was built in 1751, is located in the park. The park is also home to Dublin Zoo, Ashtown Castle, and the official residence of the United States Ambassador. Music concerts are also sometimes held in the park.

St Stephen's Green is adjacent to one of Dublin's main shopping streets, Grafton Street, and to a shopping centre named for it, while on its surrounding streets are the offices of a number of public bodies. Saint Anne's Park is a public park and recreational facility, shared between Raheny and Clontarf, both suburbs on the North Side of Dublin.
The park, the second largest municipal park in Dublin, is part of a former estate assembled by members of the Guinness family, beginning with Benjamin Lee Guinness in 1835 (the largest municipal park is nearby (North) Bull Island, also shared between Clontarf and Raheny).

The Dublin region is the economic centre of Ireland, and was at the forefront of the country's economic expansion during the Celtic Tiger period. In 2009, Dublin was listed as the fourth richest city in the world by purchasing power and 10th richest by personal income. According to "Mercer's 2011 Worldwide Cost of Living Survey", Dublin is the 13th most expensive city in the European Union (down from 10th in 2010) and the 58th most expensive place to live in the world (down from 42nd in 2010). , approximately 800,000 people were employed in the Greater Dublin Area, of whom around 600,000 were employed in the services sector and 200,000 in the industrial sector.

A number of Dublin's traditional industries, such as food processing, textile manufacturing, brewing, and distilling have gradually declined, although Guinness has been brewed at the St. James's Gate Brewery since 1759. Economic improvements in the 1990s attracted a number of global pharmaceutical, information and communications technology companies to the city and Greater Dublin Area. Companies such as Microsoft, Google, Amazon, eBay, PayPal, Yahoo!, Facebook, Twitter, Accenture and Pfizer now have European headquarters and/or operational bases in the city, with several located in enterprise clusters like the Digital Hub and Silicon Docks. This presence of these companies has driven economic expansion in the city and led to Dublin sometimes being referred to as the "Tech Capital of Europe".

Financial services have also become important to the city since the establishment of Dublin's International Financial Services Centre in 1987. More than 500 operations are approved to trade under the IFSC programme. The centre is host to half of the world's top 50 banks and to half of the top 20 insurance companies. Many international firms have established major headquarters in the city, such as Citibank and Commerzbank. The Irish Stock Exchange (ISEQ), Internet Neutral Exchange (INEX) and Irish Enterprise Exchange (IEX) are also located in Dublin. Dublin has been positioned as one of the main cities vying to host Financial Services companies hoping to retain access to the Eurozone after Brexit. The Celtic Tiger also led to a temporary boom in construction, with large redevelopment projects in the Dublin Docklands and Spencer Dock. Completed projects include the Convention Centre, the 3Arena, and the Bord Gáis Energy Theatre.

The road network in Ireland is primarily focused on Dublin. The M50 motorway, a semi-ring road which runs around the south, west and north of the city, connects important national primary routes to the rest of the country. In 2008, the West-Link toll bridge was replaced by the eFlow barrier-free tolling system, with a three-tiered charge system based on electronic tags and car pre-registration.

The first phase of a proposed eastern bypass for the city is the Dublin Port Tunnel, which officially opened in 2006 to mainly cater for heavy vehicles. The tunnel connects Dublin Port and the M1 motorway close to Dublin Airport. The city is also surrounded by an inner and outer orbital route. The inner orbital route runs approximately around the heart of the Georgian city and the outer orbital route runs primarily along the natural circle formed by Dublin's two canals, the Grand Canal and the Royal Canal, as well as the North and South Circular Roads.

The 2016 TomTom Traffic Index ranked Dublin the 15th most congested city in the world and the 7th most congested in Europe.

Dublin is served by a network of nearly 200 bus routes which cover the city and suburbs. The majority of these are controlled by Dublin Bus, but a number of smaller companies also operate. Fares are generally calculated on a stage system based on distance travelled. There are several different levels of fares, which apply on most services. A "Real Time Passenger Information" system was introduced at Dublin Bus bus stops in 2012. Electronically displayed signs relay information about the time of the next bus' arrival based on its GPS determined position. The National Transport Authority is responsible for integration of bus and rail services in Dublin and has been involved in introducing a pre-paid smart card, called a Leap card, which can be used on all of Dublin’s public transport services.

Heuston and Connolly stations are the two main railway stations in Dublin. Operated by Iarnród Éireann, the Dublin Suburban Rail network consists of five railway lines serving the Greater Dublin Area and commuter towns such as Drogheda and Dundalk in County Louth. One of these lines is the electrified Dublin Area Rapid Transit (DART) line, which runs primarily along the coast of Dublin, comprising 31 stations, from Malahide and Howth southwards as far as Greystones in County Wicklow. Commuter rail operates on the other four lines using Irish Rail diesel multiple units. In 2013, passengers for DART and Dublin Suburban lines were 16 million and 11.7 million, respectively (around 75% of all Irish Rail passengers).

The Luas is a light rail system, run by Transdev Ireland (under contract from Transport Infrastructure Ireland), and has been operating since 2004, carrying over 34 million passengers annually. The network consists of two interconnecting tram lines; the Red Line links the Docklands and city centre with the south-western suburbs of Tallaght and Saggart, while the Green Line connects northern inner city suburbs and the main city centre with suburbs to the south of the city including Sandyford and Brides Glen. Together these lines comprise a total 67 stations and of track. Construction of a 6 km extension to the Green Line, bringing it into the north of the city, commenced in June 2013 and was opened for passenger travel on December 9, 2017.

A metro service is proposed under the name of Metrolink, and planned to run from Dublin's northside to Sandyford via Dublin Airport and St. Stephen's Green, with construction projected to start after 2021.

Dublin Connolly is connected by bus to Dublin Port and ferries run by Irish Ferries and Stena Line to Holyhead for connecting trains on the North Wales Coast Line to Chester, Crewe and London Euston. Dublin Connolly to Dublin Port can be reached via Amiens Street, Dublin into Store Street or by Luas via Busáras where Dublin Bus operates services to the Ferry Terminal.

Dublin Airport (owned and operated by DAA) is located north of Dublin City in the administrative county of Fingal. It is the headquarters of Ireland's flag carrier Aer Lingus, low-cost carrier Ryanair, and regional airlines Stobart Air and CityJet. The airport offers a short and medium haul network, as well as domestic services to several regional airports in Ireland. There are also long-haul services to the United States, Canada and the Middle East. Dublin Airport is the busiest airport in Ireland, followed by Cork and Shannon. Construction of a second terminal began in 2007 and was officially opened on 19 November 2010.

In 2014, Dublin Airport was the 18th busiest airport in Europe, serving over 21 million passengers. By 2016 this increased to 27.9 million passengers passing through the airport, establishing an all-time record supported by growth in both short- and long-haul networks.

In 2015 and 2016, transatlantic traffic grew somewhat. For example, in the summer of 2015, Dublin Airport had 158 flights a week to North America, making it the sixth largest European hub for that route over the year. Transatlantic traffic was also the fastest-growing segment of the market for the airport in 2016, in which a 16% increase from 2015 brought the yearly number of passengers traveling between Dublin and North America to 2.9 million.

From 2010 to 2016, Dublin Airport saw an increase of nearly 9.5 million passengers in its annual traffic, as the number of commercial aircraft movements has similarly followed a growth trend from 163,703 in 2013 to 191,233 in 2015.

Dublin City Council began installing cycle lanes and tracks throughout the city in the 1990s, and the city had over of specific on- and off-road tracks for cyclists. In 2011, the city was ranked 9th of major world cities on the "Copenhagenize Index of Bicycle-Friendly Cities". The same index also showed a fall to 15th in 2015.
Dublinbikes is a self-service bicycle rental scheme which has been in operation in Dublin since 2009. Sponsored by JCDecaux and Just Eat, the scheme consists of 550 French-made unisex bicycles stationed at 44 terminals throughout the city centre. Users must make a subscription for either an annual Long Term Hire Card or purchase a three-day ticket. As of 2011, Dublinbikes had over 58,000 subscribers and had plans to expand the service across the city and suburbs to provide for up to 5,000 bicycles and approximately 300 terminals.

The 2011 Census revealed that 5.9 percent of commuters in Dublin cycled. A 2013 report by Dublin City Council on traffic flows crossing the canals in and out of the city found that just under 10% of all traffic was made up of cyclists, representing an increase of 14.1% over 2012 and an 87.2% increase over 2006 levels and is attributed to measures, such as, the Dublinbikes bike rental scheme, the provision of cycle lanes, public awareness campaigns to promote cycling and the introduction of the 30kph city centre speed limit.

Dublin is one of the primary centres of education in Ireland, and is home to three universities, Dublin Institute of Technology and a number of other higher education institutions. There are 20 third-level institutes in the city and in surrounding towns and suburbs.
Dublin was European Capital of Science in 2012.

The University of Dublin is the oldest university in Ireland dating from the 16th century, and is located in the city centre. Its sole constituent college, Trinity College (TCD), was established by Royal Charter in 1592 under Elizabeth I. It was closed to Roman Catholics until Catholic Emancipation, and the Catholic hierarchy then banned Roman Catholics from attending until 1970. It is situated in the city centre, on College Green, and has 15,000 students.

The National University of Ireland (NUI) has its seat in Dublin, which is also the location of the associated "constituent university" of University College Dublin (UCD), which has over 30,000 students. Founded in 1854, it is now the largest university in Ireland. UCD's main campus is at Belfield, about from the city centre in the southeastern suburbs.

With a continuous history dating back to 1887, Dublin's principal, and Ireland's largest, institution for technological education and research, Dublin Institute of Technology (DIT) has over 23,000 students. DIT specialises in engineering, architecture, sciences, health, journalism, digital media, hospitality and business but also offers art, design, music and humanities programmes. DIT has campuses, buildings and research facilities at several locations, including buildings at Kevin Street, Aungier Street, Bolton Street and Cathal Brugha Street in central Dublin. It has commenced consolidation to a new campus in Grangegorman.

Dublin City University (DCU), formerly known as the National Institute for Higher Education (NIHE), offers courses in business, engineering, science, communication courses, languages and primary education. It has around 16,000 students, and its main campus, the Glasnevin Campus, is located about from the city centre in the northern suburbs. It has two campuses on the Northside of the river, the DCU Glasnevin Campus and the DCU Drumcondra Campus. The Drumcondra campus includes St Patrick's College of Education, the nearby Mater Dei Institute and students from the Church of Ireland College of Education.

The Royal College of Surgeons in Ireland (RCSI) is a medical school which is a recognised college of the NUI, and is situated at St. Stephen's Green in the city centre. The Institute of European Affairs is also in Dublin. Dublin Business School (DBS) is Ireland's largest private third level institution with over 9,000 students located on Aungier Street. The National College of Art and Design (NCAD) supports training and research in art, design and media. The National College of Ireland (NCI) is also based in Dublin. The Economic and Social Research Institute, a social science research institute, is based on Sir John Rogerson's Quay.

The Irish public administration and management training centre has its base in Dublin, the Institute of Public Administration provides a range of undergraduate and post graduate awards via the National University of Ireland and in some instances, Queen's University Belfast. There are also smaller specialised colleges, including Griffith College Dublin, The Gaiety School of Acting and the New Media Technology College.

Outside of the city, the towns of Tallaght in South Dublin and Dún Laoghaire in Dún Laoghaire–Rathdown have regional colleges:
Institute of Technology, Tallaght has full and part-time courses in a wide range of technical subjects and the Dún Laoghaire Institute of Art, Design and Technology (IADT) supports training and research in art, design, business, psychology and media technology.
The western suburb of Blanchardstown offers childcare and sports management courses along with languages and technical subjects at the Institute of Technology, Blanchardstown.

The City of Dublin is the area administered by Dublin City Council, but the term "Dublin" is also used to refer to the contiguous urban area which includes parts of the adjacent local authority areas of Dún Laoghaire–Rathdown, Fingal and South Dublin. Together, the four areas form the traditional County Dublin. This area is sometimes known as the Dublin Region. The population of the administrative area controlled by the City Council was 553,165 in the 2016 census, while the population of the urban area was 1,173,179. The County Dublin population was 1,273,069 and that of the Greater Dublin Area 1,904,806. The area's population is expanding rapidly, and it is estimated by the Central Statistics Office that it will reach 2.1 million by 2020.

After World War Two, Italians were by far the largest immigrant group in both Dublin and Ireland and became synonymous with the catering and restaurant landscape.Since the late 1990s, Dublin has experienced a significant level of net immigration, with the greatest numbers coming from the European Union, especially the United Kingdom, Poland and Lithuania. There is also immigration from outside Europe, including from Brazil, India, the Philippines, China and Nigeria. Dublin is home to a greater proportion of newer arrivals than any other part of the country. Sixty percent of Ireland's Asian population lives in Dublin. Over 15% of Dublin's population was foreign-born in 2006.

The capital attracts the largest proportion of non-Catholic migrants from other countries. Increased secularisation in Ireland has prompted a drop in regular Catholic church attendance in Dublin from over 90 percent in the mid-1970s down to 14 percent according to a 2011 survey.

According to the 2011 census, the population of Dublin was 90% white (including 400,749 white Irish [78%], 57,748 other white [11%] and 1,923 white Irish traveller), 1% black, and 4% Asian. In terms of religion, 75% identified as Catholic, 10% as other stated religions, with 14% having no religion or no religion stated.

Dublin has a significant literary history, and produced many literary figures, including Nobel laureates William Butler Yeats, George Bernard Shaw and Samuel Beckett. Other influential writers and playwrights include Oscar Wilde, Jonathan Swift and the creator of Dracula, Bram Stoker. It is also the location of key and notable works of James Joyce, including "Ulysses", which is set in Dublin and includes much topical detail. "Dubliners" is a collection of short stories by Joyce about incidents and typical characters of the city during the early 20th century. Other renowned writers include J. M. Synge, Seán O'Casey, Brendan Behan, Maeve Binchy, John Banville and Roddy Doyle. Ireland's biggest libraries and literary museums are found in Dublin, including the National Print Museum of Ireland and National Library of Ireland. In July 2010, Dublin was named as a UNESCO City of Literature, joining Edinburgh, Melbourne and Iowa City with the permanent title.

There are several theatres within the city centre, and various well-known actors have emerged from the Dublin theatrical scene, including Noel Purcell, Michael Gambon, Brendan Gleeson, Stephen Rea, Colin Farrell, Colm Meaney and Gabriel Byrne. The best known theatres include the Gaiety, Abbey, Olympia, Gate, and Grand Canal. The Gaiety specialises in musical and operatic productions, and also opens its doors after the evening theatre production to host a variety of live music, dancing, and films. The Abbey was founded in 1904 by a group that included Yeats with the aim of promoting indigenous literary talent. It went on to provide a breakthrough for some of the city's most famous writers, such as Synge, Yeats himself and George Bernard Shaw. The Gate was founded in 1928 to promote European and American Avant Garde works. The Grand Canal Theatre is a newer 2,111 capacity theatre which opened in 2010 in the Grand Canal Dock area.

Apart from being the focus of the country's literature and theatre, Dublin is also the focal point for much of Irish art and the Irish artistic scene. The Book of Kells, a world-famous manuscript produced by Celtic monks in AD 800 and an example of Insular art, is on display in Trinity College. The Chester Beatty Library houses a collection of manuscripts, miniature paintings, prints, drawings, rare books and decorative arts assembled by American mining millionaire (and honorary Irish citizen) Sir Alfred Chester Beatty (1875–1968). The collections date from 2700 BC onwards and are drawn from Asia, the Middle East, North Africa and Europe.
In addition public art galleries are found across the city, including the Irish Museum of Modern Art, the National Gallery, the Hugh Lane Municipal Gallery, the Douglas Hyde Gallery, the Project Arts Centre and the Royal Hibernian Academy. Some of the leading private galleries include Green on Red Gallery, Kerlin Gallery, Kevin Kavangh Gallery and Mother's Tankstation.

Three branches of the National Museum of Ireland are located in Dublin: Archaeology in Kildare Street, Decorative Arts and History in Collins Barracks and Natural History in Merrion Street. The same area is also home to a number of smaller museums such as Number 29 on Fitzwilliam Street and the Little Museum of Dublin on St. Stephen's Green. Dublin is home to the National College of Art and Design, which dates from 1746, and Dublin Institute of Design, founded in 1991. Dublinia is a living history attraction showcasing the Viking and Medieval history of the city.

Dublin has long had an 'underground' arts scene, with Temple Bar hosting artists in the 1980s, and spaces such as the Project Arts Centre acting as a hub for collectives and new exhibitions. "The Guardian" noted that Dublin's independent and underground arts flourished during the economic recession of c.2010. Dublin also has many dramatic, musical and operatic companies, including Festival Productions, Lyric Opera Productions, the Pioneers' Musical & Dramatic Society, the Glasnevin Musical Society, Second Age Theatre Company, Opera Theatre Company and Opera Ireland.

Dublin was shortlisted to be World Design Capital 2014. Taoiseach Enda Kenny was quoted to say that Dublin "would be an ideal candidate to host the World Design Capital in 2014".

Dublin has a vibrant nightlife and is reputedly one of Europe's most youthful cities, with an estimate of 50% of citizens being younger than 25. There are many pubs across the city centre, with the area around St. Stephen's Green and Grafton Street, especially Harcourt Street, Camden Street, Wexford Street and Leeson Street, the location of many nightclubs and pubs.

The best known area for nightlife is Temple Bar, south of the River Liffey. The area has become popular among tourists, including stag and hen parties from Britain. It was developed as Dublin's cultural quarter and does retain this spirit as a centre for small arts productions, photographic and artists' studios, and in the form of street performers and small music venues. However, it has been criticised as overpriced, false and dirty by Lonely Planet. The areas around Leeson Street, Harcourt Street, South William Street and Camden/George's Street are popular nightlife spots for locals.

Live music is popularly played on streets and at venues throughout Dublin, and the city has produced several musicians and groups of international success, including The Dubliners, Thin Lizzy, The Boomtown Rats, U2, The Script, Sinéad O'Connor, Boyzone, Kodaline and Westlife. The two best known cinemas in the city centre are the Savoy Cinema and the Cineworld Cinema, both north of the Liffey. Alternative and special-interest cinema can be found in the Irish Film Institute in Temple Bar and in the Light House Cinema in Smithfield. Large modern multiscreen cinemas are located across suburban Dublin. The 3Arena venue in the Dublin Docklands has played host to many world-renowned performers.

Dublin city centre is a popular shopping destination for both locals and tourists. The city has numerous shopping districts, particularly around Grafton Street and Henry Street. The city centre is also the location of large department stores, including Arnotts, Brown Thomas and (prior to its 2015 closure) Clerys.

The city retains a thriving market culture, despite new shopping developments and the loss of some traditional market sites. Amongst several historic locations, Moore Street remains one of the city's oldest trading districts. There has also been some growth in local farmers' markets and other markets. In 2007, Dublin Food Co-op relocated to a warehouse in The Liberties area, where it is home to market and community events. Suburban Dublin has several modern retail centres, including Dundrum Town Centre, Blanchardstown Centre, the Square in Tallaght, Liffey Valley Shopping Centre in Clondalkin, Omni Shopping Centre in Santry, Nutgrove Shopping Centre in Rathfarnham, and Swords Pavilions in Swords.

Dublin is the centre of both media and communications in Ireland, with many newspapers, radio stations, television stations and telephone companies based there. RTÉ is Ireland's national state broadcaster, and is based in Donnybrook. Fair City is RTÉ's soap opera, located in the fictional Dublin suburb of "Carraigstown". TV3 Media, UTV Ireland, Setanta Sports, MTV Ireland and Sky News are also based in the city. The headquarters of An Post and telecommunications companies such as Eir, as well as mobile operators Meteor, Vodafone and 3 are all located there. Dublin is also the headquarters of national newspapers such as "The Irish Times" and "Irish Independent", as well as local newspapers such as "The Evening Herald".

As well as being home to RTÉ Radio, Dublin also hosts the national radio networks Today FM and Newstalk, and local stations. Commercial radio stations based in the city include 4fm (94.9 MHz), Dublin's 98FM (98.1 MHz), Radio Nova 100FM (100.3 MHz), Q102 (102.2 MHz), SPIN 1038 (103.8 MHz), FM104 (104.4 MHz), Sunshine 106.8 (106.8 MHz). There are also numerous community and special interest stations, including Dublin City FM (103.2 MHz), Dublin South FM (93.9 MHz), Liffey Sound FM (96.4 MHz), Near FM (90.3 MHz), and Raidió na Life (106.4 MHz).

Croke Park is the largest sport stadium in Ireland. The headquarters of the Gaelic Athletic Association, it has a capacity of 82,300. It is the third-largest stadium in Europe after Nou Camp in Barcelona and Wembley Stadium in London. It hosts the premier Gaelic football and hurling games, international rules football and irregularly other sporting and non-sporting events including concerts. Muhammad Ali fought there in 1972 and it played host to the opening and closing ceremonies of the 2003 Special Olympics. It also has conference and banqueting facilities. There is a GAA Museum there and tours of the stadium are offered, including a rooftop walk of the stadium. During the redevelopment of Lansdowne Road, Croke Park played host to the Irish Rugby Union Team and Republic of Ireland national football team as well as hosting the Heineken Cup rugby 2008–09 semi-final between Munster and Leinster which set a world record attendance for a club rugby match. The Dublin GAA team plays most of their home league hurling games at Parnell Park.

I.R.F.U. Stadium Lansdowne Road was laid out in 1874. This was the venue for home games of both the Irish Rugby Union Team and the Republic of Ireland national football team. A joint venture between the Irish Rugby Football Union, the FAI and the Government, saw it redeveloped into a new state-of-the-art 50,000 seat Aviva Stadium, which opened in May 2010. Aviva Stadium hosted the 2011 UEFA Europa League Final. Rugby union team Leinster Rugby play their competitive home games in the RDS Arena & the Aviva Stadium while Donnybrook Stadium hosts their friendlies and A games, Ireland A and Women, Leinster Schools and Youths and the home club games of All Ireland League clubs Old Wesley and Bective Rangers. County Dublin is home for 13 of the senior rugby union clubs in Ireland including 5 of the 10 sides in the top division 1A.

County Dublin is home to six League of Ireland association clubs; Bohemian F.C., Shamrock Rovers, St Patrick's Athletic, University College Dublin, Shelbourne and Cabinteely. The first Irish side to reach the group stages of a European competition (2011–12 UEFA Europa League group stage) are Shamrock Rovers, who play at Tallaght Stadium in South Dublin. Bohemian F.C play at Dalymount Park, the oldest football stadium in the country, and home ground for the Ireland football team from 1904 to 1990. St Patrick's Athletic play at Richmond Park; University College Dublin at the UCD Bowl in Dún Laoghaire–Rathdown; and Shelbourne at Tolka Park. Tolka Park, Dalymount Park, UCD Bowl and Tallaght Stadium, along with the Carlisle Grounds in Bray, hosted all Group 3 games in the intermediary round of the 2011 UEFA Regions' Cup.

Dublin has two ODI Cricket grounds in Castle Avenue, Clontarf and Malahide Cricket Club. The Castle Avenue hosted its first one day international match on May 21, 1999 as part of the 1999 Cricket World Cup when Bangladesh played against the West Indies. College Park has Test status and played host to Ireland's only Test cricket match to date, a women's match against Pakistan in 2000.

The Dublin Marathon has been run since 1980 at the end of October, having been staged on the final Monday in October from 1980 to 2015, before moving to the final Sunday in 2016 and 2017. The Women's Mini Marathon has been run since 1983 on the first Monday in June, which is also a bank holiday in Ireland. It is said to be the largest all female event of its kind in the world.

The Dublin area hosts greyhound racing at Shelbourne Park and horse racing at Leopardstown. The Dublin Horse Show takes place at the RDS, which hosted the Show Jumping World Championships in 1982. The national boxing arena is located in The National Stadium on the South Circular Road. The National Basketball Arena is located in Tallaght, is the home of the Irish basketball team, the venue for the basketball league finals, and has also hosted boxing and wrestling events. The National Aquatic Centre in Blanchardstown is Ireland's largest indoor water leisure facility. There are also Gaelic Handball, hockey and athletics stadia, most notably Morton Stadium in Santry, which held the athletics events of the 2003 Special Olympics.

As of the 2018 Michelin Guide, five Dublin restaurants shared six Michelin stars - including Restaurant Patrick Guilbaud with two. Irish-born Kevin Thornton was awarded two Michelin stars in 2001 - though his restaurant, Thornton's, closed in 2016. The Dublin Institute of Technology commenced a bachelor's degree in culinary skills in 1999. .

Historically, Irish coffee house were associated with those working in media. Since the beginning of the 21st century, with the growth of apartment living in the city, Dublin's cafés attracted younger patrons looking for an informal gathering place and an ad hoc office. Cafés became more popular in the city, and Irish-owned coffee chains like Java Republic, Insomnia, and O'Brien's Sandwich Bars now compete internationally. In 2008, Irish barista Stephen Morrissey won the title of World Barista Champion.

There are 12,950 students in the Dublin region attending 34 gaelscoileanna (Irish-language primary schools) and 10 gaelcholáistí (Irish-language secondary schools). Two Irish language radio stations Raidió Na Life and RTÉ Raidió na Gaeltachta have studios in the city, and the online and DAB station Raidió Rí-Rá broadcasts from studios in the city. A number of Irish language agencies are also located in the capital. Conradh na Gaeilge offers language classes, has a book shop and is a meeting place for different groups. The closest Gaeltacht to Dublin is the County Meath Gaeltacht of Ráth Cairn and Baile Ghib which is away.

Dublin is twinned with the following places:
The city is also in talks to twin with Rio de Janeiro, and Mexican city Guadalajara.





</doc>
